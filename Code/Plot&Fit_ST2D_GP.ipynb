{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee5a7ebf",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55c0b871",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.optim import SGD\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from pytorch_lightning import Trainer\n",
    "import pytorch_lightning as pl\n",
    "import os\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import scipy\n",
    "from torchinfo import summary\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0073caf",
   "metadata": {},
   "source": [
    "# Import raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe717a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device with 1 threads\n"
     ]
    }
   ],
   "source": [
    "#Defining function to check if directory exists, if not it generates it\n",
    "def check_and_make_dir(dir):\n",
    "    if not os.path.isdir(dir):os.mkdir(dir)\n",
    "#Base directory \n",
    "base_dir = '/Users/samsonmercier/Desktop/Work/PhD/Research/Second_Generals/'\n",
    "#File containing surface temperature map\n",
    "raw_ST_data = np.loadtxt(base_dir+'Data/bt-4500k/training_data_ST2D.csv', delimiter=',')\n",
    "#Path to store model\n",
    "model_save_path = base_dir+'Model_Storage/GP_ST/'\n",
    "check_and_make_dir(model_save_path)\n",
    "#Path to store plots\n",
    "plot_save_path = base_dir+'Plots/GP_ST/'\n",
    "check_and_make_dir(plot_save_path)\n",
    "\n",
    "#Last 51 columns are the temperature/pressure values, \n",
    "#First 5 are the input values (H2 pressure in bar, CO2 pressure in bar, LoD in hours, Obliquity in deg, H2+Co2 pressure) but we remove the last one since it's not adding info.\n",
    "raw_inputs = raw_ST_data[:, :4] #has shape 46 x 72 = 3,312\n",
    "raw_outputs = raw_ST_data[:, 5:]\n",
    "\n",
    "#Storing useful quantitites\n",
    "N = raw_inputs.shape[0] #Number of data points\n",
    "D = raw_inputs.shape[1] #Number of features\n",
    "O = raw_outputs.shape[1] #Number of outputs\n",
    "\n",
    "## HYPER-PARAMETERS ##\n",
    "#Defining partition of data used for 1. training and 2. testing\n",
    "data_partition = [0.8, 0.2]\n",
    "\n",
    "#Definine sub-partitiion for splitting NN dataset\n",
    "sub_data_partitions = [0.7, 0.1, 0.2]\n",
    "\n",
    "#Defining the device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_threads = 1\n",
    "torch.set_num_threads(num_threads)\n",
    "print(f\"Using {device} device with {num_threads} threads\")\n",
    "torch.set_default_device(device)\n",
    "\n",
    "#Defining the noise seed for the random partitioning of the training data\n",
    "partition_seed = 4\n",
    "rng = torch.Generator(device=device)\n",
    "rng.manual_seed(partition_seed)\n",
    "\n",
    "# Variable to show plots or not \n",
    "show_plot = False\n",
    "\n",
    "#Number of nearest neighbors to choose\n",
    "N_neigbors = 500\n",
    "\n",
    "#Optimizer learning rate\n",
    "learning_rate = 1e-5\n",
    "\n",
    "#Batch size \n",
    "batch_size = 64\n",
    "\n",
    "#Number of epochs \n",
    "n_epochs = 10\n",
    "\n",
    "#Define storage for losses\n",
    "train_losses = []\n",
    "eval_losses = []\n",
    "\n",
    "#Mode for optimization\n",
    "run_mode = 'use'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91916a9",
   "metadata": {},
   "source": [
    "# Plotting of the surface temperature map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74b0ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for raw_input, raw_output in zip(raw_inputs,raw_outputs):\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize=[8, 6])\n",
    "    \n",
    "    hm = sns.heatmap(raw_output.reshape((46, 72)), ax=ax)\n",
    "    cbar = hm.collections[0].colorbar\n",
    "    cbar.set_label('Temperature (K)')\n",
    "\n",
    "    # Fix longitude ticks\n",
    "    ax.set_xticks(np.linspace(0, 72, 5))\n",
    "    ax.set_xticklabels(np.linspace(-180, 180, 5).astype(int))\n",
    "\n",
    "    # Fix latitude ticks\n",
    "    ax.set_yticks(np.linspace(0, 46, 5))\n",
    "    ax.set_yticklabels(np.linspace(-90, 90, 5).astype(int))\n",
    "\n",
    "    ax.set_xlabel('Longitude (degrees)')\n",
    "    ax.set_ylabel('Latitude (degrees)')\n",
    "    plt.suptitle(rf'H$_2$ : {raw_input[0]} bar, CO$_2$ : {raw_input[1]} bar, LoD : {raw_input[2]:.0f} days, Obliquity : {raw_input[3]} deg')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d894c0",
   "metadata": {},
   "source": [
    "# Fitting data with an Ensemble Conditional GP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad32a1a",
   "metadata": {},
   "source": [
    "## First step : partition data into a training set, and a testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5b6afd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieving indices of data partitions\n",
    "train_idx, test_idx = torch.utils.data.random_split(range(N), data_partition, generator=rng)\n",
    "## Generate the data partitions\n",
    "### Training\n",
    "train_inputs = raw_inputs[train_idx]\n",
    "train_outputs = raw_outputs[train_idx]\n",
    "\n",
    "### Testing\n",
    "test_inputs = raw_inputs[test_idx]\n",
    "test_outputs = raw_outputs[test_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31f11a3",
   "metadata": {},
   "source": [
    "## Second step : Building Sai's Conditional GP function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e8ccf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sai_CGP(obs_features, obs_labels, query_features):\n",
    "    \"\"\"\n",
    "    Conditional Gaussian Process\n",
    "    Inputs: \n",
    "        obs_features : ndarray (D, N)\n",
    "            D-dimensional features of the N observation data points.\n",
    "        obs_labels : ndarray (K, N)\n",
    "            K-dimensional labels of the N observation data points.\n",
    "        query_features : ndarray (D, 1)\n",
    "            D-dimensional features of the query data point.\n",
    "    Outputs:\n",
    "        query_labels : ndarray (K, 1)\n",
    "            K-dimensional labels of the query data point.\n",
    "\n",
    "    \"\"\"\n",
    "    # Defining relevant means\n",
    "    mean_obs_labels = np.mean(obs_labels, axis=1, keepdims=True)\n",
    "    mean_obs_features = np.mean(obs_features, axis=1, keepdims=True)\n",
    "    \n",
    "    # Defining relevant covariance matrices\n",
    "    ## Between feature and label of observation data\n",
    "    Cyx = (obs_labels @ obs_features.T) / (obs_features.shape[0] - 1)\n",
    "    ## Between label and feature of observation data\n",
    "    Cxy = (obs_features @ obs_labels.T) / (obs_features.shape[0] - 1)\n",
    "    ## Between feature and feature of observation data\n",
    "    Cxx = (obs_features @ obs_features.T) / (obs_features.shape[0] - 1)\n",
    "    ## Between label and label of observation data\n",
    "    Cyy = (obs_labels @ obs_labels.T) / (obs_features.shape[0] - 1)\n",
    "    ## Adding regularizer to avoid singularities\n",
    "    Cxx += 1e-8 * np.eye(Cxx.shape[0]) \n",
    "\n",
    "    query_mean_labels = mean_obs_labels + (Cyx @ scipy.linalg.inv(Cxx) @ (query_features - mean_obs_features))\n",
    "\n",
    "    query_cov_labels = Cyy - Cyx @ scipy.linalg.inv(Cxx) @ Cxy\n",
    "\n",
    "    return query_mean_labels, query_cov_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e19df2",
   "metadata": {},
   "source": [
    "## Third step : Going through test set (query points), find observations in proximity, and use them to get guess labels for query point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65772b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize array to store residuals\n",
    "res = np.zeros(test_outputs.shape, dtype=float)\n",
    "\n",
    "for query_idx, (test_input, test_output) in enumerate(zip(test_inputs, test_outputs)):\n",
    "\n",
    "    #Calculate proximity of query point to observations\n",
    "    distances = np.sqrt( (test_input[0] - train_inputs[:,0])**2 + (test_input[1] - train_inputs[:,1])**2 + (test_input[2] - train_inputs[:,2])**2 + (test_input[3] - train_inputs[:,3])**2 )\n",
    "\n",
    "    #Choose the N closest points\n",
    "    N_closest_idx = np.argsort(distances)[:N_neigbors]\n",
    "    prox_train_inputs = train_inputs[N_closest_idx, :]\n",
    "    prox_train_outputs = train_outputs[N_closest_idx, :]\n",
    "    \n",
    "    #Find the query labels from nearest neigbours\n",
    "    mean_test_output, cov_test_output = Sai_CGP(prox_train_inputs.T, prox_train_outputs.T, test_input.reshape((1, 4)).T)\n",
    "    model_test_output = mean_test_output[:,0] \n",
    "    model_test_output_err = np.sqrt(np.diag(cov_test_output))\n",
    "    res[query_idx, :] = model_test_output - test_output\n",
    "\n",
    "    #Diagnostic plot\n",
    "    if show_plot:\n",
    "\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.imshow(cov_test_output, cmap='coolwarm', origin='lower')\n",
    "        plt.colorbar(label='Covariance')\n",
    "        plt.title('Joint Covariance Matrix')\n",
    "        plt.xlabel('Output index')\n",
    "        plt.ylabel('Output index')\n",
    "        plt.show()\n",
    "\n",
    "        #Convert shape\n",
    "        plot_test_output = test_output.reshape((46, 72))\n",
    "        plot_model_test_output = mean_test_output.reshape((46, 72))\n",
    "        plot_res = res[query_idx, :].reshape((46, 72))\n",
    "        \n",
    "        fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(8, 8), sharex=True, layout='constrained')        \n",
    "        # Compute global vmin/vmax across all datasets\n",
    "        vmin = np.min(test_output)\n",
    "        vmax = np.max(test_output)\n",
    "        # Plot heatmaps\n",
    "        ax1.set_title('Data')\n",
    "        hm1 = sns.heatmap(plot_test_output, ax=ax1)#, cbar=False, vmin=vmin, vmax=vmax)\n",
    "        cbar = hm1.collections[0].colorbar\n",
    "        cbar.set_label('Temperature (K)')\n",
    "        ax2.set_title('Model')\n",
    "        hm2 = sns.heatmap(plot_model_test_output, ax=ax2)#, cbar=False, vmin=vmin, vmax=vmax)\n",
    "        cbar = hm2.collections[0].colorbar\n",
    "        cbar.set_label('Temperature (K)')\n",
    "        ax3.set_title('Residuals')\n",
    "        hm3 = sns.heatmap(plot_res, ax=ax3)#, cbar=False, vmin=vmin, vmax=vmax)\n",
    "        cbar = hm3.collections[0].colorbar\n",
    "        cbar.set_label('Temperature (K)')\n",
    "        # Shared colorbar (use the last heatmap's mappable)\n",
    "        # cbar = fig.colorbar(hm3.get_children()[0], ax=[ax1, ax2, ax3], location='right')\n",
    "        # cbar.set_label(\"Temperature\")\n",
    "        # Fix longitude ticks\n",
    "        ax3.set_xticks(np.linspace(0, 72, 5))\n",
    "        ax3.set_xticklabels(np.linspace(-180, 180, 5).astype(int))\n",
    "        ax3.set_xlabel('Longitude (degrees)')\n",
    "        # Fix latitude ticks\n",
    "        for ax in [ax1, ax2, ax3]:\n",
    "            ax.set_yticks(np.linspace(0, 46, 5))\n",
    "            ax.set_yticklabels(np.linspace(-90, 90, 5).astype(int))\n",
    "            ax.set_ylabel('Latitude (degrees)')\n",
    "        plt.suptitle(rf'H$_2$ : {test_input[0]} bar, CO$_2$ : {test_input[1]} bar, LoD : {test_input[2]:.0f} days, Obliquity : {test_input[3]} deg')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468b66de",
   "metadata": {},
   "source": [
    "# Fourth step : Build a encoder-decoder NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42b59b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    \"\"\"Encoder-Decoder architecture for 46x72 image prediction\"\"\"\n",
    "    def __init__(self, in_channels=1, out_channels=1):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.enc1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)  # 46x72 -> 23x36\n",
    "        \n",
    "        self.enc2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)  # 23x36 -> 11x18\n",
    "        \n",
    "        self.enc3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Decoder\n",
    "        self.up1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)  # 11x18 -> 22x36\n",
    "        self.dec1 = nn.Sequential(\n",
    "            nn.Conv2d(128, 64, kernel_size=3, padding=1),  # 128 = 64 (from up1) + 64 (skip)\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.up2 = nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2)  # 22x36 -> 44x72\n",
    "        self.dec2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 32, kernel_size=3, padding=1),  # 64 = 32 (from up2) + 32 (skip)\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Final adjustment to get exact 46x72\n",
    "        self.final_up = nn.ConvTranspose2d(32, 32, kernel_size=(3, 1), stride=1, padding=(0, 0))\n",
    "        self.final_conv = nn.Conv2d(32, out_channels, kernel_size=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Encoder with skip connections\n",
    "        e1 = self.enc1(x)\n",
    "        p1 = self.pool1(e1)\n",
    "        \n",
    "        e2 = self.enc2(p1)\n",
    "        p2 = self.pool2(e2)\n",
    "        \n",
    "        e3 = self.enc3(p2)\n",
    "        \n",
    "        # Decoder with skip connections\n",
    "        d1 = self.up1(e3)\n",
    "        d1 = torch.cat([d1, e2[:, :, :d1.size(2), :]], dim=1)  # Crop e2 if needed\n",
    "        d1 = self.dec1(d1)\n",
    "        \n",
    "        d2 = self.up2(d1)\n",
    "        d2 = torch.cat([d2, e1[:, :, :d2.size(2), :]], dim=1)  # Crop e1 if needed\n",
    "        d2 = self.dec2(d2)\n",
    "        \n",
    "        # Final adjustment to 46x72\n",
    "        d2 = self.final_up(d2)\n",
    "        output = self.final_conv(d2)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "class CustomDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, train_inputs, train_outputs, valid_inputs, valid_outputs, \n",
    "                 test_inputs, test_outputs, batch_size, rng, reshape_for_cnn=False, \n",
    "                 img_channels=1, img_height=None, img_width=None,\n",
    "                 output_channels=None, output_height=None, output_width=None):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.rng = rng\n",
    "        self.reshape_for_cnn = reshape_for_cnn\n",
    "        self.img_channels = img_channels\n",
    "        self.img_height = img_height\n",
    "        self.img_width = img_width\n",
    "        \n",
    "        # Reshape data if needed for CNN\n",
    "        if reshape_for_cnn:\n",
    "            # Reshape inputs\n",
    "            if img_height is None or img_width is None:\n",
    "                # Auto-calculate square dimensions if not provided\n",
    "                total_features = train_inputs.shape[1]\n",
    "                img_size = int(np.sqrt(total_features / img_channels))\n",
    "                if img_size * img_size * img_channels != total_features:\n",
    "                    raise ValueError(f\"Cannot reshape {total_features} features into square image. \"\n",
    "                                     f\"Please provide img_height and img_width explicitly.\")\n",
    "                self.img_height = img_size\n",
    "                self.img_width = img_size\n",
    "            \n",
    "            self.train_inputs = train_inputs.reshape(-1, img_channels, self.img_height, self.img_width)\n",
    "            self.valid_inputs = valid_inputs.reshape(-1, img_channels, self.img_height, self.img_width)\n",
    "            self.test_inputs = test_inputs.reshape(-1, img_channels, self.img_height, self.img_width)\n",
    "            \n",
    "            self.train_outputs = train_outputs.reshape(-1, img_channels, self.img_height, self.img_width)\n",
    "            self.valid_outputs = valid_outputs.reshape(-1, img_channels, self.img_height, self.img_width)\n",
    "            self.test_outputs = test_outputs.reshape(-1, img_channels, self.img_height, self.img_width)\n",
    "\n",
    "        else:\n",
    "            self.train_inputs = train_inputs\n",
    "            self.valid_inputs = valid_inputs\n",
    "            self.test_inputs = test_inputs\n",
    "            self.train_outputs = train_outputs\n",
    "            self.valid_outputs = valid_outputs\n",
    "            self.test_outputs = test_outputs\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        dataset = TensorDataset(self.train_inputs, self.train_outputs)\n",
    "        return DataLoader(dataset, batch_size=self.batch_size, shuffle=True, generator=self.rng)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        dataset = TensorDataset(self.valid_inputs, self.valid_outputs)\n",
    "        return DataLoader(dataset, batch_size=self.batch_size, generator=self.rng)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        dataset = TensorDataset(self.test_inputs, self.test_outputs)\n",
    "        return DataLoader(dataset, batch_size=self.batch_size, generator=self.rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70380314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "EncoderDecoder                           --\n",
       "â”œâ”€Sequential: 1-1                        --\n",
       "â”‚    â””â”€Conv2d: 2-1                       320\n",
       "â”‚    â””â”€ReLU: 2-2                         --\n",
       "â”‚    â””â”€Conv2d: 2-3                       9,248\n",
       "â”‚    â””â”€ReLU: 2-4                         --\n",
       "â”œâ”€MaxPool2d: 1-2                         --\n",
       "â”œâ”€Sequential: 1-3                        --\n",
       "â”‚    â””â”€Conv2d: 2-5                       18,496\n",
       "â”‚    â””â”€ReLU: 2-6                         --\n",
       "â”‚    â””â”€Conv2d: 2-7                       36,928\n",
       "â”‚    â””â”€ReLU: 2-8                         --\n",
       "â”œâ”€MaxPool2d: 1-4                         --\n",
       "â”œâ”€Sequential: 1-5                        --\n",
       "â”‚    â””â”€Conv2d: 2-9                       73,856\n",
       "â”‚    â””â”€ReLU: 2-10                        --\n",
       "â”‚    â””â”€Conv2d: 2-11                      147,584\n",
       "â”‚    â””â”€ReLU: 2-12                        --\n",
       "â”œâ”€ConvTranspose2d: 1-6                   32,832\n",
       "â”œâ”€Sequential: 1-7                        --\n",
       "â”‚    â””â”€Conv2d: 2-13                      73,792\n",
       "â”‚    â””â”€ReLU: 2-14                        --\n",
       "â”‚    â””â”€Conv2d: 2-15                      36,928\n",
       "â”‚    â””â”€ReLU: 2-16                        --\n",
       "â”œâ”€ConvTranspose2d: 1-8                   8,224\n",
       "â”œâ”€Sequential: 1-9                        --\n",
       "â”‚    â””â”€Conv2d: 2-17                      18,464\n",
       "â”‚    â””â”€ReLU: 2-18                        --\n",
       "â”‚    â””â”€Conv2d: 2-19                      9,248\n",
       "â”‚    â””â”€ReLU: 2-20                        --\n",
       "â”œâ”€ConvTranspose2d: 1-10                  3,104\n",
       "â”œâ”€Conv2d: 1-11                           33\n",
       "=================================================================\n",
       "Total params: 469,057\n",
       "Trainable params: 469,057\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = EncoderDecoder().to(device)\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2228ee6b",
   "metadata": {},
   "source": [
    "# Fifth step : Build training dataset for NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a667161a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize array to store residuals\n",
    "train_NN_inputs = np.zeros(train_outputs.shape, dtype=float)\n",
    "\n",
    "for query_idx, (query_input, query_output) in enumerate(zip(train_inputs, train_outputs)):\n",
    "\n",
    "    #Calculate proximity of query point to observations\n",
    "    distances = np.sqrt( (query_input[0] - train_inputs[:,0])**2 + (query_input[1] - train_inputs[:,1])**2 + (query_input[2] - train_inputs[:,2])**2 + (query_input[3] - train_inputs[:,3])**2 )\n",
    "\n",
    "    #Choose the N closest points\n",
    "    N_closest_idx = np.argsort(distances)[:N_neigbors]\n",
    "    prox_train_inputs = train_inputs[N_closest_idx, :]\n",
    "    prox_train_outputs = train_outputs[N_closest_idx, :]\n",
    "    \n",
    "    #Find the query labels from nearest neigbours\n",
    "    mean_test_output, cov_test_output = Sai_CGP(prox_train_inputs.T, prox_train_outputs.T, query_input.reshape((1, 4)).T)\n",
    "    model_test_output = mean_test_output[:,0] \n",
    "    model_test_output_err = np.sqrt(np.diag(cov_test_output))\n",
    "    train_NN_inputs[query_idx, :] = model_test_output\n",
    "\n",
    "    #Diagnostic plot\n",
    "    if show_plot:\n",
    "\n",
    "        #Convert shape\n",
    "        plot_test_output = test_output.reshape((46, 72))\n",
    "        plot_model_test_output = mean_test_output.reshape((46, 72))\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(8, 8), sharex=True, layout='constrained')        \n",
    "        # Compute global vmin/vmax across all datasets\n",
    "        vmin = np.min(test_output)\n",
    "        vmax = np.max(test_output)\n",
    "        \n",
    "        # Plot heatmaps\n",
    "        ax1.set_title('Data')\n",
    "        hm1 = sns.heatmap(plot_test_output, ax=ax1)\n",
    "        cbar = hm1.collections[0].colorbar\n",
    "        cbar.set_label('Temperature (K)')\n",
    "        ax2.set_title('Model')\n",
    "        hm2 = sns.heatmap(plot_model_test_output, ax=ax2)\n",
    "        cbar = hm2.collections[0].colorbar\n",
    "        cbar.set_label('Temperature (K)')\n",
    "\n",
    "        ax2.set_xticks(np.linspace(0, 72, 5))\n",
    "        ax2.set_xticklabels(np.linspace(-180, 180, 5).astype(int))\n",
    "        ax2.set_xlabel('Longitude (degrees)')\n",
    "        \n",
    "        # Fix latitude ticks\n",
    "        for ax in [ax1, ax2]:\n",
    "            ax.set_yticks(np.linspace(0, 46, 5))\n",
    "            ax.set_yticklabels(np.linspace(-90, 90, 5).astype(int))\n",
    "            ax.set_ylabel('Latitude (degrees)')\n",
    "        plt.suptitle(rf'H$_2$O : {query_input[0]} bar, CO$_2$ : {query_input[1]} bar, LoD : {query_input[2]:.0f} days, Obliquity : {query_input[3]} deg')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e0c5b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training dataset into training, validation, and testing, and format it correctly\n",
    "\n",
    "## Retrieving indices of data partitions\n",
    "train_idx, valid_idx, test_idx = torch.utils.data.random_split(range(train_inputs.shape[0]), sub_data_partitions, generator=rng)\n",
    "\n",
    "## Generate the data partitions\n",
    "### Training\n",
    "NN_train_inputs = torch.tensor(train_NN_inputs[train_idx], dtype=torch.float32)\n",
    "NN_train_outputs = torch.tensor(train_outputs[train_idx], dtype=torch.float32)\n",
    "### Validation\n",
    "NN_valid_inputs = torch.tensor(train_NN_inputs[valid_idx], dtype=torch.float32)\n",
    "NN_valid_outputs = torch.tensor(train_outputs[valid_idx], dtype=torch.float32)\n",
    "### Testing\n",
    "NN_test_og_inputs = torch.tensor(train_inputs[test_idx], dtype=torch.float32) \n",
    "NN_test_inputs = torch.tensor(train_NN_inputs[test_idx], dtype=torch.float32)\n",
    "NN_test_outputs = torch.tensor(train_outputs[test_idx], dtype=torch.float32)\n",
    "\n",
    "# Create DataModule\n",
    "data_module = CustomDataModule(\n",
    "    NN_train_inputs, NN_train_outputs,\n",
    "    NN_valid_inputs, NN_valid_outputs,\n",
    "    NN_test_inputs, NN_test_outputs,\n",
    "    batch_size, rng, reshape_for_cnn=True,\n",
    "    img_channels=1, img_height=46, img_width=72\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28dbf238",
   "metadata": {},
   "source": [
    "# Sixth step : Define optimization block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3efd13ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch Lightning Module\n",
    "class RegressionModule(pl.LightningModule):\n",
    "    def __init__(self, model, optimizer, learning_rate):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.learning_rate = learning_rate\n",
    "        self.loss_fn = nn.MSELoss()\n",
    "        self.optimizer_class = optimizer\n",
    "        \n",
    "        # Store losses\n",
    "        self.train_losses = []\n",
    "        self.eval_losses = []\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        X, y = batch\n",
    "        pred = self(X)\n",
    "        loss = self.loss_fn(pred, y)\n",
    "        \n",
    "        # Log metrics\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        X, y = batch\n",
    "        pred = self(X)\n",
    "        loss = self.loss_fn(pred, y)\n",
    "        \n",
    "        # Log metrics\n",
    "        self.log('valid_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return self.optimizer_class(self.model.parameters(), lr=self.learning_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18beb94",
   "metadata": {},
   "source": [
    "# Seventh step : Run optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e753fb05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name    | Type           | Params | Mode \n",
      "---------------------------------------------------\n",
      "0 | model   | EncoderDecoder | 469 K  | train\n",
      "1 | loss_fn | MSELoss        | 0      | train\n",
      "---------------------------------------------------\n",
      "469 K     Trainable params\n",
      "0         Non-trainable params\n",
      "469 K     Total params\n",
      "1.876     Total estimated model params size (MB)\n",
      "33        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samsonmercier/anaconda3/envs/MLenv/lib/python3.13/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samsonmercier/anaconda3/envs/MLenv/lib/python3.13/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:04<00:00, 18.85it/s, v_num=4, train_loss_step=nan.0, valid_loss=nan.0, train_loss_epoch=nan.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:04<00:00, 18.81it/s, v_num=4, train_loss_step=nan.0, valid_loss=nan.0, train_loss_epoch=nan.0]\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Create Lightning Module\n",
    "lightning_module = RegressionModule(\n",
    "    model=model,\n",
    "    optimizer=SGD,\n",
    "    learning_rate=learning_rate\n",
    ")\n",
    "\n",
    "# Setup logger\n",
    "logger = CSVLogger(model_save_path+'logs', name='NeuralNetwork')\n",
    "\n",
    "if run_mode == 'use':\n",
    "    # Create Trainer and train\n",
    "    trainer = Trainer(\n",
    "        max_epochs=n_epochs,\n",
    "        logger=logger,\n",
    "        deterministic=True  # For reproducibility\n",
    "    )\n",
    "    \n",
    "    trainer.fit(lightning_module, datamodule=data_module)\n",
    "    \n",
    "    # Save model (PyTorch Lightning style)\n",
    "    trainer.save_checkpoint(model_save_path + f'{n_epochs}epochs_{learning_rate}LR_{batch_size}BS.ckpt')\n",
    "    \n",
    "    print(\"Done!\")\n",
    "    \n",
    "else:\n",
    "    # Load model\n",
    "    lightning_module = RegressionModule.load_from_checkpoint(\n",
    "        model_save_path + f'{n_epochs}epochs_{learning_rate}LR_{batch_size}BS.ckpt',\n",
    "        model=model,\n",
    "        optimizer=SGD,\n",
    "        learning_rate=learning_rate\n",
    "    )\n",
    "    print(\"Model loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec704607",
   "metadata": {},
   "outputs": [
    {
     "ename": "MisconfigurationException",
     "evalue": "No `test_step()` method defined to run `Trainer.test`.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMisconfigurationException\u001b[39m                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#Testing model on test dataset\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlightning_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_module\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/MLenv/lib/python3.13/site-packages/pytorch_lightning/trainer/trainer.py:774\u001b[39m, in \u001b[36mTrainer.test\u001b[39m\u001b[34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[39m\n\u001b[32m    772\u001b[39m \u001b[38;5;28mself\u001b[39m.state.status = TrainerStatus.RUNNING\n\u001b[32m    773\u001b[39m \u001b[38;5;28mself\u001b[39m.testing = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m774\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    775\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_test_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\n\u001b[32m    776\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/MLenv/lib/python3.13/site-packages/pytorch_lightning/trainer/call.py:49\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m trainer.strategy.launcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     48\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[32m     52\u001b[39m     _call_teardown_hook(trainer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/MLenv/lib/python3.13/site-packages/pytorch_lightning/trainer/trainer.py:816\u001b[39m, in \u001b[36mTrainer._test_impl\u001b[39m\u001b[34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[39m\n\u001b[32m    812\u001b[39m     download_model_from_registry(ckpt_path, \u001b[38;5;28mself\u001b[39m)\n\u001b[32m    813\u001b[39m ckpt_path = \u001b[38;5;28mself\u001b[39m._checkpoint_connector._select_ckpt_path(\n\u001b[32m    814\u001b[39m     \u001b[38;5;28mself\u001b[39m.state.fn, ckpt_path, model_provided=model_provided, model_connected=\u001b[38;5;28mself\u001b[39m.lightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    815\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m816\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    817\u001b[39m \u001b[38;5;66;03m# remove the tensors from the test results\u001b[39;00m\n\u001b[32m    818\u001b[39m results = convert_tensors_to_scalars(results)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/MLenv/lib/python3.13/site-packages/pytorch_lightning/trainer/trainer.py:961\u001b[39m, in \u001b[36mTrainer._run\u001b[39m\u001b[34m(self, model, ckpt_path)\u001b[39m\n\u001b[32m    958\u001b[39m \u001b[38;5;28mself\u001b[39m._callback_connector._attach_model_callbacks()\n\u001b[32m    959\u001b[39m \u001b[38;5;28mself\u001b[39m._callback_connector._attach_model_logging_functions()\n\u001b[32m--> \u001b[39m\u001b[32m961\u001b[39m \u001b[43m_verify_loop_configurations\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m    964\u001b[39m \u001b[38;5;66;03m# SET UP THE TRAINER\u001b[39;00m\n\u001b[32m    965\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m    966\u001b[39m log.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: setting up strategy environment\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/MLenv/lib/python3.13/site-packages/pytorch_lightning/trainer/configuration_validator.py:41\u001b[39m, in \u001b[36m_verify_loop_configurations\u001b[39m\u001b[34m(trainer)\u001b[39m\n\u001b[32m     39\u001b[39m     __verify_eval_loop_configuration(model, \u001b[33m\"\u001b[39m\u001b[33mval\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m trainer.state.fn == TrainerFn.TESTING:\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     \u001b[43m__verify_eval_loop_configuration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtest\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m trainer.state.fn == TrainerFn.PREDICTING:\n\u001b[32m     43\u001b[39m     __verify_eval_loop_configuration(model, \u001b[33m\"\u001b[39m\u001b[33mpredict\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/MLenv/lib/python3.13/site-packages/pytorch_lightning/trainer/configuration_validator.py:106\u001b[39m, in \u001b[36m__verify_eval_loop_configuration\u001b[39m\u001b[34m(model, stage)\u001b[39m\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_step:\n\u001b[32m    105\u001b[39m     trainer_method = \u001b[33m\"\u001b[39m\u001b[33mvalidate\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stage == \u001b[33m\"\u001b[39m\u001b[33mval\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m stage\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MisconfigurationException(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNo `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m()` method defined to run `Trainer.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer_method\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m`.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    108\u001b[39m \u001b[38;5;66;03m# check legacy hooks are not present\u001b[39;00m\n\u001b[32m    109\u001b[39m epoch_end_name = \u001b[33m\"\u001b[39m\u001b[33mvalidation_epoch_end\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stage == \u001b[33m\"\u001b[39m\u001b[33mval\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mtest_epoch_end\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mMisconfigurationException\u001b[39m: No `test_step()` method defined to run `Trainer.test`."
     ]
    }
   ],
   "source": [
    "#Testing model on test dataset\n",
    "trainer.test(lightning_module, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efd5ca29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   epoch  step  train_loss_epoch  train_loss_step  valid_loss\n",
      "0      0    49               NaN              NaN         NaN\n",
      "1      0    87               NaN              NaN         NaN\n",
      "2      0    87               NaN              NaN         NaN\n",
      "3      1    99               NaN              NaN         NaN\n",
      "4      1   149               NaN              NaN         NaN\n"
     ]
    }
   ],
   "source": [
    "# --- Accessing Training History After Training ---\n",
    "\n",
    "# Find the version directory (e.g., version_0, version_1, etc.)\n",
    "log_dir = model_save_path+'logs/NeuralNetwork'\n",
    "versions = [d for d in os.listdir(log_dir) if d.startswith('version_')]\n",
    "latest_version = sorted(versions)[-1]  # Get the latest version\n",
    "csv_path = os.path.join(log_dir, latest_version, 'metrics.csv')\n",
    "\n",
    "# Read the metrics\n",
    "metrics_df = pd.read_csv(csv_path)\n",
    "print(metrics_df.head())\n",
    "\n",
    "# Extract losses per epoch\n",
    "train_losses = metrics_df[metrics_df['train_loss_epoch'].notna()]['train_loss_epoch'].tolist()\n",
    "eval_losses = metrics_df[metrics_df['valid_loss'].notna()]['valid_loss'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678d2b28",
   "metadata": {},
   "source": [
    "# Eigth step : Diagnostic plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c363214",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (50,) and (0,)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Loss curves\u001b[39;00m\n\u001b[32m      2\u001b[39m fig, (ax1, ax2) = plt.subplots(\u001b[32m2\u001b[39m, \u001b[32m1\u001b[39m, sharex=\u001b[38;5;28;01mTrue\u001b[39;00m, gridspec_kw={\u001b[33m'\u001b[39m\u001b[33mheight_ratios\u001b[39m\u001b[33m'\u001b[39m:[\u001b[32m3\u001b[39m, \u001b[32m1\u001b[39m]}, figsize=(\u001b[32m10\u001b[39m, \u001b[32m6\u001b[39m))\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43max1\u001b[49m\u001b[43m.\u001b[49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_losses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mTrain\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m ax1.plot(np.arange(n_epochs), eval_losses, label=\u001b[33m\"\u001b[39m\u001b[33mValidation\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m ax2.plot(np.arange(n_epochs), np.array(train_losses) - np.array(eval_losses), label=\u001b[33m\"\u001b[39m\u001b[33mTrain\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/MLenv/lib/python3.13/site-packages/matplotlib/axes/_axes.py:1777\u001b[39m, in \u001b[36mAxes.plot\u001b[39m\u001b[34m(self, scalex, scaley, data, *args, **kwargs)\u001b[39m\n\u001b[32m   1534\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1535\u001b[39m \u001b[33;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[32m   1536\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1774\u001b[39m \u001b[33;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[32m   1775\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1776\u001b[39m kwargs = cbook.normalize_kwargs(kwargs, mlines.Line2D)\n\u001b[32m-> \u001b[39m\u001b[32m1777\u001b[39m lines = [*\u001b[38;5;28mself\u001b[39m._get_lines(\u001b[38;5;28mself\u001b[39m, *args, data=data, **kwargs)]\n\u001b[32m   1778\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[32m   1779\u001b[39m     \u001b[38;5;28mself\u001b[39m.add_line(line)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/MLenv/lib/python3.13/site-packages/matplotlib/axes/_base.py:297\u001b[39m, in \u001b[36m_process_plot_var_args.__call__\u001b[39m\u001b[34m(self, axes, data, return_kwargs, *args, **kwargs)\u001b[39m\n\u001b[32m    295\u001b[39m     this += args[\u001b[32m0\u001b[39m],\n\u001b[32m    296\u001b[39m     args = args[\u001b[32m1\u001b[39m:]\n\u001b[32m--> \u001b[39m\u001b[32m297\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m=\u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_kwargs\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/MLenv/lib/python3.13/site-packages/matplotlib/axes/_base.py:494\u001b[39m, in \u001b[36m_process_plot_var_args._plot_args\u001b[39m\u001b[34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[39m\n\u001b[32m    491\u001b[39m     axes.yaxis.update_units(y)\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x.shape[\u001b[32m0\u001b[39m] != y.shape[\u001b[32m0\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m494\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mx and y must have same first dimension, but \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    495\u001b[39m                      \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    496\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x.ndim > \u001b[32m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y.ndim > \u001b[32m2\u001b[39m:\n\u001b[32m    497\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mx and y can be no greater than 2D, but have \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    498\u001b[39m                      \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: x and y must have same first dimension, but have shapes (50,) and (0,)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loss curves\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, gridspec_kw={'height_ratios':[3, 1]}, figsize=(10, 6))\n",
    "ax1.plot(np.arange(n_epochs), train_losses, label=\"Train\")\n",
    "ax1.plot(np.arange(n_epochs), eval_losses, label=\"Validation\")\n",
    "ax2.plot(np.arange(n_epochs), np.array(train_losses) - np.array(eval_losses), label=\"Train\")\n",
    "ax1.set_yscale('log')\n",
    "ax2.set_yscale('log')\n",
    "ax2.set_xlabel(\"Epoch\")\n",
    "ax1.set_ylabel(\"MSE Loss\")\n",
    "ax2.set_ylabel(\"Loss Diff.\")\n",
    "ax1.legend()\n",
    "ax1.grid()\n",
    "plt.subplots_adjust(hspace=0)\n",
    "plt.savefig(plot_save_path+'/loss.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c72d7d28",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [3312]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m      9\u001b[39m NN_res = np.zeros(NN_test_outputs.shape, dtype=\u001b[38;5;28mfloat\u001b[39m)\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m NN_test_idx, (NN_test_input, GP_test_output, NN_test_output) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(NN_test_og_inputs, NN_test_inputs, NN_test_outputs)):\n\u001b[32m     12\u001b[39m \n\u001b[32m     13\u001b[39m     \u001b[38;5;66;03m#Retrieve prediction\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     NN_pred_output = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mGP_test_output\u001b[49m\u001b[43m)\u001b[49m.detach().numpy()\n\u001b[32m     16\u001b[39m     \u001b[38;5;66;03m#Convert to numpy\u001b[39;00m\n\u001b[32m     17\u001b[39m     NN_test_input = NN_test_input.numpy()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/MLenv/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/MLenv/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 53\u001b[39m, in \u001b[36mEncoderDecoder.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m     52\u001b[39m     \u001b[38;5;66;03m# Encoder with skip connections\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m     e1 = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m     p1 = \u001b[38;5;28mself\u001b[39m.pool1(e1)\n\u001b[32m     56\u001b[39m     e2 = \u001b[38;5;28mself\u001b[39m.enc2(p1)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/MLenv/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/MLenv/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/MLenv/lib/python3.13/site-packages/torch/nn/modules/container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    246\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    247\u001b[39m \u001b[33;03mRuns the forward pass.\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/MLenv/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/MLenv/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/MLenv/lib/python3.13/site-packages/torch/nn/modules/conv.py:548\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    547\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m548\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/MLenv/lib/python3.13/site-packages/torch/nn/modules/conv.py:543\u001b[39m, in \u001b[36mConv2d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    531\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    532\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(\n\u001b[32m    533\u001b[39m         F.pad(\n\u001b[32m    534\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    541\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    542\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m543\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    544\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    545\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/MLenv/lib/python3.13/site-packages/torch/utils/_device.py:103\u001b[39m, in \u001b[36mDeviceContext.__torch_function__\u001b[39m\u001b[34m(self, func, types, args, kwargs)\u001b[39m\n\u001b[32m    101\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _device_constructors() \u001b[38;5;129;01mand\u001b[39;00m kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mdevice\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    102\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mdevice\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.device\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [3312]"
     ]
    }
   ],
   "source": [
    "#Comparing GP predicted T-P profiles vs NN predicted T-P profiles vs true T-P profiles with residuals\n",
    "substep = 1000\n",
    "\n",
    "#Converting tensors to numpy arrays if this isn't already done\n",
    "if (type(NN_test_outputs) != np.ndarray):\n",
    "    NN_test_outputs = NN_test_outputs.numpy()\n",
    "\n",
    "GP_res = np.zeros(NN_test_outputs.shape, dtype=float)\n",
    "NN_res = np.zeros(NN_test_outputs.shape, dtype=float)\n",
    "\n",
    "for NN_test_idx, (NN_test_input, GP_test_output, NN_test_output) in enumerate(zip(NN_test_og_inputs, NN_test_inputs, NN_test_outputs)):\n",
    "\n",
    "    #Retrieve prediction\n",
    "    NN_pred_output = model(GP_test_output).detach().numpy()\n",
    "\n",
    "    #Convert to numpy\n",
    "    NN_test_input = NN_test_input.numpy()\n",
    "\n",
    "    #Storing residuals \n",
    "    GP_res[NN_test_idx, :] = GP_test_output - NN_test_output\n",
    "    NN_res[NN_test_idx, :] = NN_pred_output - NN_test_output\n",
    "\n",
    "    #Plotting\n",
    "    if (NN_test_idx % substep == 0):\n",
    "\n",
    "        #Convert shape\n",
    "        plot_test_output = NN_test_output.reshape((46, 72))\n",
    "        plot_NN_test_output = NN_pred_output.reshape((46, 72))\n",
    "        plot_GP_test_output = GP_test_output.reshape((46, 72))\n",
    "        plot_res_GP = res[NN_test_idx, :].reshape((46, 72))\n",
    "        plot_res_NN = res[NN_test_idx, :].reshape((46, 72))\n",
    "        \n",
    "        fig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(5, 1, figsize=(8, 8), sharex=True, layout='constrained')        \n",
    "        # Compute global vmin/vmax across all datasets\n",
    "        vmin = np.min(NN_test_output)\n",
    "        vmax = np.max(NN_test_output)\n",
    "        # Plot heatmaps\n",
    "        ax1.set_title('Data')\n",
    "        hm1 = sns.heatmap(plot_test_output, ax=ax1)#, cbar=False, vmin=vmin, vmax=vmax)\n",
    "        cbar = hm1.collections[0].colorbar\n",
    "        cbar.set_label('Temperature (K)')\n",
    "        ax2.set_title('GP Model')\n",
    "        hm2 = sns.heatmap(plot_GP_test_output, ax=ax2)#, cbar=False, vmin=vmin, vmax=vmax)\n",
    "        cbar = hm2.collections[0].colorbar\n",
    "        cbar.set_label('Temperature (K)')\n",
    "        ax2.set_title('NN Model')\n",
    "        hm2 = sns.heatmap(plot_NN_test_output, ax=ax2)#, cbar=False, vmin=vmin, vmax=vmax)\n",
    "        cbar = hm2.collections[0].colorbar\n",
    "        cbar.set_label('Temperature (K)')\n",
    "        ax3.set_title('GP Residuals')\n",
    "        hm3 = sns.heatmap(plot_res_GP, ax=ax3)#, cbar=False, vmin=vmin, vmax=vmax)\n",
    "        cbar = hm3.collections[0].colorbar\n",
    "        cbar.set_label('Temperature (K)')\n",
    "        ax3.set_title('NN Residuals')\n",
    "        hm3 = sns.heatmap(plot_res_NN, ax=ax3)#, cbar=False, vmin=vmin, vmax=vmax)\n",
    "        cbar = hm3.collections[0].colorbar\n",
    "        cbar.set_label('Temperature (K)')\n",
    "        # Shared colorbar (use the last heatmap's mappable)\n",
    "        # cbar = fig.colorbar(hm3.get_children()[0], ax=[ax1, ax2, ax3], location='right')\n",
    "        # cbar.set_label(\"Temperature\")\n",
    "        # Fix longitude ticks\n",
    "        ax5.set_xticks(np.linspace(0, 72, 5))\n",
    "        ax5.set_xticklabels(np.linspace(-180, 180, 5).astype(int))\n",
    "        ax5.set_xlabel('Longitude (degrees)')\n",
    "        # Fix latitude ticks\n",
    "        for ax in [ax1, ax2, ax3, ax4, ax5]:\n",
    "            ax.set_yticks(np.linspace(0, 46, 5))\n",
    "            ax.set_yticklabels(np.linspace(-90, 90, 5).astype(int))\n",
    "            ax.set_ylabel('Latitude (degrees)')\n",
    "        plt.suptitle(rf'H$_2$ : {test_input[0]} bar, CO$_2$ : {test_input[1]} bar, LoD : {test_input[2]:.0f} days, Obliquity : {test_input[3]} deg')\n",
    "\n",
    "        plt.savefig(plot_save_path+f'/pred_vs_actual_n.{NN_test_idx}.pdf')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46b19ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
