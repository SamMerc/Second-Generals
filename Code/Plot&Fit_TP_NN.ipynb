{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee5a7ebf",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55c0b871",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0073caf",
   "metadata": {},
   "source": [
    "# Import raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfe717a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#File containing temperature values\n",
    "raw_T_data = np.loadtxt('/Users/samsonmercier/Desktop/Work/PhD/Research/Second_Generals/Data/bt-4500k/training_data_T.csv', delimiter=',')\n",
    "#File containing pressure values\n",
    "raw_P_data = np.loadtxt('/Users/samsonmercier/Desktop/Work/PhD/Research/Second_Generals/Data/bt-4500k/training_data_P.csv', delimiter=',')\n",
    "#Path to store model\n",
    "model_save_path = '/Users/samsonmercier/Desktop/Work/PhD/Research/Second_Generals/Data/Model_Storage/'\n",
    "\n",
    "#Last 51 columns are the temperature/pressure values, \n",
    "#First 5 are the input values (H2 pressure in bar, CO2 pressure in bar, LoD in hours, Obliquity in deg, H2+Co2 pressure) but we remove the last one since it's not adding info.\n",
    "raw_inputs = raw_T_data[:, :4]\n",
    "raw_outputs_T = raw_T_data[:, 5:]\n",
    "raw_outputs_P = raw_P_data[:, 5:]\n",
    "\n",
    "#Storing useful quantitites\n",
    "N = raw_inputs.shape[0] #Number of data points\n",
    "D = raw_inputs.shape[1] #Number of features\n",
    "O = raw_outputs_T.shape[1] #Number of outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b3f486",
   "metadata": {},
   "source": [
    "# Fitting the training data with a basic deep neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293984f4",
   "metadata": {},
   "source": [
    "## 0th step : Shrink down data so we can work with it locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8329ae71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of samples to shrink our dataset to \n",
    "sample_size = 10000\n",
    "\n",
    "filter = np.random.choice(np.arange(N), size=sample_size, replace=False)\n",
    "\n",
    "raw_inputs = torch.tensor(raw_inputs[filter, :], dtype=torch.float32)\n",
    "raw_outputs_T = torch.tensor(raw_outputs_T[filter, :], dtype=torch.float32)\n",
    "raw_outputs_P = torch.tensor(raw_outputs_P[filter, :], dtype=torch.float32)\n",
    "\n",
    "N = sample_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79090012",
   "metadata": {},
   "source": [
    "## First step : Define a training, validation, and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78466da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining partition of data used for 1. training 2. validation and 3. testing\n",
    "data_partitions = [0.7, 0.1, 0.2]\n",
    "\n",
    "#Defining the noise seed for the random partitioning of the training data\n",
    "partition_seed = 4\n",
    "\n",
    "#Splitting the data \n",
    "## Setting noise seec\n",
    "generator = torch.Generator().manual_seed(partition_seed)\n",
    "## Retrieving indices of data partitions\n",
    "train_idx, valid_idx, test_idx = torch.utils.data.random_split(range(N), data_partitions, generator=generator)\n",
    "## Generate the data partitions\n",
    "### Training\n",
    "train_inputs = raw_inputs[train_idx]\n",
    "train_outputs_T = raw_outputs_T[train_idx]\n",
    "train_outputs_P = raw_outputs_P[train_idx]\n",
    "### Validation\n",
    "valid_inputs = raw_inputs[valid_idx]\n",
    "valid_outputs_T = raw_outputs_T[valid_idx]\n",
    "valid_outputs_P = raw_outputs_P[valid_idx]\n",
    "### Testing\n",
    "test_inputs = raw_inputs[test_idx]\n",
    "test_outputs_T = raw_outputs_T[test_idx]\n",
    "test_outputs_P = raw_outputs_P[test_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fa2735",
   "metadata": {},
   "source": [
    "## Second step : Define the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3491d4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            #Input layer\n",
    "            ## Pre-activation\n",
    "            nn.Linear(in_features = 4, out_features=100),\n",
    "            ## Activation\n",
    "            nn.ReLU(),\n",
    "            #Hidden layer n.1\n",
    "            nn.Linear(in_features = 100, out_features = 100),\n",
    "            nn.ReLU(),\n",
    "            #Hidden layer n.2\n",
    "            nn.Linear(in_features = 100, out_features = 100),\n",
    "            nn.ReLU(),\n",
    "            #Hidden layer n.3\n",
    "            nn.Linear(in_features = 100, out_features = 100),\n",
    "            nn.ReLU(),\n",
    "            #Hidden layer n.4\n",
    "            nn.Linear(in_features = 100, out_features = 100),\n",
    "            nn.ReLU(),\n",
    "            #Hidden layer n.5\n",
    "            nn.Linear(in_features = 100, out_features = 100),\n",
    "            nn.ReLU(),\n",
    "            #Output layer\n",
    "            nn.Linear(in_features = 100, out_features = 51),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce508dd",
   "metadata": {},
   "source": [
    "## Third step : Define device for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25f1e0a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device with 6 threads\n"
     ]
    }
   ],
   "source": [
    "# device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "device = \"cpu\"\n",
    "num_threads = 6\n",
    "torch.set_num_threads(num_threads)\n",
    "print(f\"Using {device} device with {num_threads} threads\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eaa87254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=4, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=100, out_features=100, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=100, out_features=100, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=100, out_features=100, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=100, bias=True)\n",
      "    (9): ReLU()\n",
      "    (10): Linear(in_features=100, out_features=100, bias=True)\n",
      "    (11): ReLU()\n",
      "    (12): Linear(in_features=100, out_features=51, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c607115",
   "metadata": {},
   "source": [
    "## Fourth step : Define optimization functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d568dc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Loss and optimizer ---\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "\n",
    "# --- Training loop ---\n",
    "def train_loop(inputs, targets, model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    pred = model(inputs)\n",
    "    loss = loss_fn(pred, targets)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "def eval_loop(inputs, targets, model, loss_fn):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred = model(inputs)\n",
    "        loss = loss_fn(pred, targets)\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd2d7f7",
   "metadata": {},
   "source": [
    "## Fifth step : Run optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1514d6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define number of epochs \n",
    "n_epochs = 30000\n",
    "\n",
    "#Define storage for losses\n",
    "train_losses = np.zeros(n_epochs, dtype=float)\n",
    "val_losses = np.zeros(n_epochs, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1beb5d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000: train_loss=46313.10547, val_loss=46319.77734\n",
      "Epoch 001: train_loss=46312.81250, val_loss=46319.48438\n",
      "Epoch 002: train_loss=46312.51953, val_loss=46319.19531\n",
      "Epoch 003: train_loss=46312.23438, val_loss=46318.90234\n",
      "Epoch 004: train_loss=46311.94141, val_loss=46318.61719\n",
      "Epoch 005: train_loss=46311.66016, val_loss=46318.33203\n",
      "Epoch 006: train_loss=46311.37500, val_loss=46318.03906\n",
      "Epoch 007: train_loss=46311.08984, val_loss=46317.75781\n",
      "Epoch 008: train_loss=46310.80859, val_loss=46317.47656\n",
      "Epoch 009: train_loss=46310.52734, val_loss=46317.19531\n",
      "Epoch 010: train_loss=46310.25391, val_loss=46316.92188\n",
      "Epoch 011: train_loss=46309.98438, val_loss=46316.64453\n",
      "Epoch 012: train_loss=46309.70312, val_loss=46316.37891\n",
      "Epoch 013: train_loss=46309.43750, val_loss=46316.10156\n",
      "Epoch 014: train_loss=46309.16797, val_loss=46315.83984\n",
      "Epoch 015: train_loss=46308.91016, val_loss=46315.58203\n",
      "Epoch 016: train_loss=46308.64844, val_loss=46315.31250\n",
      "Epoch 017: train_loss=46308.39062, val_loss=46315.05469\n",
      "Epoch 018: train_loss=46308.13281, val_loss=46314.79297\n",
      "Epoch 019: train_loss=46307.87500, val_loss=46314.53516\n",
      "Epoch 020: train_loss=46307.62109, val_loss=46314.27344\n",
      "Epoch 021: train_loss=46307.36719, val_loss=46314.02344\n",
      "Epoch 022: train_loss=46307.10938, val_loss=46313.76172\n",
      "Epoch 023: train_loss=46306.85938, val_loss=46313.51172\n",
      "Epoch 024: train_loss=46306.60156, val_loss=46313.25000\n",
      "Epoch 025: train_loss=46306.34766, val_loss=46313.00000\n",
      "Epoch 026: train_loss=46306.08984, val_loss=46312.73828\n",
      "Epoch 027: train_loss=46305.84375, val_loss=46312.48438\n",
      "Epoch 028: train_loss=46305.58594, val_loss=46312.22656\n",
      "Epoch 029: train_loss=46305.33203, val_loss=46311.97656\n",
      "Epoch 030: train_loss=46305.07422, val_loss=46311.71484\n",
      "Epoch 031: train_loss=46304.82422, val_loss=46311.46484\n",
      "Epoch 032: train_loss=46304.57422, val_loss=46311.20703\n",
      "Epoch 033: train_loss=46304.32031, val_loss=46310.95312\n",
      "Epoch 034: train_loss=46304.07031, val_loss=46310.70312\n",
      "Epoch 035: train_loss=46303.81641, val_loss=46310.44922\n",
      "Epoch 036: train_loss=46303.56641, val_loss=46310.19922\n",
      "Epoch 037: train_loss=46303.32422, val_loss=46309.94922\n",
      "Epoch 038: train_loss=46303.07031, val_loss=46309.69141\n",
      "Epoch 039: train_loss=46302.82031, val_loss=46309.43750\n",
      "Epoch 040: train_loss=46302.56641, val_loss=46309.19141\n",
      "Epoch 041: train_loss=46302.31641, val_loss=46308.93359\n",
      "Epoch 042: train_loss=46302.06641, val_loss=46308.68359\n",
      "Epoch 043: train_loss=46301.81641, val_loss=46308.42188\n",
      "Epoch 044: train_loss=46301.55859, val_loss=46308.17188\n",
      "Epoch 045: train_loss=46301.30859, val_loss=46307.91016\n",
      "Epoch 046: train_loss=46301.05859, val_loss=46307.64844\n",
      "Epoch 047: train_loss=46300.80078, val_loss=46307.39844\n",
      "Epoch 048: train_loss=46300.54297, val_loss=46307.13281\n",
      "Epoch 049: train_loss=46300.28516, val_loss=46306.87500\n",
      "Epoch 050: train_loss=46300.02344, val_loss=46306.60938\n",
      "Epoch 051: train_loss=46299.76172, val_loss=46306.34375\n",
      "Epoch 052: train_loss=46299.50000, val_loss=46306.07422\n",
      "Epoch 053: train_loss=46299.23828, val_loss=46305.81250\n",
      "Epoch 054: train_loss=46298.97656, val_loss=46305.54297\n",
      "Epoch 055: train_loss=46298.70703, val_loss=46305.26953\n",
      "Epoch 056: train_loss=46298.43359, val_loss=46305.00000\n",
      "Epoch 057: train_loss=46298.17188, val_loss=46304.72656\n",
      "Epoch 058: train_loss=46297.89844, val_loss=46304.45703\n",
      "Epoch 059: train_loss=46297.62891, val_loss=46304.17578\n",
      "Epoch 060: train_loss=46297.35938, val_loss=46303.89844\n",
      "Epoch 061: train_loss=46297.08203, val_loss=46303.61719\n",
      "Epoch 062: train_loss=46296.80859, val_loss=46303.34375\n",
      "Epoch 063: train_loss=46296.53125, val_loss=46303.05469\n",
      "Epoch 064: train_loss=46296.25000, val_loss=46302.76953\n",
      "Epoch 065: train_loss=46295.96875, val_loss=46302.48828\n",
      "Epoch 066: train_loss=46295.68750, val_loss=46302.20312\n",
      "Epoch 067: train_loss=46295.40234, val_loss=46301.90625\n",
      "Epoch 068: train_loss=46295.11328, val_loss=46301.61719\n",
      "Epoch 069: train_loss=46294.83203, val_loss=46301.32422\n",
      "Epoch 070: train_loss=46294.53906, val_loss=46301.02734\n",
      "Epoch 071: train_loss=46294.24609, val_loss=46300.73047\n",
      "Epoch 072: train_loss=46293.94922, val_loss=46300.42969\n",
      "Epoch 073: train_loss=46293.64844, val_loss=46300.12500\n",
      "Epoch 074: train_loss=46293.34766, val_loss=46299.81250\n",
      "Epoch 075: train_loss=46293.03906, val_loss=46299.50781\n",
      "Epoch 076: train_loss=46292.72656, val_loss=46299.18750\n",
      "Epoch 077: train_loss=46292.41797, val_loss=46298.87109\n",
      "Epoch 078: train_loss=46292.10156, val_loss=46298.55859\n",
      "Epoch 079: train_loss=46291.78906, val_loss=46298.23438\n",
      "Epoch 080: train_loss=46291.46484, val_loss=46297.90625\n",
      "Epoch 081: train_loss=46291.14453, val_loss=46297.57812\n",
      "Epoch 082: train_loss=46290.81641, val_loss=46297.25000\n",
      "Epoch 083: train_loss=46290.48828, val_loss=46296.90625\n",
      "Epoch 084: train_loss=46290.15625, val_loss=46296.57031\n",
      "Epoch 085: train_loss=46289.82031, val_loss=46296.22656\n",
      "Epoch 086: train_loss=46289.48047, val_loss=46295.88281\n",
      "Epoch 087: train_loss=46289.13672, val_loss=46295.53125\n",
      "Epoch 088: train_loss=46288.78906, val_loss=46295.17969\n",
      "Epoch 089: train_loss=46288.44141, val_loss=46294.82031\n",
      "Epoch 090: train_loss=46288.08594, val_loss=46294.45703\n",
      "Epoch 091: train_loss=46287.72656, val_loss=46294.08984\n",
      "Epoch 092: train_loss=46287.36328, val_loss=46293.72656\n",
      "Epoch 093: train_loss=46286.99609, val_loss=46293.34766\n",
      "Epoch 094: train_loss=46286.62891, val_loss=46292.97266\n",
      "Epoch 095: train_loss=46286.25391, val_loss=46292.58984\n",
      "Epoch 096: train_loss=46285.88281, val_loss=46292.21484\n",
      "Epoch 097: train_loss=46285.50391, val_loss=46291.82422\n",
      "Epoch 098: train_loss=46285.12500, val_loss=46291.43750\n",
      "Epoch 099: train_loss=46284.73828, val_loss=46291.03906\n",
      "Epoch 100: train_loss=46284.35156, val_loss=46290.64453\n",
      "Epoch 101: train_loss=46283.95703, val_loss=46290.24219\n",
      "Epoch 102: train_loss=46283.55469, val_loss=46289.82812\n",
      "Epoch 103: train_loss=46283.15234, val_loss=46289.41797\n",
      "Epoch 104: train_loss=46282.74219, val_loss=46288.99609\n",
      "Epoch 105: train_loss=46282.32031, val_loss=46288.57422\n",
      "Epoch 106: train_loss=46281.90625, val_loss=46288.14453\n",
      "Epoch 107: train_loss=46281.47656, val_loss=46287.70312\n",
      "Epoch 108: train_loss=46281.04688, val_loss=46287.26562\n",
      "Epoch 109: train_loss=46280.60938, val_loss=46286.81641\n",
      "Epoch 110: train_loss=46280.16797, val_loss=46286.35938\n",
      "Epoch 111: train_loss=46279.71875, val_loss=46285.90625\n",
      "Epoch 112: train_loss=46279.26953, val_loss=46285.44141\n",
      "Epoch 113: train_loss=46278.81250, val_loss=46284.98047\n",
      "Epoch 114: train_loss=46278.34766, val_loss=46284.50391\n",
      "Epoch 115: train_loss=46277.88281, val_loss=46284.02734\n",
      "Epoch 116: train_loss=46277.41016, val_loss=46283.53906\n",
      "Epoch 117: train_loss=46276.93359, val_loss=46283.05859\n",
      "Epoch 118: train_loss=46276.45312, val_loss=46282.57031\n",
      "Epoch 119: train_loss=46275.97266, val_loss=46282.07422\n",
      "Epoch 120: train_loss=46275.48438, val_loss=46281.58203\n",
      "Epoch 121: train_loss=46274.99609, val_loss=46281.08594\n",
      "Epoch 122: train_loss=46274.50391, val_loss=46280.58203\n",
      "Epoch 123: train_loss=46274.01562, val_loss=46280.08203\n",
      "Epoch 124: train_loss=46273.51562, val_loss=46279.57031\n",
      "Epoch 125: train_loss=46273.01172, val_loss=46279.05859\n",
      "Epoch 126: train_loss=46272.50781, val_loss=46278.53516\n",
      "Epoch 127: train_loss=46271.99609, val_loss=46278.01953\n",
      "Epoch 128: train_loss=46271.48438, val_loss=46277.49219\n",
      "Epoch 129: train_loss=46270.96484, val_loss=46276.96094\n",
      "Epoch 130: train_loss=46270.43750, val_loss=46276.42578\n",
      "Epoch 131: train_loss=46269.91406, val_loss=46275.89062\n",
      "Epoch 132: train_loss=46269.38281, val_loss=46275.35156\n",
      "Epoch 133: train_loss=46268.85156, val_loss=46274.80469\n",
      "Epoch 134: train_loss=46268.30859, val_loss=46274.25781\n",
      "Epoch 135: train_loss=46267.77344, val_loss=46273.70703\n",
      "Epoch 136: train_loss=46267.22266, val_loss=46273.14453\n",
      "Epoch 137: train_loss=46266.67969, val_loss=46272.58203\n",
      "Epoch 138: train_loss=46266.12109, val_loss=46272.01953\n",
      "Epoch 139: train_loss=46265.55859, val_loss=46271.44922\n",
      "Epoch 140: train_loss=46264.99609, val_loss=46270.87109\n",
      "Epoch 141: train_loss=46264.42969, val_loss=46270.28906\n",
      "Epoch 142: train_loss=46263.84766, val_loss=46269.69922\n",
      "Epoch 143: train_loss=46263.26562, val_loss=46269.10547\n",
      "Epoch 144: train_loss=46262.67969, val_loss=46268.50781\n",
      "Epoch 145: train_loss=46262.08594, val_loss=46267.89453\n",
      "Epoch 146: train_loss=46261.48438, val_loss=46267.28125\n",
      "Epoch 147: train_loss=46260.88281, val_loss=46266.66406\n",
      "Epoch 148: train_loss=46260.26953, val_loss=46266.03516\n",
      "Epoch 149: train_loss=46259.64453, val_loss=46265.39844\n",
      "Epoch 150: train_loss=46259.02344, val_loss=46264.76172\n",
      "Epoch 151: train_loss=46258.38281, val_loss=46264.10938\n",
      "Epoch 152: train_loss=46257.73828, val_loss=46263.44531\n",
      "Epoch 153: train_loss=46257.09766, val_loss=46262.78906\n",
      "Epoch 154: train_loss=46256.44141, val_loss=46262.12109\n",
      "Epoch 155: train_loss=46255.77734, val_loss=46261.44922\n",
      "Epoch 156: train_loss=46255.11328, val_loss=46260.76562\n",
      "Epoch 157: train_loss=46254.44141, val_loss=46260.07422\n",
      "Epoch 158: train_loss=46253.75781, val_loss=46259.37500\n",
      "Epoch 159: train_loss=46253.07031, val_loss=46258.67969\n",
      "Epoch 160: train_loss=46252.37500, val_loss=46257.96875\n",
      "Epoch 161: train_loss=46251.67578, val_loss=46257.25391\n",
      "Epoch 162: train_loss=46250.97266, val_loss=46256.53125\n",
      "Epoch 163: train_loss=46250.25391, val_loss=46255.79688\n",
      "Epoch 164: train_loss=46249.53516, val_loss=46255.05859\n",
      "Epoch 165: train_loss=46248.80078, val_loss=46254.31250\n",
      "Epoch 166: train_loss=46248.07031, val_loss=46253.56641\n",
      "Epoch 167: train_loss=46247.32812, val_loss=46252.80469\n",
      "Epoch 168: train_loss=46246.57812, val_loss=46252.03125\n",
      "Epoch 169: train_loss=46245.81641, val_loss=46251.25781\n",
      "Epoch 170: train_loss=46245.04688, val_loss=46250.47656\n",
      "Epoch 171: train_loss=46244.27734, val_loss=46249.68359\n",
      "Epoch 172: train_loss=46243.49609, val_loss=46248.87891\n",
      "Epoch 173: train_loss=46242.70312, val_loss=46248.07812\n",
      "Epoch 174: train_loss=46241.90625, val_loss=46247.25781\n",
      "Epoch 175: train_loss=46241.10156, val_loss=46246.42969\n",
      "Epoch 176: train_loss=46240.28516, val_loss=46245.60156\n",
      "Epoch 177: train_loss=46239.46484, val_loss=46244.76172\n",
      "Epoch 178: train_loss=46238.63672, val_loss=46243.91016\n",
      "Epoch 179: train_loss=46237.79688, val_loss=46243.05078\n",
      "Epoch 180: train_loss=46236.94531, val_loss=46242.18359\n",
      "Epoch 181: train_loss=46236.08984, val_loss=46241.30859\n",
      "Epoch 182: train_loss=46235.22266, val_loss=46240.42578\n",
      "Epoch 183: train_loss=46234.35156, val_loss=46239.53125\n",
      "Epoch 184: train_loss=46233.46484, val_loss=46238.62891\n",
      "Epoch 185: train_loss=46232.57031, val_loss=46237.71094\n",
      "Epoch 186: train_loss=46231.66797, val_loss=46236.79297\n",
      "Epoch 187: train_loss=46230.76172, val_loss=46235.85938\n",
      "Epoch 188: train_loss=46229.83203, val_loss=46234.91406\n",
      "Epoch 189: train_loss=46228.90625, val_loss=46233.96094\n",
      "Epoch 190: train_loss=46227.96094, val_loss=46232.99609\n",
      "Epoch 191: train_loss=46227.00781, val_loss=46232.02344\n",
      "Epoch 192: train_loss=46226.04297, val_loss=46231.03516\n",
      "Epoch 193: train_loss=46225.07422, val_loss=46230.03516\n",
      "Epoch 194: train_loss=46224.08984, val_loss=46229.03125\n",
      "Epoch 195: train_loss=46223.09766, val_loss=46228.01172\n",
      "Epoch 196: train_loss=46222.09375, val_loss=46226.98438\n",
      "Epoch 197: train_loss=46221.07031, val_loss=46225.94531\n",
      "Epoch 198: train_loss=46220.04297, val_loss=46224.89453\n",
      "Epoch 199: train_loss=46219.00391, val_loss=46223.83203\n",
      "Epoch 200: train_loss=46217.95312, val_loss=46222.74609\n",
      "Epoch 201: train_loss=46216.89062, val_loss=46221.66016\n",
      "Epoch 202: train_loss=46215.80859, val_loss=46220.55078\n",
      "Epoch 203: train_loss=46214.71875, val_loss=46219.43359\n",
      "Epoch 204: train_loss=46213.60938, val_loss=46218.30078\n",
      "Epoch 205: train_loss=46212.49219, val_loss=46217.14453\n",
      "Epoch 206: train_loss=46211.35547, val_loss=46215.98047\n",
      "Epoch 207: train_loss=46210.20703, val_loss=46214.80469\n",
      "Epoch 208: train_loss=46209.03516, val_loss=46213.61328\n",
      "Epoch 209: train_loss=46207.85938, val_loss=46212.39844\n",
      "Epoch 210: train_loss=46206.66797, val_loss=46211.17578\n",
      "Epoch 211: train_loss=46205.45312, val_loss=46209.93750\n",
      "Epoch 212: train_loss=46204.22656, val_loss=46208.68359\n",
      "Epoch 213: train_loss=46202.98438, val_loss=46207.41797\n",
      "Epoch 214: train_loss=46201.73438, val_loss=46206.12891\n",
      "Epoch 215: train_loss=46200.46094, val_loss=46204.82812\n",
      "Epoch 216: train_loss=46199.17578, val_loss=46203.50781\n",
      "Epoch 217: train_loss=46197.86719, val_loss=46202.16797\n",
      "Epoch 218: train_loss=46196.54688, val_loss=46200.82031\n",
      "Epoch 219: train_loss=46195.21094, val_loss=46199.45312\n",
      "Epoch 220: train_loss=46193.86328, val_loss=46198.06250\n",
      "Epoch 221: train_loss=46192.49219, val_loss=46196.66406\n",
      "Epoch 222: train_loss=46191.10547, val_loss=46195.23828\n",
      "Epoch 223: train_loss=46189.69922, val_loss=46193.80469\n",
      "Epoch 224: train_loss=46188.28125, val_loss=46192.34766\n",
      "Epoch 225: train_loss=46186.83984, val_loss=46190.87500\n",
      "Epoch 226: train_loss=46185.37891, val_loss=46189.37891\n",
      "Epoch 227: train_loss=46183.90234, val_loss=46187.86328\n",
      "Epoch 228: train_loss=46182.41016, val_loss=46186.33203\n",
      "Epoch 229: train_loss=46180.89844, val_loss=46184.77344\n",
      "Epoch 230: train_loss=46179.35547, val_loss=46183.20312\n",
      "Epoch 231: train_loss=46177.80078, val_loss=46181.60547\n",
      "Epoch 232: train_loss=46176.22266, val_loss=46179.99219\n",
      "Epoch 233: train_loss=46174.62500, val_loss=46178.35547\n",
      "Epoch 234: train_loss=46173.00781, val_loss=46176.69922\n",
      "Epoch 235: train_loss=46171.37500, val_loss=46175.01953\n",
      "Epoch 236: train_loss=46169.71484, val_loss=46173.32422\n",
      "Epoch 237: train_loss=46168.03516, val_loss=46171.60156\n",
      "Epoch 238: train_loss=46166.33203, val_loss=46169.85938\n",
      "Epoch 239: train_loss=46164.60938, val_loss=46168.08594\n",
      "Epoch 240: train_loss=46162.85938, val_loss=46166.30078\n",
      "Epoch 241: train_loss=46161.09375, val_loss=46164.48828\n",
      "Epoch 242: train_loss=46159.29688, val_loss=46162.65234\n",
      "Epoch 243: train_loss=46157.48438, val_loss=46160.79688\n",
      "Epoch 244: train_loss=46155.65625, val_loss=46158.91797\n",
      "Epoch 245: train_loss=46153.79297, val_loss=46157.01953\n",
      "Epoch 246: train_loss=46151.91406, val_loss=46155.09375\n",
      "Epoch 247: train_loss=46150.01172, val_loss=46153.14453\n",
      "Epoch 248: train_loss=46148.08984, val_loss=46151.17969\n",
      "Epoch 249: train_loss=46146.14062, val_loss=46149.17969\n",
      "Epoch 250: train_loss=46144.17188, val_loss=46147.16797\n",
      "Epoch 251: train_loss=46142.17578, val_loss=46145.12500\n",
      "Epoch 252: train_loss=46140.16016, val_loss=46143.06250\n",
      "Epoch 253: train_loss=46138.11719, val_loss=46140.96875\n",
      "Epoch 254: train_loss=46136.05469, val_loss=46138.85938\n",
      "Epoch 255: train_loss=46133.96484, val_loss=46136.72266\n",
      "Epoch 256: train_loss=46131.85547, val_loss=46134.55859\n",
      "Epoch 257: train_loss=46129.71875, val_loss=46132.37109\n",
      "Epoch 258: train_loss=46127.55469, val_loss=46130.15625\n",
      "Epoch 259: train_loss=46125.36719, val_loss=46127.91406\n",
      "Epoch 260: train_loss=46123.15234, val_loss=46125.64844\n",
      "Epoch 261: train_loss=46120.91016, val_loss=46123.34766\n",
      "Epoch 262: train_loss=46118.64062, val_loss=46121.02344\n",
      "Epoch 263: train_loss=46116.35156, val_loss=46118.67969\n",
      "Epoch 264: train_loss=46114.02734, val_loss=46116.30859\n",
      "Epoch 265: train_loss=46111.68359, val_loss=46113.90234\n",
      "Epoch 266: train_loss=46109.31250, val_loss=46111.47266\n",
      "Epoch 267: train_loss=46106.91016, val_loss=46109.01953\n",
      "Epoch 268: train_loss=46104.48047, val_loss=46106.53516\n",
      "Epoch 269: train_loss=46102.02734, val_loss=46104.02344\n",
      "Epoch 270: train_loss=46099.54297, val_loss=46101.48438\n",
      "Epoch 271: train_loss=46097.03125, val_loss=46098.91406\n",
      "Epoch 272: train_loss=46094.49609, val_loss=46096.32031\n",
      "Epoch 273: train_loss=46091.92578, val_loss=46093.68750\n",
      "Epoch 274: train_loss=46089.32812, val_loss=46091.03125\n",
      "Epoch 275: train_loss=46086.70312, val_loss=46088.34766\n",
      "Epoch 276: train_loss=46084.05078, val_loss=46085.63281\n",
      "Epoch 277: train_loss=46081.36719, val_loss=46082.89062\n",
      "Epoch 278: train_loss=46078.65625, val_loss=46080.12109\n",
      "Epoch 279: train_loss=46075.91406, val_loss=46077.32031\n",
      "Epoch 280: train_loss=46073.14844, val_loss=46074.48828\n",
      "Epoch 281: train_loss=46070.35547, val_loss=46071.62109\n",
      "Epoch 282: train_loss=46067.52344, val_loss=46068.73047\n",
      "Epoch 283: train_loss=46064.66406, val_loss=46065.81641\n",
      "Epoch 284: train_loss=46061.77734, val_loss=46062.85938\n",
      "Epoch 285: train_loss=46058.85938, val_loss=46059.87500\n",
      "Epoch 286: train_loss=46055.91406, val_loss=46056.85938\n",
      "Epoch 287: train_loss=46052.93359, val_loss=46053.81641\n",
      "Epoch 288: train_loss=46049.92188, val_loss=46050.74219\n",
      "Epoch 289: train_loss=46046.88672, val_loss=46047.62891\n",
      "Epoch 290: train_loss=46043.80859, val_loss=46044.49219\n",
      "Epoch 291: train_loss=46040.70312, val_loss=46041.30859\n",
      "Epoch 292: train_loss=46037.56250, val_loss=46038.10156\n",
      "Epoch 293: train_loss=46034.39062, val_loss=46034.85938\n",
      "Epoch 294: train_loss=46031.17578, val_loss=46031.58203\n",
      "Epoch 295: train_loss=46027.94141, val_loss=46028.26953\n",
      "Epoch 296: train_loss=46024.66406, val_loss=46024.91406\n",
      "Epoch 297: train_loss=46021.35547, val_loss=46021.53125\n",
      "Epoch 298: train_loss=46018.00391, val_loss=46018.10938\n",
      "Epoch 299: train_loss=46014.62500, val_loss=46014.65625\n",
      "Epoch 300: train_loss=46011.21094, val_loss=46011.15625\n",
      "Epoch 301: train_loss=46007.75391, val_loss=46007.62891\n",
      "Epoch 302: train_loss=46004.26953, val_loss=46004.06250\n",
      "Epoch 303: train_loss=46000.74609, val_loss=46000.45312\n",
      "Epoch 304: train_loss=45997.17969, val_loss=45996.81641\n",
      "Epoch 305: train_loss=45993.57812, val_loss=45993.13672\n",
      "Epoch 306: train_loss=45989.94141, val_loss=45989.41797\n",
      "Epoch 307: train_loss=45986.27344, val_loss=45985.65625\n",
      "Epoch 308: train_loss=45982.55469, val_loss=45981.85547\n",
      "Epoch 309: train_loss=45978.80078, val_loss=45978.02344\n",
      "Epoch 310: train_loss=45975.00781, val_loss=45974.14844\n",
      "Epoch 311: train_loss=45971.17578, val_loss=45970.22656\n",
      "Epoch 312: train_loss=45967.30078, val_loss=45966.26562\n",
      "Epoch 313: train_loss=45963.39062, val_loss=45962.26953\n",
      "Epoch 314: train_loss=45959.43359, val_loss=45958.23047\n",
      "Epoch 315: train_loss=45955.44141, val_loss=45954.14844\n",
      "Epoch 316: train_loss=45951.40625, val_loss=45950.03125\n",
      "Epoch 317: train_loss=45947.33594, val_loss=45945.86719\n",
      "Epoch 318: train_loss=45943.22266, val_loss=45941.66016\n",
      "Epoch 319: train_loss=45939.06641, val_loss=45937.41406\n",
      "Epoch 320: train_loss=45934.87500, val_loss=45933.12500\n",
      "Epoch 321: train_loss=45930.62891, val_loss=45928.78906\n",
      "Epoch 322: train_loss=45926.34375, val_loss=45924.41406\n",
      "Epoch 323: train_loss=45922.01562, val_loss=45919.98828\n",
      "Epoch 324: train_loss=45917.64062, val_loss=45915.52344\n",
      "Epoch 325: train_loss=45913.22266, val_loss=45911.01172\n",
      "Epoch 326: train_loss=45908.76562, val_loss=45906.45312\n",
      "Epoch 327: train_loss=45904.26172, val_loss=45901.85547\n",
      "Epoch 328: train_loss=45899.71484, val_loss=45897.20703\n",
      "Epoch 329: train_loss=45895.12109, val_loss=45892.51953\n",
      "Epoch 330: train_loss=45890.48438, val_loss=45887.77734\n",
      "Epoch 331: train_loss=45885.80859, val_loss=45883.00000\n",
      "Epoch 332: train_loss=45881.08203, val_loss=45878.18359\n",
      "Epoch 333: train_loss=45876.31641, val_loss=45873.31250\n",
      "Epoch 334: train_loss=45871.50391, val_loss=45868.39453\n",
      "Epoch 335: train_loss=45866.63672, val_loss=45863.41797\n",
      "Epoch 336: train_loss=45861.72266, val_loss=45858.39844\n",
      "Epoch 337: train_loss=45856.76172, val_loss=45853.33594\n",
      "Epoch 338: train_loss=45851.75391, val_loss=45848.21484\n",
      "Epoch 339: train_loss=45846.69141, val_loss=45843.03906\n",
      "Epoch 340: train_loss=45841.57812, val_loss=45837.81250\n",
      "Epoch 341: train_loss=45836.41016, val_loss=45832.53516\n",
      "Epoch 342: train_loss=45831.19531, val_loss=45827.20312\n",
      "Epoch 343: train_loss=45825.92188, val_loss=45821.82031\n",
      "Epoch 344: train_loss=45820.59375, val_loss=45816.37891\n",
      "Epoch 345: train_loss=45815.21484, val_loss=45810.89062\n",
      "Epoch 346: train_loss=45809.78125, val_loss=45805.33203\n",
      "Epoch 347: train_loss=45804.29297, val_loss=45799.72656\n",
      "Epoch 348: train_loss=45798.74609, val_loss=45794.06250\n",
      "Epoch 349: train_loss=45793.14844, val_loss=45788.33984\n",
      "Epoch 350: train_loss=45787.49219, val_loss=45782.56641\n",
      "Epoch 351: train_loss=45781.77734, val_loss=45776.72656\n",
      "Epoch 352: train_loss=45776.00781, val_loss=45770.82812\n",
      "Epoch 353: train_loss=45770.17578, val_loss=45764.86719\n",
      "Epoch 354: train_loss=45764.28516, val_loss=45758.85547\n",
      "Epoch 355: train_loss=45758.33594, val_loss=45752.78125\n",
      "Epoch 356: train_loss=45752.33594, val_loss=45746.63672\n",
      "Epoch 357: train_loss=45746.26953, val_loss=45740.44922\n",
      "Epoch 358: train_loss=45740.14844, val_loss=45734.19531\n",
      "Epoch 359: train_loss=45733.96875, val_loss=45727.87500\n",
      "Epoch 360: train_loss=45727.72656, val_loss=45721.50000\n",
      "Epoch 361: train_loss=45721.42188, val_loss=45715.06641\n",
      "Epoch 362: train_loss=45715.05469, val_loss=45708.55859\n",
      "Epoch 363: train_loss=45708.62891, val_loss=45702.00000\n",
      "Epoch 364: train_loss=45702.14453, val_loss=45695.36719\n",
      "Epoch 365: train_loss=45695.59375, val_loss=45688.67969\n",
      "Epoch 366: train_loss=45688.98047, val_loss=45681.92578\n",
      "Epoch 367: train_loss=45682.30078, val_loss=45675.10938\n",
      "Epoch 368: train_loss=45675.56250, val_loss=45668.22266\n",
      "Epoch 369: train_loss=45668.75391, val_loss=45661.26953\n",
      "Epoch 370: train_loss=45661.88281, val_loss=45654.25781\n",
      "Epoch 371: train_loss=45654.94531, val_loss=45647.16797\n",
      "Epoch 372: train_loss=45647.94531, val_loss=45640.01953\n",
      "Epoch 373: train_loss=45640.87500, val_loss=45632.80469\n",
      "Epoch 374: train_loss=45633.74219, val_loss=45625.51562\n",
      "Epoch 375: train_loss=45626.53906, val_loss=45618.16016\n",
      "Epoch 376: train_loss=45619.26953, val_loss=45610.73828\n",
      "Epoch 377: train_loss=45611.92578, val_loss=45603.23828\n",
      "Epoch 378: train_loss=45604.51953, val_loss=45595.67969\n",
      "Epoch 379: train_loss=45597.03906, val_loss=45588.03906\n",
      "Epoch 380: train_loss=45589.48828, val_loss=45580.32422\n",
      "Epoch 381: train_loss=45581.86719, val_loss=45572.53906\n",
      "Epoch 382: train_loss=45574.17188, val_loss=45564.68359\n",
      "Epoch 383: train_loss=45566.40625, val_loss=45556.75781\n",
      "Epoch 384: train_loss=45558.57031, val_loss=45548.75391\n",
      "Epoch 385: train_loss=45550.66016, val_loss=45540.67188\n",
      "Epoch 386: train_loss=45542.67578, val_loss=45532.51562\n",
      "Epoch 387: train_loss=45534.61328, val_loss=45524.28906\n",
      "Epoch 388: train_loss=45526.47656, val_loss=45515.97656\n",
      "Epoch 389: train_loss=45518.26562, val_loss=45507.59375\n",
      "Epoch 390: train_loss=45509.98047, val_loss=45499.13281\n",
      "Epoch 391: train_loss=45501.61719, val_loss=45490.58203\n",
      "Epoch 392: train_loss=45493.17578, val_loss=45481.96484\n",
      "Epoch 393: train_loss=45484.65234, val_loss=45473.26172\n",
      "Epoch 394: train_loss=45476.05469, val_loss=45464.47656\n",
      "Epoch 395: train_loss=45467.37500, val_loss=45455.60938\n",
      "Epoch 396: train_loss=45458.60938, val_loss=45446.66016\n",
      "Epoch 397: train_loss=45449.76562, val_loss=45437.62500\n",
      "Epoch 398: train_loss=45440.83594, val_loss=45428.50391\n",
      "Epoch 399: train_loss=45431.82422, val_loss=45419.30078\n",
      "Epoch 400: train_loss=45422.71875, val_loss=45410.00391\n",
      "Epoch 401: train_loss=45413.53125, val_loss=45400.62109\n",
      "Epoch 402: train_loss=45404.26172, val_loss=45391.14844\n",
      "Epoch 403: train_loss=45394.89844, val_loss=45381.58594\n",
      "Epoch 404: train_loss=45385.44141, val_loss=45371.93359\n",
      "Epoch 405: train_loss=45375.89062, val_loss=45362.17578\n",
      "Epoch 406: train_loss=45366.25000, val_loss=45352.33203\n",
      "Epoch 407: train_loss=45356.51562, val_loss=45342.39062\n",
      "Epoch 408: train_loss=45346.69141, val_loss=45332.34766\n",
      "Epoch 409: train_loss=45336.75781, val_loss=45322.21094\n",
      "Epoch 410: train_loss=45326.73828, val_loss=45311.98047\n",
      "Epoch 411: train_loss=45316.61328, val_loss=45301.65625\n",
      "Epoch 412: train_loss=45306.40234, val_loss=45291.21875\n",
      "Epoch 413: train_loss=45296.08984, val_loss=45280.69922\n",
      "Epoch 414: train_loss=45285.67969, val_loss=45270.06641\n",
      "Epoch 415: train_loss=45275.17188, val_loss=45259.33984\n",
      "Epoch 416: train_loss=45264.56250, val_loss=45248.51172\n",
      "Epoch 417: train_loss=45253.85156, val_loss=45237.57031\n",
      "Epoch 418: train_loss=45243.04688, val_loss=45226.54297\n",
      "Epoch 419: train_loss=45232.13281, val_loss=45215.40234\n",
      "Epoch 420: train_loss=45221.12109, val_loss=45204.16016\n",
      "Epoch 421: train_loss=45210.00391, val_loss=45192.81250\n",
      "Epoch 422: train_loss=45198.78125, val_loss=45181.35156\n",
      "Epoch 423: train_loss=45187.44922, val_loss=45169.78125\n",
      "Epoch 424: train_loss=45176.00781, val_loss=45158.08984\n",
      "Epoch 425: train_loss=45164.44531, val_loss=45146.28125\n",
      "Epoch 426: train_loss=45152.76953, val_loss=45134.35547\n",
      "Epoch 427: train_loss=45140.97656, val_loss=45122.32031\n",
      "Epoch 428: train_loss=45129.06641, val_loss=45110.15234\n",
      "Epoch 429: train_loss=45117.04297, val_loss=45097.87500\n",
      "Epoch 430: train_loss=45104.89844, val_loss=45085.46875\n",
      "Epoch 431: train_loss=45092.64453, val_loss=45072.95703\n",
      "Epoch 432: train_loss=45080.26172, val_loss=45060.31641\n",
      "Epoch 433: train_loss=45067.77344, val_loss=45047.55078\n",
      "Epoch 434: train_loss=45055.15234, val_loss=45034.66797\n",
      "Epoch 435: train_loss=45042.41016, val_loss=45021.65234\n",
      "Epoch 436: train_loss=45029.54297, val_loss=45008.51562\n",
      "Epoch 437: train_loss=45016.54688, val_loss=44995.24219\n",
      "Epoch 438: train_loss=45003.43359, val_loss=44981.85547\n",
      "Epoch 439: train_loss=44990.19531, val_loss=44968.33203\n",
      "Epoch 440: train_loss=44976.82812, val_loss=44954.69531\n",
      "Epoch 441: train_loss=44963.33984, val_loss=44940.92188\n",
      "Epoch 442: train_loss=44949.72656, val_loss=44927.01953\n",
      "Epoch 443: train_loss=44935.98438, val_loss=44912.99219\n",
      "Epoch 444: train_loss=44922.10938, val_loss=44898.82422\n",
      "Epoch 445: train_loss=44908.11328, val_loss=44884.53125\n",
      "Epoch 446: train_loss=44893.97656, val_loss=44870.09766\n",
      "Epoch 447: train_loss=44879.71875, val_loss=44855.52734\n",
      "Epoch 448: train_loss=44865.31641, val_loss=44840.82812\n",
      "Epoch 449: train_loss=44850.77734, val_loss=44825.99219\n",
      "Epoch 450: train_loss=44836.11719, val_loss=44811.01953\n",
      "Epoch 451: train_loss=44821.31641, val_loss=44795.91406\n",
      "Epoch 452: train_loss=44806.38672, val_loss=44780.66406\n",
      "Epoch 453: train_loss=44791.32422, val_loss=44765.28516\n",
      "Epoch 454: train_loss=44776.12500, val_loss=44749.76562\n",
      "Epoch 455: train_loss=44760.78516, val_loss=44734.10156\n",
      "Epoch 456: train_loss=44745.30078, val_loss=44718.30078\n",
      "Epoch 457: train_loss=44729.68359, val_loss=44702.33984\n",
      "Epoch 458: train_loss=44713.91406, val_loss=44686.22656\n",
      "Epoch 459: train_loss=44697.98828, val_loss=44669.97266\n",
      "Epoch 460: train_loss=44681.92188, val_loss=44653.55859\n",
      "Epoch 461: train_loss=44665.70312, val_loss=44636.99219\n",
      "Epoch 462: train_loss=44649.33594, val_loss=44620.27734\n",
      "Epoch 463: train_loss=44632.82812, val_loss=44603.42188\n",
      "Epoch 464: train_loss=44616.16797, val_loss=44586.40625\n",
      "Epoch 465: train_loss=44599.35156, val_loss=44569.23828\n",
      "Epoch 466: train_loss=44582.39062, val_loss=44551.91016\n",
      "Epoch 467: train_loss=44565.26172, val_loss=44534.42188\n",
      "Epoch 468: train_loss=44547.98047, val_loss=44516.77344\n",
      "Epoch 469: train_loss=44530.53516, val_loss=44498.96094\n",
      "Epoch 470: train_loss=44512.93750, val_loss=44480.98047\n",
      "Epoch 471: train_loss=44495.17578, val_loss=44462.84375\n",
      "Epoch 472: train_loss=44477.24609, val_loss=44444.53516\n",
      "Epoch 473: train_loss=44459.16016, val_loss=44426.06250\n",
      "Epoch 474: train_loss=44440.90625, val_loss=44407.42578\n",
      "Epoch 475: train_loss=44422.49219, val_loss=44388.61719\n",
      "Epoch 476: train_loss=44403.90234, val_loss=44369.64453\n",
      "Epoch 477: train_loss=44385.16016, val_loss=44350.50391\n",
      "Epoch 478: train_loss=44366.24219, val_loss=44331.18750\n",
      "Epoch 479: train_loss=44347.15234, val_loss=44311.71094\n",
      "Epoch 480: train_loss=44327.90234, val_loss=44292.05469\n",
      "Epoch 481: train_loss=44308.47266, val_loss=44272.22656\n",
      "Epoch 482: train_loss=44288.87109, val_loss=44252.21094\n",
      "Epoch 483: train_loss=44269.09375, val_loss=44232.01953\n",
      "Epoch 484: train_loss=44249.14062, val_loss=44211.65625\n",
      "Epoch 485: train_loss=44229.01172, val_loss=44191.11328\n",
      "Epoch 486: train_loss=44208.71094, val_loss=44170.38672\n",
      "Epoch 487: train_loss=44188.22266, val_loss=44149.48047\n",
      "Epoch 488: train_loss=44167.55078, val_loss=44128.38672\n",
      "Epoch 489: train_loss=44146.70312, val_loss=44107.10156\n",
      "Epoch 490: train_loss=44125.66406, val_loss=44085.64062\n",
      "Epoch 491: train_loss=44104.44922, val_loss=44063.98438\n",
      "Epoch 492: train_loss=44083.04297, val_loss=44042.14062\n",
      "Epoch 493: train_loss=44061.44531, val_loss=44020.10547\n",
      "Epoch 494: train_loss=44039.67188, val_loss=43997.87500\n",
      "Epoch 495: train_loss=44017.69141, val_loss=43975.45312\n",
      "Epoch 496: train_loss=43995.52734, val_loss=43952.83984\n",
      "Epoch 497: train_loss=43973.17188, val_loss=43930.03125\n",
      "Epoch 498: train_loss=43950.62500, val_loss=43907.02734\n",
      "Epoch 499: train_loss=43927.88281, val_loss=43883.82812\n",
      "Epoch 500: train_loss=43904.94922, val_loss=43860.42578\n",
      "Epoch 501: train_loss=43881.81250, val_loss=43836.81641\n",
      "Epoch 502: train_loss=43858.47656, val_loss=43813.00391\n",
      "Epoch 503: train_loss=43834.93750, val_loss=43788.98438\n",
      "Epoch 504: train_loss=43811.19531, val_loss=43764.76562\n",
      "Epoch 505: train_loss=43787.25391, val_loss=43740.33984\n",
      "Epoch 506: train_loss=43763.10938, val_loss=43715.70312\n",
      "Epoch 507: train_loss=43738.75781, val_loss=43690.87109\n",
      "Epoch 508: train_loss=43714.21094, val_loss=43665.82812\n",
      "Epoch 509: train_loss=43689.44922, val_loss=43640.57031\n",
      "Epoch 510: train_loss=43664.48047, val_loss=43615.09766\n",
      "Epoch 511: train_loss=43639.30078, val_loss=43589.41016\n",
      "Epoch 512: train_loss=43613.91016, val_loss=43563.51172\n",
      "Epoch 513: train_loss=43588.31250, val_loss=43537.39844\n",
      "Epoch 514: train_loss=43562.49609, val_loss=43511.06641\n",
      "Epoch 515: train_loss=43536.47656, val_loss=43484.51172\n",
      "Epoch 516: train_loss=43510.23438, val_loss=43457.73828\n",
      "Epoch 517: train_loss=43483.76953, val_loss=43430.74219\n",
      "Epoch 518: train_loss=43457.08594, val_loss=43403.52344\n",
      "Epoch 519: train_loss=43430.19141, val_loss=43376.08594\n",
      "Epoch 520: train_loss=43403.06641, val_loss=43348.42969\n",
      "Epoch 521: train_loss=43375.72266, val_loss=43320.53906\n",
      "Epoch 522: train_loss=43348.15625, val_loss=43292.42969\n",
      "Epoch 523: train_loss=43320.36719, val_loss=43264.08984\n",
      "Epoch 524: train_loss=43292.34766, val_loss=43235.52344\n",
      "Epoch 525: train_loss=43264.11328, val_loss=43206.73047\n",
      "Epoch 526: train_loss=43235.64844, val_loss=43177.71484\n",
      "Epoch 527: train_loss=43206.96094, val_loss=43148.46875\n",
      "Epoch 528: train_loss=43178.04297, val_loss=43118.98438\n",
      "Epoch 529: train_loss=43148.89453, val_loss=43089.26562\n",
      "Epoch 530: train_loss=43119.51953, val_loss=43059.32422\n",
      "Epoch 531: train_loss=43089.92188, val_loss=43029.14453\n",
      "Epoch 532: train_loss=43060.08984, val_loss=42998.72266\n",
      "Epoch 533: train_loss=43030.01953, val_loss=42968.07812\n",
      "Epoch 534: train_loss=42999.72266, val_loss=42937.19531\n",
      "Epoch 535: train_loss=42969.19531, val_loss=42906.07031\n",
      "Epoch 536: train_loss=42938.42969, val_loss=42874.71094\n",
      "Epoch 537: train_loss=42907.42188, val_loss=42843.10938\n",
      "Epoch 538: train_loss=42876.18359, val_loss=42811.27734\n",
      "Epoch 539: train_loss=42844.70312, val_loss=42779.20312\n",
      "Epoch 540: train_loss=42812.98828, val_loss=42746.87891\n",
      "Epoch 541: train_loss=42781.03516, val_loss=42714.31641\n",
      "Epoch 542: train_loss=42748.83984, val_loss=42681.51562\n",
      "Epoch 543: train_loss=42716.39844, val_loss=42648.46094\n",
      "Epoch 544: train_loss=42683.71875, val_loss=42615.15625\n",
      "Epoch 545: train_loss=42650.79297, val_loss=42581.61328\n",
      "Epoch 546: train_loss=42617.62500, val_loss=42547.81641\n",
      "Epoch 547: train_loss=42584.20312, val_loss=42513.76953\n",
      "Epoch 548: train_loss=42550.53125, val_loss=42479.46094\n",
      "Epoch 549: train_loss=42516.60156, val_loss=42444.90234\n",
      "Epoch 550: train_loss=42482.42578, val_loss=42410.08594\n",
      "Epoch 551: train_loss=42448.00000, val_loss=42375.01562\n",
      "Epoch 552: train_loss=42413.31641, val_loss=42339.68750\n",
      "Epoch 553: train_loss=42378.37891, val_loss=42304.10938\n",
      "Epoch 554: train_loss=42343.18750, val_loss=42268.26953\n",
      "Epoch 555: train_loss=42307.73828, val_loss=42232.16797\n",
      "Epoch 556: train_loss=42272.02344, val_loss=42195.80859\n",
      "Epoch 557: train_loss=42236.05469, val_loss=42159.17969\n",
      "Epoch 558: train_loss=42199.82422, val_loss=42122.28906\n",
      "Epoch 559: train_loss=42163.33594, val_loss=42085.13672\n",
      "Epoch 560: train_loss=42126.58594, val_loss=42047.71875\n",
      "Epoch 561: train_loss=42089.56641, val_loss=42010.03125\n",
      "Epoch 562: train_loss=42052.28516, val_loss=41972.07422\n",
      "Epoch 563: train_loss=42014.73828, val_loss=41933.84766\n",
      "Epoch 564: train_loss=41976.92578, val_loss=41895.35547\n",
      "Epoch 565: train_loss=41938.84766, val_loss=41856.59375\n",
      "Epoch 566: train_loss=41900.49609, val_loss=41817.55078\n",
      "Epoch 567: train_loss=41861.87891, val_loss=41778.23828\n",
      "Epoch 568: train_loss=41822.98438, val_loss=41738.65234\n",
      "Epoch 569: train_loss=41783.81641, val_loss=41698.79688\n",
      "Epoch 570: train_loss=41744.37891, val_loss=41658.66797\n",
      "Epoch 571: train_loss=41704.67578, val_loss=41618.26172\n",
      "Epoch 572: train_loss=41664.69531, val_loss=41577.57812\n",
      "Epoch 573: train_loss=41624.44141, val_loss=41536.61719\n",
      "Epoch 574: train_loss=41583.91406, val_loss=41495.38281\n",
      "Epoch 575: train_loss=41543.11719, val_loss=41453.86328\n",
      "Epoch 576: train_loss=41502.03906, val_loss=41412.05469\n",
      "Epoch 577: train_loss=41460.67578, val_loss=41369.97266\n",
      "Epoch 578: train_loss=41419.03906, val_loss=41327.60547\n",
      "Epoch 579: train_loss=41377.12109, val_loss=41284.96094\n",
      "Epoch 580: train_loss=41334.92578, val_loss=41242.03125\n",
      "Epoch 581: train_loss=41292.44141, val_loss=41198.81641\n",
      "Epoch 582: train_loss=41249.68750, val_loss=41155.32422\n",
      "Epoch 583: train_loss=41206.63672, val_loss=41111.53516\n",
      "Epoch 584: train_loss=41163.30078, val_loss=41067.46094\n",
      "Epoch 585: train_loss=41119.67969, val_loss=41023.08984\n",
      "Epoch 586: train_loss=41075.76953, val_loss=40978.43750\n",
      "Epoch 587: train_loss=41031.57422, val_loss=40933.49609\n",
      "Epoch 588: train_loss=40987.10156, val_loss=40888.26953\n",
      "Epoch 589: train_loss=40942.34375, val_loss=40842.75391\n",
      "Epoch 590: train_loss=40897.29297, val_loss=40796.93359\n",
      "Epoch 591: train_loss=40851.94922, val_loss=40750.82031\n",
      "Epoch 592: train_loss=40806.31250, val_loss=40704.41797\n",
      "Epoch 593: train_loss=40760.38672, val_loss=40657.71484\n",
      "Epoch 594: train_loss=40714.16797, val_loss=40610.71484\n",
      "Epoch 595: train_loss=40667.65625, val_loss=40563.42188\n",
      "Epoch 596: train_loss=40620.85938, val_loss=40515.83984\n",
      "Epoch 597: train_loss=40573.75781, val_loss=40467.96484\n",
      "Epoch 598: train_loss=40526.37109, val_loss=40419.79297\n",
      "Epoch 599: train_loss=40478.69531, val_loss=40371.32812\n",
      "Epoch 600: train_loss=40430.73438, val_loss=40322.57422\n",
      "Epoch 601: train_loss=40382.46484, val_loss=40273.51172\n",
      "Epoch 602: train_loss=40333.91016, val_loss=40224.16406\n",
      "Epoch 603: train_loss=40285.05469, val_loss=40174.52344\n",
      "Epoch 604: train_loss=40235.91406, val_loss=40124.57812\n",
      "Epoch 605: train_loss=40186.47656, val_loss=40074.33594\n",
      "Epoch 606: train_loss=40136.74219, val_loss=40023.79297\n",
      "Epoch 607: train_loss=40086.70703, val_loss=39972.93750\n",
      "Epoch 608: train_loss=40036.37109, val_loss=39921.78906\n",
      "Epoch 609: train_loss=39985.73438, val_loss=39870.33203\n",
      "Epoch 610: train_loss=39934.80469, val_loss=39818.57812\n",
      "Epoch 611: train_loss=39883.57422, val_loss=39766.52344\n",
      "Epoch 612: train_loss=39832.04688, val_loss=39714.15234\n",
      "Epoch 613: train_loss=39780.21875, val_loss=39661.49609\n",
      "Epoch 614: train_loss=39728.09375, val_loss=39608.53906\n",
      "Epoch 615: train_loss=39675.67578, val_loss=39555.27734\n",
      "Epoch 616: train_loss=39622.95703, val_loss=39501.72266\n",
      "Epoch 617: train_loss=39569.94531, val_loss=39447.87891\n",
      "Epoch 618: train_loss=39516.64062, val_loss=39393.73828\n",
      "Epoch 619: train_loss=39463.06250, val_loss=39339.30859\n",
      "Epoch 620: train_loss=39409.17578, val_loss=39284.58984\n",
      "Epoch 621: train_loss=39355.00781, val_loss=39229.57422\n",
      "Epoch 622: train_loss=39300.54688, val_loss=39174.27344\n",
      "Epoch 623: train_loss=39245.80078, val_loss=39118.67969\n",
      "Epoch 624: train_loss=39190.76172, val_loss=39062.79688\n",
      "Epoch 625: train_loss=39135.44141, val_loss=39006.62891\n",
      "Epoch 626: train_loss=39079.83203, val_loss=38950.16797\n",
      "Epoch 627: train_loss=39023.93750, val_loss=38893.41797\n",
      "Epoch 628: train_loss=38967.75781, val_loss=38836.38281\n",
      "Epoch 629: train_loss=38911.29688, val_loss=38779.07031\n",
      "Epoch 630: train_loss=38854.55469, val_loss=38721.47266\n",
      "Epoch 631: train_loss=38797.53125, val_loss=38663.59766\n",
      "Epoch 632: train_loss=38740.21875, val_loss=38605.43359\n",
      "Epoch 633: train_loss=38682.62891, val_loss=38547.00000\n",
      "Epoch 634: train_loss=38624.75781, val_loss=38488.28125\n",
      "Epoch 635: train_loss=38566.60547, val_loss=38429.28125\n",
      "Epoch 636: train_loss=38508.17578, val_loss=38369.99609\n",
      "Epoch 637: train_loss=38449.46094, val_loss=38310.42969\n",
      "Epoch 638: train_loss=38390.47266, val_loss=38250.57812\n",
      "Epoch 639: train_loss=38331.19922, val_loss=38190.44922\n",
      "Epoch 640: train_loss=38271.64844, val_loss=38130.04688\n",
      "Epoch 641: train_loss=38211.82812, val_loss=38069.36328\n",
      "Epoch 642: train_loss=38151.73438, val_loss=38008.40625\n",
      "Epoch 643: train_loss=38091.35938, val_loss=37947.17188\n",
      "Epoch 644: train_loss=38030.71875, val_loss=37885.66016\n",
      "Epoch 645: train_loss=37969.80078, val_loss=37823.87891\n",
      "Epoch 646: train_loss=37908.61328, val_loss=37761.82812\n",
      "Epoch 647: train_loss=37847.15625, val_loss=37699.50391\n",
      "Epoch 648: train_loss=37785.42969, val_loss=37636.90625\n",
      "Epoch 649: train_loss=37723.43750, val_loss=37574.03906\n",
      "Epoch 650: train_loss=37661.17578, val_loss=37510.90625\n",
      "Epoch 651: train_loss=37598.64844, val_loss=37447.50000\n",
      "Epoch 652: train_loss=37535.85156, val_loss=37383.83203\n",
      "Epoch 653: train_loss=37472.79688, val_loss=37319.89844\n",
      "Epoch 654: train_loss=37409.46875, val_loss=37255.70312\n",
      "Epoch 655: train_loss=37345.87891, val_loss=37191.25000\n",
      "Epoch 656: train_loss=37282.02734, val_loss=37126.53125\n",
      "Epoch 657: train_loss=37217.91797, val_loss=37061.54297\n",
      "Epoch 658: train_loss=37153.53125, val_loss=36996.25000\n",
      "Epoch 659: train_loss=37088.85547, val_loss=36930.64844\n",
      "Epoch 660: train_loss=37023.85938, val_loss=36864.73438\n",
      "Epoch 661: train_loss=36958.55859, val_loss=36798.51562\n",
      "Epoch 662: train_loss=36892.95312, val_loss=36732.00391\n",
      "Epoch 663: train_loss=36827.05469, val_loss=36665.20703\n",
      "Epoch 664: train_loss=36760.87109, val_loss=36598.15234\n",
      "Epoch 665: train_loss=36694.42969, val_loss=36530.84766\n",
      "Epoch 666: train_loss=36627.73438, val_loss=36463.28906\n",
      "Epoch 667: train_loss=36560.78125, val_loss=36395.48438\n",
      "Epoch 668: train_loss=36493.59375, val_loss=36327.44531\n",
      "Epoch 669: train_loss=36426.16016, val_loss=36259.15625\n",
      "Epoch 670: train_loss=36358.48828, val_loss=36190.63281\n",
      "Epoch 671: train_loss=36290.57422, val_loss=36121.87500\n",
      "Epoch 672: train_loss=36222.43359, val_loss=36052.89062\n",
      "Epoch 673: train_loss=36154.05859, val_loss=35983.67969\n",
      "Epoch 674: train_loss=36085.46484, val_loss=35914.25000\n",
      "Epoch 675: train_loss=36016.64062, val_loss=35844.60156\n",
      "Epoch 676: train_loss=35947.60938, val_loss=35774.74609\n",
      "Epoch 677: train_loss=35878.35156, val_loss=35704.67578\n",
      "Epoch 678: train_loss=35808.89453, val_loss=35634.40234\n",
      "Epoch 679: train_loss=35739.21875, val_loss=35563.92578\n",
      "Epoch 680: train_loss=35669.34375, val_loss=35493.24219\n",
      "Epoch 681: train_loss=35599.26953, val_loss=35422.35938\n",
      "Epoch 682: train_loss=35528.99609, val_loss=35351.27734\n",
      "Epoch 683: train_loss=35458.51953, val_loss=35280.00781\n",
      "Epoch 684: train_loss=35387.85547, val_loss=35208.53906\n",
      "Epoch 685: train_loss=35317.00000, val_loss=35136.88672\n",
      "Epoch 686: train_loss=35245.96094, val_loss=35065.05469\n",
      "Epoch 687: train_loss=35174.73438, val_loss=34993.05078\n",
      "Epoch 688: train_loss=35103.33984, val_loss=34920.86328\n",
      "Epoch 689: train_loss=35031.76953, val_loss=34848.50781\n",
      "Epoch 690: train_loss=34960.02734, val_loss=34775.98438\n",
      "Epoch 691: train_loss=34888.11719, val_loss=34703.30078\n",
      "Epoch 692: train_loss=34816.03906, val_loss=34630.45703\n",
      "Epoch 693: train_loss=34743.80469, val_loss=34557.45312\n",
      "Epoch 694: train_loss=34671.41406, val_loss=34484.30469\n",
      "Epoch 695: train_loss=34598.86328, val_loss=34411.01172\n",
      "Epoch 696: train_loss=34526.16797, val_loss=34337.56250\n",
      "Epoch 697: train_loss=34453.32422, val_loss=34263.97656\n",
      "Epoch 698: train_loss=34380.33203, val_loss=34190.25000\n",
      "Epoch 699: train_loss=34307.20703, val_loss=34116.39844\n",
      "Epoch 700: train_loss=34233.94141, val_loss=34042.40625\n",
      "Epoch 701: train_loss=34160.55078, val_loss=33968.30469\n",
      "Epoch 702: train_loss=34087.03516, val_loss=33894.08203\n",
      "Epoch 703: train_loss=34013.40234, val_loss=33819.75000\n",
      "Epoch 704: train_loss=33939.65234, val_loss=33745.30078\n",
      "Epoch 705: train_loss=33865.79297, val_loss=33670.75781\n",
      "Epoch 706: train_loss=33791.83203, val_loss=33596.10938\n",
      "Epoch 707: train_loss=33717.76172, val_loss=33521.36719\n",
      "Epoch 708: train_loss=33643.58594, val_loss=33446.51953\n",
      "Epoch 709: train_loss=33569.31641, val_loss=33371.58594\n",
      "Epoch 710: train_loss=33494.94922, val_loss=33296.55469\n",
      "Epoch 711: train_loss=33420.48438, val_loss=33221.44141\n",
      "Epoch 712: train_loss=33345.93750, val_loss=33146.24219\n",
      "Epoch 713: train_loss=33271.29297, val_loss=33070.95703\n",
      "Epoch 714: train_loss=33196.57031, val_loss=32995.60547\n",
      "Epoch 715: train_loss=33121.77344, val_loss=32920.17578\n",
      "Epoch 716: train_loss=33046.89844, val_loss=32844.67969\n",
      "Epoch 717: train_loss=32971.94922, val_loss=32769.12109\n",
      "Epoch 718: train_loss=32896.94531, val_loss=32693.49414\n",
      "Epoch 719: train_loss=32821.86328, val_loss=32617.81836\n",
      "Epoch 720: train_loss=32746.72852, val_loss=32542.08789\n",
      "Epoch 721: train_loss=32671.53125, val_loss=32466.30859\n",
      "Epoch 722: train_loss=32596.28711, val_loss=32390.48047\n",
      "Epoch 723: train_loss=32520.99023, val_loss=32314.61328\n",
      "Epoch 724: train_loss=32445.65234, val_loss=32238.70508\n",
      "Epoch 725: train_loss=32370.27539, val_loss=32162.76367\n",
      "Epoch 726: train_loss=32294.85742, val_loss=32086.79492\n",
      "Epoch 727: train_loss=32219.41211, val_loss=32010.80664\n",
      "Epoch 728: train_loss=32143.94141, val_loss=31934.81055\n",
      "Epoch 729: train_loss=32068.45508, val_loss=31858.80273\n",
      "Epoch 730: train_loss=31992.95508, val_loss=31782.78711\n",
      "Epoch 731: train_loss=31917.45117, val_loss=31706.77930\n",
      "Epoch 732: train_loss=31841.94531, val_loss=31630.79297\n",
      "Epoch 733: train_loss=31766.45703, val_loss=31554.81836\n",
      "Epoch 734: train_loss=31690.98242, val_loss=31478.86914\n",
      "Epoch 735: train_loss=31615.51758, val_loss=31402.94336\n",
      "Epoch 736: train_loss=31540.08398, val_loss=31327.05469\n",
      "Epoch 737: train_loss=31464.67383, val_loss=31251.20312\n",
      "Epoch 738: train_loss=31389.29688, val_loss=31175.39648\n",
      "Epoch 739: train_loss=31313.95508, val_loss=31099.63867\n",
      "Epoch 740: train_loss=31238.65430, val_loss=31023.93750\n",
      "Epoch 741: train_loss=31163.41016, val_loss=30948.29883\n",
      "Epoch 742: train_loss=31088.21875, val_loss=30872.72656\n",
      "Epoch 743: train_loss=31013.08984, val_loss=30797.22070\n",
      "Epoch 744: train_loss=30938.02930, val_loss=30721.79883\n",
      "Epoch 745: train_loss=30863.02930, val_loss=30646.46094\n",
      "Epoch 746: train_loss=30788.11523, val_loss=30571.20898\n",
      "Epoch 747: train_loss=30713.27344, val_loss=30496.04297\n",
      "Epoch 748: train_loss=30638.52148, val_loss=30420.97266\n",
      "Epoch 749: train_loss=30563.85547, val_loss=30346.00391\n",
      "Epoch 750: train_loss=30489.28711, val_loss=30271.14453\n",
      "Epoch 751: train_loss=30414.81836, val_loss=30196.40430\n",
      "Epoch 752: train_loss=30340.46680, val_loss=30121.79297\n",
      "Epoch 753: train_loss=30266.22656, val_loss=30047.30664\n",
      "Epoch 754: train_loss=30192.11719, val_loss=29972.95508\n",
      "Epoch 755: train_loss=30118.13477, val_loss=29898.74023\n",
      "Epoch 756: train_loss=30044.28711, val_loss=29824.67188\n",
      "Epoch 757: train_loss=29970.57617, val_loss=29750.76172\n",
      "Epoch 758: train_loss=29897.01758, val_loss=29677.01367\n",
      "Epoch 759: train_loss=29823.60938, val_loss=29603.42773\n",
      "Epoch 760: train_loss=29750.36328, val_loss=29530.01758\n",
      "Epoch 761: train_loss=29677.27734, val_loss=29456.78125\n",
      "Epoch 762: train_loss=29604.36133, val_loss=29383.71484\n",
      "Epoch 763: train_loss=29531.61523, val_loss=29310.83594\n",
      "Epoch 764: train_loss=29459.04883, val_loss=29238.14844\n",
      "Epoch 765: train_loss=29386.66602, val_loss=29165.66406\n",
      "Epoch 766: train_loss=29314.47461, val_loss=29093.37695\n",
      "Epoch 767: train_loss=29242.48047, val_loss=29021.30273\n",
      "Epoch 768: train_loss=29170.69141, val_loss=28949.43945\n",
      "Epoch 769: train_loss=29099.10742, val_loss=28877.78906\n",
      "Epoch 770: train_loss=29027.73438, val_loss=28806.36328\n",
      "Epoch 771: train_loss=28956.58008, val_loss=28735.16992\n",
      "Epoch 772: train_loss=28885.64062, val_loss=28664.21484\n",
      "Epoch 773: train_loss=28814.92383, val_loss=28593.50000\n",
      "Epoch 774: train_loss=28744.44922, val_loss=28523.03516\n",
      "Epoch 775: train_loss=28674.20508, val_loss=28452.81836\n",
      "Epoch 776: train_loss=28604.20703, val_loss=28382.85742\n",
      "Epoch 777: train_loss=28534.45508, val_loss=28313.15820\n",
      "Epoch 778: train_loss=28464.95117, val_loss=28243.72461\n",
      "Epoch 779: train_loss=28395.71875, val_loss=28174.56641\n",
      "Epoch 780: train_loss=28326.74609, val_loss=28105.68750\n",
      "Epoch 781: train_loss=28258.04492, val_loss=28037.09766\n",
      "Epoch 782: train_loss=28189.62695, val_loss=27968.79492\n",
      "Epoch 783: train_loss=28121.49219, val_loss=27900.79688\n",
      "Epoch 784: train_loss=28053.64453, val_loss=27833.09961\n",
      "Epoch 785: train_loss=27986.09180, val_loss=27765.70703\n",
      "Epoch 786: train_loss=27918.83594, val_loss=27698.63086\n",
      "Epoch 787: train_loss=27851.88867, val_loss=27631.86719\n",
      "Epoch 788: train_loss=27785.24805, val_loss=27565.42773\n",
      "Epoch 789: train_loss=27718.91992, val_loss=27499.31250\n",
      "Epoch 790: train_loss=27652.91016, val_loss=27433.52734\n",
      "Epoch 791: train_loss=27587.22266, val_loss=27368.08203\n",
      "Epoch 792: train_loss=27521.86719, val_loss=27302.97656\n",
      "Epoch 793: train_loss=27456.84180, val_loss=27238.21875\n",
      "Epoch 794: train_loss=27392.15234, val_loss=27173.80859\n",
      "Epoch 795: train_loss=27327.80273, val_loss=27109.75000\n",
      "Epoch 796: train_loss=27263.79688, val_loss=27046.04297\n",
      "Epoch 797: train_loss=27200.13281, val_loss=26982.69531\n",
      "Epoch 798: train_loss=27136.82617, val_loss=26919.71680\n",
      "Epoch 799: train_loss=27073.87109, val_loss=26857.10352\n",
      "Epoch 800: train_loss=27011.27344, val_loss=26794.85742\n",
      "Epoch 801: train_loss=26949.03320, val_loss=26732.98047\n",
      "Epoch 802: train_loss=26887.15625, val_loss=26671.49023\n",
      "Epoch 803: train_loss=26825.65039, val_loss=26610.38086\n",
      "Epoch 804: train_loss=26764.51953, val_loss=26549.66016\n",
      "Epoch 805: train_loss=26703.76953, val_loss=26489.32812\n",
      "Epoch 806: train_loss=26643.39648, val_loss=26429.39062\n",
      "Epoch 807: train_loss=26583.41016, val_loss=26369.84180\n",
      "Epoch 808: train_loss=26523.80664, val_loss=26310.69531\n",
      "Epoch 809: train_loss=26464.59180, val_loss=26251.94727\n",
      "Epoch 810: train_loss=26405.76953, val_loss=26193.59961\n",
      "Epoch 811: train_loss=26347.34570, val_loss=26135.66016\n",
      "Epoch 812: train_loss=26289.31250, val_loss=26078.12695\n",
      "Epoch 813: train_loss=26231.68164, val_loss=26021.00391\n",
      "Epoch 814: train_loss=26174.45312, val_loss=25964.29297\n",
      "Epoch 815: train_loss=26117.63086, val_loss=25907.99609\n",
      "Epoch 816: train_loss=26061.21094, val_loss=25852.11523\n",
      "Epoch 817: train_loss=26005.19727, val_loss=25796.64648\n",
      "Epoch 818: train_loss=25949.59375, val_loss=25741.59570\n",
      "Epoch 819: train_loss=25894.39844, val_loss=25686.96484\n",
      "Epoch 820: train_loss=25839.61328, val_loss=25632.75391\n",
      "Epoch 821: train_loss=25785.24414, val_loss=25578.96289\n",
      "Epoch 822: train_loss=25731.28516, val_loss=25525.59180\n",
      "Epoch 823: train_loss=25677.74023, val_loss=25472.64844\n",
      "Epoch 824: train_loss=25624.61328, val_loss=25420.12305\n",
      "Epoch 825: train_loss=25571.89844, val_loss=25368.01953\n",
      "Epoch 826: train_loss=25519.60352, val_loss=25316.34180\n",
      "Epoch 827: train_loss=25467.72266, val_loss=25265.09180\n",
      "Epoch 828: train_loss=25416.26172, val_loss=25214.26367\n",
      "Epoch 829: train_loss=25365.21680, val_loss=25163.86133\n",
      "Epoch 830: train_loss=25314.58789, val_loss=25113.88672\n",
      "Epoch 831: train_loss=25264.38086, val_loss=25064.33203\n",
      "Epoch 832: train_loss=25214.58594, val_loss=25015.20117\n",
      "Epoch 833: train_loss=25165.20703, val_loss=24966.49609\n",
      "Epoch 834: train_loss=25116.24414, val_loss=24918.21094\n",
      "Epoch 835: train_loss=25067.69727, val_loss=24870.34961\n",
      "Epoch 836: train_loss=25019.56641, val_loss=24822.90430\n",
      "Epoch 837: train_loss=24971.84375, val_loss=24775.88086\n",
      "Epoch 838: train_loss=24924.53906, val_loss=24729.27539\n",
      "Epoch 839: train_loss=24877.64453, val_loss=24683.08789\n",
      "Epoch 840: train_loss=24831.16016, val_loss=24637.31641\n",
      "Epoch 841: train_loss=24785.08203, val_loss=24591.95898\n",
      "Epoch 842: train_loss=24739.41602, val_loss=24547.01758\n",
      "Epoch 843: train_loss=24694.15234, val_loss=24502.48047\n",
      "Epoch 844: train_loss=24649.29492, val_loss=24458.35547\n",
      "Epoch 845: train_loss=24604.84180, val_loss=24414.63672\n",
      "Epoch 846: train_loss=24560.78906, val_loss=24371.32617\n",
      "Epoch 847: train_loss=24517.13086, val_loss=24328.41211\n",
      "Epoch 848: train_loss=24473.87305, val_loss=24285.90625\n",
      "Epoch 849: train_loss=24431.01172, val_loss=24243.79688\n",
      "Epoch 850: train_loss=24388.54297, val_loss=24202.08008\n",
      "Epoch 851: train_loss=24346.46094, val_loss=24160.75977\n",
      "Epoch 852: train_loss=24304.76953, val_loss=24119.83398\n",
      "Epoch 853: train_loss=24263.46680, val_loss=24079.29297\n",
      "Epoch 854: train_loss=24222.54883, val_loss=24039.13867\n",
      "Epoch 855: train_loss=24182.00977, val_loss=23999.36719\n",
      "Epoch 856: train_loss=24141.84766, val_loss=23959.97656\n",
      "Epoch 857: train_loss=24102.06250, val_loss=23920.96680\n",
      "Epoch 858: train_loss=24062.64844, val_loss=23882.32617\n",
      "Epoch 859: train_loss=24023.60742, val_loss=23844.05859\n",
      "Epoch 860: train_loss=23984.92969, val_loss=23806.16016\n",
      "Epoch 861: train_loss=23946.61914, val_loss=23768.62695\n",
      "Epoch 862: train_loss=23908.66406, val_loss=23731.45117\n",
      "Epoch 863: train_loss=23871.06836, val_loss=23694.63672\n",
      "Epoch 864: train_loss=23833.82617, val_loss=23658.17969\n",
      "Epoch 865: train_loss=23796.93555, val_loss=23622.07422\n",
      "Epoch 866: train_loss=23760.39453, val_loss=23586.31445\n",
      "Epoch 867: train_loss=23724.19531, val_loss=23550.90234\n",
      "Epoch 868: train_loss=23688.33789, val_loss=23515.83203\n",
      "Epoch 869: train_loss=23652.82031, val_loss=23481.09570\n",
      "Epoch 870: train_loss=23617.63281, val_loss=23446.69336\n",
      "Epoch 871: train_loss=23582.77734, val_loss=23412.62305\n",
      "Epoch 872: train_loss=23548.24805, val_loss=23378.87891\n",
      "Epoch 873: train_loss=23514.04297, val_loss=23345.45898\n",
      "Epoch 874: train_loss=23480.15625, val_loss=23312.35352\n",
      "Epoch 875: train_loss=23446.58594, val_loss=23279.56641\n",
      "Epoch 876: train_loss=23413.32617, val_loss=23247.08594\n",
      "Epoch 877: train_loss=23380.37305, val_loss=23214.91602\n",
      "Epoch 878: train_loss=23347.72461, val_loss=23183.04688\n",
      "Epoch 879: train_loss=23315.37500, val_loss=23151.47852\n",
      "Epoch 880: train_loss=23283.32422, val_loss=23120.20117\n",
      "Epoch 881: train_loss=23251.56641, val_loss=23089.21680\n",
      "Epoch 882: train_loss=23220.09570, val_loss=23058.51758\n",
      "Epoch 883: train_loss=23188.91016, val_loss=23028.10352\n",
      "Epoch 884: train_loss=23158.00391, val_loss=22997.96484\n",
      "Epoch 885: train_loss=23127.37500, val_loss=22968.10352\n",
      "Epoch 886: train_loss=23097.02148, val_loss=22938.51562\n",
      "Epoch 887: train_loss=23066.93750, val_loss=22909.19336\n",
      "Epoch 888: train_loss=23037.11523, val_loss=22880.13477\n",
      "Epoch 889: train_loss=23007.55859, val_loss=22851.33789\n",
      "Epoch 890: train_loss=22978.25977, val_loss=22822.79492\n",
      "Epoch 891: train_loss=22949.21484, val_loss=22794.50195\n",
      "Epoch 892: train_loss=22920.41797, val_loss=22766.45703\n",
      "Epoch 893: train_loss=22891.86914, val_loss=22738.65234\n",
      "Epoch 894: train_loss=22863.56250, val_loss=22711.09180\n",
      "Epoch 895: train_loss=22835.49414, val_loss=22683.76562\n",
      "Epoch 896: train_loss=22807.66016, val_loss=22656.67188\n",
      "Epoch 897: train_loss=22780.05859, val_loss=22629.80859\n",
      "Epoch 898: train_loss=22752.68555, val_loss=22603.16406\n",
      "Epoch 899: train_loss=22725.53516, val_loss=22576.74023\n",
      "Epoch 900: train_loss=22698.60352, val_loss=22550.53711\n",
      "Epoch 901: train_loss=22671.89258, val_loss=22524.54883\n",
      "Epoch 902: train_loss=22645.39062, val_loss=22498.76758\n",
      "Epoch 903: train_loss=22619.09961, val_loss=22473.19531\n",
      "Epoch 904: train_loss=22593.01562, val_loss=22447.82422\n",
      "Epoch 905: train_loss=22567.13086, val_loss=22422.65430\n",
      "Epoch 906: train_loss=22541.44922, val_loss=22397.67578\n",
      "Epoch 907: train_loss=22515.96094, val_loss=22372.89453\n",
      "Epoch 908: train_loss=22490.66797, val_loss=22348.30273\n",
      "Epoch 909: train_loss=22465.56250, val_loss=22323.89258\n",
      "Epoch 910: train_loss=22440.64258, val_loss=22299.66797\n",
      "Epoch 911: train_loss=22415.90234, val_loss=22275.61914\n",
      "Epoch 912: train_loss=22391.34375, val_loss=22251.74609\n",
      "Epoch 913: train_loss=22366.95898, val_loss=22228.04883\n",
      "Epoch 914: train_loss=22342.74805, val_loss=22204.51562\n",
      "Epoch 915: train_loss=22318.70703, val_loss=22181.15039\n",
      "Epoch 916: train_loss=22294.83203, val_loss=22157.94922\n",
      "Epoch 917: train_loss=22271.12305, val_loss=22134.91016\n",
      "Epoch 918: train_loss=22247.57031, val_loss=22112.02539\n",
      "Epoch 919: train_loss=22224.17969, val_loss=22089.29688\n",
      "Epoch 920: train_loss=22200.93750, val_loss=22066.71484\n",
      "Epoch 921: train_loss=22177.85156, val_loss=22044.28320\n",
      "Epoch 922: train_loss=22154.91602, val_loss=22021.99805\n",
      "Epoch 923: train_loss=22132.12305, val_loss=21999.85156\n",
      "Epoch 924: train_loss=22109.47461, val_loss=21977.84570\n",
      "Epoch 925: train_loss=22086.96484, val_loss=21955.97461\n",
      "Epoch 926: train_loss=22064.59570, val_loss=21934.24219\n",
      "Epoch 927: train_loss=22042.35742, val_loss=21912.63672\n",
      "Epoch 928: train_loss=22020.25391, val_loss=21891.16016\n",
      "Epoch 929: train_loss=21998.27734, val_loss=21869.81055\n",
      "Epoch 930: train_loss=21976.42773, val_loss=21848.58008\n",
      "Epoch 931: train_loss=21954.70117, val_loss=21827.47266\n",
      "Epoch 932: train_loss=21933.09766, val_loss=21806.48438\n",
      "Epoch 933: train_loss=21911.61719, val_loss=21785.61328\n",
      "Epoch 934: train_loss=21890.25195, val_loss=21764.85352\n",
      "Epoch 935: train_loss=21869.00391, val_loss=21744.21289\n",
      "Epoch 936: train_loss=21847.86914, val_loss=21723.67773\n",
      "Epoch 937: train_loss=21826.84766, val_loss=21703.25391\n",
      "Epoch 938: train_loss=21805.93359, val_loss=21682.93359\n",
      "Epoch 939: train_loss=21785.12891, val_loss=21662.72070\n",
      "Epoch 940: train_loss=21764.42969, val_loss=21642.61133\n",
      "Epoch 941: train_loss=21743.83594, val_loss=21622.59766\n",
      "Epoch 942: train_loss=21723.34180, val_loss=21602.68555\n",
      "Epoch 943: train_loss=21702.94922, val_loss=21582.87305\n",
      "Epoch 944: train_loss=21682.65625, val_loss=21563.15625\n",
      "Epoch 945: train_loss=21662.46094, val_loss=21543.53125\n",
      "Epoch 946: train_loss=21642.35938, val_loss=21523.99805\n",
      "Epoch 947: train_loss=21622.35352, val_loss=21504.55664\n",
      "Epoch 948: train_loss=21602.43555, val_loss=21485.20703\n",
      "Epoch 949: train_loss=21582.61328, val_loss=21465.93945\n",
      "Epoch 950: train_loss=21562.87500, val_loss=21446.76172\n",
      "Epoch 951: train_loss=21543.22656, val_loss=21427.66602\n",
      "Epoch 952: train_loss=21523.66211, val_loss=21408.65430\n",
      "Epoch 953: train_loss=21504.18359, val_loss=21389.72266\n",
      "Epoch 954: train_loss=21484.78711, val_loss=21370.87500\n",
      "Epoch 955: train_loss=21465.47070, val_loss=21352.09961\n",
      "Epoch 956: train_loss=21446.23438, val_loss=21333.40430\n",
      "Epoch 957: train_loss=21427.07617, val_loss=21314.78516\n",
      "Epoch 958: train_loss=21407.99609, val_loss=21296.23828\n",
      "Epoch 959: train_loss=21388.99023, val_loss=21277.76562\n",
      "Epoch 960: train_loss=21370.06055, val_loss=21259.36523\n",
      "Epoch 961: train_loss=21351.20312, val_loss=21241.03320\n",
      "Epoch 962: train_loss=21332.41797, val_loss=21222.77148\n",
      "Epoch 963: train_loss=21313.70312, val_loss=21204.57812\n",
      "Epoch 964: train_loss=21295.05859, val_loss=21186.45508\n",
      "Epoch 965: train_loss=21276.48047, val_loss=21168.39453\n",
      "Epoch 966: train_loss=21257.97656, val_loss=21150.39844\n",
      "Epoch 967: train_loss=21239.53125, val_loss=21132.46680\n",
      "Epoch 968: train_loss=21221.15430, val_loss=21114.59961\n",
      "Epoch 969: train_loss=21202.84180, val_loss=21096.78906\n",
      "Epoch 970: train_loss=21184.59375, val_loss=21079.04688\n",
      "Epoch 971: train_loss=21166.40625, val_loss=21061.36133\n",
      "Epoch 972: train_loss=21148.28125, val_loss=21043.73438\n",
      "Epoch 973: train_loss=21130.21680, val_loss=21026.16797\n",
      "Epoch 974: train_loss=21112.21094, val_loss=21008.65625\n",
      "Epoch 975: train_loss=21094.26562, val_loss=20991.20312\n",
      "Epoch 976: train_loss=21076.37891, val_loss=20973.80469\n",
      "Epoch 977: train_loss=21058.54492, val_loss=20956.46094\n",
      "Epoch 978: train_loss=21040.77148, val_loss=20939.17383\n",
      "Epoch 979: train_loss=21023.05078, val_loss=20921.93750\n",
      "Epoch 980: train_loss=21005.38867, val_loss=20904.75586\n",
      "Epoch 981: train_loss=20987.77734, val_loss=20887.62695\n",
      "Epoch 982: train_loss=20970.22266, val_loss=20870.54883\n",
      "Epoch 983: train_loss=20952.71875, val_loss=20853.51953\n",
      "Epoch 984: train_loss=20935.26758, val_loss=20836.54297\n",
      "Epoch 985: train_loss=20917.86523, val_loss=20819.61523\n",
      "Epoch 986: train_loss=20900.51367, val_loss=20802.73633\n",
      "Epoch 987: train_loss=20883.21484, val_loss=20785.90430\n",
      "Epoch 988: train_loss=20865.96484, val_loss=20769.11914\n",
      "Epoch 989: train_loss=20848.76367, val_loss=20752.38086\n",
      "Epoch 990: train_loss=20831.60742, val_loss=20735.69141\n",
      "Epoch 991: train_loss=20814.50391, val_loss=20719.04688\n",
      "Epoch 992: train_loss=20797.44141, val_loss=20702.44727\n",
      "Epoch 993: train_loss=20780.42969, val_loss=20685.88867\n",
      "Epoch 994: train_loss=20763.46094, val_loss=20669.37695\n",
      "Epoch 995: train_loss=20746.53906, val_loss=20652.90820\n",
      "Epoch 996: train_loss=20729.66211, val_loss=20636.48047\n",
      "Epoch 997: train_loss=20712.83008, val_loss=20620.09766\n",
      "Epoch 998: train_loss=20696.03906, val_loss=20603.75586\n",
      "Epoch 999: train_loss=20679.29297, val_loss=20587.45898\n",
      "Epoch 1000: train_loss=20662.58789, val_loss=20571.19922\n",
      "Epoch 1001: train_loss=20645.92578, val_loss=20554.98242\n",
      "Epoch 1002: train_loss=20629.30469, val_loss=20538.80469\n",
      "Epoch 1003: train_loss=20612.72656, val_loss=20522.66992\n",
      "Epoch 1004: train_loss=20596.19141, val_loss=20506.57227\n",
      "Epoch 1005: train_loss=20579.69531, val_loss=20490.51367\n",
      "Epoch 1006: train_loss=20563.23828, val_loss=20474.49414\n",
      "Epoch 1007: train_loss=20546.82227, val_loss=20458.51367\n",
      "Epoch 1008: train_loss=20530.44531, val_loss=20442.57227\n",
      "Epoch 1009: train_loss=20514.11133, val_loss=20426.66602\n",
      "Epoch 1010: train_loss=20497.80859, val_loss=20410.80078\n",
      "Epoch 1011: train_loss=20481.55078, val_loss=20394.97070\n",
      "Epoch 1012: train_loss=20465.32812, val_loss=20379.17773\n",
      "Epoch 1013: train_loss=20449.14258, val_loss=20363.42188\n",
      "Epoch 1014: train_loss=20432.99609, val_loss=20347.70117\n",
      "Epoch 1015: train_loss=20416.88672, val_loss=20332.01758\n",
      "Epoch 1016: train_loss=20400.81445, val_loss=20316.36719\n",
      "Epoch 1017: train_loss=20384.77539, val_loss=20300.75195\n",
      "Epoch 1018: train_loss=20368.77344, val_loss=20285.17188\n",
      "Epoch 1019: train_loss=20352.80664, val_loss=20269.62891\n",
      "Epoch 1020: train_loss=20336.87305, val_loss=20254.11523\n",
      "Epoch 1021: train_loss=20320.97656, val_loss=20238.63672\n",
      "Epoch 1022: train_loss=20305.11719, val_loss=20223.19531\n",
      "Epoch 1023: train_loss=20289.28711, val_loss=20207.78320\n",
      "Epoch 1024: train_loss=20273.49414, val_loss=20192.40430\n",
      "Epoch 1025: train_loss=20257.73242, val_loss=20177.05859\n",
      "Epoch 1026: train_loss=20242.00586, val_loss=20161.74414\n",
      "Epoch 1027: train_loss=20226.31250, val_loss=20146.46289\n",
      "Epoch 1028: train_loss=20210.65039, val_loss=20131.21289\n",
      "Epoch 1029: train_loss=20195.02148, val_loss=20115.99609\n",
      "Epoch 1030: train_loss=20179.42383, val_loss=20100.81055\n",
      "Epoch 1031: train_loss=20163.86133, val_loss=20085.65430\n",
      "Epoch 1032: train_loss=20148.33008, val_loss=20070.53125\n",
      "Epoch 1033: train_loss=20132.82812, val_loss=20055.43750\n",
      "Epoch 1034: train_loss=20117.35742, val_loss=20040.37500\n",
      "Epoch 1035: train_loss=20101.91992, val_loss=20025.34180\n",
      "Epoch 1036: train_loss=20086.51367, val_loss=20010.33984\n",
      "Epoch 1037: train_loss=20071.13672, val_loss=19995.36719\n",
      "Epoch 1038: train_loss=20055.79102, val_loss=19980.42383\n",
      "Epoch 1039: train_loss=20040.47461, val_loss=19965.50977\n",
      "Epoch 1040: train_loss=20025.19141, val_loss=19950.62695\n",
      "Epoch 1041: train_loss=20009.93555, val_loss=19935.77148\n",
      "Epoch 1042: train_loss=19994.71094, val_loss=19920.94531\n",
      "Epoch 1043: train_loss=19979.51367, val_loss=19906.15039\n",
      "Epoch 1044: train_loss=19964.34570, val_loss=19891.38086\n",
      "Epoch 1045: train_loss=19949.20898, val_loss=19876.64062\n",
      "Epoch 1046: train_loss=19934.10156, val_loss=19861.93164\n",
      "Epoch 1047: train_loss=19919.01953, val_loss=19847.24609\n",
      "Epoch 1048: train_loss=19903.96875, val_loss=19832.58789\n",
      "Epoch 1049: train_loss=19888.94531, val_loss=19817.96094\n",
      "Epoch 1050: train_loss=19873.95117, val_loss=19803.35938\n",
      "Epoch 1051: train_loss=19858.98633, val_loss=19788.78516\n",
      "Epoch 1052: train_loss=19844.04492, val_loss=19774.24023\n",
      "Epoch 1053: train_loss=19829.13281, val_loss=19759.71875\n",
      "Epoch 1054: train_loss=19814.25000, val_loss=19745.22656\n",
      "Epoch 1055: train_loss=19799.39648, val_loss=19730.76367\n",
      "Epoch 1056: train_loss=19784.56836, val_loss=19716.32227\n",
      "Epoch 1057: train_loss=19769.76562, val_loss=19701.91016\n",
      "Epoch 1058: train_loss=19754.98828, val_loss=19687.52344\n",
      "Epoch 1059: train_loss=19740.24219, val_loss=19673.16406\n",
      "Epoch 1060: train_loss=19725.52148, val_loss=19658.82812\n",
      "Epoch 1061: train_loss=19710.82422, val_loss=19644.51953\n",
      "Epoch 1062: train_loss=19696.15430, val_loss=19630.23633\n",
      "Epoch 1063: train_loss=19681.51172, val_loss=19615.97656\n",
      "Epoch 1064: train_loss=19666.89062, val_loss=19601.74414\n",
      "Epoch 1065: train_loss=19652.29883, val_loss=19587.53711\n",
      "Epoch 1066: train_loss=19637.73047, val_loss=19573.35352\n",
      "Epoch 1067: train_loss=19623.18945, val_loss=19559.19531\n",
      "Epoch 1068: train_loss=19608.67383, val_loss=19545.06250\n",
      "Epoch 1069: train_loss=19594.18359, val_loss=19530.95312\n",
      "Epoch 1070: train_loss=19579.71680, val_loss=19516.86914\n",
      "Epoch 1071: train_loss=19565.27539, val_loss=19502.81055\n",
      "Epoch 1072: train_loss=19550.85938, val_loss=19488.77344\n",
      "Epoch 1073: train_loss=19536.46875, val_loss=19474.76367\n",
      "Epoch 1074: train_loss=19522.10352, val_loss=19460.77539\n",
      "Epoch 1075: train_loss=19507.76172, val_loss=19446.81250\n",
      "Epoch 1076: train_loss=19493.44336, val_loss=19432.87305\n",
      "Epoch 1077: train_loss=19479.14844, val_loss=19418.95898\n",
      "Epoch 1078: train_loss=19464.87695, val_loss=19405.06641\n",
      "Epoch 1079: train_loss=19450.63086, val_loss=19391.19531\n",
      "Epoch 1080: train_loss=19436.40625, val_loss=19377.34766\n",
      "Epoch 1081: train_loss=19422.20508, val_loss=19363.52344\n",
      "Epoch 1082: train_loss=19408.02734, val_loss=19349.72266\n",
      "Epoch 1083: train_loss=19393.87305, val_loss=19335.94336\n",
      "Epoch 1084: train_loss=19379.74219, val_loss=19322.18945\n",
      "Epoch 1085: train_loss=19365.63477, val_loss=19308.45312\n",
      "Epoch 1086: train_loss=19351.54883, val_loss=19294.74219\n",
      "Epoch 1087: train_loss=19337.48633, val_loss=19281.05469\n",
      "Epoch 1088: train_loss=19323.44531, val_loss=19267.38672\n",
      "Epoch 1089: train_loss=19309.42773, val_loss=19253.74219\n",
      "Epoch 1090: train_loss=19295.43164, val_loss=19240.11914\n",
      "Epoch 1091: train_loss=19281.45703, val_loss=19226.51953\n",
      "Epoch 1092: train_loss=19267.50586, val_loss=19212.93750\n",
      "Epoch 1093: train_loss=19253.57617, val_loss=19199.38086\n",
      "Epoch 1094: train_loss=19239.66992, val_loss=19185.84375\n",
      "Epoch 1095: train_loss=19225.78711, val_loss=19172.33008\n",
      "Epoch 1096: train_loss=19211.92188, val_loss=19158.83594\n",
      "Epoch 1097: train_loss=19198.08203, val_loss=19145.36328\n",
      "Epoch 1098: train_loss=19184.26172, val_loss=19131.91211\n",
      "Epoch 1099: train_loss=19170.46094, val_loss=19118.48242\n",
      "Epoch 1100: train_loss=19156.68164, val_loss=19105.07422\n",
      "Epoch 1101: train_loss=19142.92773, val_loss=19091.68555\n",
      "Epoch 1102: train_loss=19129.19531, val_loss=19078.31836\n",
      "Epoch 1103: train_loss=19115.48047, val_loss=19064.97070\n",
      "Epoch 1104: train_loss=19101.78516, val_loss=19051.64648\n",
      "Epoch 1105: train_loss=19088.11523, val_loss=19038.33789\n",
      "Epoch 1106: train_loss=19074.46289, val_loss=19025.05469\n",
      "Epoch 1107: train_loss=19060.83398, val_loss=19011.78906\n",
      "Epoch 1108: train_loss=19047.22266, val_loss=18998.54297\n",
      "Epoch 1109: train_loss=19033.63086, val_loss=18985.31836\n",
      "Epoch 1110: train_loss=19020.06250, val_loss=18972.11328\n",
      "Epoch 1111: train_loss=19006.51367, val_loss=18958.93164\n",
      "Epoch 1112: train_loss=18992.98828, val_loss=18945.77539\n",
      "Epoch 1113: train_loss=18979.48633, val_loss=18932.63672\n",
      "Epoch 1114: train_loss=18966.00586, val_loss=18919.52148\n",
      "Epoch 1115: train_loss=18952.54688, val_loss=18906.42383\n",
      "Epoch 1116: train_loss=18939.10742, val_loss=18893.34766\n",
      "Epoch 1117: train_loss=18925.68750, val_loss=18880.29297\n",
      "Epoch 1118: train_loss=18912.29102, val_loss=18867.25977\n",
      "Epoch 1119: train_loss=18898.91016, val_loss=18854.24414\n",
      "Epoch 1120: train_loss=18885.55273, val_loss=18841.25195\n",
      "Epoch 1121: train_loss=18872.21484, val_loss=18828.27539\n",
      "Epoch 1122: train_loss=18858.89648, val_loss=18815.32031\n",
      "Epoch 1123: train_loss=18845.59570, val_loss=18802.38086\n",
      "Epoch 1124: train_loss=18832.31641, val_loss=18789.46289\n",
      "Epoch 1125: train_loss=18819.05469, val_loss=18776.56445\n",
      "Epoch 1126: train_loss=18805.81250, val_loss=18763.68359\n",
      "Epoch 1127: train_loss=18792.59180, val_loss=18750.82227\n",
      "Epoch 1128: train_loss=18779.38477, val_loss=18737.97852\n",
      "Epoch 1129: train_loss=18766.19922, val_loss=18725.15234\n",
      "Epoch 1130: train_loss=18753.03320, val_loss=18712.34570\n",
      "Epoch 1131: train_loss=18739.88281, val_loss=18699.55469\n",
      "Epoch 1132: train_loss=18726.75586, val_loss=18686.78320\n",
      "Epoch 1133: train_loss=18713.64258, val_loss=18674.03125\n",
      "Epoch 1134: train_loss=18700.54883, val_loss=18661.29492\n",
      "Epoch 1135: train_loss=18687.47461, val_loss=18648.58008\n",
      "Epoch 1136: train_loss=18674.41797, val_loss=18635.88867\n",
      "Epoch 1137: train_loss=18661.38477, val_loss=18623.21875\n",
      "Epoch 1138: train_loss=18648.37109, val_loss=18610.56445\n",
      "Epoch 1139: train_loss=18635.37695, val_loss=18597.92773\n",
      "Epoch 1140: train_loss=18622.40039, val_loss=18585.31055\n",
      "Epoch 1141: train_loss=18609.44141, val_loss=18572.70898\n",
      "Epoch 1142: train_loss=18596.50195, val_loss=18560.12500\n",
      "Epoch 1143: train_loss=18583.58008, val_loss=18547.55859\n",
      "Epoch 1144: train_loss=18570.67383, val_loss=18535.00977\n",
      "Epoch 1145: train_loss=18557.78906, val_loss=18522.47656\n",
      "Epoch 1146: train_loss=18544.91797, val_loss=18509.96289\n",
      "Epoch 1147: train_loss=18532.06445, val_loss=18497.47070\n",
      "Epoch 1148: train_loss=18519.23438, val_loss=18485.00195\n",
      "Epoch 1149: train_loss=18506.42188, val_loss=18472.54883\n",
      "Epoch 1150: train_loss=18493.62695, val_loss=18460.11328\n",
      "Epoch 1151: train_loss=18480.84961, val_loss=18447.69336\n",
      "Epoch 1152: train_loss=18468.09180, val_loss=18435.29297\n",
      "Epoch 1153: train_loss=18455.34766, val_loss=18422.90820\n",
      "Epoch 1154: train_loss=18442.62500, val_loss=18410.53906\n",
      "Epoch 1155: train_loss=18429.91797, val_loss=18398.18750\n",
      "Epoch 1156: train_loss=18417.22461, val_loss=18385.85156\n",
      "Epoch 1157: train_loss=18404.55078, val_loss=18373.53320\n",
      "Epoch 1158: train_loss=18391.89453, val_loss=18361.23438\n",
      "Epoch 1159: train_loss=18379.25391, val_loss=18348.94727\n",
      "Epoch 1160: train_loss=18366.63086, val_loss=18336.67969\n",
      "Epoch 1161: train_loss=18354.02734, val_loss=18324.43164\n",
      "Epoch 1162: train_loss=18341.44336, val_loss=18312.20508\n",
      "Epoch 1163: train_loss=18328.87500, val_loss=18299.99219\n",
      "Epoch 1164: train_loss=18316.32617, val_loss=18287.79883\n",
      "Epoch 1165: train_loss=18303.79297, val_loss=18275.62109\n",
      "Epoch 1166: train_loss=18291.27539, val_loss=18263.46094\n",
      "Epoch 1167: train_loss=18278.77539, val_loss=18251.31641\n",
      "Epoch 1168: train_loss=18266.28906, val_loss=18239.18945\n",
      "Epoch 1169: train_loss=18253.82227, val_loss=18227.08008\n",
      "Epoch 1170: train_loss=18241.37305, val_loss=18214.98242\n",
      "Epoch 1171: train_loss=18228.93750, val_loss=18202.90430\n",
      "Epoch 1172: train_loss=18216.51953, val_loss=18190.83984\n",
      "Epoch 1173: train_loss=18204.12305, val_loss=18178.79492\n",
      "Epoch 1174: train_loss=18191.73828, val_loss=18166.76367\n",
      "Epoch 1175: train_loss=18179.37305, val_loss=18154.75000\n",
      "Epoch 1176: train_loss=18167.02148, val_loss=18142.75195\n",
      "Epoch 1177: train_loss=18154.68750, val_loss=18130.77148\n",
      "Epoch 1178: train_loss=18142.36914, val_loss=18118.80273\n",
      "Epoch 1179: train_loss=18130.06250, val_loss=18106.84961\n",
      "Epoch 1180: train_loss=18117.77539, val_loss=18094.91406\n",
      "Epoch 1181: train_loss=18105.50195, val_loss=18082.99023\n",
      "Epoch 1182: train_loss=18093.24609, val_loss=18071.08594\n",
      "Epoch 1183: train_loss=18081.00195, val_loss=18059.19336\n",
      "Epoch 1184: train_loss=18068.77344, val_loss=18047.31641\n",
      "Epoch 1185: train_loss=18056.56055, val_loss=18035.45508\n",
      "Epoch 1186: train_loss=18044.36328, val_loss=18023.61133\n",
      "Epoch 1187: train_loss=18032.17773, val_loss=18011.78125\n",
      "Epoch 1188: train_loss=18020.01172, val_loss=17999.96484\n",
      "Epoch 1189: train_loss=18007.85938, val_loss=17988.16406\n",
      "Epoch 1190: train_loss=17995.72070, val_loss=17976.38086\n",
      "Epoch 1191: train_loss=17983.59961, val_loss=17964.61133\n",
      "Epoch 1192: train_loss=17971.49414, val_loss=17952.85547\n",
      "Epoch 1193: train_loss=17959.40234, val_loss=17941.11719\n",
      "Epoch 1194: train_loss=17947.33008, val_loss=17929.39258\n",
      "Epoch 1195: train_loss=17935.26758, val_loss=17917.68359\n",
      "Epoch 1196: train_loss=17923.22461, val_loss=17905.98633\n",
      "Epoch 1197: train_loss=17911.19141, val_loss=17894.30664\n",
      "Epoch 1198: train_loss=17899.17383, val_loss=17882.63672\n",
      "Epoch 1199: train_loss=17887.17383, val_loss=17870.98438\n",
      "Epoch 1200: train_loss=17875.18164, val_loss=17859.34180\n",
      "Epoch 1201: train_loss=17863.20898, val_loss=17847.71484\n",
      "Epoch 1202: train_loss=17851.25000, val_loss=17836.10547\n",
      "Epoch 1203: train_loss=17839.30664, val_loss=17824.50781\n",
      "Epoch 1204: train_loss=17827.37695, val_loss=17812.92578\n",
      "Epoch 1205: train_loss=17815.46289, val_loss=17801.36133\n",
      "Epoch 1206: train_loss=17803.56445, val_loss=17789.80859\n",
      "Epoch 1207: train_loss=17791.67578, val_loss=17778.27148\n",
      "Epoch 1208: train_loss=17779.80469, val_loss=17766.74805\n",
      "Epoch 1209: train_loss=17767.94531, val_loss=17755.23438\n",
      "Epoch 1210: train_loss=17756.09961, val_loss=17743.73633\n",
      "Epoch 1211: train_loss=17744.27148, val_loss=17732.25000\n",
      "Epoch 1212: train_loss=17732.45117, val_loss=17720.77734\n",
      "Epoch 1213: train_loss=17720.64648, val_loss=17709.32031\n",
      "Epoch 1214: train_loss=17708.85547, val_loss=17697.87305\n",
      "Epoch 1215: train_loss=17697.07422, val_loss=17686.43750\n",
      "Epoch 1216: train_loss=17685.30859, val_loss=17675.01562\n",
      "Epoch 1217: train_loss=17673.55469, val_loss=17663.60742\n",
      "Epoch 1218: train_loss=17661.81641, val_loss=17652.21094\n",
      "Epoch 1219: train_loss=17650.08789, val_loss=17640.82617\n",
      "Epoch 1220: train_loss=17638.37500, val_loss=17629.45703\n",
      "Epoch 1221: train_loss=17626.67188, val_loss=17618.09766\n",
      "Epoch 1222: train_loss=17614.98047, val_loss=17606.75195\n",
      "Epoch 1223: train_loss=17603.30664, val_loss=17595.41797\n",
      "Epoch 1224: train_loss=17591.64258, val_loss=17584.09375\n",
      "Epoch 1225: train_loss=17579.99023, val_loss=17572.78320\n",
      "Epoch 1226: train_loss=17568.35156, val_loss=17561.48438\n",
      "Epoch 1227: train_loss=17556.72656, val_loss=17550.20312\n",
      "Epoch 1228: train_loss=17545.11328, val_loss=17538.93359\n",
      "Epoch 1229: train_loss=17533.51367, val_loss=17527.67578\n",
      "Epoch 1230: train_loss=17521.92969, val_loss=17516.42969\n",
      "Epoch 1231: train_loss=17510.35547, val_loss=17505.19727\n",
      "Epoch 1232: train_loss=17498.79297, val_loss=17493.97461\n",
      "Epoch 1233: train_loss=17487.24414, val_loss=17482.76367\n",
      "Epoch 1234: train_loss=17475.70508, val_loss=17471.56641\n",
      "Epoch 1235: train_loss=17464.17969, val_loss=17460.37891\n",
      "Epoch 1236: train_loss=17452.66602, val_loss=17449.20508\n",
      "Epoch 1237: train_loss=17441.16406, val_loss=17438.03906\n",
      "Epoch 1238: train_loss=17429.67383, val_loss=17426.89062\n",
      "Epoch 1239: train_loss=17418.19531, val_loss=17415.75000\n",
      "Epoch 1240: train_loss=17406.72852, val_loss=17404.62109\n",
      "Epoch 1241: train_loss=17395.27539, val_loss=17393.50391\n",
      "Epoch 1242: train_loss=17383.83203, val_loss=17382.39844\n",
      "Epoch 1243: train_loss=17372.40039, val_loss=17371.30469\n",
      "Epoch 1244: train_loss=17360.97852, val_loss=17360.21875\n",
      "Epoch 1245: train_loss=17349.57031, val_loss=17349.14648\n",
      "Epoch 1246: train_loss=17338.17383, val_loss=17338.08594\n",
      "Epoch 1247: train_loss=17326.78711, val_loss=17327.03516\n",
      "Epoch 1248: train_loss=17315.41602, val_loss=17315.99609\n",
      "Epoch 1249: train_loss=17304.05078, val_loss=17304.97070\n",
      "Epoch 1250: train_loss=17292.70117, val_loss=17293.95508\n",
      "Epoch 1251: train_loss=17281.36328, val_loss=17282.94922\n",
      "Epoch 1252: train_loss=17270.03320, val_loss=17271.95703\n",
      "Epoch 1253: train_loss=17258.71680, val_loss=17260.97656\n",
      "Epoch 1254: train_loss=17247.41211, val_loss=17250.00781\n",
      "Epoch 1255: train_loss=17236.11719, val_loss=17239.04688\n",
      "Epoch 1256: train_loss=17224.83398, val_loss=17228.10156\n",
      "Epoch 1257: train_loss=17213.56250, val_loss=17217.16406\n",
      "Epoch 1258: train_loss=17202.30273, val_loss=17206.24023\n",
      "Epoch 1259: train_loss=17191.05469, val_loss=17195.32617\n",
      "Epoch 1260: train_loss=17179.81641, val_loss=17184.41992\n",
      "Epoch 1261: train_loss=17168.58789, val_loss=17173.52734\n",
      "Epoch 1262: train_loss=17157.36914, val_loss=17162.64062\n",
      "Epoch 1263: train_loss=17146.16406, val_loss=17151.76758\n",
      "Epoch 1264: train_loss=17134.96680, val_loss=17140.90430\n",
      "Epoch 1265: train_loss=17123.78125, val_loss=17130.05273\n",
      "Epoch 1266: train_loss=17112.60547, val_loss=17119.21094\n",
      "Epoch 1267: train_loss=17101.44141, val_loss=17108.37891\n",
      "Epoch 1268: train_loss=17090.28516, val_loss=17097.55469\n",
      "Epoch 1269: train_loss=17079.14062, val_loss=17086.74414\n",
      "Epoch 1270: train_loss=17068.00977, val_loss=17075.94336\n",
      "Epoch 1271: train_loss=17056.88477, val_loss=17065.15234\n",
      "Epoch 1272: train_loss=17045.77148, val_loss=17054.37109\n",
      "Epoch 1273: train_loss=17034.66797, val_loss=17043.59961\n",
      "Epoch 1274: train_loss=17023.57617, val_loss=17032.83984\n",
      "Epoch 1275: train_loss=17012.49414, val_loss=17022.08789\n",
      "Epoch 1276: train_loss=17001.42188, val_loss=17011.34766\n",
      "Epoch 1277: train_loss=16990.36133, val_loss=17000.61914\n",
      "Epoch 1278: train_loss=16979.31055, val_loss=16989.89844\n",
      "Epoch 1279: train_loss=16968.27148, val_loss=16979.18945\n",
      "Epoch 1280: train_loss=16957.23828, val_loss=16968.48828\n",
      "Epoch 1281: train_loss=16946.21875, val_loss=16957.79883\n",
      "Epoch 1282: train_loss=16935.20898, val_loss=16947.11914\n",
      "Epoch 1283: train_loss=16924.20703, val_loss=16936.44727\n",
      "Epoch 1284: train_loss=16913.21484, val_loss=16925.78711\n",
      "Epoch 1285: train_loss=16902.23438, val_loss=16915.13477\n",
      "Epoch 1286: train_loss=16891.26367, val_loss=16904.49414\n",
      "Epoch 1287: train_loss=16880.30078, val_loss=16893.86328\n",
      "Epoch 1288: train_loss=16869.34961, val_loss=16883.23828\n",
      "Epoch 1289: train_loss=16858.40820, val_loss=16872.62305\n",
      "Epoch 1290: train_loss=16847.47461, val_loss=16862.01953\n",
      "Epoch 1291: train_loss=16836.55078, val_loss=16851.42578\n",
      "Epoch 1292: train_loss=16825.63867, val_loss=16840.83984\n",
      "Epoch 1293: train_loss=16814.73047, val_loss=16830.25977\n",
      "Epoch 1294: train_loss=16803.83789, val_loss=16819.69141\n",
      "Epoch 1295: train_loss=16792.95117, val_loss=16809.13281\n",
      "Epoch 1296: train_loss=16782.07422, val_loss=16798.58398\n",
      "Epoch 1297: train_loss=16771.20898, val_loss=16788.04492\n",
      "Epoch 1298: train_loss=16760.35156, val_loss=16777.51562\n",
      "Epoch 1299: train_loss=16749.50391, val_loss=16766.99414\n",
      "Epoch 1300: train_loss=16738.66602, val_loss=16756.49023\n",
      "Epoch 1301: train_loss=16727.84180, val_loss=16745.99414\n",
      "Epoch 1302: train_loss=16717.03125, val_loss=16735.50781\n",
      "Epoch 1303: train_loss=16706.23047, val_loss=16725.03125\n",
      "Epoch 1304: train_loss=16695.43945, val_loss=16714.56641\n",
      "Epoch 1305: train_loss=16684.65820, val_loss=16704.11328\n",
      "Epoch 1306: train_loss=16673.88672, val_loss=16693.66797\n",
      "Epoch 1307: train_loss=16663.12695, val_loss=16683.23828\n",
      "Epoch 1308: train_loss=16652.37891, val_loss=16672.82227\n",
      "Epoch 1309: train_loss=16641.64844, val_loss=16662.41797\n",
      "Epoch 1310: train_loss=16630.92188, val_loss=16652.02539\n",
      "Epoch 1311: train_loss=16620.20898, val_loss=16641.64062\n",
      "Epoch 1312: train_loss=16609.50781, val_loss=16631.26562\n",
      "Epoch 1313: train_loss=16598.81445, val_loss=16620.90234\n",
      "Epoch 1314: train_loss=16588.13281, val_loss=16610.55078\n",
      "Epoch 1315: train_loss=16577.46680, val_loss=16600.21484\n",
      "Epoch 1316: train_loss=16566.81055, val_loss=16589.89453\n",
      "Epoch 1317: train_loss=16556.17773, val_loss=16579.59375\n",
      "Epoch 1318: train_loss=16545.55469, val_loss=16569.30859\n",
      "Epoch 1319: train_loss=16534.95508, val_loss=16559.03906\n",
      "Epoch 1320: train_loss=16524.36719, val_loss=16548.78320\n",
      "Epoch 1321: train_loss=16513.79492, val_loss=16538.53906\n",
      "Epoch 1322: train_loss=16503.23633, val_loss=16528.30664\n",
      "Epoch 1323: train_loss=16492.68750, val_loss=16518.08203\n",
      "Epoch 1324: train_loss=16482.14844, val_loss=16507.86719\n",
      "Epoch 1325: train_loss=16471.62305, val_loss=16497.66211\n",
      "Epoch 1326: train_loss=16461.10742, val_loss=16487.46680\n",
      "Epoch 1327: train_loss=16450.59961, val_loss=16477.27930\n",
      "Epoch 1328: train_loss=16440.10547, val_loss=16467.10547\n",
      "Epoch 1329: train_loss=16429.61719, val_loss=16456.93945\n",
      "Epoch 1330: train_loss=16419.14062, val_loss=16446.78516\n",
      "Epoch 1331: train_loss=16408.67383, val_loss=16436.64258\n",
      "Epoch 1332: train_loss=16398.21680, val_loss=16426.50586\n",
      "Epoch 1333: train_loss=16387.76758, val_loss=16416.37891\n",
      "Epoch 1334: train_loss=16377.33008, val_loss=16406.25977\n",
      "Epoch 1335: train_loss=16366.89844, val_loss=16396.15039\n",
      "Epoch 1336: train_loss=16356.47656, val_loss=16386.04883\n",
      "Epoch 1337: train_loss=16346.06348, val_loss=16375.95508\n",
      "Epoch 1338: train_loss=16335.65820, val_loss=16365.86914\n",
      "Epoch 1339: train_loss=16325.26172, val_loss=16355.79199\n",
      "Epoch 1340: train_loss=16314.87402, val_loss=16345.72266\n",
      "Epoch 1341: train_loss=16304.49512, val_loss=16335.66113\n",
      "Epoch 1342: train_loss=16294.12305, val_loss=16325.61035\n",
      "Epoch 1343: train_loss=16283.75977, val_loss=16315.56738\n",
      "Epoch 1344: train_loss=16273.40625, val_loss=16305.53125\n",
      "Epoch 1345: train_loss=16263.05859, val_loss=16295.50195\n",
      "Epoch 1346: train_loss=16252.72168, val_loss=16285.48047\n",
      "Epoch 1347: train_loss=16242.39160, val_loss=16275.46973\n",
      "Epoch 1348: train_loss=16232.07129, val_loss=16265.46484\n",
      "Epoch 1349: train_loss=16221.75586, val_loss=16255.47168\n",
      "Epoch 1350: train_loss=16211.45020, val_loss=16245.48438\n",
      "Epoch 1351: train_loss=16201.15137, val_loss=16235.50195\n",
      "Epoch 1352: train_loss=16190.86230, val_loss=16225.53223\n",
      "Epoch 1353: train_loss=16180.58105, val_loss=16215.56934\n",
      "Epoch 1354: train_loss=16170.30859, val_loss=16205.61328\n",
      "Epoch 1355: train_loss=16160.04395, val_loss=16195.66602\n",
      "Epoch 1356: train_loss=16149.78809, val_loss=16185.72559\n",
      "Epoch 1357: train_loss=16139.53809, val_loss=16175.79297\n",
      "Epoch 1358: train_loss=16129.29785, val_loss=16165.86816\n",
      "Epoch 1359: train_loss=16119.06348, val_loss=16155.94922\n",
      "Epoch 1360: train_loss=16108.83984, val_loss=16146.04004\n",
      "Epoch 1361: train_loss=16098.62207, val_loss=16136.13672\n",
      "Epoch 1362: train_loss=16088.41113, val_loss=16126.24316\n",
      "Epoch 1363: train_loss=16078.20801, val_loss=16116.35156\n",
      "Epoch 1364: train_loss=16068.01270, val_loss=16106.47168\n",
      "Epoch 1365: train_loss=16057.82422, val_loss=16096.59863\n",
      "Epoch 1366: train_loss=16047.64453, val_loss=16086.73145\n",
      "Epoch 1367: train_loss=16037.47168, val_loss=16076.87109\n",
      "Epoch 1368: train_loss=16027.30664, val_loss=16067.01953\n",
      "Epoch 1369: train_loss=16017.14746, val_loss=16057.17188\n",
      "Epoch 1370: train_loss=16006.99609, val_loss=16047.33203\n",
      "Epoch 1371: train_loss=15996.85156, val_loss=16037.50000\n",
      "Epoch 1372: train_loss=15986.71484, val_loss=16027.67480\n",
      "Epoch 1373: train_loss=15976.58594, val_loss=16017.85449\n",
      "Epoch 1374: train_loss=15966.46191, val_loss=16008.04297\n",
      "Epoch 1375: train_loss=15956.34668, val_loss=15998.23730\n",
      "Epoch 1376: train_loss=15946.23730, val_loss=15988.43750\n",
      "Epoch 1377: train_loss=15936.13672, val_loss=15978.64648\n",
      "Epoch 1378: train_loss=15926.04297, val_loss=15968.86133\n",
      "Epoch 1379: train_loss=15915.95605, val_loss=15959.08691\n",
      "Epoch 1380: train_loss=15905.87793, val_loss=15949.32422\n",
      "Epoch 1381: train_loss=15895.81348, val_loss=15939.57129\n",
      "Epoch 1382: train_loss=15885.75488, val_loss=15929.82324\n",
      "Epoch 1383: train_loss=15875.70605, val_loss=15920.08398\n",
      "Epoch 1384: train_loss=15865.66406, val_loss=15910.34961\n",
      "Epoch 1385: train_loss=15855.62793, val_loss=15900.62305\n",
      "Epoch 1386: train_loss=15845.60156, val_loss=15890.90234\n",
      "Epoch 1387: train_loss=15835.58203, val_loss=15881.19043\n",
      "Epoch 1388: train_loss=15825.57031, val_loss=15871.48340\n",
      "Epoch 1389: train_loss=15815.56543, val_loss=15861.78516\n",
      "Epoch 1390: train_loss=15805.56641, val_loss=15852.09180\n",
      "Epoch 1391: train_loss=15795.57715, val_loss=15842.40527\n",
      "Epoch 1392: train_loss=15785.59082, val_loss=15832.72559\n",
      "Epoch 1393: train_loss=15775.61523, val_loss=15823.05371\n",
      "Epoch 1394: train_loss=15765.65137, val_loss=15813.38867\n",
      "Epoch 1395: train_loss=15755.69238, val_loss=15803.73047\n",
      "Epoch 1396: train_loss=15745.74512, val_loss=15794.08301\n",
      "Epoch 1397: train_loss=15735.80273, val_loss=15784.44043\n",
      "Epoch 1398: train_loss=15725.86816, val_loss=15774.80566\n",
      "Epoch 1399: train_loss=15715.94043, val_loss=15765.17480\n",
      "Epoch 1400: train_loss=15706.01855, val_loss=15755.55469\n",
      "Epoch 1401: train_loss=15696.10449, val_loss=15745.93848\n",
      "Epoch 1402: train_loss=15686.19727, val_loss=15736.32910\n",
      "Epoch 1403: train_loss=15676.29590, val_loss=15726.72754\n",
      "Epoch 1404: train_loss=15666.40234, val_loss=15717.12988\n",
      "Epoch 1405: train_loss=15656.51562, val_loss=15707.54004\n",
      "Epoch 1406: train_loss=15646.63379, val_loss=15697.95410\n",
      "Epoch 1407: train_loss=15636.75488, val_loss=15688.37305\n",
      "Epoch 1408: train_loss=15626.88379, val_loss=15678.78418\n",
      "Epoch 1409: train_loss=15617.00488, val_loss=15669.22070\n",
      "Epoch 1410: train_loss=15607.15527, val_loss=15659.66797\n",
      "Epoch 1411: train_loss=15597.31445, val_loss=15650.12109\n",
      "Epoch 1412: train_loss=15587.47559, val_loss=15640.58105\n",
      "Epoch 1413: train_loss=15577.64453, val_loss=15631.04492\n",
      "Epoch 1414: train_loss=15567.81738, val_loss=15621.51562\n",
      "Epoch 1415: train_loss=15557.99609, val_loss=15611.99414\n",
      "Epoch 1416: train_loss=15548.18555, val_loss=15602.47754\n",
      "Epoch 1417: train_loss=15538.37793, val_loss=15592.96777\n",
      "Epoch 1418: train_loss=15528.57812, val_loss=15583.46387\n",
      "Epoch 1419: train_loss=15518.78418, val_loss=15573.96875\n",
      "Epoch 1420: train_loss=15508.99902, val_loss=15564.47852\n",
      "Epoch 1421: train_loss=15499.21777, val_loss=15554.99414\n",
      "Epoch 1422: train_loss=15489.44727, val_loss=15545.51758\n",
      "Epoch 1423: train_loss=15479.67871, val_loss=15536.04395\n",
      "Epoch 1424: train_loss=15469.91797, val_loss=15526.57812\n",
      "Epoch 1425: train_loss=15460.16602, val_loss=15517.11621\n",
      "Epoch 1426: train_loss=15450.41602, val_loss=15507.66211\n",
      "Epoch 1427: train_loss=15440.67383, val_loss=15498.20996\n",
      "Epoch 1428: train_loss=15430.93848, val_loss=15488.76758\n",
      "Epoch 1429: train_loss=15421.20801, val_loss=15479.33008\n",
      "Epoch 1430: train_loss=15411.48535, val_loss=15469.89844\n",
      "Epoch 1431: train_loss=15401.76855, val_loss=15460.47266\n",
      "Epoch 1432: train_loss=15392.05664, val_loss=15451.05273\n",
      "Epoch 1433: train_loss=15382.35059, val_loss=15441.63770\n",
      "Epoch 1434: train_loss=15372.65039, val_loss=15432.22949\n",
      "Epoch 1435: train_loss=15362.95703, val_loss=15422.82520\n",
      "Epoch 1436: train_loss=15353.26953, val_loss=15413.42578\n",
      "Epoch 1437: train_loss=15343.58887, val_loss=15404.03418\n",
      "Epoch 1438: train_loss=15333.91211, val_loss=15394.64551\n",
      "Epoch 1439: train_loss=15324.24219, val_loss=15385.26367\n",
      "Epoch 1440: train_loss=15314.57520, val_loss=15375.88574\n",
      "Epoch 1441: train_loss=15304.91602, val_loss=15366.51562\n",
      "Epoch 1442: train_loss=15295.26465, val_loss=15357.15137\n",
      "Epoch 1443: train_loss=15285.61914, val_loss=15347.79492\n",
      "Epoch 1444: train_loss=15275.98340, val_loss=15338.44238\n",
      "Epoch 1445: train_loss=15266.35156, val_loss=15329.09473\n",
      "Epoch 1446: train_loss=15256.72559, val_loss=15319.75488\n",
      "Epoch 1447: train_loss=15247.10645, val_loss=15310.42090\n",
      "Epoch 1448: train_loss=15237.49414, val_loss=15301.09277\n",
      "Epoch 1449: train_loss=15227.88379, val_loss=15291.76855\n",
      "Epoch 1450: train_loss=15218.28320, val_loss=15282.44922\n",
      "Epoch 1451: train_loss=15208.68750, val_loss=15273.13867\n",
      "Epoch 1452: train_loss=15199.09863, val_loss=15263.83105\n",
      "Epoch 1453: train_loss=15189.51367, val_loss=15254.52832\n",
      "Epoch 1454: train_loss=15179.93555, val_loss=15245.23340\n",
      "Epoch 1455: train_loss=15170.36328, val_loss=15235.94043\n",
      "Epoch 1456: train_loss=15160.79590, val_loss=15226.65430\n",
      "Epoch 1457: train_loss=15151.23438, val_loss=15217.37500\n",
      "Epoch 1458: train_loss=15141.67969, val_loss=15208.09961\n",
      "Epoch 1459: train_loss=15132.13086, val_loss=15198.83203\n",
      "Epoch 1460: train_loss=15122.58691, val_loss=15189.56641\n",
      "Epoch 1461: train_loss=15113.04688, val_loss=15180.30762\n",
      "Epoch 1462: train_loss=15103.51562, val_loss=15171.05566\n",
      "Epoch 1463: train_loss=15093.98633, val_loss=15161.80859\n",
      "Epoch 1464: train_loss=15084.46484, val_loss=15152.56445\n",
      "Epoch 1465: train_loss=15074.94922, val_loss=15143.32617\n",
      "Epoch 1466: train_loss=15065.43652, val_loss=15134.09375\n",
      "Epoch 1467: train_loss=15055.93359, val_loss=15124.86621\n",
      "Epoch 1468: train_loss=15046.43262, val_loss=15115.64453\n",
      "Epoch 1469: train_loss=15036.93652, val_loss=15106.42676\n",
      "Epoch 1470: train_loss=15027.44629, val_loss=15097.21191\n",
      "Epoch 1471: train_loss=15017.96289, val_loss=15088.00293\n",
      "Epoch 1472: train_loss=15008.48145, val_loss=15078.79883\n",
      "Epoch 1473: train_loss=14999.00684, val_loss=15069.60059\n",
      "Epoch 1474: train_loss=14989.53906, val_loss=15060.40723\n",
      "Epoch 1475: train_loss=14980.07422, val_loss=15051.21680\n",
      "Epoch 1476: train_loss=14970.61621, val_loss=15042.03027\n",
      "Epoch 1477: train_loss=14961.16016, val_loss=15032.84863\n",
      "Epoch 1478: train_loss=14951.71094, val_loss=15023.67285\n",
      "Epoch 1479: train_loss=14942.26562, val_loss=15014.50000\n",
      "Epoch 1480: train_loss=14932.82520, val_loss=15005.33203\n",
      "Epoch 1481: train_loss=14923.39160, val_loss=14996.16895\n",
      "Epoch 1482: train_loss=14913.96387, val_loss=14987.01074\n",
      "Epoch 1483: train_loss=14904.53906, val_loss=14977.85742\n",
      "Epoch 1484: train_loss=14895.11816, val_loss=14968.70996\n",
      "Epoch 1485: train_loss=14885.70703, val_loss=14959.56738\n",
      "Epoch 1486: train_loss=14876.29883, val_loss=14950.42773\n",
      "Epoch 1487: train_loss=14866.89551, val_loss=14941.29590\n",
      "Epoch 1488: train_loss=14857.49805, val_loss=14932.16602\n",
      "Epoch 1489: train_loss=14848.10352, val_loss=14923.04297\n",
      "Epoch 1490: train_loss=14838.71484, val_loss=14913.92285\n",
      "Epoch 1491: train_loss=14829.33301, val_loss=14904.81055\n",
      "Epoch 1492: train_loss=14819.95508, val_loss=14895.70117\n",
      "Epoch 1493: train_loss=14810.58203, val_loss=14886.59668\n",
      "Epoch 1494: train_loss=14801.21582, val_loss=14877.50000\n",
      "Epoch 1495: train_loss=14791.85449, val_loss=14868.41016\n",
      "Epoch 1496: train_loss=14782.49805, val_loss=14859.32129\n",
      "Epoch 1497: train_loss=14773.14746, val_loss=14850.24023\n",
      "Epoch 1498: train_loss=14763.80371, val_loss=14841.16309\n",
      "Epoch 1499: train_loss=14754.46484, val_loss=14832.09180\n",
      "Epoch 1500: train_loss=14745.12793, val_loss=14823.02637\n",
      "Epoch 1501: train_loss=14735.79883, val_loss=14813.96484\n",
      "Epoch 1502: train_loss=14726.47266, val_loss=14804.90625\n",
      "Epoch 1503: train_loss=14717.15137, val_loss=14795.85547\n",
      "Epoch 1504: train_loss=14707.83496, val_loss=14786.80762\n",
      "Epoch 1505: train_loss=14698.52441, val_loss=14777.76465\n",
      "Epoch 1506: train_loss=14689.21973, val_loss=14768.72363\n",
      "Epoch 1507: train_loss=14679.91797, val_loss=14759.69043\n",
      "Epoch 1508: train_loss=14670.62109, val_loss=14750.66016\n",
      "Epoch 1509: train_loss=14661.33203, val_loss=14741.63672\n",
      "Epoch 1510: train_loss=14652.04297, val_loss=14732.61523\n",
      "Epoch 1511: train_loss=14642.76270, val_loss=14723.60156\n",
      "Epoch 1512: train_loss=14633.48730, val_loss=14714.59180\n",
      "Epoch 1513: train_loss=14624.21484, val_loss=14705.58594\n",
      "Epoch 1514: train_loss=14614.94922, val_loss=14696.58887\n",
      "Epoch 1515: train_loss=14605.69043, val_loss=14687.59375\n",
      "Epoch 1516: train_loss=14596.43555, val_loss=14678.60352\n",
      "Epoch 1517: train_loss=14587.18555, val_loss=14669.61816\n",
      "Epoch 1518: train_loss=14577.93945, val_loss=14660.63770\n",
      "Epoch 1519: train_loss=14568.70020, val_loss=14651.66309\n",
      "Epoch 1520: train_loss=14559.46582, val_loss=14642.69043\n",
      "Epoch 1521: train_loss=14550.23535, val_loss=14633.72559\n",
      "Epoch 1522: train_loss=14541.01074, val_loss=14624.76270\n",
      "Epoch 1523: train_loss=14531.78906, val_loss=14615.80566\n",
      "Epoch 1524: train_loss=14522.57324, val_loss=14606.85254\n",
      "Epoch 1525: train_loss=14513.36328, val_loss=14597.90332\n",
      "Epoch 1526: train_loss=14504.15723, val_loss=14588.95898\n",
      "Epoch 1527: train_loss=14494.95801, val_loss=14580.02051\n",
      "Epoch 1528: train_loss=14485.75977, val_loss=14571.08594\n",
      "Epoch 1529: train_loss=14476.56934, val_loss=14562.15723\n",
      "Epoch 1530: train_loss=14467.38184, val_loss=14553.23340\n",
      "Epoch 1531: train_loss=14458.20117, val_loss=14544.30859\n",
      "Epoch 1532: train_loss=14449.02441, val_loss=14535.39160\n",
      "Epoch 1533: train_loss=14439.85254, val_loss=14526.47754\n",
      "Epoch 1534: train_loss=14430.68750, val_loss=14517.56934\n",
      "Epoch 1535: train_loss=14421.52246, val_loss=14508.66699\n",
      "Epoch 1536: train_loss=14412.36719, val_loss=14499.77051\n",
      "Epoch 1537: train_loss=14403.21582, val_loss=14490.87793\n",
      "Epoch 1538: train_loss=14394.06836, val_loss=14481.98730\n",
      "Epoch 1539: train_loss=14384.92676, val_loss=14473.10352\n",
      "Epoch 1540: train_loss=14375.79102, val_loss=14464.22363\n",
      "Epoch 1541: train_loss=14366.66016, val_loss=14455.34863\n",
      "Epoch 1542: train_loss=14357.53223, val_loss=14446.47949\n",
      "Epoch 1543: train_loss=14348.41113, val_loss=14437.61719\n",
      "Epoch 1544: train_loss=14339.29590, val_loss=14428.75488\n",
      "Epoch 1545: train_loss=14330.18262, val_loss=14419.89746\n",
      "Epoch 1546: train_loss=14321.07715, val_loss=14411.04590\n",
      "Epoch 1547: train_loss=14311.97656, val_loss=14402.19824\n",
      "Epoch 1548: train_loss=14302.87891, val_loss=14393.35742\n",
      "Epoch 1549: train_loss=14293.78809, val_loss=14384.52051\n",
      "Epoch 1550: train_loss=14284.70215, val_loss=14375.68457\n",
      "Epoch 1551: train_loss=14275.62012, val_loss=14366.85645\n",
      "Epoch 1552: train_loss=14266.54297, val_loss=14358.03125\n",
      "Epoch 1553: train_loss=14257.47070, val_loss=14349.21191\n",
      "Epoch 1554: train_loss=14248.40527, val_loss=14340.39746\n",
      "Epoch 1555: train_loss=14239.34277, val_loss=14331.58789\n",
      "Epoch 1556: train_loss=14230.28516, val_loss=14322.78125\n",
      "Epoch 1557: train_loss=14221.23145, val_loss=14313.97754\n",
      "Epoch 1558: train_loss=14212.18457, val_loss=14305.18164\n",
      "Epoch 1559: train_loss=14203.14355, val_loss=14296.38770\n",
      "Epoch 1560: train_loss=14194.10449, val_loss=14287.59961\n",
      "Epoch 1561: train_loss=14185.07324, val_loss=14278.81641\n",
      "Epoch 1562: train_loss=14176.04492, val_loss=14270.03711\n",
      "Epoch 1563: train_loss=14167.02148, val_loss=14261.26172\n",
      "Epoch 1564: train_loss=14158.00488, val_loss=14252.49414\n",
      "Epoch 1565: train_loss=14148.99219, val_loss=14243.72754\n",
      "Epoch 1566: train_loss=14139.98438, val_loss=14234.96777\n",
      "Epoch 1567: train_loss=14130.98242, val_loss=14226.21387\n",
      "Epoch 1568: train_loss=14121.98535, val_loss=14217.46191\n",
      "Epoch 1569: train_loss=14112.99414, val_loss=14208.71484\n",
      "Epoch 1570: train_loss=14104.00684, val_loss=14199.97656\n",
      "Epoch 1571: train_loss=14095.02734, val_loss=14191.23828\n",
      "Epoch 1572: train_loss=14086.04980, val_loss=14182.50781\n",
      "Epoch 1573: train_loss=14077.08008, val_loss=14173.78418\n",
      "Epoch 1574: train_loss=14068.11328, val_loss=14165.06055\n",
      "Epoch 1575: train_loss=14059.15332, val_loss=14156.34277\n",
      "Epoch 1576: train_loss=14050.19824, val_loss=14147.63184\n",
      "Epoch 1577: train_loss=14041.24902, val_loss=14138.92383\n",
      "Epoch 1578: train_loss=14032.30273, val_loss=14130.22363\n",
      "Epoch 1579: train_loss=14023.36328, val_loss=14121.52734\n",
      "Epoch 1580: train_loss=14014.42969, val_loss=14112.83496\n",
      "Epoch 1581: train_loss=14005.50000, val_loss=14104.14648\n",
      "Epoch 1582: train_loss=13996.57520, val_loss=14095.46387\n",
      "Epoch 1583: train_loss=13987.65918, val_loss=14086.78906\n",
      "Epoch 1584: train_loss=13978.74609, val_loss=14078.11719\n",
      "Epoch 1585: train_loss=13969.83984, val_loss=14069.45117\n",
      "Epoch 1586: train_loss=13960.93652, val_loss=14060.79004\n",
      "Epoch 1587: train_loss=13952.04004, val_loss=14052.13379\n",
      "Epoch 1588: train_loss=13943.15137, val_loss=14043.48145\n",
      "Epoch 1589: train_loss=13934.26465, val_loss=14034.83496\n",
      "Epoch 1590: train_loss=13925.38574, val_loss=14026.19336\n",
      "Epoch 1591: train_loss=13916.50977, val_loss=14017.55957\n",
      "Epoch 1592: train_loss=13907.64062, val_loss=14008.92969\n",
      "Epoch 1593: train_loss=13898.77637, val_loss=14000.30371\n",
      "Epoch 1594: train_loss=13889.91895, val_loss=13991.68262\n",
      "Epoch 1595: train_loss=13881.06543, val_loss=13983.06934\n",
      "Epoch 1596: train_loss=13872.21680, val_loss=13974.45801\n",
      "Epoch 1597: train_loss=13863.37500, val_loss=13965.85449\n",
      "Epoch 1598: train_loss=13854.53906, val_loss=13957.25391\n",
      "Epoch 1599: train_loss=13845.70898, val_loss=13948.65918\n",
      "Epoch 1600: train_loss=13836.88184, val_loss=13940.06836\n",
      "Epoch 1601: train_loss=13828.06152, val_loss=13931.48242\n",
      "Epoch 1602: train_loss=13819.24902, val_loss=13922.90234\n",
      "Epoch 1603: train_loss=13810.43848, val_loss=13914.32812\n",
      "Epoch 1604: train_loss=13801.63574, val_loss=13905.75977\n",
      "Epoch 1605: train_loss=13792.83789, val_loss=13897.19629\n",
      "Epoch 1606: train_loss=13784.04492, val_loss=13888.63477\n",
      "Epoch 1607: train_loss=13775.26074, val_loss=13880.08203\n",
      "Epoch 1608: train_loss=13766.47949, val_loss=13871.53027\n",
      "Epoch 1609: train_loss=13757.70508, val_loss=13862.98828\n",
      "Epoch 1610: train_loss=13748.93652, val_loss=13854.45117\n",
      "Epoch 1611: train_loss=13740.17285, val_loss=13845.91602\n",
      "Epoch 1612: train_loss=13731.41406, val_loss=13837.38477\n",
      "Epoch 1613: train_loss=13722.66113, val_loss=13828.86133\n",
      "Epoch 1614: train_loss=13713.91309, val_loss=13820.34180\n",
      "Epoch 1615: train_loss=13705.17188, val_loss=13811.82715\n",
      "Epoch 1616: train_loss=13696.43457, val_loss=13803.31836\n",
      "Epoch 1617: train_loss=13687.70312, val_loss=13794.81348\n",
      "Epoch 1618: train_loss=13678.97754, val_loss=13786.31543\n",
      "Epoch 1619: train_loss=13670.25781, val_loss=13777.82129\n",
      "Epoch 1620: train_loss=13661.54590, val_loss=13769.33398\n",
      "Epoch 1621: train_loss=13652.83398, val_loss=13760.84961\n",
      "Epoch 1622: train_loss=13644.12988, val_loss=13752.37012\n",
      "Epoch 1623: train_loss=13635.43164, val_loss=13743.89746\n",
      "Epoch 1624: train_loss=13626.73926, val_loss=13735.42773\n",
      "Epoch 1625: train_loss=13618.05273, val_loss=13726.96484\n",
      "Epoch 1626: train_loss=13609.37207, val_loss=13718.51270\n",
      "Epoch 1627: train_loss=13600.69922, val_loss=13710.06445\n",
      "Epoch 1628: train_loss=13592.03418, val_loss=13701.62402\n",
      "Epoch 1629: train_loss=13583.37695, val_loss=13693.18945\n",
      "Epoch 1630: train_loss=13574.72363, val_loss=13684.75879\n",
      "Epoch 1631: train_loss=13566.07812, val_loss=13676.33594\n",
      "Epoch 1632: train_loss=13557.43848, val_loss=13667.91797\n",
      "Epoch 1633: train_loss=13548.80371, val_loss=13659.50195\n",
      "Epoch 1634: train_loss=13540.17578, val_loss=13651.09375\n",
      "Epoch 1635: train_loss=13531.55078, val_loss=13642.68848\n",
      "Epoch 1636: train_loss=13522.93359, val_loss=13634.28906\n",
      "Epoch 1637: train_loss=13514.32129, val_loss=13625.89355\n",
      "Epoch 1638: train_loss=13505.71387, val_loss=13617.50195\n",
      "Epoch 1639: train_loss=13497.11133, val_loss=13609.11523\n",
      "Epoch 1640: train_loss=13488.51367, val_loss=13600.73535\n",
      "Epoch 1641: train_loss=13479.92188, val_loss=13592.36230\n",
      "Epoch 1642: train_loss=13471.33496, val_loss=13583.99023\n",
      "Epoch 1643: train_loss=13462.75293, val_loss=13575.62012\n",
      "Epoch 1644: train_loss=13454.17383, val_loss=13567.25488\n",
      "Epoch 1645: train_loss=13445.60156, val_loss=13558.89453\n",
      "Epoch 1646: train_loss=13437.03418, val_loss=13550.53906\n",
      "Epoch 1647: train_loss=13428.47070, val_loss=13542.18945\n",
      "Epoch 1648: train_loss=13419.91406, val_loss=13533.84180\n",
      "Epoch 1649: train_loss=13411.36133, val_loss=13525.49512\n",
      "Epoch 1650: train_loss=13402.81055, val_loss=13517.15430\n",
      "Epoch 1651: train_loss=13394.26562, val_loss=13508.81836\n",
      "Epoch 1652: train_loss=13385.72656, val_loss=13500.48926\n",
      "Epoch 1653: train_loss=13377.19141, val_loss=13492.16406\n",
      "Epoch 1654: train_loss=13368.66309, val_loss=13483.83594\n",
      "Epoch 1655: train_loss=13360.13672, val_loss=13475.51660\n",
      "Epoch 1656: train_loss=13351.61621, val_loss=13467.20020\n",
      "Epoch 1657: train_loss=13343.09863, val_loss=13458.89160\n",
      "Epoch 1658: train_loss=13334.58789, val_loss=13450.59180\n",
      "Epoch 1659: train_loss=13326.08691, val_loss=13442.29883\n",
      "Epoch 1660: train_loss=13317.59082, val_loss=13434.00879\n",
      "Epoch 1661: train_loss=13309.10254, val_loss=13425.72559\n",
      "Epoch 1662: train_loss=13300.61816, val_loss=13417.44922\n",
      "Epoch 1663: train_loss=13292.14258, val_loss=13409.17676\n",
      "Epoch 1664: train_loss=13283.67773, val_loss=13400.91699\n",
      "Epoch 1665: train_loss=13275.22168, val_loss=13392.66016\n",
      "Epoch 1666: train_loss=13266.77344, val_loss=13384.41113\n",
      "Epoch 1667: train_loss=13258.33301, val_loss=13376.17090\n",
      "Epoch 1668: train_loss=13249.89746, val_loss=13367.93555\n",
      "Epoch 1669: train_loss=13241.46973, val_loss=13359.70996\n",
      "Epoch 1670: train_loss=13233.05273, val_loss=13351.49219\n",
      "Epoch 1671: train_loss=13224.64453, val_loss=13343.27930\n",
      "Epoch 1672: train_loss=13216.24609, val_loss=13335.07812\n",
      "Epoch 1673: train_loss=13207.85645, val_loss=13326.88281\n",
      "Epoch 1674: train_loss=13199.47461, val_loss=13318.69141\n",
      "Epoch 1675: train_loss=13191.10059, val_loss=13310.51172\n",
      "Epoch 1676: train_loss=13182.73633, val_loss=13302.33984\n",
      "Epoch 1677: train_loss=13174.37988, val_loss=13294.17676\n",
      "Epoch 1678: train_loss=13166.03223, val_loss=13286.02148\n",
      "Epoch 1679: train_loss=13157.69336, val_loss=13277.87207\n",
      "Epoch 1680: train_loss=13149.36230, val_loss=13269.72949\n",
      "Epoch 1681: train_loss=13141.03613, val_loss=13261.59766\n",
      "Epoch 1682: train_loss=13132.71777, val_loss=13253.46973\n",
      "Epoch 1683: train_loss=13124.40820, val_loss=13245.34668\n",
      "Epoch 1684: train_loss=13116.10352, val_loss=13237.23340\n",
      "Epoch 1685: train_loss=13107.80664, val_loss=13229.12402\n",
      "Epoch 1686: train_loss=13099.51758, val_loss=13221.02344\n",
      "Epoch 1687: train_loss=13091.23438, val_loss=13212.93066\n",
      "Epoch 1688: train_loss=13082.95996, val_loss=13204.84277\n",
      "Epoch 1689: train_loss=13074.69141, val_loss=13196.76270\n",
      "Epoch 1690: train_loss=13066.42969, val_loss=13188.68848\n",
      "Epoch 1691: train_loss=13058.17383, val_loss=13180.62207\n",
      "Epoch 1692: train_loss=13049.92773, val_loss=13172.56152\n",
      "Epoch 1693: train_loss=13041.68848, val_loss=13164.50684\n",
      "Epoch 1694: train_loss=13033.45605, val_loss=13156.45898\n",
      "Epoch 1695: train_loss=13025.23145, val_loss=13148.41699\n",
      "Epoch 1696: train_loss=13017.01367, val_loss=13140.38184\n",
      "Epoch 1697: train_loss=13008.80469, val_loss=13132.35352\n",
      "Epoch 1698: train_loss=13000.60059, val_loss=13124.32910\n",
      "Epoch 1699: train_loss=12992.40625, val_loss=13116.31445\n",
      "Epoch 1700: train_loss=12984.21680, val_loss=13108.30664\n",
      "Epoch 1701: train_loss=12976.03809, val_loss=13100.30566\n",
      "Epoch 1702: train_loss=12967.86426, val_loss=13092.31152\n",
      "Epoch 1703: train_loss=12959.69824, val_loss=13084.32520\n",
      "Epoch 1704: train_loss=12951.54004, val_loss=13076.34473\n",
      "Epoch 1705: train_loss=12943.39160, val_loss=13068.37109\n",
      "Epoch 1706: train_loss=12935.24707, val_loss=13060.39746\n",
      "Epoch 1707: train_loss=12927.10547, val_loss=13052.39844\n",
      "Epoch 1708: train_loss=12918.94141, val_loss=13044.41504\n",
      "Epoch 1709: train_loss=12910.79004, val_loss=13036.46875\n",
      "Epoch 1710: train_loss=12902.67285, val_loss=13028.53516\n",
      "Epoch 1711: train_loss=12894.57324, val_loss=13020.61035\n",
      "Epoch 1712: train_loss=12886.48340, val_loss=13012.69336\n",
      "Epoch 1713: train_loss=12878.40039, val_loss=13004.78906\n",
      "Epoch 1714: train_loss=12870.32910, val_loss=12996.89062\n",
      "Epoch 1715: train_loss=12862.26367, val_loss=12989.00000\n",
      "Epoch 1716: train_loss=12854.20605, val_loss=12981.11523\n",
      "Epoch 1717: train_loss=12846.15430, val_loss=12973.23828\n",
      "Epoch 1718: train_loss=12838.11133, val_loss=12965.36816\n",
      "Epoch 1719: train_loss=12830.07715, val_loss=12957.50781\n",
      "Epoch 1720: train_loss=12822.04785, val_loss=12949.65430\n",
      "Epoch 1721: train_loss=12814.02930, val_loss=12941.80859\n",
      "Epoch 1722: train_loss=12806.01660, val_loss=12933.97363\n",
      "Epoch 1723: train_loss=12798.01270, val_loss=12926.14355\n",
      "Epoch 1724: train_loss=12790.01562, val_loss=12918.32324\n",
      "Epoch 1725: train_loss=12782.02539, val_loss=12910.51270\n",
      "Epoch 1726: train_loss=12774.04590, val_loss=12902.71387\n",
      "Epoch 1727: train_loss=12766.08008, val_loss=12894.92188\n",
      "Epoch 1728: train_loss=12758.12500, val_loss=12887.14062\n",
      "Epoch 1729: train_loss=12750.17676, val_loss=12879.36523\n",
      "Epoch 1730: train_loss=12742.24023, val_loss=12871.60059\n",
      "Epoch 1731: train_loss=12734.31152, val_loss=12863.84473\n",
      "Epoch 1732: train_loss=12726.39258, val_loss=12856.09668\n",
      "Epoch 1733: train_loss=12718.48340, val_loss=12848.35938\n",
      "Epoch 1734: train_loss=12710.58398, val_loss=12840.62891\n",
      "Epoch 1735: train_loss=12702.69238, val_loss=12832.90625\n",
      "Epoch 1736: train_loss=12694.80957, val_loss=12825.19043\n",
      "Epoch 1737: train_loss=12686.93555, val_loss=12817.48438\n",
      "Epoch 1738: train_loss=12679.06738, val_loss=12809.78223\n",
      "Epoch 1739: train_loss=12671.20801, val_loss=12802.08984\n",
      "Epoch 1740: train_loss=12663.35938, val_loss=12794.40527\n",
      "Epoch 1741: train_loss=12655.51660, val_loss=12786.72949\n",
      "Epoch 1742: train_loss=12647.68457, val_loss=12779.06055\n",
      "Epoch 1743: train_loss=12639.86133, val_loss=12771.40332\n",
      "Epoch 1744: train_loss=12632.04785, val_loss=12763.75879\n",
      "Epoch 1745: train_loss=12624.24512, val_loss=12756.12109\n",
      "Epoch 1746: train_loss=12616.45117, val_loss=12748.49121\n",
      "Epoch 1747: train_loss=12608.66699, val_loss=12740.86914\n",
      "Epoch 1748: train_loss=12600.89062, val_loss=12733.25684\n",
      "Epoch 1749: train_loss=12593.12305, val_loss=12725.65625\n",
      "Epoch 1750: train_loss=12585.36719, val_loss=12718.06250\n",
      "Epoch 1751: train_loss=12577.62012, val_loss=12710.48047\n",
      "Epoch 1752: train_loss=12569.88281, val_loss=12702.90430\n",
      "Epoch 1753: train_loss=12562.15625, val_loss=12695.34082\n",
      "Epoch 1754: train_loss=12554.43945, val_loss=12687.78711\n",
      "Epoch 1755: train_loss=12546.73340, val_loss=12680.24219\n",
      "Epoch 1756: train_loss=12539.03809, val_loss=12672.70508\n",
      "Epoch 1757: train_loss=12531.35156, val_loss=12665.18164\n",
      "Epoch 1758: train_loss=12523.67676, val_loss=12657.66895\n",
      "Epoch 1759: train_loss=12516.01074, val_loss=12650.16699\n",
      "Epoch 1760: train_loss=12508.35547, val_loss=12642.67285\n",
      "Epoch 1761: train_loss=12500.70801, val_loss=12635.19141\n",
      "Epoch 1762: train_loss=12493.07129, val_loss=12627.72070\n",
      "Epoch 1763: train_loss=12485.44434, val_loss=12620.25781\n",
      "Epoch 1764: train_loss=12477.82422, val_loss=12612.80371\n",
      "Epoch 1765: train_loss=12470.21484, val_loss=12605.35840\n",
      "Epoch 1766: train_loss=12462.61328, val_loss=12597.92285\n",
      "Epoch 1767: train_loss=12455.02344, val_loss=12590.49512\n",
      "Epoch 1768: train_loss=12447.44238, val_loss=12583.07812\n",
      "Epoch 1769: train_loss=12439.87207, val_loss=12575.67090\n",
      "Epoch 1770: train_loss=12432.30957, val_loss=12568.27246\n",
      "Epoch 1771: train_loss=12424.75879, val_loss=12560.88086\n",
      "Epoch 1772: train_loss=12417.21582, val_loss=12553.50000\n",
      "Epoch 1773: train_loss=12409.68359, val_loss=12546.12793\n",
      "Epoch 1774: train_loss=12402.16211, val_loss=12538.76465\n",
      "Epoch 1775: train_loss=12394.65137, val_loss=12531.40918\n",
      "Epoch 1776: train_loss=12387.15039, val_loss=12524.06445\n",
      "Epoch 1777: train_loss=12379.65820, val_loss=12516.72852\n",
      "Epoch 1778: train_loss=12372.17871, val_loss=12509.40234\n",
      "Epoch 1779: train_loss=12364.70801, val_loss=12502.08398\n",
      "Epoch 1780: train_loss=12357.24609, val_loss=12494.77637\n",
      "Epoch 1781: train_loss=12349.79590, val_loss=12487.47656\n",
      "Epoch 1782: train_loss=12342.35352, val_loss=12480.18457\n",
      "Epoch 1783: train_loss=12334.92578, val_loss=12472.90234\n",
      "Epoch 1784: train_loss=12327.50293, val_loss=12465.62891\n",
      "Epoch 1785: train_loss=12320.09277, val_loss=12458.36719\n",
      "Epoch 1786: train_loss=12312.69043, val_loss=12451.11230\n",
      "Epoch 1787: train_loss=12305.29883, val_loss=12443.86719\n",
      "Epoch 1788: train_loss=12297.91699, val_loss=12436.63281\n",
      "Epoch 1789: train_loss=12290.54688, val_loss=12429.40723\n",
      "Epoch 1790: train_loss=12283.18555, val_loss=12422.19141\n",
      "Epoch 1791: train_loss=12275.83496, val_loss=12414.98633\n",
      "Epoch 1792: train_loss=12268.50000, val_loss=12407.79199\n",
      "Epoch 1793: train_loss=12261.17383, val_loss=12400.60742\n",
      "Epoch 1794: train_loss=12253.85938, val_loss=12393.43457\n",
      "Epoch 1795: train_loss=12246.55566, val_loss=12386.27051\n",
      "Epoch 1796: train_loss=12239.26562, val_loss=12379.11719\n",
      "Epoch 1797: train_loss=12231.98535, val_loss=12371.97266\n",
      "Epoch 1798: train_loss=12224.71680, val_loss=12364.84180\n",
      "Epoch 1799: train_loss=12217.45898, val_loss=12357.72266\n",
      "Epoch 1800: train_loss=12210.21191, val_loss=12350.61230\n",
      "Epoch 1801: train_loss=12202.97656, val_loss=12343.51465\n",
      "Epoch 1802: train_loss=12195.75000, val_loss=12336.42578\n",
      "Epoch 1803: train_loss=12188.53418, val_loss=12329.34668\n",
      "Epoch 1804: train_loss=12181.33008, val_loss=12322.27930\n",
      "Epoch 1805: train_loss=12174.13672, val_loss=12315.22168\n",
      "Epoch 1806: train_loss=12166.95605, val_loss=12308.17773\n",
      "Epoch 1807: train_loss=12159.78613, val_loss=12301.14648\n",
      "Epoch 1808: train_loss=12152.63379, val_loss=12294.12402\n",
      "Epoch 1809: train_loss=12145.49219, val_loss=12287.11621\n",
      "Epoch 1810: train_loss=12138.36133, val_loss=12280.11816\n",
      "Epoch 1811: train_loss=12131.24023, val_loss=12273.13184\n",
      "Epoch 1812: train_loss=12124.13281, val_loss=12266.15820\n",
      "Epoch 1813: train_loss=12117.03809, val_loss=12259.19531\n",
      "Epoch 1814: train_loss=12109.95410, val_loss=12252.24512\n",
      "Epoch 1815: train_loss=12102.88281, val_loss=12245.30469\n",
      "Epoch 1816: train_loss=12095.82031, val_loss=12238.37500\n",
      "Epoch 1817: train_loss=12088.77051, val_loss=12231.45508\n",
      "Epoch 1818: train_loss=12081.73242, val_loss=12224.54688\n",
      "Epoch 1819: train_loss=12074.70508, val_loss=12217.64648\n",
      "Epoch 1820: train_loss=12067.69043, val_loss=12210.75781\n",
      "Epoch 1821: train_loss=12060.68652, val_loss=12203.87891\n",
      "Epoch 1822: train_loss=12053.69043, val_loss=12197.00977\n",
      "Epoch 1823: train_loss=12046.70703, val_loss=12190.15039\n",
      "Epoch 1824: train_loss=12039.73633, val_loss=12183.30371\n",
      "Epoch 1825: train_loss=12032.77441, val_loss=12176.46191\n",
      "Epoch 1826: train_loss=12025.82324, val_loss=12169.63281\n",
      "Epoch 1827: train_loss=12018.88379, val_loss=12162.81641\n",
      "Epoch 1828: train_loss=12011.95312, val_loss=12156.00684\n",
      "Epoch 1829: train_loss=12005.03516, val_loss=12149.20996\n",
      "Epoch 1830: train_loss=11998.12793, val_loss=12142.42383\n",
      "Epoch 1831: train_loss=11991.23242, val_loss=12135.64844\n",
      "Epoch 1832: train_loss=11984.34863, val_loss=12128.88379\n",
      "Epoch 1833: train_loss=11977.47461, val_loss=12122.12988\n",
      "Epoch 1834: train_loss=11970.61133, val_loss=12115.38672\n",
      "Epoch 1835: train_loss=11963.75977, val_loss=12108.65723\n",
      "Epoch 1836: train_loss=11956.92090, val_loss=12101.93555\n",
      "Epoch 1837: train_loss=11950.09473, val_loss=12095.22656\n",
      "Epoch 1838: train_loss=11943.27930, val_loss=12088.52930\n",
      "Epoch 1839: train_loss=11936.47559, val_loss=12081.84180\n",
      "Epoch 1840: train_loss=11929.68359, val_loss=12075.16699\n",
      "Epoch 1841: train_loss=11922.90234, val_loss=12068.50391\n",
      "Epoch 1842: train_loss=11916.13379, val_loss=12061.85645\n",
      "Epoch 1843: train_loss=11909.37598, val_loss=12055.22363\n",
      "Epoch 1844: train_loss=11902.63477, val_loss=12048.60352\n",
      "Epoch 1845: train_loss=11895.90723, val_loss=12041.99902\n",
      "Epoch 1846: train_loss=11889.19238, val_loss=12035.40234\n",
      "Epoch 1847: train_loss=11882.49023, val_loss=12028.82031\n",
      "Epoch 1848: train_loss=11875.80078, val_loss=12022.24902\n",
      "Epoch 1849: train_loss=11869.12207, val_loss=12015.68848\n",
      "Epoch 1850: train_loss=11862.45703, val_loss=12009.14355\n",
      "Epoch 1851: train_loss=11855.80762, val_loss=12002.61230\n",
      "Epoch 1852: train_loss=11849.16895, val_loss=11996.09180\n",
      "Epoch 1853: train_loss=11842.54590, val_loss=11989.58594\n",
      "Epoch 1854: train_loss=11835.93652, val_loss=11983.09180\n",
      "Epoch 1855: train_loss=11829.33984, val_loss=11976.60645\n",
      "Epoch 1856: train_loss=11822.75977, val_loss=11970.13379\n",
      "Epoch 1857: train_loss=11816.19238, val_loss=11963.67090\n",
      "Epoch 1858: train_loss=11809.63672, val_loss=11957.22461\n",
      "Epoch 1859: train_loss=11803.09473, val_loss=11950.78809\n",
      "Epoch 1860: train_loss=11796.56445, val_loss=11944.36230\n",
      "Epoch 1861: train_loss=11790.04492, val_loss=11937.94727\n",
      "Epoch 1862: train_loss=11783.53711, val_loss=11931.54492\n",
      "Epoch 1863: train_loss=11777.04199, val_loss=11925.15527\n",
      "Epoch 1864: train_loss=11770.56152, val_loss=11918.77637\n",
      "Epoch 1865: train_loss=11764.09180, val_loss=11912.40820\n",
      "Epoch 1866: train_loss=11757.63477, val_loss=11906.05176\n",
      "Epoch 1867: train_loss=11751.19043, val_loss=11899.70801\n",
      "Epoch 1868: train_loss=11744.75586, val_loss=11893.37207\n",
      "Epoch 1869: train_loss=11738.33398, val_loss=11887.04980\n",
      "Epoch 1870: train_loss=11731.92285, val_loss=11880.73633\n",
      "Epoch 1871: train_loss=11725.52441, val_loss=11874.43457\n",
      "Epoch 1872: train_loss=11719.13770, val_loss=11868.14258\n",
      "Epoch 1873: train_loss=11712.76172, val_loss=11861.86328\n",
      "Epoch 1874: train_loss=11706.39746, val_loss=11855.59180\n",
      "Epoch 1875: train_loss=11700.04492, val_loss=11849.33105\n",
      "Epoch 1876: train_loss=11693.70215, val_loss=11843.08301\n",
      "Epoch 1877: train_loss=11687.37402, val_loss=11836.84473\n",
      "Epoch 1878: train_loss=11681.05566, val_loss=11830.61914\n",
      "Epoch 1879: train_loss=11674.74902, val_loss=11824.40430\n",
      "Epoch 1880: train_loss=11668.45605, val_loss=11818.20020\n",
      "Epoch 1881: train_loss=11662.17285, val_loss=11812.00781\n",
      "Epoch 1882: train_loss=11655.90430, val_loss=11805.82812\n",
      "Epoch 1883: train_loss=11649.64648, val_loss=11799.65820\n",
      "Epoch 1884: train_loss=11643.39941, val_loss=11793.50000\n",
      "Epoch 1885: train_loss=11637.16504, val_loss=11787.35449\n",
      "Epoch 1886: train_loss=11630.94238, val_loss=11781.21680\n",
      "Epoch 1887: train_loss=11624.73047, val_loss=11775.09180\n",
      "Epoch 1888: train_loss=11618.53223, val_loss=11768.97754\n",
      "Epoch 1889: train_loss=11612.34570, val_loss=11762.87402\n",
      "Epoch 1890: train_loss=11606.17090, val_loss=11756.78223\n",
      "Epoch 1891: train_loss=11600.00684, val_loss=11750.70117\n",
      "Epoch 1892: train_loss=11593.85547, val_loss=11744.62988\n",
      "Epoch 1893: train_loss=11587.71484, val_loss=11738.57031\n",
      "Epoch 1894: train_loss=11581.58789, val_loss=11732.52148\n",
      "Epoch 1895: train_loss=11575.47266, val_loss=11726.48535\n",
      "Epoch 1896: train_loss=11569.36914, val_loss=11720.46094\n",
      "Epoch 1897: train_loss=11563.28320, val_loss=11714.44922\n",
      "Epoch 1898: train_loss=11557.21094, val_loss=11708.44824\n",
      "Epoch 1899: train_loss=11551.15137, val_loss=11702.46191\n",
      "Epoch 1900: train_loss=11545.10352, val_loss=11696.48535\n",
      "Epoch 1901: train_loss=11539.06836, val_loss=11690.52246\n",
      "Epoch 1902: train_loss=11533.04785, val_loss=11684.57031\n",
      "Epoch 1903: train_loss=11527.04004, val_loss=11678.62988\n",
      "Epoch 1904: train_loss=11521.04102, val_loss=11672.70117\n",
      "Epoch 1905: train_loss=11515.05762, val_loss=11666.78320\n",
      "Epoch 1906: train_loss=11509.08496, val_loss=11660.87988\n",
      "Epoch 1907: train_loss=11503.12305, val_loss=11654.98828\n",
      "Epoch 1908: train_loss=11497.17480, val_loss=11649.10645\n",
      "Epoch 1909: train_loss=11491.23926, val_loss=11643.23926\n",
      "Epoch 1910: train_loss=11485.31445, val_loss=11637.38379\n",
      "Epoch 1911: train_loss=11479.40332, val_loss=11631.54297\n",
      "Epoch 1912: train_loss=11473.50391, val_loss=11625.71582\n",
      "Epoch 1913: train_loss=11467.61719, val_loss=11619.89746\n",
      "Epoch 1914: train_loss=11461.74121, val_loss=11614.09277\n",
      "Epoch 1915: train_loss=11455.87988, val_loss=11608.29980\n",
      "Epoch 1916: train_loss=11450.03223, val_loss=11602.52246\n",
      "Epoch 1917: train_loss=11444.19824, val_loss=11596.75488\n",
      "Epoch 1918: train_loss=11438.37500, val_loss=11591.00000\n",
      "Epoch 1919: train_loss=11432.56445, val_loss=11585.25781\n",
      "Epoch 1920: train_loss=11426.76758, val_loss=11579.52539\n",
      "Epoch 1921: train_loss=11420.98145, val_loss=11573.80762\n",
      "Epoch 1922: train_loss=11415.20898, val_loss=11568.09961\n",
      "Epoch 1923: train_loss=11409.44824, val_loss=11562.40332\n",
      "Epoch 1924: train_loss=11403.69922, val_loss=11556.71875\n",
      "Epoch 1925: train_loss=11397.96289, val_loss=11551.04492\n",
      "Epoch 1926: train_loss=11392.23926, val_loss=11545.38281\n",
      "Epoch 1927: train_loss=11386.52637, val_loss=11539.73242\n",
      "Epoch 1928: train_loss=11380.82422, val_loss=11534.09082\n",
      "Epoch 1929: train_loss=11375.13672, val_loss=11528.46289\n",
      "Epoch 1930: train_loss=11369.46094, val_loss=11522.84570\n",
      "Epoch 1931: train_loss=11363.79590, val_loss=11517.24219\n",
      "Epoch 1932: train_loss=11358.14355, val_loss=11511.64746\n",
      "Epoch 1933: train_loss=11352.50293, val_loss=11506.06543\n",
      "Epoch 1934: train_loss=11346.87695, val_loss=11500.49609\n",
      "Epoch 1935: train_loss=11341.26074, val_loss=11494.93457\n",
      "Epoch 1936: train_loss=11335.65820, val_loss=11489.38672\n",
      "Epoch 1937: train_loss=11330.06641, val_loss=11483.85156\n",
      "Epoch 1938: train_loss=11324.48926, val_loss=11478.32422\n",
      "Epoch 1939: train_loss=11318.92188, val_loss=11472.81055\n",
      "Epoch 1940: train_loss=11313.36719, val_loss=11467.30957\n",
      "Epoch 1941: train_loss=11307.82520, val_loss=11461.81738\n",
      "Epoch 1942: train_loss=11302.29199, val_loss=11456.33594\n",
      "Epoch 1943: train_loss=11296.77637, val_loss=11450.87207\n",
      "Epoch 1944: train_loss=11291.27148, val_loss=11445.41992\n",
      "Epoch 1945: train_loss=11285.77930, val_loss=11439.97949\n",
      "Epoch 1946: train_loss=11280.29883, val_loss=11434.54980\n",
      "Epoch 1947: train_loss=11274.83008, val_loss=11429.13086\n",
      "Epoch 1948: train_loss=11269.37500, val_loss=11423.72559\n",
      "Epoch 1949: train_loss=11263.93164, val_loss=11418.33008\n",
      "Epoch 1950: train_loss=11258.50098, val_loss=11412.94434\n",
      "Epoch 1951: train_loss=11253.08203, val_loss=11407.57129\n",
      "Epoch 1952: train_loss=11247.67578, val_loss=11402.21191\n",
      "Epoch 1953: train_loss=11242.28418, val_loss=11396.86914\n",
      "Epoch 1954: train_loss=11236.90527, val_loss=11391.53809\n",
      "Epoch 1955: train_loss=11231.54199, val_loss=11386.22266\n",
      "Epoch 1956: train_loss=11226.19629, val_loss=11380.92188\n",
      "Epoch 1957: train_loss=11220.86621, val_loss=11375.63574\n",
      "Epoch 1958: train_loss=11215.55371, val_loss=11370.36523\n",
      "Epoch 1959: train_loss=11210.25293, val_loss=11365.10742\n",
      "Epoch 1960: train_loss=11204.96680, val_loss=11359.86230\n",
      "Epoch 1961: train_loss=11199.69434, val_loss=11354.62793\n",
      "Epoch 1962: train_loss=11194.43066, val_loss=11349.40625\n",
      "Epoch 1963: train_loss=11189.18359, val_loss=11344.19824\n",
      "Epoch 1964: train_loss=11183.94824, val_loss=11339.00293\n",
      "Epoch 1965: train_loss=11178.72559, val_loss=11333.81738\n",
      "Epoch 1966: train_loss=11173.51758, val_loss=11328.64551\n",
      "Epoch 1967: train_loss=11168.32324, val_loss=11323.48828\n",
      "Epoch 1968: train_loss=11163.14453, val_loss=11318.34766\n",
      "Epoch 1969: train_loss=11157.98047, val_loss=11313.21484\n",
      "Epoch 1970: train_loss=11152.82910, val_loss=11308.09961\n",
      "Epoch 1971: train_loss=11147.69238, val_loss=11302.99707\n",
      "Epoch 1972: train_loss=11142.56738, val_loss=11297.90527\n",
      "Epoch 1973: train_loss=11137.45703, val_loss=11292.82715\n",
      "Epoch 1974: train_loss=11132.35938, val_loss=11287.76562\n",
      "Epoch 1975: train_loss=11127.27539, val_loss=11282.71289\n",
      "Epoch 1976: train_loss=11122.20410, val_loss=11277.67383\n",
      "Epoch 1977: train_loss=11117.14551, val_loss=11272.64648\n",
      "Epoch 1978: train_loss=11112.10059, val_loss=11267.63379\n",
      "Epoch 1979: train_loss=11107.06738, val_loss=11262.63184\n",
      "Epoch 1980: train_loss=11102.04980, val_loss=11257.64551\n",
      "Epoch 1981: train_loss=11097.04395, val_loss=11252.66992\n",
      "Epoch 1982: train_loss=11092.05078, val_loss=11247.70801\n",
      "Epoch 1983: train_loss=11087.07031, val_loss=11242.75977\n",
      "Epoch 1984: train_loss=11082.10352, val_loss=11237.82520\n",
      "Epoch 1985: train_loss=11077.14844, val_loss=11232.90137\n",
      "Epoch 1986: train_loss=11072.20703, val_loss=11227.99219\n",
      "Epoch 1987: train_loss=11067.28027, val_loss=11223.09766\n",
      "Epoch 1988: train_loss=11062.36621, val_loss=11218.21387\n",
      "Epoch 1989: train_loss=11057.46680, val_loss=11213.34375\n",
      "Epoch 1990: train_loss=11052.57812, val_loss=11208.49023\n",
      "Epoch 1991: train_loss=11047.70410, val_loss=11203.64941\n",
      "Epoch 1992: train_loss=11042.84082, val_loss=11198.81836\n",
      "Epoch 1993: train_loss=11037.98828, val_loss=11194.00000\n",
      "Epoch 1994: train_loss=11033.15137, val_loss=11189.19531\n",
      "Epoch 1995: train_loss=11028.32520, val_loss=11184.40430\n",
      "Epoch 1996: train_loss=11023.51172, val_loss=11179.62207\n",
      "Epoch 1997: train_loss=11018.71289, val_loss=11174.85449\n",
      "Epoch 1998: train_loss=11013.92383, val_loss=11170.10059\n",
      "Epoch 1999: train_loss=11009.14844, val_loss=11165.35742\n",
      "Epoch 2000: train_loss=11004.38867, val_loss=11160.62793\n",
      "Epoch 2001: train_loss=10999.64355, val_loss=11155.91016\n",
      "Epoch 2002: train_loss=10994.90723, val_loss=11151.20703\n",
      "Epoch 2003: train_loss=10990.18945, val_loss=11146.51465\n",
      "Epoch 2004: train_loss=10985.48145, val_loss=11141.83398\n",
      "Epoch 2005: train_loss=10980.78516, val_loss=11137.16699\n",
      "Epoch 2006: train_loss=10976.10254, val_loss=11132.51367\n",
      "Epoch 2007: train_loss=10971.43262, val_loss=11127.87207\n",
      "Epoch 2008: train_loss=10966.77734, val_loss=11123.24609\n",
      "Epoch 2009: train_loss=10962.13672, val_loss=11118.63477\n",
      "Epoch 2010: train_loss=10957.50879, val_loss=11114.03027\n",
      "Epoch 2011: train_loss=10952.89355, val_loss=11109.44141\n",
      "Epoch 2012: train_loss=10948.29395, val_loss=11104.86621\n",
      "Epoch 2013: train_loss=10943.70703, val_loss=11100.30566\n",
      "Epoch 2014: train_loss=10939.13281, val_loss=11095.75781\n",
      "Epoch 2015: train_loss=10934.57227, val_loss=11091.22363\n",
      "Epoch 2016: train_loss=10930.02246, val_loss=11086.70020\n",
      "Epoch 2017: train_loss=10925.48926, val_loss=11082.18945\n",
      "Epoch 2018: train_loss=10920.96387, val_loss=11077.68945\n",
      "Epoch 2019: train_loss=10916.45312, val_loss=11073.20117\n",
      "Epoch 2020: train_loss=10911.95215, val_loss=11068.72461\n",
      "Epoch 2021: train_loss=10907.46289, val_loss=11064.25977\n",
      "Epoch 2022: train_loss=10902.98633, val_loss=11059.80469\n",
      "Epoch 2023: train_loss=10898.52051, val_loss=11055.36523\n",
      "Epoch 2024: train_loss=10894.07324, val_loss=11050.93652\n",
      "Epoch 2025: train_loss=10889.63574, val_loss=11046.51953\n",
      "Epoch 2026: train_loss=10885.21289, val_loss=11042.11719\n",
      "Epoch 2027: train_loss=10880.80176, val_loss=11037.72852\n",
      "Epoch 2028: train_loss=10876.40332, val_loss=11033.34863\n",
      "Epoch 2029: train_loss=10872.01855, val_loss=11028.98242\n",
      "Epoch 2030: train_loss=10867.64453, val_loss=11024.62793\n",
      "Epoch 2031: train_loss=10863.28320, val_loss=11020.28320\n",
      "Epoch 2032: train_loss=10858.93457, val_loss=11015.95117\n",
      "Epoch 2033: train_loss=10854.59766, val_loss=11011.63184\n",
      "Epoch 2034: train_loss=10850.27344, val_loss=11007.32520\n",
      "Epoch 2035: train_loss=10845.96191, val_loss=11003.03027\n",
      "Epoch 2036: train_loss=10841.66211, val_loss=10998.74609\n",
      "Epoch 2037: train_loss=10837.37402, val_loss=10994.47363\n",
      "Epoch 2038: train_loss=10833.09863, val_loss=10990.21582\n",
      "Epoch 2039: train_loss=10828.83398, val_loss=10985.96680\n",
      "Epoch 2040: train_loss=10824.58203, val_loss=10981.72852\n",
      "Epoch 2041: train_loss=10820.34277, val_loss=10977.50195\n",
      "Epoch 2042: train_loss=10816.11523, val_loss=10973.28809\n",
      "Epoch 2043: train_loss=10811.89941, val_loss=10969.08301\n",
      "Epoch 2044: train_loss=10807.69434, val_loss=10964.89160\n",
      "Epoch 2045: train_loss=10803.50098, val_loss=10960.70996\n",
      "Epoch 2046: train_loss=10799.31934, val_loss=10956.53906\n",
      "Epoch 2047: train_loss=10795.15039, val_loss=10952.37988\n",
      "Epoch 2048: train_loss=10790.99219, val_loss=10948.23438\n",
      "Epoch 2049: train_loss=10786.84668, val_loss=10944.10059\n",
      "Epoch 2050: train_loss=10782.71387, val_loss=10939.97949\n",
      "Epoch 2051: train_loss=10778.59375, val_loss=10935.86816\n",
      "Epoch 2052: train_loss=10774.48535, val_loss=10931.76855\n",
      "Epoch 2053: train_loss=10770.38867, val_loss=10927.67969\n",
      "Epoch 2054: train_loss=10766.30273, val_loss=10923.60156\n",
      "Epoch 2055: train_loss=10762.23047, val_loss=10919.53418\n",
      "Epoch 2056: train_loss=10758.16895, val_loss=10915.48145\n",
      "Epoch 2057: train_loss=10754.12109, val_loss=10911.43750\n",
      "Epoch 2058: train_loss=10750.08398, val_loss=10907.40820\n",
      "Epoch 2059: train_loss=10746.06055, val_loss=10903.38867\n",
      "Epoch 2060: train_loss=10742.04980, val_loss=10899.38086\n",
      "Epoch 2061: train_loss=10738.05078, val_loss=10895.38379\n",
      "Epoch 2062: train_loss=10734.06738, val_loss=10891.39746\n",
      "Epoch 2063: train_loss=10730.09277, val_loss=10887.42383\n",
      "Epoch 2064: train_loss=10726.13086, val_loss=10883.46094\n",
      "Epoch 2065: train_loss=10722.17969, val_loss=10879.51074\n",
      "Epoch 2066: train_loss=10718.24121, val_loss=10875.57031\n",
      "Epoch 2067: train_loss=10714.31445, val_loss=10871.64258\n",
      "Epoch 2068: train_loss=10710.39844, val_loss=10867.72754\n",
      "Epoch 2069: train_loss=10706.49512, val_loss=10863.82227\n",
      "Epoch 2070: train_loss=10702.60254, val_loss=10859.92773\n",
      "Epoch 2071: train_loss=10698.72461, val_loss=10856.04688\n",
      "Epoch 2072: train_loss=10694.85742, val_loss=10852.17871\n",
      "Epoch 2073: train_loss=10691.00195, val_loss=10848.32129\n",
      "Epoch 2074: train_loss=10687.15918, val_loss=10844.47461\n",
      "Epoch 2075: train_loss=10683.33008, val_loss=10840.64160\n",
      "Epoch 2076: train_loss=10679.51074, val_loss=10836.82031\n",
      "Epoch 2077: train_loss=10675.70605, val_loss=10833.01172\n",
      "Epoch 2078: train_loss=10671.91211, val_loss=10829.21387\n",
      "Epoch 2079: train_loss=10668.13086, val_loss=10825.42773\n",
      "Epoch 2080: train_loss=10664.36230, val_loss=10821.65625\n",
      "Epoch 2081: train_loss=10660.60449, val_loss=10817.89453\n",
      "Epoch 2082: train_loss=10656.85938, val_loss=10814.14648\n",
      "Epoch 2083: train_loss=10653.12793, val_loss=10810.40918\n",
      "Epoch 2084: train_loss=10649.40820, val_loss=10806.68359\n",
      "Epoch 2085: train_loss=10645.70020, val_loss=10802.97168\n",
      "Epoch 2086: train_loss=10642.00488, val_loss=10799.26758\n",
      "Epoch 2087: train_loss=10638.32031, val_loss=10795.57617\n",
      "Epoch 2088: train_loss=10634.64648, val_loss=10791.89844\n",
      "Epoch 2089: train_loss=10630.98340, val_loss=10788.22949\n",
      "Epoch 2090: train_loss=10627.33301, val_loss=10784.56934\n",
      "Epoch 2091: train_loss=10623.69238, val_loss=10780.92188\n",
      "Epoch 2092: train_loss=10620.06348, val_loss=10777.28418\n",
      "Epoch 2093: train_loss=10616.44434, val_loss=10773.65820\n",
      "Epoch 2094: train_loss=10612.83594, val_loss=10770.04004\n",
      "Epoch 2095: train_loss=10609.23926, val_loss=10766.43359\n",
      "Epoch 2096: train_loss=10605.65234, val_loss=10762.83887\n",
      "Epoch 2097: train_loss=10602.07715, val_loss=10759.25293\n",
      "Epoch 2098: train_loss=10598.51172, val_loss=10755.67676\n",
      "Epoch 2099: train_loss=10594.95801, val_loss=10752.11133\n",
      "Epoch 2100: train_loss=10591.41309, val_loss=10748.55664\n",
      "Epoch 2101: train_loss=10587.88184, val_loss=10745.01758\n",
      "Epoch 2102: train_loss=10584.36230, val_loss=10741.48926\n",
      "Epoch 2103: train_loss=10580.85547, val_loss=10737.97168\n",
      "Epoch 2104: train_loss=10577.35938, val_loss=10734.46387\n",
      "Epoch 2105: train_loss=10573.87402, val_loss=10730.96875\n",
      "Epoch 2106: train_loss=10570.40234, val_loss=10727.48633\n",
      "Epoch 2107: train_loss=10566.94043, val_loss=10724.01855\n",
      "Epoch 2108: train_loss=10563.49414, val_loss=10720.56445\n",
      "Epoch 2109: train_loss=10560.06055, val_loss=10717.12012\n",
      "Epoch 2110: train_loss=10556.63574, val_loss=10713.68652\n",
      "Epoch 2111: train_loss=10553.22656, val_loss=10710.26660\n",
      "Epoch 2112: train_loss=10549.82910, val_loss=10706.85645\n",
      "Epoch 2113: train_loss=10546.44238, val_loss=10703.45996\n",
      "Epoch 2114: train_loss=10543.06738, val_loss=10700.07715\n",
      "Epoch 2115: train_loss=10539.70312, val_loss=10696.70508\n",
      "Epoch 2116: train_loss=10536.35156, val_loss=10693.34375\n",
      "Epoch 2117: train_loss=10533.00781, val_loss=10689.99316\n",
      "Epoch 2118: train_loss=10529.67773, val_loss=10686.65332\n",
      "Epoch 2119: train_loss=10526.35742, val_loss=10683.32520\n",
      "Epoch 2120: train_loss=10523.04688, val_loss=10680.00879\n",
      "Epoch 2121: train_loss=10519.74805, val_loss=10676.70117\n",
      "Epoch 2122: train_loss=10516.45801, val_loss=10673.40527\n",
      "Epoch 2123: train_loss=10513.18164, val_loss=10670.12012\n",
      "Epoch 2124: train_loss=10509.91504, val_loss=10666.84766\n",
      "Epoch 2125: train_loss=10506.66016, val_loss=10663.58301\n",
      "Epoch 2126: train_loss=10503.41504, val_loss=10660.33105\n",
      "Epoch 2127: train_loss=10500.17969, val_loss=10657.08691\n",
      "Epoch 2128: train_loss=10496.95703, val_loss=10653.85156\n",
      "Epoch 2129: train_loss=10493.74219, val_loss=10650.62793\n",
      "Epoch 2130: train_loss=10490.53809, val_loss=10647.41406\n",
      "Epoch 2131: train_loss=10487.34375, val_loss=10644.21191\n",
      "Epoch 2132: train_loss=10484.15918, val_loss=10641.01660\n",
      "Epoch 2133: train_loss=10480.98535, val_loss=10637.83301\n",
      "Epoch 2134: train_loss=10477.82227, val_loss=10634.65918\n",
      "Epoch 2135: train_loss=10474.66992, val_loss=10631.49805\n",
      "Epoch 2136: train_loss=10471.52832, val_loss=10628.34668\n",
      "Epoch 2137: train_loss=10468.39746, val_loss=10625.20703\n",
      "Epoch 2138: train_loss=10465.27832, val_loss=10622.07617\n",
      "Epoch 2139: train_loss=10462.16895, val_loss=10618.95508\n",
      "Epoch 2140: train_loss=10459.06836, val_loss=10615.84473\n",
      "Epoch 2141: train_loss=10455.97754, val_loss=10612.74121\n",
      "Epoch 2142: train_loss=10452.89844, val_loss=10609.64941\n",
      "Epoch 2143: train_loss=10449.82715, val_loss=10606.56348\n",
      "Epoch 2144: train_loss=10446.76367, val_loss=10603.49023\n",
      "Epoch 2145: train_loss=10443.71191, val_loss=10600.42285\n",
      "Epoch 2146: train_loss=10440.66992, val_loss=10597.36621\n",
      "Epoch 2147: train_loss=10437.63672, val_loss=10594.31934\n",
      "Epoch 2148: train_loss=10434.61426, val_loss=10591.28223\n",
      "Epoch 2149: train_loss=10431.60156, val_loss=10588.25391\n",
      "Epoch 2150: train_loss=10428.59961, val_loss=10585.23633\n",
      "Epoch 2151: train_loss=10425.60547, val_loss=10582.22559\n",
      "Epoch 2152: train_loss=10422.62207, val_loss=10579.22559\n",
      "Epoch 2153: train_loss=10419.64746, val_loss=10576.23242\n",
      "Epoch 2154: train_loss=10416.68164, val_loss=10573.24902\n",
      "Epoch 2155: train_loss=10413.72461, val_loss=10570.27539\n",
      "Epoch 2156: train_loss=10410.77832, val_loss=10567.30859\n",
      "Epoch 2157: train_loss=10407.84180, val_loss=10564.35156\n",
      "Epoch 2158: train_loss=10404.91309, val_loss=10561.40527\n",
      "Epoch 2159: train_loss=10401.99609, val_loss=10558.46484\n",
      "Epoch 2160: train_loss=10399.08984, val_loss=10555.53711\n",
      "Epoch 2161: train_loss=10396.19434, val_loss=10552.62109\n",
      "Epoch 2162: train_loss=10393.30762, val_loss=10549.71484\n",
      "Epoch 2163: train_loss=10390.42871, val_loss=10546.82129\n",
      "Epoch 2164: train_loss=10387.56152, val_loss=10543.93457\n",
      "Epoch 2165: train_loss=10384.70410, val_loss=10541.05566\n",
      "Epoch 2166: train_loss=10381.85547, val_loss=10538.18457\n",
      "Epoch 2167: train_loss=10379.01758, val_loss=10535.32324\n",
      "Epoch 2168: train_loss=10376.19238, val_loss=10532.46973\n",
      "Epoch 2169: train_loss=10373.37402, val_loss=10529.62598\n",
      "Epoch 2170: train_loss=10370.56543, val_loss=10526.79395\n",
      "Epoch 2171: train_loss=10367.77051, val_loss=10523.97168\n",
      "Epoch 2172: train_loss=10364.98340, val_loss=10521.16113\n",
      "Epoch 2173: train_loss=10362.20410, val_loss=10518.36133\n",
      "Epoch 2174: train_loss=10359.43457, val_loss=10515.56934\n",
      "Epoch 2175: train_loss=10356.67285, val_loss=10512.78223\n",
      "Epoch 2176: train_loss=10353.92188, val_loss=10510.00391\n",
      "Epoch 2177: train_loss=10351.17676, val_loss=10507.23242\n",
      "Epoch 2178: train_loss=10348.44336, val_loss=10504.47266\n",
      "Epoch 2179: train_loss=10345.71875, val_loss=10501.72363\n",
      "Epoch 2180: train_loss=10343.00195, val_loss=10498.98438\n",
      "Epoch 2181: train_loss=10340.29785, val_loss=10496.25391\n",
      "Epoch 2182: train_loss=10337.59863, val_loss=10493.52930\n",
      "Epoch 2183: train_loss=10334.91113, val_loss=10490.81543\n",
      "Epoch 2184: train_loss=10332.23145, val_loss=10488.11426\n",
      "Epoch 2185: train_loss=10329.56250, val_loss=10485.42285\n",
      "Epoch 2186: train_loss=10326.90234, val_loss=10482.74023\n",
      "Epoch 2187: train_loss=10324.25293, val_loss=10480.06641\n",
      "Epoch 2188: train_loss=10321.60938, val_loss=10477.39844\n",
      "Epoch 2189: train_loss=10318.97461, val_loss=10474.74219\n",
      "Epoch 2190: train_loss=10316.34961, val_loss=10472.09570\n",
      "Epoch 2191: train_loss=10313.73340, val_loss=10469.45605\n",
      "Epoch 2192: train_loss=10311.12402, val_loss=10466.82520\n",
      "Epoch 2193: train_loss=10308.52539, val_loss=10464.20410\n",
      "Epoch 2194: train_loss=10305.93555, val_loss=10461.59277\n",
      "Epoch 2195: train_loss=10303.35449, val_loss=10458.98926\n",
      "Epoch 2196: train_loss=10300.78125, val_loss=10456.39551\n",
      "Epoch 2197: train_loss=10298.21777, val_loss=10453.80859\n",
      "Epoch 2198: train_loss=10295.66016, val_loss=10451.23242\n",
      "Epoch 2199: train_loss=10293.11133, val_loss=10448.66211\n",
      "Epoch 2200: train_loss=10290.57129, val_loss=10446.10156\n",
      "Epoch 2201: train_loss=10288.03809, val_loss=10443.54980\n",
      "Epoch 2202: train_loss=10285.51660, val_loss=10441.00781\n",
      "Epoch 2203: train_loss=10283.00098, val_loss=10438.47266\n",
      "Epoch 2204: train_loss=10280.49219, val_loss=10435.94629\n",
      "Epoch 2205: train_loss=10277.99316, val_loss=10433.42773\n",
      "Epoch 2206: train_loss=10275.50000, val_loss=10430.91602\n",
      "Epoch 2207: train_loss=10273.01562, val_loss=10428.41211\n",
      "Epoch 2208: train_loss=10270.54004, val_loss=10425.91992\n",
      "Epoch 2209: train_loss=10268.07227, val_loss=10423.44141\n",
      "Epoch 2210: train_loss=10265.61621, val_loss=10420.96973\n",
      "Epoch 2211: train_loss=10263.16992, val_loss=10418.50586\n",
      "Epoch 2212: train_loss=10260.73145, val_loss=10416.04980\n",
      "Epoch 2213: train_loss=10258.30176, val_loss=10413.60254\n",
      "Epoch 2214: train_loss=10255.87891, val_loss=10411.16602\n",
      "Epoch 2215: train_loss=10253.46680, val_loss=10408.74121\n",
      "Epoch 2216: train_loss=10251.06738, val_loss=10406.32324\n",
      "Epoch 2217: train_loss=10248.67676, val_loss=10403.91504\n",
      "Epoch 2218: train_loss=10246.29492, val_loss=10401.51367\n",
      "Epoch 2219: train_loss=10243.91992, val_loss=10399.12305\n",
      "Epoch 2220: train_loss=10241.55371, val_loss=10396.73828\n",
      "Epoch 2221: train_loss=10239.19727, val_loss=10394.36328\n",
      "Epoch 2222: train_loss=10236.84668, val_loss=10391.99414\n",
      "Epoch 2223: train_loss=10234.50586, val_loss=10389.63574\n",
      "Epoch 2224: train_loss=10232.16992, val_loss=10387.28418\n",
      "Epoch 2225: train_loss=10229.84277, val_loss=10384.93945\n",
      "Epoch 2226: train_loss=10227.52246, val_loss=10382.60352\n",
      "Epoch 2227: train_loss=10225.20898, val_loss=10380.27441\n",
      "Epoch 2228: train_loss=10222.90332, val_loss=10377.95215\n",
      "Epoch 2229: train_loss=10220.60449, val_loss=10375.63770\n",
      "Epoch 2230: train_loss=10218.31445, val_loss=10373.32812\n",
      "Epoch 2231: train_loss=10216.03027, val_loss=10371.02734\n",
      "Epoch 2232: train_loss=10213.75488, val_loss=10368.73438\n",
      "Epoch 2233: train_loss=10211.48730, val_loss=10366.44922\n",
      "Epoch 2234: train_loss=10209.22754, val_loss=10364.17090\n",
      "Epoch 2235: train_loss=10206.97559, val_loss=10361.90234\n",
      "Epoch 2236: train_loss=10204.73242, val_loss=10359.64258\n",
      "Epoch 2237: train_loss=10202.49805, val_loss=10357.38965\n",
      "Epoch 2238: train_loss=10200.27051, val_loss=10355.14355\n",
      "Epoch 2239: train_loss=10198.05176, val_loss=10352.90430\n",
      "Epoch 2240: train_loss=10195.84082, val_loss=10350.67383\n",
      "Epoch 2241: train_loss=10193.63770, val_loss=10348.45117\n",
      "Epoch 2242: train_loss=10191.44141, val_loss=10346.23926\n",
      "Epoch 2243: train_loss=10189.25488, val_loss=10344.03223\n",
      "Epoch 2244: train_loss=10187.07422, val_loss=10341.83301\n",
      "Epoch 2245: train_loss=10184.90137, val_loss=10339.63965\n",
      "Epoch 2246: train_loss=10182.73438, val_loss=10337.45117\n",
      "Epoch 2247: train_loss=10180.57324, val_loss=10335.27051\n",
      "Epoch 2248: train_loss=10178.41992, val_loss=10333.09570\n",
      "Epoch 2249: train_loss=10176.27246, val_loss=10330.92676\n",
      "Epoch 2250: train_loss=10174.13184, val_loss=10328.76270\n",
      "Epoch 2251: train_loss=10171.99707, val_loss=10326.60645\n",
      "Epoch 2252: train_loss=10169.86816, val_loss=10324.45703\n",
      "Epoch 2253: train_loss=10167.74609, val_loss=10322.31543\n",
      "Epoch 2254: train_loss=10165.63184, val_loss=10320.17773\n",
      "Epoch 2255: train_loss=10163.52246, val_loss=10318.04590\n",
      "Epoch 2256: train_loss=10161.41992, val_loss=10315.91992\n",
      "Epoch 2257: train_loss=10159.32324, val_loss=10313.79980\n",
      "Epoch 2258: train_loss=10157.23535, val_loss=10311.68555\n",
      "Epoch 2259: train_loss=10155.15332, val_loss=10309.57715\n",
      "Epoch 2260: train_loss=10153.07812, val_loss=10307.47461\n",
      "Epoch 2261: train_loss=10151.00781, val_loss=10305.37500\n",
      "Epoch 2262: train_loss=10148.94434, val_loss=10303.28223\n",
      "Epoch 2263: train_loss=10146.88477, val_loss=10301.19238\n",
      "Epoch 2264: train_loss=10144.83203, val_loss=10299.10742\n",
      "Epoch 2265: train_loss=10142.78125, val_loss=10297.02441\n",
      "Epoch 2266: train_loss=10140.73535, val_loss=10294.95117\n",
      "Epoch 2267: train_loss=10138.69824, val_loss=10292.88770\n",
      "Epoch 2268: train_loss=10136.67090, val_loss=10290.83203\n",
      "Epoch 2269: train_loss=10134.64844, val_loss=10288.78027\n",
      "Epoch 2270: train_loss=10132.63379, val_loss=10286.73730\n",
      "Epoch 2271: train_loss=10130.62305, val_loss=10284.69824\n",
      "Epoch 2272: train_loss=10128.61914, val_loss=10282.66797\n",
      "Epoch 2273: train_loss=10126.62305, val_loss=10280.64551\n",
      "Epoch 2274: train_loss=10124.63184, val_loss=10278.62695\n",
      "Epoch 2275: train_loss=10122.64551, val_loss=10276.61328\n",
      "Epoch 2276: train_loss=10120.66699, val_loss=10274.60938\n",
      "Epoch 2277: train_loss=10118.69824, val_loss=10272.61523\n",
      "Epoch 2278: train_loss=10116.73535, val_loss=10270.62695\n",
      "Epoch 2279: train_loss=10114.77637, val_loss=10268.64453\n",
      "Epoch 2280: train_loss=10112.82031, val_loss=10266.67188\n",
      "Epoch 2281: train_loss=10110.87207, val_loss=10264.70508\n",
      "Epoch 2282: train_loss=10108.92969, val_loss=10262.74219\n",
      "Epoch 2283: train_loss=10106.99512, val_loss=10260.78418\n",
      "Epoch 2284: train_loss=10105.06445, val_loss=10258.83008\n",
      "Epoch 2285: train_loss=10103.13965, val_loss=10256.87988\n",
      "Epoch 2286: train_loss=10101.21973, val_loss=10254.93457\n",
      "Epoch 2287: train_loss=10099.30371, val_loss=10252.99609\n",
      "Epoch 2288: train_loss=10097.39648, val_loss=10251.06348\n",
      "Epoch 2289: train_loss=10095.49414, val_loss=10249.13477\n",
      "Epoch 2290: train_loss=10093.59766, val_loss=10247.21289\n",
      "Epoch 2291: train_loss=10091.71094, val_loss=10245.30078\n",
      "Epoch 2292: train_loss=10089.82812, val_loss=10243.39746\n",
      "Epoch 2293: train_loss=10087.95215, val_loss=10241.50195\n",
      "Epoch 2294: train_loss=10086.08203, val_loss=10239.61328\n",
      "Epoch 2295: train_loss=10084.21777, val_loss=10237.73145\n",
      "Epoch 2296: train_loss=10082.36133, val_loss=10235.85254\n",
      "Epoch 2297: train_loss=10080.50977, val_loss=10233.97754\n",
      "Epoch 2298: train_loss=10078.66406, val_loss=10232.10840\n",
      "Epoch 2299: train_loss=10076.82227, val_loss=10230.24316\n",
      "Epoch 2300: train_loss=10074.98535, val_loss=10228.38574\n",
      "Epoch 2301: train_loss=10073.15625, val_loss=10226.53613\n",
      "Epoch 2302: train_loss=10071.33301, val_loss=10224.69043\n",
      "Epoch 2303: train_loss=10069.51465, val_loss=10222.85254\n",
      "Epoch 2304: train_loss=10067.70020, val_loss=10221.02051\n",
      "Epoch 2305: train_loss=10065.89453, val_loss=10219.19043\n",
      "Epoch 2306: train_loss=10064.09277, val_loss=10217.36523\n",
      "Epoch 2307: train_loss=10062.29688, val_loss=10215.54590\n",
      "Epoch 2308: train_loss=10060.50488, val_loss=10213.73340\n",
      "Epoch 2309: train_loss=10058.71875, val_loss=10211.93066\n",
      "Epoch 2310: train_loss=10056.94238, val_loss=10210.13379\n",
      "Epoch 2311: train_loss=10055.17090, val_loss=10208.33594\n",
      "Epoch 2312: train_loss=10053.40332, val_loss=10206.54590\n",
      "Epoch 2313: train_loss=10051.64355, val_loss=10204.76465\n",
      "Epoch 2314: train_loss=10049.89160, val_loss=10202.98828\n",
      "Epoch 2315: train_loss=10048.14062, val_loss=10201.22070\n",
      "Epoch 2316: train_loss=10046.40137, val_loss=10199.45703\n",
      "Epoch 2317: train_loss=10044.66406, val_loss=10197.69727\n",
      "Epoch 2318: train_loss=10042.93262, val_loss=10195.94434\n",
      "Epoch 2319: train_loss=10041.20605, val_loss=10194.19727\n",
      "Epoch 2320: train_loss=10039.48633, val_loss=10192.45508\n",
      "Epoch 2321: train_loss=10037.77051, val_loss=10190.71973\n",
      "Epoch 2322: train_loss=10036.06152, val_loss=10188.99023\n",
      "Epoch 2323: train_loss=10034.35840, val_loss=10187.26367\n",
      "Epoch 2324: train_loss=10032.66016, val_loss=10185.54395\n",
      "Epoch 2325: train_loss=10030.96777, val_loss=10183.82910\n",
      "Epoch 2326: train_loss=10029.28125, val_loss=10182.11914\n",
      "Epoch 2327: train_loss=10027.59863, val_loss=10180.41504\n",
      "Epoch 2328: train_loss=10025.92188, val_loss=10178.71680\n",
      "Epoch 2329: train_loss=10024.25098, val_loss=10177.02148\n",
      "Epoch 2330: train_loss=10022.58398, val_loss=10175.33105\n",
      "Epoch 2331: train_loss=10020.91895, val_loss=10173.64551\n",
      "Epoch 2332: train_loss=10019.26172, val_loss=10171.96484\n",
      "Epoch 2333: train_loss=10017.60938, val_loss=10170.28711\n",
      "Epoch 2334: train_loss=10015.96094, val_loss=10168.61719\n",
      "Epoch 2335: train_loss=10014.32031, val_loss=10166.94922\n",
      "Epoch 2336: train_loss=10012.68164, val_loss=10165.28809\n",
      "Epoch 2337: train_loss=10011.04883, val_loss=10163.63184\n",
      "Epoch 2338: train_loss=10009.42090, val_loss=10161.97852\n",
      "Epoch 2339: train_loss=10007.79688, val_loss=10160.33203\n",
      "Epoch 2340: train_loss=10006.17871, val_loss=10158.68750\n",
      "Epoch 2341: train_loss=10004.56445, val_loss=10157.04980\n",
      "Epoch 2342: train_loss=10002.95508, val_loss=10155.41602\n",
      "Epoch 2343: train_loss=10001.35156, val_loss=10153.78711\n",
      "Epoch 2344: train_loss=9999.75195, val_loss=10152.16309\n",
      "Epoch 2345: train_loss=9998.15723, val_loss=10150.54199\n",
      "Epoch 2346: train_loss=9996.56641, val_loss=10148.92969\n",
      "Epoch 2347: train_loss=9994.98047, val_loss=10147.31641\n",
      "Epoch 2348: train_loss=9993.39844, val_loss=10145.71094\n",
      "Epoch 2349: train_loss=9991.82031, val_loss=10144.10938\n",
      "Epoch 2350: train_loss=9990.24707, val_loss=10142.51758\n",
      "Epoch 2351: train_loss=9988.68066, val_loss=10140.92871\n",
      "Epoch 2352: train_loss=9987.11914, val_loss=10139.34473\n",
      "Epoch 2353: train_loss=9985.56152, val_loss=10137.76660\n",
      "Epoch 2354: train_loss=9984.00977, val_loss=10136.19043\n",
      "Epoch 2355: train_loss=9982.46094, val_loss=10134.62109\n",
      "Epoch 2356: train_loss=9980.91699, val_loss=10133.05371\n",
      "Epoch 2357: train_loss=9979.37598, val_loss=10131.49316\n",
      "Epoch 2358: train_loss=9977.84180, val_loss=10129.93262\n",
      "Epoch 2359: train_loss=9976.30957, val_loss=10128.37793\n",
      "Epoch 2360: train_loss=9974.78125, val_loss=10126.82617\n",
      "Epoch 2361: train_loss=9973.25879, val_loss=10125.27832\n",
      "Epoch 2362: train_loss=9971.73828, val_loss=10123.73535\n",
      "Epoch 2363: train_loss=9970.22363, val_loss=10122.19434\n",
      "Epoch 2364: train_loss=9968.70996, val_loss=10120.65918\n",
      "Epoch 2365: train_loss=9967.20312, val_loss=10119.12793\n",
      "Epoch 2366: train_loss=9965.69824, val_loss=10117.60059\n",
      "Epoch 2367: train_loss=9964.19824, val_loss=10116.07715\n",
      "Epoch 2368: train_loss=9962.70215, val_loss=10114.55664\n",
      "Epoch 2369: train_loss=9961.20898, val_loss=10113.04199\n",
      "Epoch 2370: train_loss=9959.71973, val_loss=10111.52734\n",
      "Epoch 2371: train_loss=9958.23535, val_loss=10110.02148\n",
      "Epoch 2372: train_loss=9956.75879, val_loss=10108.52051\n",
      "Epoch 2373: train_loss=9955.28613, val_loss=10107.02148\n",
      "Epoch 2374: train_loss=9953.81641, val_loss=10105.52832\n",
      "Epoch 2375: train_loss=9952.35352, val_loss=10104.03711\n",
      "Epoch 2376: train_loss=9950.89160, val_loss=10102.54980\n",
      "Epoch 2377: train_loss=9949.43652, val_loss=10101.06445\n",
      "Epoch 2378: train_loss=9947.98340, val_loss=10099.58105\n",
      "Epoch 2379: train_loss=9946.53516, val_loss=10098.10059\n",
      "Epoch 2380: train_loss=9945.09277, val_loss=10096.62500\n",
      "Epoch 2381: train_loss=9943.65430, val_loss=10095.15430\n",
      "Epoch 2382: train_loss=9942.22070, val_loss=10093.68848\n",
      "Epoch 2383: train_loss=9940.79004, val_loss=10092.22559\n",
      "Epoch 2384: train_loss=9939.36621, val_loss=10090.77051\n",
      "Epoch 2385: train_loss=9937.94629, val_loss=10089.31836\n",
      "Epoch 2386: train_loss=9936.52930, val_loss=10087.87109\n",
      "Epoch 2387: train_loss=9935.11719, val_loss=10086.42676\n",
      "Epoch 2388: train_loss=9933.70996, val_loss=10084.98828\n",
      "Epoch 2389: train_loss=9932.30566, val_loss=10083.55469\n",
      "Epoch 2390: train_loss=9930.90527, val_loss=10082.13086\n",
      "Epoch 2391: train_loss=9929.51758, val_loss=10080.71680\n",
      "Epoch 2392: train_loss=9928.13184, val_loss=10079.30762\n",
      "Epoch 2393: train_loss=9926.74609, val_loss=10077.90137\n",
      "Epoch 2394: train_loss=9925.36035, val_loss=10076.50195\n",
      "Epoch 2395: train_loss=9923.97852, val_loss=10075.10938\n",
      "Epoch 2396: train_loss=9922.59863, val_loss=10073.72656\n",
      "Epoch 2397: train_loss=9921.22754, val_loss=10072.34570\n",
      "Epoch 2398: train_loss=9919.86230, val_loss=10070.96582\n",
      "Epoch 2399: train_loss=9918.50098, val_loss=10069.58789\n",
      "Epoch 2400: train_loss=9917.14258, val_loss=10068.21191\n",
      "Epoch 2401: train_loss=9915.78711, val_loss=10066.83789\n",
      "Epoch 2402: train_loss=9914.43555, val_loss=10065.46680\n",
      "Epoch 2403: train_loss=9913.08691, val_loss=10064.09766\n",
      "Epoch 2404: train_loss=9911.74023, val_loss=10062.73145\n",
      "Epoch 2405: train_loss=9910.40137, val_loss=10061.37109\n",
      "Epoch 2406: train_loss=9909.06836, val_loss=10060.01953\n",
      "Epoch 2407: train_loss=9907.73926, val_loss=10058.67285\n",
      "Epoch 2408: train_loss=9906.41309, val_loss=10057.33203\n",
      "Epoch 2409: train_loss=9905.08984, val_loss=10055.99707\n",
      "Epoch 2410: train_loss=9903.76855, val_loss=10054.66699\n",
      "Epoch 2411: train_loss=9902.45117, val_loss=10053.34473\n",
      "Epoch 2412: train_loss=9901.14160, val_loss=10052.02246\n",
      "Epoch 2413: train_loss=9899.83594, val_loss=10050.70020\n",
      "Epoch 2414: train_loss=9898.53027, val_loss=10049.37793\n",
      "Epoch 2415: train_loss=9897.22949, val_loss=10048.05566\n",
      "Epoch 2416: train_loss=9895.93066, val_loss=10046.73926\n",
      "Epoch 2417: train_loss=9894.63574, val_loss=10045.42480\n",
      "Epoch 2418: train_loss=9893.34766, val_loss=10044.11719\n",
      "Epoch 2419: train_loss=9892.06055, val_loss=10042.81445\n",
      "Epoch 2420: train_loss=9890.77637, val_loss=10041.51367\n",
      "Epoch 2421: train_loss=9889.49512, val_loss=10040.21680\n",
      "Epoch 2422: train_loss=9888.21680, val_loss=10038.92578\n",
      "Epoch 2423: train_loss=9886.94238, val_loss=10037.63867\n",
      "Epoch 2424: train_loss=9885.67188, val_loss=10036.35645\n",
      "Epoch 2425: train_loss=9884.40625, val_loss=10035.07227\n",
      "Epoch 2426: train_loss=9883.14160, val_loss=10033.78906\n",
      "Epoch 2427: train_loss=9881.88086, val_loss=10032.50781\n",
      "Epoch 2428: train_loss=9880.62207, val_loss=10031.23047\n",
      "Epoch 2429: train_loss=9879.36719, val_loss=10029.95703\n",
      "Epoch 2430: train_loss=9878.11621, val_loss=10028.68750\n",
      "Epoch 2431: train_loss=9876.86621, val_loss=10027.42188\n",
      "Epoch 2432: train_loss=9875.61914, val_loss=10026.15918\n",
      "Epoch 2433: train_loss=9874.37793, val_loss=10024.89941\n",
      "Epoch 2434: train_loss=9873.13867, val_loss=10023.64453\n",
      "Epoch 2435: train_loss=9871.90332, val_loss=10022.39258\n",
      "Epoch 2436: train_loss=9870.67285, val_loss=10021.14160\n",
      "Epoch 2437: train_loss=9869.44434, val_loss=10019.89258\n",
      "Epoch 2438: train_loss=9868.21777, val_loss=10018.64746\n",
      "Epoch 2439: train_loss=9866.99609, val_loss=10017.40527\n",
      "Epoch 2440: train_loss=9865.77637, val_loss=10016.16797\n",
      "Epoch 2441: train_loss=9864.55859, val_loss=10014.93457\n",
      "Epoch 2442: train_loss=9863.34473, val_loss=10013.70508\n",
      "Epoch 2443: train_loss=9862.13379, val_loss=10012.47656\n",
      "Epoch 2444: train_loss=9860.92383, val_loss=10011.25000\n",
      "Epoch 2445: train_loss=9859.71973, val_loss=10010.02832\n",
      "Epoch 2446: train_loss=9858.51758, val_loss=10008.80762\n",
      "Epoch 2447: train_loss=9857.31836, val_loss=10007.58984\n",
      "Epoch 2448: train_loss=9856.12402, val_loss=10006.37500\n",
      "Epoch 2449: train_loss=9854.93262, val_loss=10005.16309\n",
      "Epoch 2450: train_loss=9853.74316, val_loss=10003.95312\n",
      "Epoch 2451: train_loss=9852.55762, val_loss=10002.74902\n",
      "Epoch 2452: train_loss=9851.37402, val_loss=10001.54785\n",
      "Epoch 2453: train_loss=9850.19336, val_loss=10000.35156\n",
      "Epoch 2454: train_loss=9849.01855, val_loss=9999.15820\n",
      "Epoch 2455: train_loss=9847.84570, val_loss=9997.96973\n",
      "Epoch 2456: train_loss=9846.67676, val_loss=9996.78125\n",
      "Epoch 2457: train_loss=9845.50879, val_loss=9995.59473\n",
      "Epoch 2458: train_loss=9844.34473, val_loss=9994.41113\n",
      "Epoch 2459: train_loss=9843.18262, val_loss=9993.22949\n",
      "Epoch 2460: train_loss=9842.02441, val_loss=9992.05273\n",
      "Epoch 2461: train_loss=9840.86914, val_loss=9990.88184\n",
      "Epoch 2462: train_loss=9839.71680, val_loss=9989.71484\n",
      "Epoch 2463: train_loss=9838.56934, val_loss=9988.55273\n",
      "Epoch 2464: train_loss=9837.42578, val_loss=9987.39355\n",
      "Epoch 2465: train_loss=9836.28320, val_loss=9986.23730\n",
      "Epoch 2466: train_loss=9835.14551, val_loss=9985.08594\n",
      "Epoch 2467: train_loss=9834.00977, val_loss=9983.93750\n",
      "Epoch 2468: train_loss=9832.87793, val_loss=9982.79297\n",
      "Epoch 2469: train_loss=9831.74707, val_loss=9981.64941\n",
      "Epoch 2470: train_loss=9830.62012, val_loss=9980.50879\n",
      "Epoch 2471: train_loss=9829.49512, val_loss=9979.36914\n",
      "Epoch 2472: train_loss=9828.37305, val_loss=9978.23438\n",
      "Epoch 2473: train_loss=9827.25391, val_loss=9977.10156\n",
      "Epoch 2474: train_loss=9826.13574, val_loss=9975.97266\n",
      "Epoch 2475: train_loss=9825.02148, val_loss=9974.84570\n",
      "Epoch 2476: train_loss=9823.90918, val_loss=9973.72070\n",
      "Epoch 2477: train_loss=9822.80078, val_loss=9972.59863\n",
      "Epoch 2478: train_loss=9821.69141, val_loss=9971.47852\n",
      "Epoch 2479: train_loss=9820.58789, val_loss=9970.36230\n",
      "Epoch 2480: train_loss=9819.48438, val_loss=9969.24902\n",
      "Epoch 2481: train_loss=9818.38477, val_loss=9968.13672\n",
      "Epoch 2482: train_loss=9817.28516, val_loss=9967.02734\n",
      "Epoch 2483: train_loss=9816.18945, val_loss=9965.92090\n",
      "Epoch 2484: train_loss=9815.09668, val_loss=9964.81738\n",
      "Epoch 2485: train_loss=9814.00488, val_loss=9963.71875\n",
      "Epoch 2486: train_loss=9812.91895, val_loss=9962.61914\n",
      "Epoch 2487: train_loss=9811.83496, val_loss=9961.52441\n",
      "Epoch 2488: train_loss=9810.75293, val_loss=9960.43066\n",
      "Epoch 2489: train_loss=9809.67285, val_loss=9959.33984\n",
      "Epoch 2490: train_loss=9808.59668, val_loss=9958.24902\n",
      "Epoch 2491: train_loss=9807.52246, val_loss=9957.16113\n",
      "Epoch 2492: train_loss=9806.45117, val_loss=9956.07422\n",
      "Epoch 2493: train_loss=9805.38281, val_loss=9954.99121\n",
      "Epoch 2494: train_loss=9804.31836, val_loss=9953.91016\n",
      "Epoch 2495: train_loss=9803.25684, val_loss=9952.83301\n",
      "Epoch 2496: train_loss=9802.19727, val_loss=9951.75879\n",
      "Epoch 2497: train_loss=9801.14160, val_loss=9950.68652\n",
      "Epoch 2498: train_loss=9800.08594, val_loss=9949.61523\n",
      "Epoch 2499: train_loss=9799.03320, val_loss=9948.54492\n",
      "Epoch 2500: train_loss=9797.98438, val_loss=9947.47949\n",
      "Epoch 2501: train_loss=9796.93652, val_loss=9946.41406\n",
      "Epoch 2502: train_loss=9795.89062, val_loss=9945.35254\n",
      "Epoch 2503: train_loss=9794.84961, val_loss=9944.29590\n",
      "Epoch 2504: train_loss=9793.81250, val_loss=9943.24121\n",
      "Epoch 2505: train_loss=9792.77832, val_loss=9942.19043\n",
      "Epoch 2506: train_loss=9791.74707, val_loss=9941.14160\n",
      "Epoch 2507: train_loss=9790.71777, val_loss=9940.09863\n",
      "Epoch 2508: train_loss=9789.69336, val_loss=9939.06055\n",
      "Epoch 2509: train_loss=9788.67383, val_loss=9938.02539\n",
      "Epoch 2510: train_loss=9787.65625, val_loss=9936.99414\n",
      "Epoch 2511: train_loss=9786.64160, val_loss=9935.96484\n",
      "Epoch 2512: train_loss=9785.63086, val_loss=9934.93848\n",
      "Epoch 2513: train_loss=9784.62305, val_loss=9933.91699\n",
      "Epoch 2514: train_loss=9783.61621, val_loss=9932.89746\n",
      "Epoch 2515: train_loss=9782.61328, val_loss=9931.88184\n",
      "Epoch 2516: train_loss=9781.61230, val_loss=9930.86719\n",
      "Epoch 2517: train_loss=9780.61523, val_loss=9929.85645\n",
      "Epoch 2518: train_loss=9779.61816, val_loss=9928.84863\n",
      "Epoch 2519: train_loss=9778.62793, val_loss=9927.84473\n",
      "Epoch 2520: train_loss=9777.63867, val_loss=9926.84570\n",
      "Epoch 2521: train_loss=9776.65332, val_loss=9925.84668\n",
      "Epoch 2522: train_loss=9775.66992, val_loss=9924.85059\n",
      "Epoch 2523: train_loss=9774.68848, val_loss=9923.85840\n",
      "Epoch 2524: train_loss=9773.70898, val_loss=9922.86719\n",
      "Epoch 2525: train_loss=9772.73145, val_loss=9921.87891\n",
      "Epoch 2526: train_loss=9771.75684, val_loss=9920.89453\n",
      "Epoch 2527: train_loss=9770.78320, val_loss=9919.91211\n",
      "Epoch 2528: train_loss=9769.81250, val_loss=9918.93164\n",
      "Epoch 2529: train_loss=9768.84473, val_loss=9917.95703\n",
      "Epoch 2530: train_loss=9767.87988, val_loss=9916.98438\n",
      "Epoch 2531: train_loss=9766.91797, val_loss=9916.01465\n",
      "Epoch 2532: train_loss=9765.95703, val_loss=9915.04590\n",
      "Epoch 2533: train_loss=9765.00000, val_loss=9914.07910\n",
      "Epoch 2534: train_loss=9764.04492, val_loss=9913.11426\n",
      "Epoch 2535: train_loss=9763.09082, val_loss=9912.15137\n",
      "Epoch 2536: train_loss=9762.13867, val_loss=9911.19043\n",
      "Epoch 2537: train_loss=9761.18848, val_loss=9910.23242\n",
      "Epoch 2538: train_loss=9760.23926, val_loss=9909.27539\n",
      "Epoch 2539: train_loss=9759.29199, val_loss=9908.32129\n",
      "Epoch 2540: train_loss=9758.34766, val_loss=9907.36914\n",
      "Epoch 2541: train_loss=9757.40430, val_loss=9906.41992\n",
      "Epoch 2542: train_loss=9756.46387, val_loss=9905.47168\n",
      "Epoch 2543: train_loss=9755.52637, val_loss=9904.52734\n",
      "Epoch 2544: train_loss=9754.58789, val_loss=9903.58398\n",
      "Epoch 2545: train_loss=9753.65527, val_loss=9902.64355\n",
      "Epoch 2546: train_loss=9752.72363, val_loss=9901.70508\n",
      "Epoch 2547: train_loss=9751.79395, val_loss=9900.76660\n",
      "Epoch 2548: train_loss=9750.86621, val_loss=9899.83008\n",
      "Epoch 2549: train_loss=9749.93848, val_loss=9898.89355\n",
      "Epoch 2550: train_loss=9749.01367, val_loss=9897.95898\n",
      "Epoch 2551: train_loss=9748.08984, val_loss=9897.02539\n",
      "Epoch 2552: train_loss=9747.16797, val_loss=9896.09375\n",
      "Epoch 2553: train_loss=9746.24805, val_loss=9895.16504\n",
      "Epoch 2554: train_loss=9745.33008, val_loss=9894.23828\n",
      "Epoch 2555: train_loss=9744.41504, val_loss=9893.31348\n",
      "Epoch 2556: train_loss=9743.50098, val_loss=9892.39062\n",
      "Epoch 2557: train_loss=9742.58887, val_loss=9891.47070\n",
      "Epoch 2558: train_loss=9741.68066, val_loss=9890.55273\n",
      "Epoch 2559: train_loss=9740.77246, val_loss=9889.63672\n",
      "Epoch 2560: train_loss=9739.86816, val_loss=9888.72266\n",
      "Epoch 2561: train_loss=9738.96387, val_loss=9887.80957\n",
      "Epoch 2562: train_loss=9738.06250, val_loss=9886.89844\n",
      "Epoch 2563: train_loss=9737.16406, val_loss=9885.98926\n",
      "Epoch 2564: train_loss=9736.26758, val_loss=9885.08398\n",
      "Epoch 2565: train_loss=9735.37305, val_loss=9884.17773\n",
      "Epoch 2566: train_loss=9734.48047, val_loss=9883.27441\n",
      "Epoch 2567: train_loss=9733.58887, val_loss=9882.37402\n",
      "Epoch 2568: train_loss=9732.70117, val_loss=9881.47559\n",
      "Epoch 2569: train_loss=9731.81543, val_loss=9880.58008\n",
      "Epoch 2570: train_loss=9730.93262, val_loss=9879.68750\n",
      "Epoch 2571: train_loss=9730.05273, val_loss=9878.79785\n",
      "Epoch 2572: train_loss=9729.17578, val_loss=9877.91016\n",
      "Epoch 2573: train_loss=9728.29980, val_loss=9877.02441\n",
      "Epoch 2574: train_loss=9727.42676, val_loss=9876.13965\n",
      "Epoch 2575: train_loss=9726.55469, val_loss=9875.25684\n",
      "Epoch 2576: train_loss=9725.68555, val_loss=9874.37598\n",
      "Epoch 2577: train_loss=9724.81738, val_loss=9873.49805\n",
      "Epoch 2578: train_loss=9723.95312, val_loss=9872.62109\n",
      "Epoch 2579: train_loss=9723.09082, val_loss=9871.74707\n",
      "Epoch 2580: train_loss=9722.23145, val_loss=9870.87402\n",
      "Epoch 2581: train_loss=9721.37305, val_loss=9870.00488\n",
      "Epoch 2582: train_loss=9720.51758, val_loss=9869.13672\n",
      "Epoch 2583: train_loss=9719.66211, val_loss=9868.27148\n",
      "Epoch 2584: train_loss=9718.80957, val_loss=9867.40723\n",
      "Epoch 2585: train_loss=9717.95801, val_loss=9866.54395\n",
      "Epoch 2586: train_loss=9717.10840, val_loss=9865.68262\n",
      "Epoch 2587: train_loss=9716.26172, val_loss=9864.82324\n",
      "Epoch 2588: train_loss=9715.41406, val_loss=9863.96387\n",
      "Epoch 2589: train_loss=9714.56641, val_loss=9863.10547\n",
      "Epoch 2590: train_loss=9713.72168, val_loss=9862.24414\n",
      "Epoch 2591: train_loss=9712.87793, val_loss=9861.38379\n",
      "Epoch 2592: train_loss=9712.03516, val_loss=9860.52344\n",
      "Epoch 2593: train_loss=9711.19141, val_loss=9859.66406\n",
      "Epoch 2594: train_loss=9710.35059, val_loss=9858.80566\n",
      "Epoch 2595: train_loss=9709.50977, val_loss=9857.94531\n",
      "Epoch 2596: train_loss=9708.67090, val_loss=9857.08594\n",
      "Epoch 2597: train_loss=9707.83398, val_loss=9856.23340\n",
      "Epoch 2598: train_loss=9707.00195, val_loss=9855.39746\n",
      "Epoch 2599: train_loss=9706.18262, val_loss=9854.56348\n",
      "Epoch 2600: train_loss=9705.36328, val_loss=9853.73145\n",
      "Epoch 2601: train_loss=9704.54102, val_loss=9852.90039\n",
      "Epoch 2602: train_loss=9703.72070, val_loss=9852.07129\n",
      "Epoch 2603: train_loss=9702.89746, val_loss=9851.24414\n",
      "Epoch 2604: train_loss=9702.07617, val_loss=9850.41895\n",
      "Epoch 2605: train_loss=9701.25488, val_loss=9849.60547\n",
      "Epoch 2606: train_loss=9700.44238, val_loss=9848.79395\n",
      "Epoch 2607: train_loss=9699.63379, val_loss=9847.98535\n",
      "Epoch 2608: train_loss=9698.82910, val_loss=9847.17383\n",
      "Epoch 2609: train_loss=9698.02344, val_loss=9846.36133\n",
      "Epoch 2610: train_loss=9697.21875, val_loss=9845.54883\n",
      "Epoch 2611: train_loss=9696.41504, val_loss=9844.73340\n",
      "Epoch 2612: train_loss=9695.61328, val_loss=9843.91797\n",
      "Epoch 2613: train_loss=9694.81152, val_loss=9843.10254\n",
      "Epoch 2614: train_loss=9694.01074, val_loss=9842.28809\n",
      "Epoch 2615: train_loss=9693.21094, val_loss=9841.47559\n",
      "Epoch 2616: train_loss=9692.41309, val_loss=9840.66504\n",
      "Epoch 2617: train_loss=9691.61914, val_loss=9839.86230\n",
      "Epoch 2618: train_loss=9690.82812, val_loss=9839.06055\n",
      "Epoch 2619: train_loss=9690.03906, val_loss=9838.26074\n",
      "Epoch 2620: train_loss=9689.25195, val_loss=9837.46387\n",
      "Epoch 2621: train_loss=9688.46387, val_loss=9836.67090\n",
      "Epoch 2622: train_loss=9687.67578, val_loss=9835.88379\n",
      "Epoch 2623: train_loss=9686.89551, val_loss=9835.09863\n",
      "Epoch 2624: train_loss=9686.11816, val_loss=9834.31250\n",
      "Epoch 2625: train_loss=9685.34082, val_loss=9833.52637\n",
      "Epoch 2626: train_loss=9684.56543, val_loss=9832.74121\n",
      "Epoch 2627: train_loss=9683.79102, val_loss=9831.95605\n",
      "Epoch 2628: train_loss=9683.01758, val_loss=9831.17285\n",
      "Epoch 2629: train_loss=9682.24805, val_loss=9830.39453\n",
      "Epoch 2630: train_loss=9681.48242, val_loss=9829.62109\n",
      "Epoch 2631: train_loss=9680.71777, val_loss=9828.84863\n",
      "Epoch 2632: train_loss=9679.95508, val_loss=9828.08008\n",
      "Epoch 2633: train_loss=9679.19336, val_loss=9827.31250\n",
      "Epoch 2634: train_loss=9678.43164, val_loss=9826.54980\n",
      "Epoch 2635: train_loss=9677.67383, val_loss=9825.78906\n",
      "Epoch 2636: train_loss=9676.91797, val_loss=9825.03027\n",
      "Epoch 2637: train_loss=9676.16504, val_loss=9824.27148\n",
      "Epoch 2638: train_loss=9675.41406, val_loss=9823.51367\n",
      "Epoch 2639: train_loss=9674.66309, val_loss=9822.75586\n",
      "Epoch 2640: train_loss=9673.91504, val_loss=9822.00293\n",
      "Epoch 2641: train_loss=9673.16895, val_loss=9821.25293\n",
      "Epoch 2642: train_loss=9672.42480, val_loss=9820.50488\n",
      "Epoch 2643: train_loss=9671.68066, val_loss=9819.76172\n",
      "Epoch 2644: train_loss=9670.93848, val_loss=9819.01758\n",
      "Epoch 2645: train_loss=9670.19922, val_loss=9818.27637\n",
      "Epoch 2646: train_loss=9669.46094, val_loss=9817.53320\n",
      "Epoch 2647: train_loss=9668.72363, val_loss=9816.79297\n",
      "Epoch 2648: train_loss=9667.98828, val_loss=9816.05371\n",
      "Epoch 2649: train_loss=9667.25586, val_loss=9815.31836\n",
      "Epoch 2650: train_loss=9666.52246, val_loss=9814.58594\n",
      "Epoch 2651: train_loss=9665.79102, val_loss=9813.85449\n",
      "Epoch 2652: train_loss=9665.06152, val_loss=9813.12207\n",
      "Epoch 2653: train_loss=9664.33398, val_loss=9812.39062\n",
      "Epoch 2654: train_loss=9663.60742, val_loss=9811.66211\n",
      "Epoch 2655: train_loss=9662.88379, val_loss=9810.93652\n",
      "Epoch 2656: train_loss=9662.16016, val_loss=9810.21191\n",
      "Epoch 2657: train_loss=9661.43945, val_loss=9809.49121\n",
      "Epoch 2658: train_loss=9660.71973, val_loss=9808.77051\n",
      "Epoch 2659: train_loss=9660.00000, val_loss=9808.04980\n",
      "Epoch 2660: train_loss=9659.28418, val_loss=9807.33008\n",
      "Epoch 2661: train_loss=9658.56836, val_loss=9806.61328\n",
      "Epoch 2662: train_loss=9657.85352, val_loss=9805.89844\n",
      "Epoch 2663: train_loss=9657.13867, val_loss=9805.18262\n",
      "Epoch 2664: train_loss=9656.42578, val_loss=9804.46875\n",
      "Epoch 2665: train_loss=9655.71582, val_loss=9803.75488\n",
      "Epoch 2666: train_loss=9655.00586, val_loss=9803.04395\n",
      "Epoch 2667: train_loss=9654.29590, val_loss=9802.33301\n",
      "Epoch 2668: train_loss=9653.58887, val_loss=9801.62207\n",
      "Epoch 2669: train_loss=9652.88184, val_loss=9800.91211\n",
      "Epoch 2670: train_loss=9652.17773, val_loss=9800.20605\n",
      "Epoch 2671: train_loss=9651.47363, val_loss=9799.50098\n",
      "Epoch 2672: train_loss=9650.77246, val_loss=9798.79688\n",
      "Epoch 2673: train_loss=9650.07227, val_loss=9798.09277\n",
      "Epoch 2674: train_loss=9649.37109, val_loss=9797.38965\n",
      "Epoch 2675: train_loss=9648.67480, val_loss=9796.68848\n",
      "Epoch 2676: train_loss=9647.97559, val_loss=9795.98828\n",
      "Epoch 2677: train_loss=9647.28223, val_loss=9795.28906\n",
      "Epoch 2678: train_loss=9646.58789, val_loss=9794.59180\n",
      "Epoch 2679: train_loss=9645.89355, val_loss=9793.89551\n",
      "Epoch 2680: train_loss=9645.20215, val_loss=9793.19922\n",
      "Epoch 2681: train_loss=9644.51074, val_loss=9792.50684\n",
      "Epoch 2682: train_loss=9643.82129, val_loss=9791.81543\n",
      "Epoch 2683: train_loss=9643.13281, val_loss=9791.12500\n",
      "Epoch 2684: train_loss=9642.44434, val_loss=9790.43555\n",
      "Epoch 2685: train_loss=9641.75781, val_loss=9789.74707\n",
      "Epoch 2686: train_loss=9641.07324, val_loss=9789.06250\n",
      "Epoch 2687: train_loss=9640.38867, val_loss=9788.37793\n",
      "Epoch 2688: train_loss=9639.70508, val_loss=9787.69336\n",
      "Epoch 2689: train_loss=9639.02344, val_loss=9787.01074\n",
      "Epoch 2690: train_loss=9638.34180, val_loss=9786.32812\n",
      "Epoch 2691: train_loss=9637.66309, val_loss=9785.64844\n",
      "Epoch 2692: train_loss=9636.98242, val_loss=9784.96875\n",
      "Epoch 2693: train_loss=9636.30371, val_loss=9784.29004\n",
      "Epoch 2694: train_loss=9635.62793, val_loss=9783.61426\n",
      "Epoch 2695: train_loss=9634.95215, val_loss=9782.93945\n",
      "Epoch 2696: train_loss=9634.27637, val_loss=9782.26562\n",
      "Epoch 2697: train_loss=9633.60352, val_loss=9781.59473\n",
      "Epoch 2698: train_loss=9632.93066, val_loss=9780.92383\n",
      "Epoch 2699: train_loss=9632.26074, val_loss=9780.25586\n",
      "Epoch 2700: train_loss=9631.58984, val_loss=9779.58789\n",
      "Epoch 2701: train_loss=9630.92090, val_loss=9778.91895\n",
      "Epoch 2702: train_loss=9630.25293, val_loss=9778.25293\n",
      "Epoch 2703: train_loss=9629.58398, val_loss=9777.58398\n",
      "Epoch 2704: train_loss=9628.91406, val_loss=9776.91504\n",
      "Epoch 2705: train_loss=9628.24609, val_loss=9776.23828\n",
      "Epoch 2706: train_loss=9627.57129, val_loss=9775.56055\n",
      "Epoch 2707: train_loss=9626.89551, val_loss=9774.89160\n",
      "Epoch 2708: train_loss=9626.22363, val_loss=9774.22656\n",
      "Epoch 2709: train_loss=9625.55957, val_loss=9773.56445\n",
      "Epoch 2710: train_loss=9624.89746, val_loss=9772.90430\n",
      "Epoch 2711: train_loss=9624.23730, val_loss=9772.24512\n",
      "Epoch 2712: train_loss=9623.57910, val_loss=9771.58887\n",
      "Epoch 2713: train_loss=9622.92285, val_loss=9770.93164\n",
      "Epoch 2714: train_loss=9622.26660, val_loss=9770.27637\n",
      "Epoch 2715: train_loss=9621.61133, val_loss=9769.62109\n",
      "Epoch 2716: train_loss=9620.95605, val_loss=9768.96777\n",
      "Epoch 2717: train_loss=9620.30273, val_loss=9768.31543\n",
      "Epoch 2718: train_loss=9619.65137, val_loss=9767.66211\n",
      "Epoch 2719: train_loss=9618.99805, val_loss=9767.01074\n",
      "Epoch 2720: train_loss=9618.34668, val_loss=9766.36230\n",
      "Epoch 2721: train_loss=9617.69727, val_loss=9765.71387\n",
      "Epoch 2722: train_loss=9617.04785, val_loss=9765.06836\n",
      "Epoch 2723: train_loss=9616.39941, val_loss=9764.42383\n",
      "Epoch 2724: train_loss=9615.75293, val_loss=9763.77930\n",
      "Epoch 2725: train_loss=9615.10742, val_loss=9763.13770\n",
      "Epoch 2726: train_loss=9614.46191, val_loss=9762.49707\n",
      "Epoch 2727: train_loss=9613.81934, val_loss=9761.85742\n",
      "Epoch 2728: train_loss=9613.17676, val_loss=9761.21875\n",
      "Epoch 2729: train_loss=9612.53516, val_loss=9760.58203\n",
      "Epoch 2730: train_loss=9611.89551, val_loss=9759.94629\n",
      "Epoch 2731: train_loss=9611.25586, val_loss=9759.31250\n",
      "Epoch 2732: train_loss=9610.61719, val_loss=9758.67871\n",
      "Epoch 2733: train_loss=9609.98145, val_loss=9758.04590\n",
      "Epoch 2734: train_loss=9609.34375, val_loss=9757.41504\n",
      "Epoch 2735: train_loss=9608.70801, val_loss=9756.78516\n",
      "Epoch 2736: train_loss=9608.07422, val_loss=9756.15527\n",
      "Epoch 2737: train_loss=9607.43945, val_loss=9755.52637\n",
      "Epoch 2738: train_loss=9606.80664, val_loss=9754.89844\n",
      "Epoch 2739: train_loss=9606.17480, val_loss=9754.27148\n",
      "Epoch 2740: train_loss=9605.54395, val_loss=9753.64258\n",
      "Epoch 2741: train_loss=9604.91309, val_loss=9753.01465\n",
      "Epoch 2742: train_loss=9604.28125, val_loss=9752.38770\n",
      "Epoch 2743: train_loss=9603.65137, val_loss=9751.75684\n",
      "Epoch 2744: train_loss=9603.01953, val_loss=9751.13086\n",
      "Epoch 2745: train_loss=9602.39258, val_loss=9750.50977\n",
      "Epoch 2746: train_loss=9601.76660, val_loss=9749.87695\n",
      "Epoch 2747: train_loss=9601.13281, val_loss=9749.23633\n",
      "Epoch 2748: train_loss=9600.49316, val_loss=9748.59570\n",
      "Epoch 2749: train_loss=9599.85742, val_loss=9747.95020\n",
      "Epoch 2750: train_loss=9599.21777, val_loss=9747.29004\n",
      "Epoch 2751: train_loss=9598.56934, val_loss=9746.62695\n",
      "Epoch 2752: train_loss=9597.92773, val_loss=9745.95801\n",
      "Epoch 2753: train_loss=9597.28320, val_loss=9745.29004\n",
      "Epoch 2754: train_loss=9596.64160, val_loss=9744.62793\n",
      "Epoch 2755: train_loss=9595.99316, val_loss=9743.97070\n",
      "Epoch 2756: train_loss=9595.35156, val_loss=9743.32715\n",
      "Epoch 2757: train_loss=9594.71875, val_loss=9742.68652\n",
      "Epoch 2758: train_loss=9594.08789, val_loss=9742.04199\n",
      "Epoch 2759: train_loss=9593.45703, val_loss=9741.40430\n",
      "Epoch 2760: train_loss=9592.83496, val_loss=9740.77637\n",
      "Epoch 2761: train_loss=9592.22559, val_loss=9740.15723\n",
      "Epoch 2762: train_loss=9591.62402, val_loss=9739.53906\n",
      "Epoch 2763: train_loss=9591.02344, val_loss=9738.92676\n",
      "Epoch 2764: train_loss=9590.42285, val_loss=9738.31738\n",
      "Epoch 2765: train_loss=9589.82227, val_loss=9737.71582\n",
      "Epoch 2766: train_loss=9589.22461, val_loss=9737.11035\n",
      "Epoch 2767: train_loss=9588.62207, val_loss=9736.50293\n",
      "Epoch 2768: train_loss=9588.01562, val_loss=9735.90332\n",
      "Epoch 2769: train_loss=9587.41211, val_loss=9735.30469\n",
      "Epoch 2770: train_loss=9586.80957, val_loss=9734.71094\n",
      "Epoch 2771: train_loss=9586.21094, val_loss=9734.11816\n",
      "Epoch 2772: train_loss=9585.61426, val_loss=9733.52832\n",
      "Epoch 2773: train_loss=9585.01758, val_loss=9732.93848\n",
      "Epoch 2774: train_loss=9584.42188, val_loss=9732.34961\n",
      "Epoch 2775: train_loss=9583.82910, val_loss=9731.76074\n",
      "Epoch 2776: train_loss=9583.23633, val_loss=9731.17383\n",
      "Epoch 2777: train_loss=9582.64551, val_loss=9730.58594\n",
      "Epoch 2778: train_loss=9582.05664, val_loss=9730.00000\n",
      "Epoch 2779: train_loss=9581.46582, val_loss=9729.41504\n",
      "Epoch 2780: train_loss=9580.87793, val_loss=9728.83008\n",
      "Epoch 2781: train_loss=9580.29004, val_loss=9728.24609\n",
      "Epoch 2782: train_loss=9579.70410, val_loss=9727.66211\n",
      "Epoch 2783: train_loss=9579.12012, val_loss=9727.07812\n",
      "Epoch 2784: train_loss=9578.53516, val_loss=9726.49316\n",
      "Epoch 2785: train_loss=9577.94922, val_loss=9725.90820\n",
      "Epoch 2786: train_loss=9577.36719, val_loss=9725.32422\n",
      "Epoch 2787: train_loss=9576.78320, val_loss=9724.74121\n",
      "Epoch 2788: train_loss=9576.20312, val_loss=9724.15918\n",
      "Epoch 2789: train_loss=9575.62012, val_loss=9723.57812\n",
      "Epoch 2790: train_loss=9575.04102, val_loss=9722.99707\n",
      "Epoch 2791: train_loss=9574.46191, val_loss=9722.41699\n",
      "Epoch 2792: train_loss=9573.88184, val_loss=9721.83691\n",
      "Epoch 2793: train_loss=9573.30469, val_loss=9721.25781\n",
      "Epoch 2794: train_loss=9572.72656, val_loss=9720.67871\n",
      "Epoch 2795: train_loss=9572.15039, val_loss=9720.10059\n",
      "Epoch 2796: train_loss=9571.57422, val_loss=9719.52344\n",
      "Epoch 2797: train_loss=9570.99902, val_loss=9718.94727\n",
      "Epoch 2798: train_loss=9570.42480, val_loss=9718.37012\n",
      "Epoch 2799: train_loss=9569.84961, val_loss=9717.79395\n",
      "Epoch 2800: train_loss=9569.27734, val_loss=9717.21875\n",
      "Epoch 2801: train_loss=9568.70508, val_loss=9716.64453\n",
      "Epoch 2802: train_loss=9568.13379, val_loss=9716.07129\n",
      "Epoch 2803: train_loss=9567.56348, val_loss=9715.49902\n",
      "Epoch 2804: train_loss=9566.99219, val_loss=9714.92871\n",
      "Epoch 2805: train_loss=9566.42285, val_loss=9714.35938\n",
      "Epoch 2806: train_loss=9565.85547, val_loss=9713.79102\n",
      "Epoch 2807: train_loss=9565.28906, val_loss=9713.22266\n",
      "Epoch 2808: train_loss=9564.72266, val_loss=9712.65527\n",
      "Epoch 2809: train_loss=9564.15527, val_loss=9712.08887\n",
      "Epoch 2810: train_loss=9563.59082, val_loss=9711.52344\n",
      "Epoch 2811: train_loss=9563.02637, val_loss=9710.95703\n",
      "Epoch 2812: train_loss=9562.46094, val_loss=9710.39258\n",
      "Epoch 2813: train_loss=9561.89844, val_loss=9709.82812\n",
      "Epoch 2814: train_loss=9561.33496, val_loss=9709.26270\n",
      "Epoch 2815: train_loss=9560.77344, val_loss=9708.69922\n",
      "Epoch 2816: train_loss=9560.21191, val_loss=9708.13574\n",
      "Epoch 2817: train_loss=9559.65137, val_loss=9707.57227\n",
      "Epoch 2818: train_loss=9559.08887, val_loss=9707.00879\n",
      "Epoch 2819: train_loss=9558.52832, val_loss=9706.44629\n",
      "Epoch 2820: train_loss=9557.96680, val_loss=9705.88379\n",
      "Epoch 2821: train_loss=9557.40820, val_loss=9705.32031\n",
      "Epoch 2822: train_loss=9556.84961, val_loss=9704.75781\n",
      "Epoch 2823: train_loss=9556.29199, val_loss=9704.19531\n",
      "Epoch 2824: train_loss=9555.73438, val_loss=9703.63477\n",
      "Epoch 2825: train_loss=9555.17578, val_loss=9703.07422\n",
      "Epoch 2826: train_loss=9554.61914, val_loss=9702.51270\n",
      "Epoch 2827: train_loss=9554.06250, val_loss=9701.95215\n",
      "Epoch 2828: train_loss=9553.50684, val_loss=9701.39258\n",
      "Epoch 2829: train_loss=9552.95215, val_loss=9700.83301\n",
      "Epoch 2830: train_loss=9552.39648, val_loss=9700.27344\n",
      "Epoch 2831: train_loss=9551.84082, val_loss=9699.71484\n",
      "Epoch 2832: train_loss=9551.28809, val_loss=9699.15430\n",
      "Epoch 2833: train_loss=9550.73438, val_loss=9698.59375\n",
      "Epoch 2834: train_loss=9550.18164, val_loss=9698.03516\n",
      "Epoch 2835: train_loss=9549.62891, val_loss=9697.47656\n",
      "Epoch 2836: train_loss=9549.07715, val_loss=9696.92188\n",
      "Epoch 2837: train_loss=9548.52930, val_loss=9696.36816\n",
      "Epoch 2838: train_loss=9547.97949, val_loss=9695.81641\n",
      "Epoch 2839: train_loss=9547.43359, val_loss=9695.26465\n",
      "Epoch 2840: train_loss=9546.88574, val_loss=9694.71387\n",
      "Epoch 2841: train_loss=9546.33984, val_loss=9694.16309\n",
      "Epoch 2842: train_loss=9545.79297, val_loss=9693.61328\n",
      "Epoch 2843: train_loss=9545.24707, val_loss=9693.06445\n",
      "Epoch 2844: train_loss=9544.70215, val_loss=9692.51562\n",
      "Epoch 2845: train_loss=9544.15723, val_loss=9691.96680\n",
      "Epoch 2846: train_loss=9543.61426, val_loss=9691.41992\n",
      "Epoch 2847: train_loss=9543.06934, val_loss=9690.87402\n",
      "Epoch 2848: train_loss=9542.52734, val_loss=9690.32812\n",
      "Epoch 2849: train_loss=9541.98535, val_loss=9689.78320\n",
      "Epoch 2850: train_loss=9541.44434, val_loss=9689.23828\n",
      "Epoch 2851: train_loss=9540.90527, val_loss=9688.69531\n",
      "Epoch 2852: train_loss=9540.36426, val_loss=9688.15137\n",
      "Epoch 2853: train_loss=9539.82617, val_loss=9687.60938\n",
      "Epoch 2854: train_loss=9539.28809, val_loss=9687.06738\n",
      "Epoch 2855: train_loss=9538.75000, val_loss=9686.52637\n",
      "Epoch 2856: train_loss=9538.21484, val_loss=9685.98730\n",
      "Epoch 2857: train_loss=9537.67871, val_loss=9685.44727\n",
      "Epoch 2858: train_loss=9537.14453, val_loss=9684.91016\n",
      "Epoch 2859: train_loss=9536.61230, val_loss=9684.37305\n",
      "Epoch 2860: train_loss=9536.08008, val_loss=9683.83887\n",
      "Epoch 2861: train_loss=9535.54883, val_loss=9683.30371\n",
      "Epoch 2862: train_loss=9535.01855, val_loss=9682.77051\n",
      "Epoch 2863: train_loss=9534.48730, val_loss=9682.23926\n",
      "Epoch 2864: train_loss=9533.95801, val_loss=9681.70898\n",
      "Epoch 2865: train_loss=9533.42969, val_loss=9681.17969\n",
      "Epoch 2866: train_loss=9532.90137, val_loss=9680.65137\n",
      "Epoch 2867: train_loss=9532.37402, val_loss=9680.12305\n",
      "Epoch 2868: train_loss=9531.84766, val_loss=9679.59570\n",
      "Epoch 2869: train_loss=9531.32422, val_loss=9679.06934\n",
      "Epoch 2870: train_loss=9530.79980, val_loss=9678.54297\n",
      "Epoch 2871: train_loss=9530.27539, val_loss=9678.01855\n",
      "Epoch 2872: train_loss=9529.75293, val_loss=9677.49414\n",
      "Epoch 2873: train_loss=9529.23242, val_loss=9676.97070\n",
      "Epoch 2874: train_loss=9528.71191, val_loss=9676.44824\n",
      "Epoch 2875: train_loss=9528.19141, val_loss=9675.92676\n",
      "Epoch 2876: train_loss=9527.67285, val_loss=9675.40625\n",
      "Epoch 2877: train_loss=9527.15332, val_loss=9674.88672\n",
      "Epoch 2878: train_loss=9526.63672, val_loss=9674.36914\n",
      "Epoch 2879: train_loss=9526.11816, val_loss=9673.85352\n",
      "Epoch 2880: train_loss=9525.60059, val_loss=9673.33691\n",
      "Epoch 2881: train_loss=9525.08594, val_loss=9672.82227\n",
      "Epoch 2882: train_loss=9524.57031, val_loss=9672.30762\n",
      "Epoch 2883: train_loss=9524.05664, val_loss=9671.79492\n",
      "Epoch 2884: train_loss=9523.54395, val_loss=9671.28125\n",
      "Epoch 2885: train_loss=9523.03125, val_loss=9670.76855\n",
      "Epoch 2886: train_loss=9522.51758, val_loss=9670.25684\n",
      "Epoch 2887: train_loss=9522.00781, val_loss=9669.74609\n",
      "Epoch 2888: train_loss=9521.49805, val_loss=9669.23633\n",
      "Epoch 2889: train_loss=9520.98828, val_loss=9668.72656\n",
      "Epoch 2890: train_loss=9520.48047, val_loss=9668.21875\n",
      "Epoch 2891: train_loss=9519.97266, val_loss=9667.71191\n",
      "Epoch 2892: train_loss=9519.46680, val_loss=9667.20605\n",
      "Epoch 2893: train_loss=9518.96094, val_loss=9666.70312\n",
      "Epoch 2894: train_loss=9518.45410, val_loss=9666.19922\n",
      "Epoch 2895: train_loss=9517.95020, val_loss=9665.69629\n",
      "Epoch 2896: train_loss=9517.44629, val_loss=9665.19434\n",
      "Epoch 2897: train_loss=9516.94043, val_loss=9664.69238\n",
      "Epoch 2898: train_loss=9516.43750, val_loss=9664.19043\n",
      "Epoch 2899: train_loss=9515.93457, val_loss=9663.69043\n",
      "Epoch 2900: train_loss=9515.43262, val_loss=9663.18945\n",
      "Epoch 2901: train_loss=9514.93164, val_loss=9662.68945\n",
      "Epoch 2902: train_loss=9514.43066, val_loss=9662.19043\n",
      "Epoch 2903: train_loss=9513.92969, val_loss=9661.69141\n",
      "Epoch 2904: train_loss=9513.43066, val_loss=9661.19336\n",
      "Epoch 2905: train_loss=9512.93164, val_loss=9660.69531\n",
      "Epoch 2906: train_loss=9512.43359, val_loss=9660.19922\n",
      "Epoch 2907: train_loss=9511.93750, val_loss=9659.70410\n",
      "Epoch 2908: train_loss=9511.44043, val_loss=9659.21094\n",
      "Epoch 2909: train_loss=9510.94531, val_loss=9658.71777\n",
      "Epoch 2910: train_loss=9510.45117, val_loss=9658.22656\n",
      "Epoch 2911: train_loss=9509.95605, val_loss=9657.73535\n",
      "Epoch 2912: train_loss=9509.46387, val_loss=9657.24512\n",
      "Epoch 2913: train_loss=9508.96973, val_loss=9656.75586\n",
      "Epoch 2914: train_loss=9508.47656, val_loss=9656.26660\n",
      "Epoch 2915: train_loss=9507.98438, val_loss=9655.77930\n",
      "Epoch 2916: train_loss=9507.49316, val_loss=9655.29102\n",
      "Epoch 2917: train_loss=9507.00098, val_loss=9654.80273\n",
      "Epoch 2918: train_loss=9506.50879, val_loss=9654.31641\n",
      "Epoch 2919: train_loss=9506.01953, val_loss=9653.82910\n",
      "Epoch 2920: train_loss=9505.52832, val_loss=9653.34180\n",
      "Epoch 2921: train_loss=9505.03809, val_loss=9652.85547\n",
      "Epoch 2922: train_loss=9504.54785, val_loss=9652.36816\n",
      "Epoch 2923: train_loss=9504.05762, val_loss=9651.88184\n",
      "Epoch 2924: train_loss=9503.56836, val_loss=9651.39453\n",
      "Epoch 2925: train_loss=9503.07812, val_loss=9650.90723\n",
      "Epoch 2926: train_loss=9502.58984, val_loss=9650.41992\n",
      "Epoch 2927: train_loss=9502.10059, val_loss=9649.93262\n",
      "Epoch 2928: train_loss=9501.61133, val_loss=9649.44531\n",
      "Epoch 2929: train_loss=9501.12207, val_loss=9648.95703\n",
      "Epoch 2930: train_loss=9500.63281, val_loss=9648.46973\n",
      "Epoch 2931: train_loss=9500.14453, val_loss=9647.98242\n",
      "Epoch 2932: train_loss=9499.65527, val_loss=9647.49707\n",
      "Epoch 2933: train_loss=9499.16504, val_loss=9647.01074\n",
      "Epoch 2934: train_loss=9498.67578, val_loss=9646.52441\n",
      "Epoch 2935: train_loss=9498.18359, val_loss=9646.03906\n",
      "Epoch 2936: train_loss=9497.69043, val_loss=9645.55078\n",
      "Epoch 2937: train_loss=9497.19336, val_loss=9645.05957\n",
      "Epoch 2938: train_loss=9496.69434, val_loss=9644.57031\n",
      "Epoch 2939: train_loss=9496.19336, val_loss=9644.08105\n",
      "Epoch 2940: train_loss=9495.69727, val_loss=9643.59180\n",
      "Epoch 2941: train_loss=9495.20020, val_loss=9643.10449\n",
      "Epoch 2942: train_loss=9494.70410, val_loss=9642.61621\n",
      "Epoch 2943: train_loss=9494.20703, val_loss=9642.12695\n",
      "Epoch 2944: train_loss=9493.70996, val_loss=9641.63770\n",
      "Epoch 2945: train_loss=9493.21094, val_loss=9641.14746\n",
      "Epoch 2946: train_loss=9492.71094, val_loss=9640.65527\n",
      "Epoch 2947: train_loss=9492.20996, val_loss=9640.16211\n",
      "Epoch 2948: train_loss=9491.70508, val_loss=9639.66602\n",
      "Epoch 2949: train_loss=9491.20117, val_loss=9639.16895\n",
      "Epoch 2950: train_loss=9490.69434, val_loss=9638.66895\n",
      "Epoch 2951: train_loss=9490.18652, val_loss=9638.16797\n",
      "Epoch 2952: train_loss=9489.67578, val_loss=9637.66602\n",
      "Epoch 2953: train_loss=9489.16309, val_loss=9637.16406\n",
      "Epoch 2954: train_loss=9488.65039, val_loss=9636.66016\n",
      "Epoch 2955: train_loss=9488.13379, val_loss=9636.15527\n",
      "Epoch 2956: train_loss=9487.61719, val_loss=9635.65137\n",
      "Epoch 2957: train_loss=9487.10156, val_loss=9635.14941\n",
      "Epoch 2958: train_loss=9486.58398, val_loss=9634.64941\n",
      "Epoch 2959: train_loss=9486.06641, val_loss=9634.14941\n",
      "Epoch 2960: train_loss=9485.54980, val_loss=9633.64551\n",
      "Epoch 2961: train_loss=9485.03125, val_loss=9633.13965\n",
      "Epoch 2962: train_loss=9484.51270, val_loss=9632.63477\n",
      "Epoch 2963: train_loss=9483.99414, val_loss=9632.12793\n",
      "Epoch 2964: train_loss=9483.47656, val_loss=9631.62207\n",
      "Epoch 2965: train_loss=9482.95605, val_loss=9631.11621\n",
      "Epoch 2966: train_loss=9482.43555, val_loss=9630.61035\n",
      "Epoch 2967: train_loss=9481.91406, val_loss=9630.10352\n",
      "Epoch 2968: train_loss=9481.39160, val_loss=9629.59863\n",
      "Epoch 2969: train_loss=9480.87109, val_loss=9629.09375\n",
      "Epoch 2970: train_loss=9480.35059, val_loss=9628.59082\n",
      "Epoch 2971: train_loss=9479.83105, val_loss=9628.08496\n",
      "Epoch 2972: train_loss=9479.31152, val_loss=9627.58008\n",
      "Epoch 2973: train_loss=9478.79199, val_loss=9627.07227\n",
      "Epoch 2974: train_loss=9478.27441, val_loss=9626.56348\n",
      "Epoch 2975: train_loss=9477.75781, val_loss=9626.05566\n",
      "Epoch 2976: train_loss=9477.24023, val_loss=9625.54688\n",
      "Epoch 2977: train_loss=9476.72363, val_loss=9625.03613\n",
      "Epoch 2978: train_loss=9476.20801, val_loss=9624.52539\n",
      "Epoch 2979: train_loss=9475.69141, val_loss=9624.01660\n",
      "Epoch 2980: train_loss=9475.17578, val_loss=9623.50781\n",
      "Epoch 2981: train_loss=9474.66211, val_loss=9623.00098\n",
      "Epoch 2982: train_loss=9474.14941, val_loss=9622.49609\n",
      "Epoch 2983: train_loss=9473.64160, val_loss=9621.99512\n",
      "Epoch 2984: train_loss=9473.13477, val_loss=9621.49707\n",
      "Epoch 2985: train_loss=9472.63184, val_loss=9621.00488\n",
      "Epoch 2986: train_loss=9472.13281, val_loss=9620.51660\n",
      "Epoch 2987: train_loss=9471.63672, val_loss=9620.02832\n",
      "Epoch 2988: train_loss=9471.14258, val_loss=9619.54004\n",
      "Epoch 2989: train_loss=9470.64844, val_loss=9619.05176\n",
      "Epoch 2990: train_loss=9470.15527, val_loss=9618.56348\n",
      "Epoch 2991: train_loss=9469.65918, val_loss=9618.07617\n",
      "Epoch 2992: train_loss=9469.16602, val_loss=9617.58789\n",
      "Epoch 2993: train_loss=9468.67090, val_loss=9617.09863\n",
      "Epoch 2994: train_loss=9468.17676, val_loss=9616.60840\n",
      "Epoch 2995: train_loss=9467.68262, val_loss=9616.12012\n",
      "Epoch 2996: train_loss=9467.18848, val_loss=9615.63281\n",
      "Epoch 2997: train_loss=9466.69336, val_loss=9615.14551\n",
      "Epoch 2998: train_loss=9466.19922, val_loss=9614.65820\n",
      "Epoch 2999: train_loss=9465.70508, val_loss=9614.17285\n",
      "Epoch 3000: train_loss=9465.21387, val_loss=9613.68945\n",
      "Epoch 3001: train_loss=9464.72363, val_loss=9613.20508\n",
      "Epoch 3002: train_loss=9464.23145, val_loss=9612.71973\n",
      "Epoch 3003: train_loss=9463.74023, val_loss=9612.23535\n",
      "Epoch 3004: train_loss=9463.25000, val_loss=9611.75195\n",
      "Epoch 3005: train_loss=9462.75977, val_loss=9611.27148\n",
      "Epoch 3006: train_loss=9462.27051, val_loss=9610.79004\n",
      "Epoch 3007: train_loss=9461.78125, val_loss=9610.30859\n",
      "Epoch 3008: train_loss=9461.29199, val_loss=9609.83008\n",
      "Epoch 3009: train_loss=9460.80371, val_loss=9609.35059\n",
      "Epoch 3010: train_loss=9460.31543, val_loss=9608.87305\n",
      "Epoch 3011: train_loss=9459.82812, val_loss=9608.39355\n",
      "Epoch 3012: train_loss=9459.34082, val_loss=9607.91602\n",
      "Epoch 3013: train_loss=9458.85254, val_loss=9607.44141\n",
      "Epoch 3014: train_loss=9458.36719, val_loss=9606.96582\n",
      "Epoch 3015: train_loss=9457.88184, val_loss=9606.49121\n",
      "Epoch 3016: train_loss=9457.39941, val_loss=9606.01953\n",
      "Epoch 3017: train_loss=9456.91699, val_loss=9605.54590\n",
      "Epoch 3018: train_loss=9456.43457, val_loss=9605.07227\n",
      "Epoch 3019: train_loss=9455.95215, val_loss=9604.59961\n",
      "Epoch 3020: train_loss=9455.47070, val_loss=9604.12500\n",
      "Epoch 3021: train_loss=9454.98828, val_loss=9603.64941\n",
      "Epoch 3022: train_loss=9454.50586, val_loss=9603.17383\n",
      "Epoch 3023: train_loss=9454.02441, val_loss=9602.69824\n",
      "Epoch 3024: train_loss=9453.54199, val_loss=9602.22070\n",
      "Epoch 3025: train_loss=9453.05859, val_loss=9601.74414\n",
      "Epoch 3026: train_loss=9452.57422, val_loss=9601.26855\n",
      "Epoch 3027: train_loss=9452.09180, val_loss=9600.79492\n",
      "Epoch 3028: train_loss=9451.60938, val_loss=9600.32520\n",
      "Epoch 3029: train_loss=9451.12793, val_loss=9599.85840\n",
      "Epoch 3030: train_loss=9450.64941, val_loss=9599.39355\n",
      "Epoch 3031: train_loss=9450.17090, val_loss=9598.92969\n",
      "Epoch 3032: train_loss=9449.69531, val_loss=9598.46484\n",
      "Epoch 3033: train_loss=9449.21777, val_loss=9598.00195\n",
      "Epoch 3034: train_loss=9448.74121, val_loss=9597.53809\n",
      "Epoch 3035: train_loss=9448.26562, val_loss=9597.07520\n",
      "Epoch 3036: train_loss=9447.79004, val_loss=9596.61328\n",
      "Epoch 3037: train_loss=9447.31543, val_loss=9596.15137\n",
      "Epoch 3038: train_loss=9446.84375, val_loss=9595.69043\n",
      "Epoch 3039: train_loss=9446.37207, val_loss=9595.23145\n",
      "Epoch 3040: train_loss=9445.90625, val_loss=9594.77832\n",
      "Epoch 3041: train_loss=9445.44727, val_loss=9594.32812\n",
      "Epoch 3042: train_loss=9444.99121, val_loss=9593.87891\n",
      "Epoch 3043: train_loss=9444.53809, val_loss=9593.42578\n",
      "Epoch 3044: train_loss=9444.08301, val_loss=9592.97266\n",
      "Epoch 3045: train_loss=9443.62891, val_loss=9592.52051\n",
      "Epoch 3046: train_loss=9443.17480, val_loss=9592.06738\n",
      "Epoch 3047: train_loss=9442.72168, val_loss=9591.61328\n",
      "Epoch 3048: train_loss=9442.26855, val_loss=9591.16211\n",
      "Epoch 3049: train_loss=9441.81543, val_loss=9590.70605\n",
      "Epoch 3050: train_loss=9441.36133, val_loss=9590.25098\n",
      "Epoch 3051: train_loss=9440.90918, val_loss=9589.79688\n",
      "Epoch 3052: train_loss=9440.45703, val_loss=9589.34082\n",
      "Epoch 3053: train_loss=9440.00684, val_loss=9588.88770\n",
      "Epoch 3054: train_loss=9439.55469, val_loss=9588.43262\n",
      "Epoch 3055: train_loss=9439.10254, val_loss=9587.97949\n",
      "Epoch 3056: train_loss=9438.65234, val_loss=9587.52539\n",
      "Epoch 3057: train_loss=9438.20215, val_loss=9587.07031\n",
      "Epoch 3058: train_loss=9437.75293, val_loss=9586.61621\n",
      "Epoch 3059: train_loss=9437.30273, val_loss=9586.16309\n",
      "Epoch 3060: train_loss=9436.85449, val_loss=9585.70898\n",
      "Epoch 3061: train_loss=9436.40527, val_loss=9585.25781\n",
      "Epoch 3062: train_loss=9435.95801, val_loss=9584.80469\n",
      "Epoch 3063: train_loss=9435.50879, val_loss=9584.35254\n",
      "Epoch 3064: train_loss=9435.06250, val_loss=9583.90039\n",
      "Epoch 3065: train_loss=9434.61523, val_loss=9583.45020\n",
      "Epoch 3066: train_loss=9434.16895, val_loss=9583.00000\n",
      "Epoch 3067: train_loss=9433.72266, val_loss=9582.54980\n",
      "Epoch 3068: train_loss=9433.27637, val_loss=9582.09863\n",
      "Epoch 3069: train_loss=9432.83105, val_loss=9581.64844\n",
      "Epoch 3070: train_loss=9432.38574, val_loss=9581.19727\n",
      "Epoch 3071: train_loss=9431.94238, val_loss=9580.74707\n",
      "Epoch 3072: train_loss=9431.49707, val_loss=9580.29785\n",
      "Epoch 3073: train_loss=9431.05273, val_loss=9579.84766\n",
      "Epoch 3074: train_loss=9430.61035, val_loss=9579.39844\n",
      "Epoch 3075: train_loss=9430.16699, val_loss=9578.95020\n",
      "Epoch 3076: train_loss=9429.72461, val_loss=9578.50293\n",
      "Epoch 3077: train_loss=9429.28223, val_loss=9578.05566\n",
      "Epoch 3078: train_loss=9428.83984, val_loss=9577.61035\n",
      "Epoch 3079: train_loss=9428.39746, val_loss=9577.16406\n",
      "Epoch 3080: train_loss=9427.95605, val_loss=9576.71777\n",
      "Epoch 3081: train_loss=9427.51367, val_loss=9576.27246\n",
      "Epoch 3082: train_loss=9427.07324, val_loss=9575.82520\n",
      "Epoch 3083: train_loss=9426.63281, val_loss=9575.38086\n",
      "Epoch 3084: train_loss=9426.19238, val_loss=9574.93457\n",
      "Epoch 3085: train_loss=9425.75195, val_loss=9574.48828\n",
      "Epoch 3086: train_loss=9425.31250, val_loss=9574.04199\n",
      "Epoch 3087: train_loss=9424.87207, val_loss=9573.59668\n",
      "Epoch 3088: train_loss=9424.43262, val_loss=9573.15039\n",
      "Epoch 3089: train_loss=9423.99414, val_loss=9572.70508\n",
      "Epoch 3090: train_loss=9423.55469, val_loss=9572.25879\n",
      "Epoch 3091: train_loss=9423.11621, val_loss=9571.81445\n",
      "Epoch 3092: train_loss=9422.67773, val_loss=9571.36914\n",
      "Epoch 3093: train_loss=9422.24023, val_loss=9570.92676\n",
      "Epoch 3094: train_loss=9421.80273, val_loss=9570.48340\n",
      "Epoch 3095: train_loss=9421.36719, val_loss=9570.04004\n",
      "Epoch 3096: train_loss=9420.92969, val_loss=9569.59766\n",
      "Epoch 3097: train_loss=9420.49316, val_loss=9569.15430\n",
      "Epoch 3098: train_loss=9420.05664, val_loss=9568.71289\n",
      "Epoch 3099: train_loss=9419.62109, val_loss=9568.26953\n",
      "Epoch 3100: train_loss=9419.18750, val_loss=9567.82910\n",
      "Epoch 3101: train_loss=9418.75098, val_loss=9567.38770\n",
      "Epoch 3102: train_loss=9418.31641, val_loss=9566.94727\n",
      "Epoch 3103: train_loss=9417.88184, val_loss=9566.50586\n",
      "Epoch 3104: train_loss=9417.44727, val_loss=9566.06543\n",
      "Epoch 3105: train_loss=9417.01367, val_loss=9565.62402\n",
      "Epoch 3106: train_loss=9416.58008, val_loss=9565.18555\n",
      "Epoch 3107: train_loss=9416.14648, val_loss=9564.74609\n",
      "Epoch 3108: train_loss=9415.71387, val_loss=9564.30469\n",
      "Epoch 3109: train_loss=9415.28027, val_loss=9563.86523\n",
      "Epoch 3110: train_loss=9414.84863, val_loss=9563.42480\n",
      "Epoch 3111: train_loss=9414.41602, val_loss=9562.98633\n",
      "Epoch 3112: train_loss=9413.98438, val_loss=9562.54980\n",
      "Epoch 3113: train_loss=9413.55371, val_loss=9562.11035\n",
      "Epoch 3114: train_loss=9413.12402, val_loss=9561.66992\n",
      "Epoch 3115: train_loss=9412.69336, val_loss=9561.22949\n",
      "Epoch 3116: train_loss=9412.26270, val_loss=9560.78809\n",
      "Epoch 3117: train_loss=9411.83301, val_loss=9560.34668\n",
      "Epoch 3118: train_loss=9411.40234, val_loss=9559.90527\n",
      "Epoch 3119: train_loss=9410.97266, val_loss=9559.46582\n",
      "Epoch 3120: train_loss=9410.54395, val_loss=9559.02539\n",
      "Epoch 3121: train_loss=9410.11426, val_loss=9558.58594\n",
      "Epoch 3122: train_loss=9409.68555, val_loss=9558.14648\n",
      "Epoch 3123: train_loss=9409.25586, val_loss=9557.70703\n",
      "Epoch 3124: train_loss=9408.82812, val_loss=9557.26855\n",
      "Epoch 3125: train_loss=9408.40039, val_loss=9556.83105\n",
      "Epoch 3126: train_loss=9407.97168, val_loss=9556.39453\n",
      "Epoch 3127: train_loss=9407.54492, val_loss=9555.95801\n",
      "Epoch 3128: train_loss=9407.11914, val_loss=9555.52344\n",
      "Epoch 3129: train_loss=9406.69531, val_loss=9555.08984\n",
      "Epoch 3130: train_loss=9406.27051, val_loss=9554.65625\n",
      "Epoch 3131: train_loss=9405.84570, val_loss=9554.22363\n",
      "Epoch 3132: train_loss=9405.42285, val_loss=9553.79297\n",
      "Epoch 3133: train_loss=9405.00000, val_loss=9553.36426\n",
      "Epoch 3134: train_loss=9404.57812, val_loss=9552.93652\n",
      "Epoch 3135: train_loss=9404.15723, val_loss=9552.50684\n",
      "Epoch 3136: train_loss=9403.73535, val_loss=9552.07812\n",
      "Epoch 3137: train_loss=9403.31543, val_loss=9551.64941\n",
      "Epoch 3138: train_loss=9402.89551, val_loss=9551.22168\n",
      "Epoch 3139: train_loss=9402.47559, val_loss=9550.79395\n",
      "Epoch 3140: train_loss=9402.05859, val_loss=9550.36719\n",
      "Epoch 3141: train_loss=9401.63965, val_loss=9549.94238\n",
      "Epoch 3142: train_loss=9401.22168, val_loss=9549.51758\n",
      "Epoch 3143: train_loss=9400.80469, val_loss=9549.09473\n",
      "Epoch 3144: train_loss=9400.38770, val_loss=9548.67090\n",
      "Epoch 3145: train_loss=9399.97168, val_loss=9548.24805\n",
      "Epoch 3146: train_loss=9399.55371, val_loss=9547.82520\n",
      "Epoch 3147: train_loss=9399.13867, val_loss=9547.40332\n",
      "Epoch 3148: train_loss=9398.72266, val_loss=9546.98047\n",
      "Epoch 3149: train_loss=9398.30664, val_loss=9546.55762\n",
      "Epoch 3150: train_loss=9397.89160, val_loss=9546.13672\n",
      "Epoch 3151: train_loss=9397.47559, val_loss=9545.71582\n",
      "Epoch 3152: train_loss=9397.06348, val_loss=9545.29395\n",
      "Epoch 3153: train_loss=9396.65039, val_loss=9544.87305\n",
      "Epoch 3154: train_loss=9396.23535, val_loss=9544.45312\n",
      "Epoch 3155: train_loss=9395.82129, val_loss=9544.03223\n",
      "Epoch 3156: train_loss=9395.40918, val_loss=9543.61133\n",
      "Epoch 3157: train_loss=9394.99609, val_loss=9543.19141\n",
      "Epoch 3158: train_loss=9394.58301, val_loss=9542.77246\n",
      "Epoch 3159: train_loss=9394.17188, val_loss=9542.35352\n",
      "Epoch 3160: train_loss=9393.75977, val_loss=9541.93457\n",
      "Epoch 3161: train_loss=9393.34863, val_loss=9541.51562\n",
      "Epoch 3162: train_loss=9392.93652, val_loss=9541.09570\n",
      "Epoch 3163: train_loss=9392.52539, val_loss=9540.67871\n",
      "Epoch 3164: train_loss=9392.11426, val_loss=9540.25977\n",
      "Epoch 3165: train_loss=9391.70312, val_loss=9539.84082\n",
      "Epoch 3166: train_loss=9391.29395, val_loss=9539.42285\n",
      "Epoch 3167: train_loss=9390.88281, val_loss=9539.00488\n",
      "Epoch 3168: train_loss=9390.47168, val_loss=9538.58691\n",
      "Epoch 3169: train_loss=9390.06250, val_loss=9538.16895\n",
      "Epoch 3170: train_loss=9389.65234, val_loss=9537.75293\n",
      "Epoch 3171: train_loss=9389.24316, val_loss=9537.33398\n",
      "Epoch 3172: train_loss=9388.83203, val_loss=9536.91699\n",
      "Epoch 3173: train_loss=9388.42383, val_loss=9536.49805\n",
      "Epoch 3174: train_loss=9388.01465, val_loss=9536.08105\n",
      "Epoch 3175: train_loss=9387.60645, val_loss=9535.66406\n",
      "Epoch 3176: train_loss=9387.19727, val_loss=9535.24805\n",
      "Epoch 3177: train_loss=9386.79004, val_loss=9534.83105\n",
      "Epoch 3178: train_loss=9386.38086, val_loss=9534.41406\n",
      "Epoch 3179: train_loss=9385.97363, val_loss=9533.99707\n",
      "Epoch 3180: train_loss=9385.56543, val_loss=9533.58203\n",
      "Epoch 3181: train_loss=9385.15820, val_loss=9533.16602\n",
      "Epoch 3182: train_loss=9384.75098, val_loss=9532.75000\n",
      "Epoch 3183: train_loss=9384.34375, val_loss=9532.33301\n",
      "Epoch 3184: train_loss=9383.93652, val_loss=9531.91699\n",
      "Epoch 3185: train_loss=9383.52832, val_loss=9531.50098\n",
      "Epoch 3186: train_loss=9383.12305, val_loss=9531.08594\n",
      "Epoch 3187: train_loss=9382.71582, val_loss=9530.66895\n",
      "Epoch 3188: train_loss=9382.30957, val_loss=9530.25293\n",
      "Epoch 3189: train_loss=9381.90332, val_loss=9529.83691\n",
      "Epoch 3190: train_loss=9381.49805, val_loss=9529.42188\n",
      "Epoch 3191: train_loss=9381.09277, val_loss=9529.00684\n",
      "Epoch 3192: train_loss=9380.68652, val_loss=9528.59082\n",
      "Epoch 3193: train_loss=9380.28125, val_loss=9528.17480\n",
      "Epoch 3194: train_loss=9379.87598, val_loss=9527.75879\n",
      "Epoch 3195: train_loss=9379.46973, val_loss=9527.34375\n",
      "Epoch 3196: train_loss=9379.06641, val_loss=9526.92773\n",
      "Epoch 3197: train_loss=9378.66211, val_loss=9526.51270\n",
      "Epoch 3198: train_loss=9378.25684, val_loss=9526.09863\n",
      "Epoch 3199: train_loss=9377.85254, val_loss=9525.68457\n",
      "Epoch 3200: train_loss=9377.44824, val_loss=9525.26953\n",
      "Epoch 3201: train_loss=9377.04492, val_loss=9524.85547\n",
      "Epoch 3202: train_loss=9376.64062, val_loss=9524.44141\n",
      "Epoch 3203: train_loss=9376.23828, val_loss=9524.02734\n",
      "Epoch 3204: train_loss=9375.83594, val_loss=9523.61426\n",
      "Epoch 3205: train_loss=9375.43262, val_loss=9523.20020\n",
      "Epoch 3206: train_loss=9375.02930, val_loss=9522.78711\n",
      "Epoch 3207: train_loss=9374.62695, val_loss=9522.37305\n",
      "Epoch 3208: train_loss=9374.22559, val_loss=9521.95898\n",
      "Epoch 3209: train_loss=9373.82227, val_loss=9521.54590\n",
      "Epoch 3210: train_loss=9373.42090, val_loss=9521.13086\n",
      "Epoch 3211: train_loss=9373.01855, val_loss=9520.71777\n",
      "Epoch 3212: train_loss=9372.61621, val_loss=9520.30469\n",
      "Epoch 3213: train_loss=9372.21387, val_loss=9519.89160\n",
      "Epoch 3214: train_loss=9371.81250, val_loss=9519.47949\n",
      "Epoch 3215: train_loss=9371.41113, val_loss=9519.06543\n",
      "Epoch 3216: train_loss=9371.00879, val_loss=9518.65137\n",
      "Epoch 3217: train_loss=9370.60742, val_loss=9518.23730\n",
      "Epoch 3218: train_loss=9370.20508, val_loss=9517.82227\n",
      "Epoch 3219: train_loss=9369.80371, val_loss=9517.41016\n",
      "Epoch 3220: train_loss=9369.40234, val_loss=9516.99805\n",
      "Epoch 3221: train_loss=9369.00098, val_loss=9516.58496\n",
      "Epoch 3222: train_loss=9368.59863, val_loss=9516.17090\n",
      "Epoch 3223: train_loss=9368.19727, val_loss=9515.75781\n",
      "Epoch 3224: train_loss=9367.79688, val_loss=9515.34473\n",
      "Epoch 3225: train_loss=9367.39551, val_loss=9514.93066\n",
      "Epoch 3226: train_loss=9366.99414, val_loss=9514.51758\n",
      "Epoch 3227: train_loss=9366.59277, val_loss=9514.10547\n",
      "Epoch 3228: train_loss=9366.19238, val_loss=9513.69238\n",
      "Epoch 3229: train_loss=9365.79199, val_loss=9513.28125\n",
      "Epoch 3230: train_loss=9365.39258, val_loss=9512.87012\n",
      "Epoch 3231: train_loss=9364.99219, val_loss=9512.45898\n",
      "Epoch 3232: train_loss=9364.59375, val_loss=9512.04883\n",
      "Epoch 3233: train_loss=9364.19629, val_loss=9511.63965\n",
      "Epoch 3234: train_loss=9363.79785, val_loss=9511.23145\n",
      "Epoch 3235: train_loss=9363.39941, val_loss=9510.82520\n",
      "Epoch 3236: train_loss=9363.00293, val_loss=9510.41797\n",
      "Epoch 3237: train_loss=9362.60449, val_loss=9510.01074\n",
      "Epoch 3238: train_loss=9362.20801, val_loss=9509.60352\n",
      "Epoch 3239: train_loss=9361.81152, val_loss=9509.19434\n",
      "Epoch 3240: train_loss=9361.41504, val_loss=9508.78516\n",
      "Epoch 3241: train_loss=9361.01855, val_loss=9508.37598\n",
      "Epoch 3242: train_loss=9360.62305, val_loss=9507.96680\n",
      "Epoch 3243: train_loss=9360.22949, val_loss=9507.55469\n",
      "Epoch 3244: train_loss=9359.83301, val_loss=9507.14648\n",
      "Epoch 3245: train_loss=9359.43848, val_loss=9506.73828\n",
      "Epoch 3246: train_loss=9359.04395, val_loss=9506.33203\n",
      "Epoch 3247: train_loss=9358.65039, val_loss=9505.92578\n",
      "Epoch 3248: train_loss=9358.25684, val_loss=9505.52051\n",
      "Epoch 3249: train_loss=9357.86133, val_loss=9505.11523\n",
      "Epoch 3250: train_loss=9357.46777, val_loss=9504.71094\n",
      "Epoch 3251: train_loss=9357.07422, val_loss=9504.30469\n",
      "Epoch 3252: train_loss=9356.68066, val_loss=9503.89844\n",
      "Epoch 3253: train_loss=9356.28613, val_loss=9503.49219\n",
      "Epoch 3254: train_loss=9355.89453, val_loss=9503.08594\n",
      "Epoch 3255: train_loss=9355.50098, val_loss=9502.67969\n",
      "Epoch 3256: train_loss=9355.10840, val_loss=9502.27441\n",
      "Epoch 3257: train_loss=9354.71582, val_loss=9501.86914\n",
      "Epoch 3258: train_loss=9354.32422, val_loss=9501.46582\n",
      "Epoch 3259: train_loss=9353.93164, val_loss=9501.06152\n",
      "Epoch 3260: train_loss=9353.54004, val_loss=9500.65723\n",
      "Epoch 3261: train_loss=9353.14746, val_loss=9500.25195\n",
      "Epoch 3262: train_loss=9352.75586, val_loss=9499.84766\n",
      "Epoch 3263: train_loss=9352.36523, val_loss=9499.44336\n",
      "Epoch 3264: train_loss=9351.97363, val_loss=9499.03906\n",
      "Epoch 3265: train_loss=9351.58398, val_loss=9498.63672\n",
      "Epoch 3266: train_loss=9351.19336, val_loss=9498.23535\n",
      "Epoch 3267: train_loss=9350.80273, val_loss=9497.83301\n",
      "Epoch 3268: train_loss=9350.41406, val_loss=9497.43164\n",
      "Epoch 3269: train_loss=9350.02441, val_loss=9497.03125\n",
      "Epoch 3270: train_loss=9349.63477, val_loss=9496.63281\n",
      "Epoch 3271: train_loss=9349.24609, val_loss=9496.23242\n",
      "Epoch 3272: train_loss=9348.85742, val_loss=9495.83105\n",
      "Epoch 3273: train_loss=9348.46777, val_loss=9495.43066\n",
      "Epoch 3274: train_loss=9348.07910, val_loss=9495.03027\n",
      "Epoch 3275: train_loss=9347.69043, val_loss=9494.62988\n",
      "Epoch 3276: train_loss=9347.30273, val_loss=9494.23047\n",
      "Epoch 3277: train_loss=9346.91602, val_loss=9493.82910\n",
      "Epoch 3278: train_loss=9346.52734, val_loss=9493.42773\n",
      "Epoch 3279: train_loss=9346.13867, val_loss=9493.02734\n",
      "Epoch 3280: train_loss=9345.75098, val_loss=9492.62793\n",
      "Epoch 3281: train_loss=9345.36426, val_loss=9492.23047\n",
      "Epoch 3282: train_loss=9344.97656, val_loss=9491.83203\n",
      "Epoch 3283: train_loss=9344.58984, val_loss=9491.43164\n",
      "Epoch 3284: train_loss=9344.20215, val_loss=9491.03223\n",
      "Epoch 3285: train_loss=9343.81543, val_loss=9490.63184\n",
      "Epoch 3286: train_loss=9343.42773, val_loss=9490.23145\n",
      "Epoch 3287: train_loss=9343.04102, val_loss=9489.83301\n",
      "Epoch 3288: train_loss=9342.65430, val_loss=9489.43457\n",
      "Epoch 3289: train_loss=9342.26758, val_loss=9489.03320\n",
      "Epoch 3290: train_loss=9341.87988, val_loss=9488.63086\n",
      "Epoch 3291: train_loss=9341.49414, val_loss=9488.22949\n",
      "Epoch 3292: train_loss=9341.10742, val_loss=9487.82812\n",
      "Epoch 3293: train_loss=9340.71973, val_loss=9487.42871\n",
      "Epoch 3294: train_loss=9340.33398, val_loss=9487.02637\n",
      "Epoch 3295: train_loss=9339.94727, val_loss=9486.62305\n",
      "Epoch 3296: train_loss=9339.56055, val_loss=9486.22168\n",
      "Epoch 3297: train_loss=9339.17383, val_loss=9485.81934\n",
      "Epoch 3298: train_loss=9338.78711, val_loss=9485.41895\n",
      "Epoch 3299: train_loss=9338.40039, val_loss=9485.01758\n",
      "Epoch 3300: train_loss=9338.01367, val_loss=9484.61719\n",
      "Epoch 3301: train_loss=9337.62891, val_loss=9484.21777\n",
      "Epoch 3302: train_loss=9337.24219, val_loss=9483.81641\n",
      "Epoch 3303: train_loss=9336.85645, val_loss=9483.41602\n",
      "Epoch 3304: train_loss=9336.46973, val_loss=9483.01465\n",
      "Epoch 3305: train_loss=9336.08398, val_loss=9482.61523\n",
      "Epoch 3306: train_loss=9335.69922, val_loss=9482.21582\n",
      "Epoch 3307: train_loss=9335.31348, val_loss=9481.81641\n",
      "Epoch 3308: train_loss=9334.92871, val_loss=9481.41699\n",
      "Epoch 3309: train_loss=9334.54297, val_loss=9481.01562\n",
      "Epoch 3310: train_loss=9334.15820, val_loss=9480.61523\n",
      "Epoch 3311: train_loss=9333.77246, val_loss=9480.21582\n",
      "Epoch 3312: train_loss=9333.38770, val_loss=9479.81543\n",
      "Epoch 3313: train_loss=9333.00391, val_loss=9479.41602\n",
      "Epoch 3314: train_loss=9332.62012, val_loss=9479.01758\n",
      "Epoch 3315: train_loss=9332.23535, val_loss=9478.61816\n",
      "Epoch 3316: train_loss=9331.85156, val_loss=9478.21777\n",
      "Epoch 3317: train_loss=9331.46777, val_loss=9477.81934\n",
      "Epoch 3318: train_loss=9331.08496, val_loss=9477.41992\n",
      "Epoch 3319: train_loss=9330.70117, val_loss=9477.02246\n",
      "Epoch 3320: train_loss=9330.31641, val_loss=9476.62500\n",
      "Epoch 3321: train_loss=9329.93359, val_loss=9476.22754\n",
      "Epoch 3322: train_loss=9329.54980, val_loss=9475.83105\n",
      "Epoch 3323: train_loss=9329.16602, val_loss=9475.43457\n",
      "Epoch 3324: train_loss=9328.78320, val_loss=9475.03516\n",
      "Epoch 3325: train_loss=9328.39941, val_loss=9474.63770\n",
      "Epoch 3326: train_loss=9328.01758, val_loss=9474.24023\n",
      "Epoch 3327: train_loss=9327.63477, val_loss=9473.84277\n",
      "Epoch 3328: train_loss=9327.25195, val_loss=9473.44629\n",
      "Epoch 3329: train_loss=9326.86914, val_loss=9473.05078\n",
      "Epoch 3330: train_loss=9326.48730, val_loss=9472.65527\n",
      "Epoch 3331: train_loss=9326.10645, val_loss=9472.25977\n",
      "Epoch 3332: train_loss=9325.72461, val_loss=9471.86328\n",
      "Epoch 3333: train_loss=9325.34473, val_loss=9471.46875\n",
      "Epoch 3334: train_loss=9324.96484, val_loss=9471.07422\n",
      "Epoch 3335: train_loss=9324.58496, val_loss=9470.68066\n",
      "Epoch 3336: train_loss=9324.20508, val_loss=9470.28809\n",
      "Epoch 3337: train_loss=9323.82520, val_loss=9469.89551\n",
      "Epoch 3338: train_loss=9323.44727, val_loss=9469.50293\n",
      "Epoch 3339: train_loss=9323.06738, val_loss=9469.10742\n",
      "Epoch 3340: train_loss=9322.68848, val_loss=9468.71191\n",
      "Epoch 3341: train_loss=9322.31055, val_loss=9468.31934\n",
      "Epoch 3342: train_loss=9321.93066, val_loss=9467.92676\n",
      "Epoch 3343: train_loss=9321.55273, val_loss=9467.53516\n",
      "Epoch 3344: train_loss=9321.17383, val_loss=9467.14355\n",
      "Epoch 3345: train_loss=9320.79590, val_loss=9466.75195\n",
      "Epoch 3346: train_loss=9320.41797, val_loss=9466.35840\n",
      "Epoch 3347: train_loss=9320.04004, val_loss=9465.96582\n",
      "Epoch 3348: train_loss=9319.66113, val_loss=9465.57324\n",
      "Epoch 3349: train_loss=9319.28516, val_loss=9465.18066\n",
      "Epoch 3350: train_loss=9318.90625, val_loss=9464.78906\n",
      "Epoch 3351: train_loss=9318.52832, val_loss=9464.39746\n",
      "Epoch 3352: train_loss=9318.15234, val_loss=9464.00586\n",
      "Epoch 3353: train_loss=9317.77344, val_loss=9463.61328\n",
      "Epoch 3354: train_loss=9317.39648, val_loss=9463.22168\n",
      "Epoch 3355: train_loss=9317.01855, val_loss=9462.82812\n",
      "Epoch 3356: train_loss=9316.64160, val_loss=9462.43652\n",
      "Epoch 3357: train_loss=9316.26465, val_loss=9462.04492\n",
      "Epoch 3358: train_loss=9315.88770, val_loss=9461.65332\n",
      "Epoch 3359: train_loss=9315.50977, val_loss=9461.26074\n",
      "Epoch 3360: train_loss=9315.13379, val_loss=9460.87012\n",
      "Epoch 3361: train_loss=9314.75684, val_loss=9460.48047\n",
      "Epoch 3362: train_loss=9314.37891, val_loss=9460.08887\n",
      "Epoch 3363: train_loss=9314.00293, val_loss=9459.69727\n",
      "Epoch 3364: train_loss=9313.62598, val_loss=9459.30566\n",
      "Epoch 3365: train_loss=9313.24805, val_loss=9458.91309\n",
      "Epoch 3366: train_loss=9312.87207, val_loss=9458.52148\n",
      "Epoch 3367: train_loss=9312.49414, val_loss=9458.13086\n",
      "Epoch 3368: train_loss=9312.11719, val_loss=9457.73926\n",
      "Epoch 3369: train_loss=9311.74121, val_loss=9457.34766\n",
      "Epoch 3370: train_loss=9311.36523, val_loss=9456.95703\n",
      "Epoch 3371: train_loss=9310.98926, val_loss=9456.56641\n",
      "Epoch 3372: train_loss=9310.61230, val_loss=9456.17480\n",
      "Epoch 3373: train_loss=9310.23633, val_loss=9455.78320\n",
      "Epoch 3374: train_loss=9309.86035, val_loss=9455.39355\n",
      "Epoch 3375: train_loss=9309.48535, val_loss=9455.00391\n",
      "Epoch 3376: train_loss=9309.10938, val_loss=9454.61426\n",
      "Epoch 3377: train_loss=9308.73340, val_loss=9454.22461\n",
      "Epoch 3378: train_loss=9308.35840, val_loss=9453.83496\n",
      "Epoch 3379: train_loss=9307.98242, val_loss=9453.44531\n",
      "Epoch 3380: train_loss=9307.60742, val_loss=9453.05469\n",
      "Epoch 3381: train_loss=9307.23242, val_loss=9452.66602\n",
      "Epoch 3382: train_loss=9306.85840, val_loss=9452.27637\n",
      "Epoch 3383: train_loss=9306.48340, val_loss=9451.88770\n",
      "Epoch 3384: train_loss=9306.10938, val_loss=9451.49707\n",
      "Epoch 3385: train_loss=9305.73438, val_loss=9451.10742\n",
      "Epoch 3386: train_loss=9305.36035, val_loss=9450.71777\n",
      "Epoch 3387: train_loss=9304.98633, val_loss=9450.32910\n",
      "Epoch 3388: train_loss=9304.61230, val_loss=9449.94043\n",
      "Epoch 3389: train_loss=9304.23828, val_loss=9449.55078\n",
      "Epoch 3390: train_loss=9303.86426, val_loss=9449.16113\n",
      "Epoch 3391: train_loss=9303.48926, val_loss=9448.77148\n",
      "Epoch 3392: train_loss=9303.11426, val_loss=9448.37988\n",
      "Epoch 3393: train_loss=9302.74121, val_loss=9447.99023\n",
      "Epoch 3394: train_loss=9302.36621, val_loss=9447.59961\n",
      "Epoch 3395: train_loss=9301.99316, val_loss=9447.21094\n",
      "Epoch 3396: train_loss=9301.61914, val_loss=9446.82227\n",
      "Epoch 3397: train_loss=9301.24512, val_loss=9446.43359\n",
      "Epoch 3398: train_loss=9300.87207, val_loss=9446.04688\n",
      "Epoch 3399: train_loss=9300.49902, val_loss=9445.65918\n",
      "Epoch 3400: train_loss=9300.12500, val_loss=9445.27344\n",
      "Epoch 3401: train_loss=9299.75098, val_loss=9444.88574\n",
      "Epoch 3402: train_loss=9299.37891, val_loss=9444.49609\n",
      "Epoch 3403: train_loss=9299.00391, val_loss=9444.10742\n",
      "Epoch 3404: train_loss=9298.63184, val_loss=9443.71875\n",
      "Epoch 3405: train_loss=9298.25684, val_loss=9443.32910\n",
      "Epoch 3406: train_loss=9297.88379, val_loss=9442.94043\n",
      "Epoch 3407: train_loss=9297.50977, val_loss=9442.54980\n",
      "Epoch 3408: train_loss=9297.13770, val_loss=9442.16016\n",
      "Epoch 3409: train_loss=9296.76367, val_loss=9441.77051\n",
      "Epoch 3410: train_loss=9296.38965, val_loss=9441.38086\n",
      "Epoch 3411: train_loss=9296.01660, val_loss=9440.99121\n",
      "Epoch 3412: train_loss=9295.64355, val_loss=9440.60156\n",
      "Epoch 3413: train_loss=9295.26953, val_loss=9440.21094\n",
      "Epoch 3414: train_loss=9294.89648, val_loss=9439.82031\n",
      "Epoch 3415: train_loss=9294.52246, val_loss=9439.42871\n",
      "Epoch 3416: train_loss=9294.14844, val_loss=9439.04004\n",
      "Epoch 3417: train_loss=9293.77637, val_loss=9438.65137\n",
      "Epoch 3418: train_loss=9293.40137, val_loss=9438.26172\n",
      "Epoch 3419: train_loss=9293.02832, val_loss=9437.87305\n",
      "Epoch 3420: train_loss=9292.65625, val_loss=9437.48438\n",
      "Epoch 3421: train_loss=9292.28418, val_loss=9437.09473\n",
      "Epoch 3422: train_loss=9291.91211, val_loss=9436.70605\n",
      "Epoch 3423: train_loss=9291.54199, val_loss=9436.31641\n",
      "Epoch 3424: train_loss=9291.16895, val_loss=9435.92871\n",
      "Epoch 3425: train_loss=9290.79883, val_loss=9435.54004\n",
      "Epoch 3426: train_loss=9290.42676, val_loss=9435.15234\n",
      "Epoch 3427: train_loss=9290.05664, val_loss=9434.76465\n",
      "Epoch 3428: train_loss=9289.68652, val_loss=9434.37793\n",
      "Epoch 3429: train_loss=9289.31543, val_loss=9433.99121\n",
      "Epoch 3430: train_loss=9288.94336, val_loss=9433.60352\n",
      "Epoch 3431: train_loss=9288.57324, val_loss=9433.21582\n",
      "Epoch 3432: train_loss=9288.20312, val_loss=9432.82812\n",
      "Epoch 3433: train_loss=9287.83203, val_loss=9432.44141\n",
      "Epoch 3434: train_loss=9287.46191, val_loss=9432.05469\n",
      "Epoch 3435: train_loss=9287.09082, val_loss=9431.66602\n",
      "Epoch 3436: train_loss=9286.72168, val_loss=9431.27832\n",
      "Epoch 3437: train_loss=9286.35059, val_loss=9430.89062\n",
      "Epoch 3438: train_loss=9285.98047, val_loss=9430.50391\n",
      "Epoch 3439: train_loss=9285.61133, val_loss=9430.11816\n",
      "Epoch 3440: train_loss=9285.24121, val_loss=9429.72949\n",
      "Epoch 3441: train_loss=9284.87109, val_loss=9429.34277\n",
      "Epoch 3442: train_loss=9284.50000, val_loss=9428.95410\n",
      "Epoch 3443: train_loss=9284.13086, val_loss=9428.56738\n",
      "Epoch 3444: train_loss=9283.75977, val_loss=9428.17969\n",
      "Epoch 3445: train_loss=9283.39062, val_loss=9427.79004\n",
      "Epoch 3446: train_loss=9283.02051, val_loss=9427.40039\n",
      "Epoch 3447: train_loss=9282.64941, val_loss=9427.01172\n",
      "Epoch 3448: train_loss=9282.27930, val_loss=9426.62305\n",
      "Epoch 3449: train_loss=9281.90918, val_loss=9426.23242\n",
      "Epoch 3450: train_loss=9281.53809, val_loss=9425.84180\n",
      "Epoch 3451: train_loss=9281.16699, val_loss=9425.45020\n",
      "Epoch 3452: train_loss=9280.79590, val_loss=9425.05957\n",
      "Epoch 3453: train_loss=9280.42480, val_loss=9424.66699\n",
      "Epoch 3454: train_loss=9280.05273, val_loss=9424.27441\n",
      "Epoch 3455: train_loss=9279.67969, val_loss=9423.88086\n",
      "Epoch 3456: train_loss=9279.30566, val_loss=9423.48535\n",
      "Epoch 3457: train_loss=9278.93164, val_loss=9423.09180\n",
      "Epoch 3458: train_loss=9278.55566, val_loss=9422.69727\n",
      "Epoch 3459: train_loss=9278.18164, val_loss=9422.30176\n",
      "Epoch 3460: train_loss=9277.80762, val_loss=9421.90527\n",
      "Epoch 3461: train_loss=9277.43262, val_loss=9421.50977\n",
      "Epoch 3462: train_loss=9277.05859, val_loss=9421.11230\n",
      "Epoch 3463: train_loss=9276.68457, val_loss=9420.71582\n",
      "Epoch 3464: train_loss=9276.31055, val_loss=9420.31836\n",
      "Epoch 3465: train_loss=9275.93652, val_loss=9419.92188\n",
      "Epoch 3466: train_loss=9275.56250, val_loss=9419.52637\n",
      "Epoch 3467: train_loss=9275.19043, val_loss=9419.12988\n",
      "Epoch 3468: train_loss=9274.81641, val_loss=9418.73340\n",
      "Epoch 3469: train_loss=9274.44336, val_loss=9418.33691\n",
      "Epoch 3470: train_loss=9274.06934, val_loss=9417.94238\n",
      "Epoch 3471: train_loss=9273.69727, val_loss=9417.54883\n",
      "Epoch 3472: train_loss=9273.32715, val_loss=9417.15625\n",
      "Epoch 3473: train_loss=9272.95508, val_loss=9416.76465\n",
      "Epoch 3474: train_loss=9272.58398, val_loss=9416.37012\n",
      "Epoch 3475: train_loss=9272.21191, val_loss=9415.97656\n",
      "Epoch 3476: train_loss=9271.83984, val_loss=9415.58105\n",
      "Epoch 3477: train_loss=9271.46777, val_loss=9415.18652\n",
      "Epoch 3478: train_loss=9271.09570, val_loss=9414.79297\n",
      "Epoch 3479: train_loss=9270.72266, val_loss=9414.39844\n",
      "Epoch 3480: train_loss=9270.35059, val_loss=9414.00391\n",
      "Epoch 3481: train_loss=9269.97754, val_loss=9413.61035\n",
      "Epoch 3482: train_loss=9269.60645, val_loss=9413.21680\n",
      "Epoch 3483: train_loss=9269.23340, val_loss=9412.82422\n",
      "Epoch 3484: train_loss=9268.86328, val_loss=9412.43164\n",
      "Epoch 3485: train_loss=9268.49219, val_loss=9412.03906\n",
      "Epoch 3486: train_loss=9268.12109, val_loss=9411.64648\n",
      "Epoch 3487: train_loss=9267.74805, val_loss=9411.25391\n",
      "Epoch 3488: train_loss=9267.37598, val_loss=9410.86133\n",
      "Epoch 3489: train_loss=9267.00391, val_loss=9410.46680\n",
      "Epoch 3490: train_loss=9266.63184, val_loss=9410.07324\n",
      "Epoch 3491: train_loss=9266.25879, val_loss=9409.68066\n",
      "Epoch 3492: train_loss=9265.88770, val_loss=9409.28711\n",
      "Epoch 3493: train_loss=9265.51562, val_loss=9408.89453\n",
      "Epoch 3494: train_loss=9265.14355, val_loss=9408.50098\n",
      "Epoch 3495: train_loss=9264.76953, val_loss=9408.10645\n",
      "Epoch 3496: train_loss=9264.39746, val_loss=9407.71387\n",
      "Epoch 3497: train_loss=9264.02637, val_loss=9407.32031\n",
      "Epoch 3498: train_loss=9263.65332, val_loss=9406.92676\n",
      "Epoch 3499: train_loss=9263.28223, val_loss=9406.53320\n",
      "Epoch 3500: train_loss=9262.90918, val_loss=9406.13867\n",
      "Epoch 3501: train_loss=9262.53711, val_loss=9405.74512\n",
      "Epoch 3502: train_loss=9262.16406, val_loss=9405.35059\n",
      "Epoch 3503: train_loss=9261.79102, val_loss=9404.95605\n",
      "Epoch 3504: train_loss=9261.41895, val_loss=9404.56250\n",
      "Epoch 3505: train_loss=9261.04590, val_loss=9404.16895\n",
      "Epoch 3506: train_loss=9260.67480, val_loss=9403.77539\n",
      "Epoch 3507: train_loss=9260.30176, val_loss=9403.38086\n",
      "Epoch 3508: train_loss=9259.92871, val_loss=9402.98633\n",
      "Epoch 3509: train_loss=9259.55469, val_loss=9402.59277\n",
      "Epoch 3510: train_loss=9259.18262, val_loss=9402.19824\n",
      "Epoch 3511: train_loss=9258.81055, val_loss=9401.80469\n",
      "Epoch 3512: train_loss=9258.43750, val_loss=9401.40918\n",
      "Epoch 3513: train_loss=9258.06445, val_loss=9401.01367\n",
      "Epoch 3514: train_loss=9257.69141, val_loss=9400.61816\n",
      "Epoch 3515: train_loss=9257.31836, val_loss=9400.22363\n",
      "Epoch 3516: train_loss=9256.94531, val_loss=9399.82910\n",
      "Epoch 3517: train_loss=9256.57324, val_loss=9399.43555\n",
      "Epoch 3518: train_loss=9256.19824, val_loss=9399.04297\n",
      "Epoch 3519: train_loss=9255.82715, val_loss=9398.64941\n",
      "Epoch 3520: train_loss=9255.45312, val_loss=9398.25586\n",
      "Epoch 3521: train_loss=9255.07910, val_loss=9397.86133\n",
      "Epoch 3522: train_loss=9254.70605, val_loss=9397.46875\n",
      "Epoch 3523: train_loss=9254.33398, val_loss=9397.07520\n",
      "Epoch 3524: train_loss=9253.95996, val_loss=9396.68066\n",
      "Epoch 3525: train_loss=9253.58789, val_loss=9396.28711\n",
      "Epoch 3526: train_loss=9253.21387, val_loss=9395.89258\n",
      "Epoch 3527: train_loss=9252.84082, val_loss=9395.50000\n",
      "Epoch 3528: train_loss=9252.46777, val_loss=9395.10742\n",
      "Epoch 3529: train_loss=9252.09375, val_loss=9394.71387\n",
      "Epoch 3530: train_loss=9251.72070, val_loss=9394.32129\n",
      "Epoch 3531: train_loss=9251.34766, val_loss=9393.92871\n",
      "Epoch 3532: train_loss=9250.97363, val_loss=9393.53613\n",
      "Epoch 3533: train_loss=9250.60059, val_loss=9393.14160\n",
      "Epoch 3534: train_loss=9250.22754, val_loss=9392.74902\n",
      "Epoch 3535: train_loss=9249.85449, val_loss=9392.35547\n",
      "Epoch 3536: train_loss=9249.48047, val_loss=9391.96191\n",
      "Epoch 3537: train_loss=9249.10938, val_loss=9391.56934\n",
      "Epoch 3538: train_loss=9248.73535, val_loss=9391.17773\n",
      "Epoch 3539: train_loss=9248.36328, val_loss=9390.78516\n",
      "Epoch 3540: train_loss=9247.99023, val_loss=9390.39258\n",
      "Epoch 3541: train_loss=9247.61816, val_loss=9390.00000\n",
      "Epoch 3542: train_loss=9247.24609, val_loss=9389.60840\n",
      "Epoch 3543: train_loss=9246.87207, val_loss=9389.21582\n",
      "Epoch 3544: train_loss=9246.50098, val_loss=9388.82227\n",
      "Epoch 3545: train_loss=9246.12695, val_loss=9388.42773\n",
      "Epoch 3546: train_loss=9245.75391, val_loss=9388.03418\n",
      "Epoch 3547: train_loss=9245.38086, val_loss=9387.63965\n",
      "Epoch 3548: train_loss=9245.00781, val_loss=9387.24414\n",
      "Epoch 3549: train_loss=9244.63477, val_loss=9386.84863\n",
      "Epoch 3550: train_loss=9244.25977, val_loss=9386.45508\n",
      "Epoch 3551: train_loss=9243.88672, val_loss=9386.06055\n",
      "Epoch 3552: train_loss=9243.51367, val_loss=9385.66699\n",
      "Epoch 3553: train_loss=9243.13867, val_loss=9385.27148\n",
      "Epoch 3554: train_loss=9242.76465, val_loss=9384.87695\n",
      "Epoch 3555: train_loss=9242.39062, val_loss=9384.48047\n",
      "Epoch 3556: train_loss=9242.01562, val_loss=9384.08496\n",
      "Epoch 3557: train_loss=9241.64258, val_loss=9383.68848\n",
      "Epoch 3558: train_loss=9241.26758, val_loss=9383.29199\n",
      "Epoch 3559: train_loss=9240.89355, val_loss=9382.89551\n",
      "Epoch 3560: train_loss=9240.51855, val_loss=9382.49902\n",
      "Epoch 3561: train_loss=9240.14453, val_loss=9382.10352\n",
      "Epoch 3562: train_loss=9239.76953, val_loss=9381.70898\n",
      "Epoch 3563: train_loss=9239.39453, val_loss=9381.31152\n",
      "Epoch 3564: train_loss=9239.02148, val_loss=9380.91602\n",
      "Epoch 3565: train_loss=9238.64551, val_loss=9380.51953\n",
      "Epoch 3566: train_loss=9238.27246, val_loss=9380.12207\n",
      "Epoch 3567: train_loss=9237.89746, val_loss=9379.72559\n",
      "Epoch 3568: train_loss=9237.52246, val_loss=9379.33008\n",
      "Epoch 3569: train_loss=9237.14844, val_loss=9378.93359\n",
      "Epoch 3570: train_loss=9236.77344, val_loss=9378.53711\n",
      "Epoch 3571: train_loss=9236.39941, val_loss=9378.14258\n",
      "Epoch 3572: train_loss=9236.02441, val_loss=9377.74512\n",
      "Epoch 3573: train_loss=9235.64941, val_loss=9377.34961\n",
      "Epoch 3574: train_loss=9235.27539, val_loss=9376.95410\n",
      "Epoch 3575: train_loss=9234.90137, val_loss=9376.55859\n",
      "Epoch 3576: train_loss=9234.52637, val_loss=9376.16309\n",
      "Epoch 3577: train_loss=9234.15137, val_loss=9375.76660\n",
      "Epoch 3578: train_loss=9233.77832, val_loss=9375.37109\n",
      "Epoch 3579: train_loss=9233.40234, val_loss=9374.97461\n",
      "Epoch 3580: train_loss=9233.02832, val_loss=9374.57715\n",
      "Epoch 3581: train_loss=9232.65527, val_loss=9374.18066\n",
      "Epoch 3582: train_loss=9232.28027, val_loss=9373.78516\n",
      "Epoch 3583: train_loss=9231.90527, val_loss=9373.38867\n",
      "Epoch 3584: train_loss=9231.53223, val_loss=9372.99316\n",
      "Epoch 3585: train_loss=9231.15820, val_loss=9372.59668\n",
      "Epoch 3586: train_loss=9230.78320, val_loss=9372.20117\n",
      "Epoch 3587: train_loss=9230.41016, val_loss=9371.80566\n",
      "Epoch 3588: train_loss=9230.03613, val_loss=9371.41016\n",
      "Epoch 3589: train_loss=9229.66211, val_loss=9371.01562\n",
      "Epoch 3590: train_loss=9229.28906, val_loss=9370.62012\n",
      "Epoch 3591: train_loss=9228.91504, val_loss=9370.22461\n",
      "Epoch 3592: train_loss=9228.54199, val_loss=9369.83105\n",
      "Epoch 3593: train_loss=9228.16895, val_loss=9369.43652\n",
      "Epoch 3594: train_loss=9227.79590, val_loss=9369.04297\n",
      "Epoch 3595: train_loss=9227.42285, val_loss=9368.64844\n",
      "Epoch 3596: train_loss=9227.05078, val_loss=9368.25586\n",
      "Epoch 3597: train_loss=9226.67773, val_loss=9367.86230\n",
      "Epoch 3598: train_loss=9226.30566, val_loss=9367.46875\n",
      "Epoch 3599: train_loss=9225.93359, val_loss=9367.07520\n",
      "Epoch 3600: train_loss=9225.56152, val_loss=9366.68262\n",
      "Epoch 3601: train_loss=9225.18945, val_loss=9366.29004\n",
      "Epoch 3602: train_loss=9224.81836, val_loss=9365.89648\n",
      "Epoch 3603: train_loss=9224.44727, val_loss=9365.50293\n",
      "Epoch 3604: train_loss=9224.07617, val_loss=9365.11133\n",
      "Epoch 3605: train_loss=9223.70410, val_loss=9364.71680\n",
      "Epoch 3606: train_loss=9223.33301, val_loss=9364.32422\n",
      "Epoch 3607: train_loss=9222.96191, val_loss=9363.93066\n",
      "Epoch 3608: train_loss=9222.59180, val_loss=9363.53906\n",
      "Epoch 3609: train_loss=9222.21973, val_loss=9363.14648\n",
      "Epoch 3610: train_loss=9221.84961, val_loss=9362.75195\n",
      "Epoch 3611: train_loss=9221.47949, val_loss=9362.35840\n",
      "Epoch 3612: train_loss=9221.10742, val_loss=9361.96484\n",
      "Epoch 3613: train_loss=9220.73730, val_loss=9361.57227\n",
      "Epoch 3614: train_loss=9220.36816, val_loss=9361.17871\n",
      "Epoch 3615: train_loss=9219.99805, val_loss=9360.78711\n",
      "Epoch 3616: train_loss=9219.62695, val_loss=9360.39355\n",
      "Epoch 3617: train_loss=9219.25781, val_loss=9360.00098\n",
      "Epoch 3618: train_loss=9218.88770, val_loss=9359.60938\n",
      "Epoch 3619: train_loss=9218.51953, val_loss=9359.21973\n",
      "Epoch 3620: train_loss=9218.15137, val_loss=9358.83008\n",
      "Epoch 3621: train_loss=9217.78223, val_loss=9358.44043\n",
      "Epoch 3622: train_loss=9217.41406, val_loss=9358.05078\n",
      "Epoch 3623: train_loss=9217.04590, val_loss=9357.66113\n",
      "Epoch 3624: train_loss=9216.67871, val_loss=9357.27246\n",
      "Epoch 3625: train_loss=9216.30957, val_loss=9356.88379\n",
      "Epoch 3626: train_loss=9215.94336, val_loss=9356.49414\n",
      "Epoch 3627: train_loss=9215.57520, val_loss=9356.10449\n",
      "Epoch 3628: train_loss=9215.20801, val_loss=9355.71289\n",
      "Epoch 3629: train_loss=9214.84082, val_loss=9355.32324\n",
      "Epoch 3630: train_loss=9214.47363, val_loss=9354.93359\n",
      "Epoch 3631: train_loss=9214.10742, val_loss=9354.54492\n",
      "Epoch 3632: train_loss=9213.74023, val_loss=9354.15625\n",
      "Epoch 3633: train_loss=9213.37402, val_loss=9353.76855\n",
      "Epoch 3634: train_loss=9213.00781, val_loss=9353.37988\n",
      "Epoch 3635: train_loss=9212.64160, val_loss=9352.99219\n",
      "Epoch 3636: train_loss=9212.27441, val_loss=9352.60352\n",
      "Epoch 3637: train_loss=9211.90723, val_loss=9352.21289\n",
      "Epoch 3638: train_loss=9211.54102, val_loss=9351.82422\n",
      "Epoch 3639: train_loss=9211.17578, val_loss=9351.43457\n",
      "Epoch 3640: train_loss=9210.80957, val_loss=9351.04590\n",
      "Epoch 3641: train_loss=9210.44336, val_loss=9350.65723\n",
      "Epoch 3642: train_loss=9210.07910, val_loss=9350.26855\n",
      "Epoch 3643: train_loss=9209.71289, val_loss=9349.88086\n",
      "Epoch 3644: train_loss=9209.34668, val_loss=9349.49316\n",
      "Epoch 3645: train_loss=9208.98242, val_loss=9349.10449\n",
      "Epoch 3646: train_loss=9208.61719, val_loss=9348.71582\n",
      "Epoch 3647: train_loss=9208.25098, val_loss=9348.32715\n",
      "Epoch 3648: train_loss=9207.88574, val_loss=9347.93945\n",
      "Epoch 3649: train_loss=9207.51855, val_loss=9347.55176\n",
      "Epoch 3650: train_loss=9207.15430, val_loss=9347.16309\n",
      "Epoch 3651: train_loss=9206.78809, val_loss=9346.77441\n",
      "Epoch 3652: train_loss=9206.42285, val_loss=9346.38672\n",
      "Epoch 3653: train_loss=9206.05664, val_loss=9345.99902\n",
      "Epoch 3654: train_loss=9205.69141, val_loss=9345.61133\n",
      "Epoch 3655: train_loss=9205.32520, val_loss=9345.22461\n",
      "Epoch 3656: train_loss=9204.96094, val_loss=9344.83691\n",
      "Epoch 3657: train_loss=9204.59570, val_loss=9344.45020\n",
      "Epoch 3658: train_loss=9204.22949, val_loss=9344.06055\n",
      "Epoch 3659: train_loss=9203.86426, val_loss=9343.67090\n",
      "Epoch 3660: train_loss=9203.49902, val_loss=9343.28125\n",
      "Epoch 3661: train_loss=9203.13281, val_loss=9342.89160\n",
      "Epoch 3662: train_loss=9202.76855, val_loss=9342.50195\n",
      "Epoch 3663: train_loss=9202.40234, val_loss=9342.11426\n",
      "Epoch 3664: train_loss=9202.03711, val_loss=9341.72754\n",
      "Epoch 3665: train_loss=9201.67090, val_loss=9341.33984\n",
      "Epoch 3666: train_loss=9201.30664, val_loss=9340.95410\n",
      "Epoch 3667: train_loss=9200.94238, val_loss=9340.56641\n",
      "Epoch 3668: train_loss=9200.57715, val_loss=9340.17871\n",
      "Epoch 3669: train_loss=9200.21094, val_loss=9339.79102\n",
      "Epoch 3670: train_loss=9199.84668, val_loss=9339.40332\n",
      "Epoch 3671: train_loss=9199.48145, val_loss=9339.01562\n",
      "Epoch 3672: train_loss=9199.11523, val_loss=9338.62988\n",
      "Epoch 3673: train_loss=9198.75098, val_loss=9338.24316\n",
      "Epoch 3674: train_loss=9198.38574, val_loss=9337.85645\n",
      "Epoch 3675: train_loss=9198.02148, val_loss=9337.47168\n",
      "Epoch 3676: train_loss=9197.65527, val_loss=9337.08594\n",
      "Epoch 3677: train_loss=9197.29199, val_loss=9336.69922\n",
      "Epoch 3678: train_loss=9196.92578, val_loss=9336.31152\n",
      "Epoch 3679: train_loss=9196.56152, val_loss=9335.92480\n",
      "Epoch 3680: train_loss=9196.19727, val_loss=9335.53711\n",
      "Epoch 3681: train_loss=9195.83105, val_loss=9335.14941\n",
      "Epoch 3682: train_loss=9195.46582, val_loss=9334.76172\n",
      "Epoch 3683: train_loss=9195.10156, val_loss=9334.37598\n",
      "Epoch 3684: train_loss=9194.73438, val_loss=9333.98926\n",
      "Epoch 3685: train_loss=9194.37012, val_loss=9333.60156\n",
      "Epoch 3686: train_loss=9194.00391, val_loss=9333.21484\n",
      "Epoch 3687: train_loss=9193.63867, val_loss=9332.82715\n",
      "Epoch 3688: train_loss=9193.27441, val_loss=9332.44141\n",
      "Epoch 3689: train_loss=9192.91016, val_loss=9332.05371\n",
      "Epoch 3690: train_loss=9192.54297, val_loss=9331.66602\n",
      "Epoch 3691: train_loss=9192.17871, val_loss=9331.28027\n",
      "Epoch 3692: train_loss=9191.81250, val_loss=9330.89355\n",
      "Epoch 3693: train_loss=9191.44727, val_loss=9330.50684\n",
      "Epoch 3694: train_loss=9191.08301, val_loss=9330.12109\n",
      "Epoch 3695: train_loss=9190.71777, val_loss=9329.73535\n",
      "Epoch 3696: train_loss=9190.35156, val_loss=9329.34863\n",
      "Epoch 3697: train_loss=9189.98730, val_loss=9328.96289\n",
      "Epoch 3698: train_loss=9189.62305, val_loss=9328.57812\n",
      "Epoch 3699: train_loss=9189.25879, val_loss=9328.19336\n",
      "Epoch 3700: train_loss=9188.89551, val_loss=9327.80957\n",
      "Epoch 3701: train_loss=9188.53223, val_loss=9327.42676\n",
      "Epoch 3702: train_loss=9188.16895, val_loss=9327.04297\n",
      "Epoch 3703: train_loss=9187.80664, val_loss=9326.65820\n",
      "Epoch 3704: train_loss=9187.44531, val_loss=9326.27539\n",
      "Epoch 3705: train_loss=9187.08203, val_loss=9325.89062\n",
      "Epoch 3706: train_loss=9186.71875, val_loss=9325.50586\n",
      "Epoch 3707: train_loss=9186.35742, val_loss=9325.12109\n",
      "Epoch 3708: train_loss=9185.99512, val_loss=9324.73730\n",
      "Epoch 3709: train_loss=9185.63281, val_loss=9324.35254\n",
      "Epoch 3710: train_loss=9185.27051, val_loss=9323.96973\n",
      "Epoch 3711: train_loss=9184.90723, val_loss=9323.58496\n",
      "Epoch 3712: train_loss=9184.54688, val_loss=9323.20215\n",
      "Epoch 3713: train_loss=9184.18457, val_loss=9322.81738\n",
      "Epoch 3714: train_loss=9183.82227, val_loss=9322.43555\n",
      "Epoch 3715: train_loss=9183.45996, val_loss=9322.05273\n",
      "Epoch 3716: train_loss=9183.09863, val_loss=9321.66895\n",
      "Epoch 3717: train_loss=9182.73535, val_loss=9321.28613\n",
      "Epoch 3718: train_loss=9182.37402, val_loss=9320.90332\n",
      "Epoch 3719: train_loss=9182.01270, val_loss=9320.52246\n",
      "Epoch 3720: train_loss=9181.65039, val_loss=9320.13965\n",
      "Epoch 3721: train_loss=9181.28809, val_loss=9319.75781\n",
      "Epoch 3722: train_loss=9180.92676, val_loss=9319.37793\n",
      "Epoch 3723: train_loss=9180.56543, val_loss=9318.99609\n",
      "Epoch 3724: train_loss=9180.20312, val_loss=9318.61621\n",
      "Epoch 3725: train_loss=9179.84082, val_loss=9318.23535\n",
      "Epoch 3726: train_loss=9179.47949, val_loss=9317.85449\n",
      "Epoch 3727: train_loss=9179.11719, val_loss=9317.47266\n",
      "Epoch 3728: train_loss=9178.75488, val_loss=9317.09180\n",
      "Epoch 3729: train_loss=9178.39355, val_loss=9316.71094\n",
      "Epoch 3730: train_loss=9178.03125, val_loss=9316.32910\n",
      "Epoch 3731: train_loss=9177.66992, val_loss=9315.94922\n",
      "Epoch 3732: train_loss=9177.30762, val_loss=9315.56738\n",
      "Epoch 3733: train_loss=9176.94629, val_loss=9315.18652\n",
      "Epoch 3734: train_loss=9176.58594, val_loss=9314.80566\n",
      "Epoch 3735: train_loss=9176.22363, val_loss=9314.42480\n",
      "Epoch 3736: train_loss=9175.86133, val_loss=9314.04395\n",
      "Epoch 3737: train_loss=9175.50000, val_loss=9313.66113\n",
      "Epoch 3738: train_loss=9175.13965, val_loss=9313.28027\n",
      "Epoch 3739: train_loss=9174.77734, val_loss=9312.89746\n",
      "Epoch 3740: train_loss=9174.41602, val_loss=9312.51660\n",
      "Epoch 3741: train_loss=9174.05566, val_loss=9312.13574\n",
      "Epoch 3742: train_loss=9173.69336, val_loss=9311.75488\n",
      "Epoch 3743: train_loss=9173.33203, val_loss=9311.37402\n",
      "Epoch 3744: train_loss=9172.97070, val_loss=9310.99121\n",
      "Epoch 3745: train_loss=9172.60840, val_loss=9310.60840\n",
      "Epoch 3746: train_loss=9172.24609, val_loss=9310.22656\n",
      "Epoch 3747: train_loss=9171.88477, val_loss=9309.84277\n",
      "Epoch 3748: train_loss=9171.52246, val_loss=9309.46094\n",
      "Epoch 3749: train_loss=9171.16211, val_loss=9309.08105\n",
      "Epoch 3750: train_loss=9170.79883, val_loss=9308.69922\n",
      "Epoch 3751: train_loss=9170.43750, val_loss=9308.31934\n",
      "Epoch 3752: train_loss=9170.07715, val_loss=9307.93945\n",
      "Epoch 3753: train_loss=9169.71680, val_loss=9307.56152\n",
      "Epoch 3754: train_loss=9169.35645, val_loss=9307.18359\n",
      "Epoch 3755: train_loss=9168.99316, val_loss=9306.80762\n",
      "Epoch 3756: train_loss=9168.63184, val_loss=9306.43164\n",
      "Epoch 3757: train_loss=9168.27051, val_loss=9306.05664\n",
      "Epoch 3758: train_loss=9167.90820, val_loss=9305.68262\n",
      "Epoch 3759: train_loss=9167.54980, val_loss=9305.30664\n",
      "Epoch 3760: train_loss=9167.18945, val_loss=9304.92773\n",
      "Epoch 3761: train_loss=9166.82910, val_loss=9304.54883\n",
      "Epoch 3762: train_loss=9166.46680, val_loss=9304.16797\n",
      "Epoch 3763: train_loss=9166.10645, val_loss=9303.78711\n",
      "Epoch 3764: train_loss=9165.74414, val_loss=9303.40430\n",
      "Epoch 3765: train_loss=9165.38379, val_loss=9303.02344\n",
      "Epoch 3766: train_loss=9165.02246, val_loss=9302.64551\n",
      "Epoch 3767: train_loss=9164.66211, val_loss=9302.26660\n",
      "Epoch 3768: train_loss=9164.30273, val_loss=9301.88672\n",
      "Epoch 3769: train_loss=9163.94141, val_loss=9301.50781\n",
      "Epoch 3770: train_loss=9163.58008, val_loss=9301.12988\n",
      "Epoch 3771: train_loss=9163.21875, val_loss=9300.75391\n",
      "Epoch 3772: train_loss=9162.85840, val_loss=9300.37598\n",
      "Epoch 3773: train_loss=9162.49805, val_loss=9299.99902\n",
      "Epoch 3774: train_loss=9162.13770, val_loss=9299.62207\n",
      "Epoch 3775: train_loss=9161.77734, val_loss=9299.24219\n",
      "Epoch 3776: train_loss=9161.41699, val_loss=9298.86523\n",
      "Epoch 3777: train_loss=9161.05664, val_loss=9298.48730\n",
      "Epoch 3778: train_loss=9160.69727, val_loss=9298.10938\n",
      "Epoch 3779: train_loss=9160.33691, val_loss=9297.73145\n",
      "Epoch 3780: train_loss=9159.97656, val_loss=9297.35547\n",
      "Epoch 3781: train_loss=9159.61719, val_loss=9296.98047\n",
      "Epoch 3782: train_loss=9159.25684, val_loss=9296.60449\n",
      "Epoch 3783: train_loss=9158.89648, val_loss=9296.22852\n",
      "Epoch 3784: train_loss=9158.53809, val_loss=9295.85352\n",
      "Epoch 3785: train_loss=9158.17773, val_loss=9295.47754\n",
      "Epoch 3786: train_loss=9157.81738, val_loss=9295.10254\n",
      "Epoch 3787: train_loss=9157.45801, val_loss=9294.72656\n",
      "Epoch 3788: train_loss=9157.09668, val_loss=9294.35059\n",
      "Epoch 3789: train_loss=9156.73730, val_loss=9293.97559\n",
      "Epoch 3790: train_loss=9156.37793, val_loss=9293.60059\n",
      "Epoch 3791: train_loss=9156.01758, val_loss=9293.22461\n",
      "Epoch 3792: train_loss=9155.65820, val_loss=9292.84863\n",
      "Epoch 3793: train_loss=9155.29688, val_loss=9292.47363\n",
      "Epoch 3794: train_loss=9154.93750, val_loss=9292.09863\n",
      "Epoch 3795: train_loss=9154.57715, val_loss=9291.72363\n",
      "Epoch 3796: train_loss=9154.21680, val_loss=9291.34961\n",
      "Epoch 3797: train_loss=9153.85742, val_loss=9290.97363\n",
      "Epoch 3798: train_loss=9153.49805, val_loss=9290.59863\n",
      "Epoch 3799: train_loss=9153.13770, val_loss=9290.22168\n",
      "Epoch 3800: train_loss=9152.77832, val_loss=9289.84570\n",
      "Epoch 3801: train_loss=9152.41797, val_loss=9289.47168\n",
      "Epoch 3802: train_loss=9152.05762, val_loss=9289.09473\n",
      "Epoch 3803: train_loss=9151.69727, val_loss=9288.71680\n",
      "Epoch 3804: train_loss=9151.33789, val_loss=9288.34180\n",
      "Epoch 3805: train_loss=9150.97754, val_loss=9287.96582\n",
      "Epoch 3806: train_loss=9150.61719, val_loss=9287.59082\n",
      "Epoch 3807: train_loss=9150.25781, val_loss=9287.21387\n",
      "Epoch 3808: train_loss=9149.89746, val_loss=9286.83691\n",
      "Epoch 3809: train_loss=9149.53711, val_loss=9286.46191\n",
      "Epoch 3810: train_loss=9149.17773, val_loss=9286.08594\n",
      "Epoch 3811: train_loss=9148.81738, val_loss=9285.70996\n",
      "Epoch 3812: train_loss=9148.45801, val_loss=9285.33496\n",
      "Epoch 3813: train_loss=9148.09570, val_loss=9284.95898\n",
      "Epoch 3814: train_loss=9147.73633, val_loss=9284.58301\n",
      "Epoch 3815: train_loss=9147.37598, val_loss=9284.20801\n",
      "Epoch 3816: train_loss=9147.01660, val_loss=9283.83203\n",
      "Epoch 3817: train_loss=9146.65625, val_loss=9283.45898\n",
      "Epoch 3818: train_loss=9146.29590, val_loss=9283.08301\n",
      "Epoch 3819: train_loss=9145.93652, val_loss=9282.70801\n",
      "Epoch 3820: train_loss=9145.57520, val_loss=9282.33301\n",
      "Epoch 3821: train_loss=9145.21680, val_loss=9281.95703\n",
      "Epoch 3822: train_loss=9144.85645, val_loss=9281.58105\n",
      "Epoch 3823: train_loss=9144.49609, val_loss=9281.20703\n",
      "Epoch 3824: train_loss=9144.13672, val_loss=9280.83105\n",
      "Epoch 3825: train_loss=9143.77637, val_loss=9280.45410\n",
      "Epoch 3826: train_loss=9143.41602, val_loss=9280.07812\n",
      "Epoch 3827: train_loss=9143.05664, val_loss=9279.70410\n",
      "Epoch 3828: train_loss=9142.69629, val_loss=9279.32812\n",
      "Epoch 3829: train_loss=9142.33594, val_loss=9278.95312\n",
      "Epoch 3830: train_loss=9141.97754, val_loss=9278.57715\n",
      "Epoch 3831: train_loss=9141.61621, val_loss=9278.20215\n",
      "Epoch 3832: train_loss=9141.25586, val_loss=9277.82617\n",
      "Epoch 3833: train_loss=9140.89648, val_loss=9277.44922\n",
      "Epoch 3834: train_loss=9140.53613, val_loss=9277.07324\n",
      "Epoch 3835: train_loss=9140.17676, val_loss=9276.69727\n",
      "Epoch 3836: train_loss=9139.81543, val_loss=9276.31934\n",
      "Epoch 3837: train_loss=9139.45508, val_loss=9275.94336\n",
      "Epoch 3838: train_loss=9139.09570, val_loss=9275.56641\n",
      "Epoch 3839: train_loss=9138.73535, val_loss=9275.18848\n",
      "Epoch 3840: train_loss=9138.37500, val_loss=9274.81055\n",
      "Epoch 3841: train_loss=9138.01562, val_loss=9274.43555\n",
      "Epoch 3842: train_loss=9137.65527, val_loss=9274.06152\n",
      "Epoch 3843: train_loss=9137.29492, val_loss=9273.68750\n",
      "Epoch 3844: train_loss=9136.93359, val_loss=9273.31250\n",
      "Epoch 3845: train_loss=9136.57422, val_loss=9272.93750\n",
      "Epoch 3846: train_loss=9136.21387, val_loss=9272.56348\n",
      "Epoch 3847: train_loss=9135.85449, val_loss=9272.18848\n",
      "Epoch 3848: train_loss=9135.49414, val_loss=9271.81348\n",
      "Epoch 3849: train_loss=9135.13379, val_loss=9271.43555\n",
      "Epoch 3850: train_loss=9134.77246, val_loss=9271.05859\n",
      "Epoch 3851: train_loss=9134.41406, val_loss=9270.68066\n",
      "Epoch 3852: train_loss=9134.05371, val_loss=9270.30469\n",
      "Epoch 3853: train_loss=9133.69434, val_loss=9269.93066\n",
      "Epoch 3854: train_loss=9133.33398, val_loss=9269.55664\n",
      "Epoch 3855: train_loss=9132.97461, val_loss=9269.17969\n",
      "Epoch 3856: train_loss=9132.61328, val_loss=9268.80371\n",
      "Epoch 3857: train_loss=9132.25391, val_loss=9268.42871\n",
      "Epoch 3858: train_loss=9131.89258, val_loss=9268.05566\n",
      "Epoch 3859: train_loss=9131.53320, val_loss=9267.67969\n",
      "Epoch 3860: train_loss=9131.17383, val_loss=9267.30273\n",
      "Epoch 3861: train_loss=9130.81250, val_loss=9266.92676\n",
      "Epoch 3862: train_loss=9130.45312, val_loss=9266.55078\n",
      "Epoch 3863: train_loss=9130.09277, val_loss=9266.17480\n",
      "Epoch 3864: train_loss=9129.73340, val_loss=9265.79980\n",
      "Epoch 3865: train_loss=9129.37305, val_loss=9265.42285\n",
      "Epoch 3866: train_loss=9129.01270, val_loss=9265.04785\n",
      "Epoch 3867: train_loss=9128.65332, val_loss=9264.67090\n",
      "Epoch 3868: train_loss=9128.29395, val_loss=9264.29785\n",
      "Epoch 3869: train_loss=9127.93359, val_loss=9263.92188\n",
      "Epoch 3870: train_loss=9127.57324, val_loss=9263.54492\n",
      "Epoch 3871: train_loss=9127.21289, val_loss=9263.16797\n",
      "Epoch 3872: train_loss=9126.85254, val_loss=9262.79199\n",
      "Epoch 3873: train_loss=9126.49219, val_loss=9262.41797\n",
      "Epoch 3874: train_loss=9126.13281, val_loss=9262.04199\n",
      "Epoch 3875: train_loss=9125.77246, val_loss=9261.66406\n",
      "Epoch 3876: train_loss=9125.41211, val_loss=9261.28809\n",
      "Epoch 3877: train_loss=9125.05078, val_loss=9260.91309\n",
      "Epoch 3878: train_loss=9124.69238, val_loss=9260.53809\n",
      "Epoch 3879: train_loss=9124.33105, val_loss=9260.16016\n",
      "Epoch 3880: train_loss=9123.97168, val_loss=9259.78320\n",
      "Epoch 3881: train_loss=9123.61133, val_loss=9259.40723\n",
      "Epoch 3882: train_loss=9123.25098, val_loss=9259.03320\n",
      "Epoch 3883: train_loss=9122.89062, val_loss=9258.65625\n",
      "Epoch 3884: train_loss=9122.53027, val_loss=9258.28027\n",
      "Epoch 3885: train_loss=9122.17090, val_loss=9257.90234\n",
      "Epoch 3886: train_loss=9121.80957, val_loss=9257.52734\n",
      "Epoch 3887: train_loss=9121.45020, val_loss=9257.14941\n",
      "Epoch 3888: train_loss=9121.08789, val_loss=9256.77344\n",
      "Epoch 3889: train_loss=9120.72949, val_loss=9256.39746\n",
      "Epoch 3890: train_loss=9120.36914, val_loss=9256.02051\n",
      "Epoch 3891: train_loss=9120.00879, val_loss=9255.64355\n",
      "Epoch 3892: train_loss=9119.64941, val_loss=9255.26855\n",
      "Epoch 3893: train_loss=9119.28809, val_loss=9254.89453\n",
      "Epoch 3894: train_loss=9118.92773, val_loss=9254.51660\n",
      "Epoch 3895: train_loss=9118.56641, val_loss=9254.14062\n",
      "Epoch 3896: train_loss=9118.20703, val_loss=9253.76367\n",
      "Epoch 3897: train_loss=9117.84668, val_loss=9253.38672\n",
      "Epoch 3898: train_loss=9117.48633, val_loss=9253.01172\n",
      "Epoch 3899: train_loss=9117.12793, val_loss=9252.63672\n",
      "Epoch 3900: train_loss=9116.76660, val_loss=9252.26074\n",
      "Epoch 3901: train_loss=9116.40527, val_loss=9251.88574\n",
      "Epoch 3902: train_loss=9116.04590, val_loss=9251.51074\n",
      "Epoch 3903: train_loss=9115.68457, val_loss=9251.13574\n",
      "Epoch 3904: train_loss=9115.32520, val_loss=9250.75879\n",
      "Epoch 3905: train_loss=9114.96582, val_loss=9250.38379\n",
      "Epoch 3906: train_loss=9114.60547, val_loss=9250.00879\n",
      "Epoch 3907: train_loss=9114.24414, val_loss=9249.63477\n",
      "Epoch 3908: train_loss=9113.88379, val_loss=9249.26074\n",
      "Epoch 3909: train_loss=9113.52441, val_loss=9248.88477\n",
      "Epoch 3910: train_loss=9113.16406, val_loss=9248.50781\n",
      "Epoch 3911: train_loss=9112.80371, val_loss=9248.13281\n",
      "Epoch 3912: train_loss=9112.44238, val_loss=9247.75879\n",
      "Epoch 3913: train_loss=9112.08203, val_loss=9247.38672\n",
      "Epoch 3914: train_loss=9111.72168, val_loss=9247.01074\n",
      "Epoch 3915: train_loss=9111.36133, val_loss=9246.63379\n",
      "Epoch 3916: train_loss=9111.00098, val_loss=9246.25781\n",
      "Epoch 3917: train_loss=9110.63965, val_loss=9245.88281\n",
      "Epoch 3918: train_loss=9110.28027, val_loss=9245.51074\n",
      "Epoch 3919: train_loss=9109.91895, val_loss=9245.13574\n",
      "Epoch 3920: train_loss=9109.55762, val_loss=9244.76074\n",
      "Epoch 3921: train_loss=9109.19727, val_loss=9244.38574\n",
      "Epoch 3922: train_loss=9108.83691, val_loss=9244.01074\n",
      "Epoch 3923: train_loss=9108.47656, val_loss=9243.63574\n",
      "Epoch 3924: train_loss=9108.11523, val_loss=9243.26172\n",
      "Epoch 3925: train_loss=9107.75391, val_loss=9242.88770\n",
      "Epoch 3926: train_loss=9107.39355, val_loss=9242.51465\n",
      "Epoch 3927: train_loss=9107.03320, val_loss=9242.13965\n",
      "Epoch 3928: train_loss=9106.67188, val_loss=9241.76465\n",
      "Epoch 3929: train_loss=9106.31055, val_loss=9241.38965\n",
      "Epoch 3930: train_loss=9105.95117, val_loss=9241.01562\n",
      "Epoch 3931: train_loss=9105.58984, val_loss=9240.64062\n",
      "Epoch 3932: train_loss=9105.22852, val_loss=9240.26562\n",
      "Epoch 3933: train_loss=9104.86914, val_loss=9239.89062\n",
      "Epoch 3934: train_loss=9104.50879, val_loss=9239.51465\n",
      "Epoch 3935: train_loss=9104.14746, val_loss=9239.14062\n",
      "Epoch 3936: train_loss=9103.78809, val_loss=9238.76660\n",
      "Epoch 3937: train_loss=9103.42676, val_loss=9238.39355\n",
      "Epoch 3938: train_loss=9103.06641, val_loss=9238.01953\n",
      "Epoch 3939: train_loss=9102.70508, val_loss=9237.64551\n",
      "Epoch 3940: train_loss=9102.34570, val_loss=9237.27148\n",
      "Epoch 3941: train_loss=9101.98438, val_loss=9236.89746\n",
      "Epoch 3942: train_loss=9101.62500, val_loss=9236.52344\n",
      "Epoch 3943: train_loss=9101.26465, val_loss=9236.15039\n",
      "Epoch 3944: train_loss=9100.90430, val_loss=9235.77734\n",
      "Epoch 3945: train_loss=9100.54395, val_loss=9235.40430\n",
      "Epoch 3946: train_loss=9100.18359, val_loss=9235.02930\n",
      "Epoch 3947: train_loss=9099.82324, val_loss=9234.65430\n",
      "Epoch 3948: train_loss=9099.46289, val_loss=9234.28125\n",
      "Epoch 3949: train_loss=9099.10156, val_loss=9233.90918\n",
      "Epoch 3950: train_loss=9098.74121, val_loss=9233.53516\n",
      "Epoch 3951: train_loss=9098.38184, val_loss=9233.16113\n",
      "Epoch 3952: train_loss=9098.02246, val_loss=9232.78516\n",
      "Epoch 3953: train_loss=9097.66016, val_loss=9232.41309\n",
      "Epoch 3954: train_loss=9097.30078, val_loss=9232.04004\n",
      "Epoch 3955: train_loss=9096.94043, val_loss=9231.66699\n",
      "Epoch 3956: train_loss=9096.58105, val_loss=9231.29395\n",
      "Epoch 3957: train_loss=9096.22168, val_loss=9230.91895\n",
      "Epoch 3958: train_loss=9095.85840, val_loss=9230.54688\n",
      "Epoch 3959: train_loss=9095.50098, val_loss=9230.17285\n",
      "Epoch 3960: train_loss=9095.13867, val_loss=9229.80078\n",
      "Epoch 3961: train_loss=9094.77832, val_loss=9229.42773\n",
      "Epoch 3962: train_loss=9094.41797, val_loss=9229.05371\n",
      "Epoch 3963: train_loss=9094.05762, val_loss=9228.67969\n",
      "Epoch 3964: train_loss=9093.69629, val_loss=9228.30469\n",
      "Epoch 3965: train_loss=9093.33691, val_loss=9227.93262\n",
      "Epoch 3966: train_loss=9092.97656, val_loss=9227.56055\n",
      "Epoch 3967: train_loss=9092.61621, val_loss=9227.18750\n",
      "Epoch 3968: train_loss=9092.25488, val_loss=9226.81250\n",
      "Epoch 3969: train_loss=9091.89551, val_loss=9226.43750\n",
      "Epoch 3970: train_loss=9091.53418, val_loss=9226.06348\n",
      "Epoch 3971: train_loss=9091.17480, val_loss=9225.68945\n",
      "Epoch 3972: train_loss=9090.81348, val_loss=9225.31641\n",
      "Epoch 3973: train_loss=9090.45215, val_loss=9224.94336\n",
      "Epoch 3974: train_loss=9090.09277, val_loss=9224.57031\n",
      "Epoch 3975: train_loss=9089.73242, val_loss=9224.19434\n",
      "Epoch 3976: train_loss=9089.37109, val_loss=9223.81934\n",
      "Epoch 3977: train_loss=9089.01172, val_loss=9223.44629\n",
      "Epoch 3978: train_loss=9088.65039, val_loss=9223.07227\n",
      "Epoch 3979: train_loss=9088.29004, val_loss=9222.69824\n",
      "Epoch 3980: train_loss=9087.92871, val_loss=9222.32422\n",
      "Epoch 3981: train_loss=9087.56836, val_loss=9221.94922\n",
      "Epoch 3982: train_loss=9087.20801, val_loss=9221.57324\n",
      "Epoch 3983: train_loss=9086.84668, val_loss=9221.19824\n",
      "Epoch 3984: train_loss=9086.48730, val_loss=9220.82324\n",
      "Epoch 3985: train_loss=9086.12695, val_loss=9220.44922\n",
      "Epoch 3986: train_loss=9085.76367, val_loss=9220.07422\n",
      "Epoch 3987: train_loss=9085.40527, val_loss=9219.69531\n",
      "Epoch 3988: train_loss=9085.04297, val_loss=9219.32031\n",
      "Epoch 3989: train_loss=9084.68262, val_loss=9218.94434\n",
      "Epoch 3990: train_loss=9084.32129, val_loss=9218.57031\n",
      "Epoch 3991: train_loss=9083.95996, val_loss=9218.19434\n",
      "Epoch 3992: train_loss=9083.59961, val_loss=9217.81836\n",
      "Epoch 3993: train_loss=9083.23828, val_loss=9217.44238\n",
      "Epoch 3994: train_loss=9082.87695, val_loss=9217.06934\n",
      "Epoch 3995: train_loss=9082.51562, val_loss=9216.69238\n",
      "Epoch 3996: train_loss=9082.15430, val_loss=9216.31641\n",
      "Epoch 3997: train_loss=9081.79395, val_loss=9215.93945\n",
      "Epoch 3998: train_loss=9081.43164, val_loss=9215.56543\n",
      "Epoch 3999: train_loss=9081.07129, val_loss=9215.18945\n",
      "Epoch 4000: train_loss=9080.71094, val_loss=9214.81348\n",
      "Epoch 4001: train_loss=9080.34863, val_loss=9214.43750\n",
      "Epoch 4002: train_loss=9079.98828, val_loss=9214.06250\n",
      "Epoch 4003: train_loss=9079.62695, val_loss=9213.68555\n",
      "Epoch 4004: train_loss=9079.26465, val_loss=9213.30957\n",
      "Epoch 4005: train_loss=9078.90430, val_loss=9212.93457\n",
      "Epoch 4006: train_loss=9078.54297, val_loss=9212.56055\n",
      "Epoch 4007: train_loss=9078.18262, val_loss=9212.18359\n",
      "Epoch 4008: train_loss=9077.82031, val_loss=9211.80762\n",
      "Epoch 4009: train_loss=9077.45898, val_loss=9211.43262\n",
      "Epoch 4010: train_loss=9077.09766, val_loss=9211.05859\n",
      "Epoch 4011: train_loss=9076.73633, val_loss=9210.68164\n",
      "Epoch 4012: train_loss=9076.37305, val_loss=9210.30566\n",
      "Epoch 4013: train_loss=9076.01270, val_loss=9209.92969\n",
      "Epoch 4014: train_loss=9075.65137, val_loss=9209.55469\n",
      "Epoch 4015: train_loss=9075.29004, val_loss=9209.17676\n",
      "Epoch 4016: train_loss=9074.92676, val_loss=9208.80176\n",
      "Epoch 4017: train_loss=9074.56641, val_loss=9208.42578\n",
      "Epoch 4018: train_loss=9074.20312, val_loss=9208.04980\n",
      "Epoch 4019: train_loss=9073.84180, val_loss=9207.67090\n",
      "Epoch 4020: train_loss=9073.48047, val_loss=9207.29492\n",
      "Epoch 4021: train_loss=9073.11816, val_loss=9206.91992\n",
      "Epoch 4022: train_loss=9072.75586, val_loss=9206.54395\n",
      "Epoch 4023: train_loss=9072.39453, val_loss=9206.16699\n",
      "Epoch 4024: train_loss=9072.03223, val_loss=9205.78809\n",
      "Epoch 4025: train_loss=9071.66992, val_loss=9205.41113\n",
      "Epoch 4026: train_loss=9071.30664, val_loss=9205.03613\n",
      "Epoch 4027: train_loss=9070.94434, val_loss=9204.65820\n",
      "Epoch 4028: train_loss=9070.58203, val_loss=9204.28125\n",
      "Epoch 4029: train_loss=9070.22070, val_loss=9203.90430\n",
      "Epoch 4030: train_loss=9069.85742, val_loss=9203.52637\n",
      "Epoch 4031: train_loss=9069.49512, val_loss=9203.14746\n",
      "Epoch 4032: train_loss=9069.13184, val_loss=9202.77051\n",
      "Epoch 4033: train_loss=9068.76953, val_loss=9202.39453\n",
      "Epoch 4034: train_loss=9068.40625, val_loss=9202.01758\n",
      "Epoch 4035: train_loss=9068.04395, val_loss=9201.63965\n",
      "Epoch 4036: train_loss=9067.68164, val_loss=9201.26074\n",
      "Epoch 4037: train_loss=9067.31738, val_loss=9200.88184\n",
      "Epoch 4038: train_loss=9066.95605, val_loss=9200.50488\n",
      "Epoch 4039: train_loss=9066.59180, val_loss=9200.12695\n",
      "Epoch 4040: train_loss=9066.22949, val_loss=9199.75000\n",
      "Epoch 4041: train_loss=9065.86621, val_loss=9199.37109\n",
      "Epoch 4042: train_loss=9065.50195, val_loss=9198.99316\n",
      "Epoch 4043: train_loss=9065.13965, val_loss=9198.61621\n",
      "Epoch 4044: train_loss=9064.77637, val_loss=9198.23633\n",
      "Epoch 4045: train_loss=9064.41309, val_loss=9197.85742\n",
      "Epoch 4046: train_loss=9064.04980, val_loss=9197.48047\n",
      "Epoch 4047: train_loss=9063.68555, val_loss=9197.10352\n",
      "Epoch 4048: train_loss=9063.32422, val_loss=9196.72363\n",
      "Epoch 4049: train_loss=9062.95898, val_loss=9196.34277\n",
      "Epoch 4050: train_loss=9062.59570, val_loss=9195.96387\n",
      "Epoch 4051: train_loss=9062.23242, val_loss=9195.58691\n",
      "Epoch 4052: train_loss=9061.86816, val_loss=9195.20898\n",
      "Epoch 4053: train_loss=9061.50293, val_loss=9194.83105\n",
      "Epoch 4054: train_loss=9061.13965, val_loss=9194.45312\n",
      "Epoch 4055: train_loss=9060.77637, val_loss=9194.07324\n",
      "Epoch 4056: train_loss=9060.41211, val_loss=9193.69531\n",
      "Epoch 4057: train_loss=9060.04785, val_loss=9193.31934\n",
      "Epoch 4058: train_loss=9059.68262, val_loss=9192.93945\n",
      "Epoch 4059: train_loss=9059.31836, val_loss=9192.56055\n",
      "Epoch 4060: train_loss=9058.95410, val_loss=9192.18262\n",
      "Epoch 4061: train_loss=9058.58984, val_loss=9191.80469\n",
      "Epoch 4062: train_loss=9058.22559, val_loss=9191.42480\n",
      "Epoch 4063: train_loss=9057.86133, val_loss=9191.04688\n",
      "Epoch 4064: train_loss=9057.49512, val_loss=9190.66602\n",
      "Epoch 4065: train_loss=9057.12988, val_loss=9190.28613\n",
      "Epoch 4066: train_loss=9056.76367, val_loss=9189.90625\n",
      "Epoch 4067: train_loss=9056.39746, val_loss=9189.52637\n",
      "Epoch 4068: train_loss=9056.03223, val_loss=9189.14648\n",
      "Epoch 4069: train_loss=9055.66699, val_loss=9188.76660\n",
      "Epoch 4070: train_loss=9055.30078, val_loss=9188.38770\n",
      "Epoch 4071: train_loss=9054.93555, val_loss=9188.00684\n",
      "Epoch 4072: train_loss=9054.56836, val_loss=9187.62793\n",
      "Epoch 4073: train_loss=9054.20215, val_loss=9187.25000\n",
      "Epoch 4074: train_loss=9053.83691, val_loss=9186.87402\n",
      "Epoch 4075: train_loss=9053.47266, val_loss=9186.49512\n",
      "Epoch 4076: train_loss=9053.10840, val_loss=9186.11719\n",
      "Epoch 4077: train_loss=9052.74512, val_loss=9185.74023\n",
      "Epoch 4078: train_loss=9052.38086, val_loss=9185.36328\n",
      "Epoch 4079: train_loss=9052.01758, val_loss=9184.98633\n",
      "Epoch 4080: train_loss=9051.65332, val_loss=9184.61035\n",
      "Epoch 4081: train_loss=9051.29102, val_loss=9184.23145\n",
      "Epoch 4082: train_loss=9050.92773, val_loss=9183.85156\n",
      "Epoch 4083: train_loss=9050.56348, val_loss=9183.47266\n",
      "Epoch 4084: train_loss=9050.20020, val_loss=9183.09180\n",
      "Epoch 4085: train_loss=9049.83594, val_loss=9182.71094\n",
      "Epoch 4086: train_loss=9049.47168, val_loss=9182.33105\n",
      "Epoch 4087: train_loss=9049.10742, val_loss=9181.95215\n",
      "Epoch 4088: train_loss=9048.74219, val_loss=9181.57031\n",
      "Epoch 4089: train_loss=9048.37793, val_loss=9181.19238\n",
      "Epoch 4090: train_loss=9048.01367, val_loss=9180.81348\n",
      "Epoch 4091: train_loss=9047.65137, val_loss=9180.43359\n",
      "Epoch 4092: train_loss=9047.28711, val_loss=9180.05469\n",
      "Epoch 4093: train_loss=9046.92383, val_loss=9179.67578\n",
      "Epoch 4094: train_loss=9046.56055, val_loss=9179.29590\n",
      "Epoch 4095: train_loss=9046.19629, val_loss=9178.91797\n",
      "Epoch 4096: train_loss=9045.83301, val_loss=9178.54004\n",
      "Epoch 4097: train_loss=9045.46973, val_loss=9178.16309\n",
      "Epoch 4098: train_loss=9045.10645, val_loss=9177.78223\n",
      "Epoch 4099: train_loss=9044.74219, val_loss=9177.40332\n",
      "Epoch 4100: train_loss=9044.37988, val_loss=9177.02344\n",
      "Epoch 4101: train_loss=9044.01562, val_loss=9176.64551\n",
      "Epoch 4102: train_loss=9043.65137, val_loss=9176.26562\n",
      "Epoch 4103: train_loss=9043.28711, val_loss=9175.89062\n",
      "Epoch 4104: train_loss=9042.92383, val_loss=9175.51270\n",
      "Epoch 4105: train_loss=9042.56055, val_loss=9175.13379\n",
      "Epoch 4106: train_loss=9042.19629, val_loss=9174.75488\n",
      "Epoch 4107: train_loss=9041.83203, val_loss=9174.37793\n",
      "Epoch 4108: train_loss=9041.46875, val_loss=9174.00000\n",
      "Epoch 4109: train_loss=9041.10645, val_loss=9173.62109\n",
      "Epoch 4110: train_loss=9040.74219, val_loss=9173.24219\n",
      "Epoch 4111: train_loss=9040.37891, val_loss=9172.86426\n",
      "Epoch 4112: train_loss=9040.01660, val_loss=9172.48730\n",
      "Epoch 4113: train_loss=9039.65234, val_loss=9172.11035\n",
      "Epoch 4114: train_loss=9039.29004, val_loss=9171.73340\n",
      "Epoch 4115: train_loss=9038.92676, val_loss=9171.35352\n",
      "Epoch 4116: train_loss=9038.56445, val_loss=9170.97461\n",
      "Epoch 4117: train_loss=9038.20020, val_loss=9170.59668\n",
      "Epoch 4118: train_loss=9037.83789, val_loss=9170.22070\n",
      "Epoch 4119: train_loss=9037.47363, val_loss=9169.84180\n",
      "Epoch 4120: train_loss=9037.11133, val_loss=9169.46191\n",
      "Epoch 4121: train_loss=9036.74805, val_loss=9169.08301\n",
      "Epoch 4122: train_loss=9036.38574, val_loss=9168.70312\n",
      "Epoch 4123: train_loss=9036.02148, val_loss=9168.32520\n",
      "Epoch 4124: train_loss=9035.65820, val_loss=9167.94629\n",
      "Epoch 4125: train_loss=9035.29590, val_loss=9167.56738\n",
      "Epoch 4126: train_loss=9034.93262, val_loss=9167.18750\n",
      "Epoch 4127: train_loss=9034.56934, val_loss=9166.80859\n",
      "Epoch 4128: train_loss=9034.20605, val_loss=9166.43164\n",
      "Epoch 4129: train_loss=9033.84375, val_loss=9166.05078\n",
      "Epoch 4130: train_loss=9033.47949, val_loss=9165.66992\n",
      "Epoch 4131: train_loss=9033.11719, val_loss=9165.29102\n",
      "Epoch 4132: train_loss=9032.75391, val_loss=9164.91211\n",
      "Epoch 4133: train_loss=9032.38965, val_loss=9164.53223\n",
      "Epoch 4134: train_loss=9032.02734, val_loss=9164.15527\n",
      "Epoch 4135: train_loss=9031.66309, val_loss=9163.77637\n",
      "Epoch 4136: train_loss=9031.30078, val_loss=9163.39453\n",
      "Epoch 4137: train_loss=9030.93555, val_loss=9163.01660\n",
      "Epoch 4138: train_loss=9030.57324, val_loss=9162.63672\n",
      "Epoch 4139: train_loss=9030.20898, val_loss=9162.25977\n",
      "Epoch 4140: train_loss=9029.84668, val_loss=9161.87988\n",
      "Epoch 4141: train_loss=9029.48242, val_loss=9161.50000\n",
      "Epoch 4142: train_loss=9029.12012, val_loss=9161.12207\n",
      "Epoch 4143: train_loss=9028.75586, val_loss=9160.74414\n",
      "Epoch 4144: train_loss=9028.39258, val_loss=9160.36426\n",
      "Epoch 4145: train_loss=9028.02832, val_loss=9159.98926\n",
      "Epoch 4146: train_loss=9027.66602, val_loss=9159.61035\n",
      "Epoch 4147: train_loss=9027.30176, val_loss=9159.22949\n",
      "Epoch 4148: train_loss=9026.93750, val_loss=9158.85059\n",
      "Epoch 4149: train_loss=9026.57422, val_loss=9158.47168\n",
      "Epoch 4150: train_loss=9026.21191, val_loss=9158.09277\n",
      "Epoch 4151: train_loss=9025.84766, val_loss=9157.71777\n",
      "Epoch 4152: train_loss=9025.48438, val_loss=9157.33789\n",
      "Epoch 4153: train_loss=9025.12012, val_loss=9156.95605\n",
      "Epoch 4154: train_loss=9024.75488, val_loss=9156.57324\n",
      "Epoch 4155: train_loss=9024.38867, val_loss=9156.18750\n",
      "Epoch 4156: train_loss=9024.02051, val_loss=9155.79883\n",
      "Epoch 4157: train_loss=9023.64551, val_loss=9155.40723\n",
      "Epoch 4158: train_loss=9023.27344, val_loss=9155.01074\n",
      "Epoch 4159: train_loss=9022.90039, val_loss=9154.62109\n",
      "Epoch 4160: train_loss=9022.52832, val_loss=9154.23535\n",
      "Epoch 4161: train_loss=9022.15820, val_loss=9153.85449\n",
      "Epoch 4162: train_loss=9021.79395, val_loss=9153.47852\n",
      "Epoch 4163: train_loss=9021.43359, val_loss=9153.10156\n",
      "Epoch 4164: train_loss=9021.07129, val_loss=9152.72559\n",
      "Epoch 4165: train_loss=9020.70996, val_loss=9152.34961\n",
      "Epoch 4166: train_loss=9020.34766, val_loss=9151.97168\n",
      "Epoch 4167: train_loss=9019.98535, val_loss=9151.59375\n",
      "Epoch 4168: train_loss=9019.62109, val_loss=9151.21582\n",
      "Epoch 4169: train_loss=9019.25781, val_loss=9150.83594\n",
      "Epoch 4170: train_loss=9018.89258, val_loss=9150.45508\n",
      "Epoch 4171: train_loss=9018.52734, val_loss=9150.07520\n",
      "Epoch 4172: train_loss=9018.16113, val_loss=9149.69531\n",
      "Epoch 4173: train_loss=9017.79688, val_loss=9149.31445\n",
      "Epoch 4174: train_loss=9017.42969, val_loss=9148.93262\n",
      "Epoch 4175: train_loss=9017.06543, val_loss=9148.55176\n",
      "Epoch 4176: train_loss=9016.69824, val_loss=9148.17090\n",
      "Epoch 4177: train_loss=9016.33301, val_loss=9147.79492\n",
      "Epoch 4178: train_loss=9015.96875, val_loss=9147.41504\n",
      "Epoch 4179: train_loss=9015.60352, val_loss=9147.03320\n",
      "Epoch 4180: train_loss=9015.23926, val_loss=9146.65625\n",
      "Epoch 4181: train_loss=9014.87598, val_loss=9146.27832\n",
      "Epoch 4182: train_loss=9014.51172, val_loss=9145.90137\n",
      "Epoch 4183: train_loss=9014.14844, val_loss=9145.52246\n",
      "Epoch 4184: train_loss=9013.78418, val_loss=9145.14062\n",
      "Epoch 4185: train_loss=9013.41895, val_loss=9144.76074\n",
      "Epoch 4186: train_loss=9013.05371, val_loss=9144.37988\n",
      "Epoch 4187: train_loss=9012.68848, val_loss=9144.00000\n",
      "Epoch 4188: train_loss=9012.32324, val_loss=9143.61816\n",
      "Epoch 4189: train_loss=9011.95898, val_loss=9143.23926\n",
      "Epoch 4190: train_loss=9011.59473, val_loss=9142.86035\n",
      "Epoch 4191: train_loss=9011.22949, val_loss=9142.48047\n",
      "Epoch 4192: train_loss=9010.86426, val_loss=9142.10059\n",
      "Epoch 4193: train_loss=9010.49902, val_loss=9141.72070\n",
      "Epoch 4194: train_loss=9010.13477, val_loss=9141.34180\n",
      "Epoch 4195: train_loss=9009.76953, val_loss=9140.96191\n",
      "Epoch 4196: train_loss=9009.40430, val_loss=9140.58203\n",
      "Epoch 4197: train_loss=9009.03809, val_loss=9140.20117\n",
      "Epoch 4198: train_loss=9008.67383, val_loss=9139.82227\n",
      "Epoch 4199: train_loss=9008.30762, val_loss=9139.44141\n",
      "Epoch 4200: train_loss=9007.94141, val_loss=9139.06055\n",
      "Epoch 4201: train_loss=9007.57715, val_loss=9138.68164\n",
      "Epoch 4202: train_loss=9007.21094, val_loss=9138.30273\n",
      "Epoch 4203: train_loss=9006.84570, val_loss=9137.92188\n",
      "Epoch 4204: train_loss=9006.48047, val_loss=9137.54102\n",
      "Epoch 4205: train_loss=9006.11328, val_loss=9137.16113\n",
      "Epoch 4206: train_loss=9005.74902, val_loss=9136.78125\n",
      "Epoch 4207: train_loss=9005.38184, val_loss=9136.40039\n",
      "Epoch 4208: train_loss=9005.01562, val_loss=9136.02051\n",
      "Epoch 4209: train_loss=9004.65039, val_loss=9135.64062\n",
      "Epoch 4210: train_loss=9004.28516, val_loss=9135.25977\n",
      "Epoch 4211: train_loss=9003.91992, val_loss=9134.88184\n",
      "Epoch 4212: train_loss=9003.55566, val_loss=9134.50000\n",
      "Epoch 4213: train_loss=9003.19043, val_loss=9134.11914\n",
      "Epoch 4214: train_loss=9002.82422, val_loss=9133.73828\n",
      "Epoch 4215: train_loss=9002.45898, val_loss=9133.35742\n",
      "Epoch 4216: train_loss=9002.09277, val_loss=9132.97949\n",
      "Epoch 4217: train_loss=9001.72754, val_loss=9132.59863\n",
      "Epoch 4218: train_loss=9001.36230, val_loss=9132.21680\n",
      "Epoch 4219: train_loss=9000.99609, val_loss=9131.83594\n",
      "Epoch 4220: train_loss=9000.62988, val_loss=9131.45508\n",
      "Epoch 4221: train_loss=9000.26465, val_loss=9131.07422\n",
      "Epoch 4222: train_loss=8999.89844, val_loss=9130.69336\n",
      "Epoch 4223: train_loss=8999.53125, val_loss=9130.31250\n",
      "Epoch 4224: train_loss=8999.16602, val_loss=9129.93262\n",
      "Epoch 4225: train_loss=8998.79980, val_loss=9129.55078\n",
      "Epoch 4226: train_loss=8998.43457, val_loss=9129.16992\n",
      "Epoch 4227: train_loss=8998.06836, val_loss=9128.78906\n",
      "Epoch 4228: train_loss=8997.70312, val_loss=9128.40918\n",
      "Epoch 4229: train_loss=8997.33594, val_loss=9128.02734\n",
      "Epoch 4230: train_loss=8996.97168, val_loss=9127.64551\n",
      "Epoch 4231: train_loss=8996.60547, val_loss=9127.26465\n",
      "Epoch 4232: train_loss=8996.24121, val_loss=9126.88477\n",
      "Epoch 4233: train_loss=8995.87500, val_loss=9126.50391\n",
      "Epoch 4234: train_loss=8995.50879, val_loss=9126.12109\n",
      "Epoch 4235: train_loss=8995.14258, val_loss=9125.74023\n",
      "Epoch 4236: train_loss=8994.77832, val_loss=9125.35938\n",
      "Epoch 4237: train_loss=8994.41309, val_loss=9124.97656\n",
      "Epoch 4238: train_loss=8994.04590, val_loss=9124.59668\n",
      "Epoch 4239: train_loss=8993.67969, val_loss=9124.21387\n",
      "Epoch 4240: train_loss=8993.31348, val_loss=9123.83203\n",
      "Epoch 4241: train_loss=8992.94824, val_loss=9123.45215\n",
      "Epoch 4242: train_loss=8992.58203, val_loss=9123.06934\n",
      "Epoch 4243: train_loss=8992.21484, val_loss=9122.68652\n",
      "Epoch 4244: train_loss=8991.84961, val_loss=9122.30566\n",
      "Epoch 4245: train_loss=8991.48340, val_loss=9121.92676\n",
      "Epoch 4246: train_loss=8991.11621, val_loss=9121.54395\n",
      "Epoch 4247: train_loss=8990.75098, val_loss=9121.16113\n",
      "Epoch 4248: train_loss=8990.38477, val_loss=9120.77930\n",
      "Epoch 4249: train_loss=8990.01855, val_loss=9120.39746\n",
      "Epoch 4250: train_loss=8989.65137, val_loss=9120.01465\n",
      "Epoch 4251: train_loss=8989.28613, val_loss=9119.63477\n",
      "Epoch 4252: train_loss=8988.92090, val_loss=9119.25488\n",
      "Epoch 4253: train_loss=8988.55469, val_loss=9118.87207\n",
      "Epoch 4254: train_loss=8988.18750, val_loss=9118.49023\n",
      "Epoch 4255: train_loss=8987.82129, val_loss=9118.11035\n",
      "Epoch 4256: train_loss=8987.45605, val_loss=9117.72754\n",
      "Epoch 4257: train_loss=8987.08887, val_loss=9117.34473\n",
      "Epoch 4258: train_loss=8986.72168, val_loss=9116.96484\n",
      "Epoch 4259: train_loss=8986.35547, val_loss=9116.58301\n",
      "Epoch 4260: train_loss=8985.98828, val_loss=9116.20117\n",
      "Epoch 4261: train_loss=8985.62207, val_loss=9115.81836\n",
      "Epoch 4262: train_loss=8985.25684, val_loss=9115.43750\n",
      "Epoch 4263: train_loss=8984.88965, val_loss=9115.05566\n",
      "Epoch 4264: train_loss=8984.52441, val_loss=9114.67188\n",
      "Epoch 4265: train_loss=8984.15625, val_loss=9114.29004\n",
      "Epoch 4266: train_loss=8983.79004, val_loss=9113.91016\n",
      "Epoch 4267: train_loss=8983.42480, val_loss=9113.52734\n",
      "Epoch 4268: train_loss=8983.05762, val_loss=9113.14355\n",
      "Epoch 4269: train_loss=8982.69043, val_loss=9112.76074\n",
      "Epoch 4270: train_loss=8982.32422, val_loss=9112.37891\n",
      "Epoch 4271: train_loss=8981.95703, val_loss=9111.99902\n",
      "Epoch 4272: train_loss=8981.59082, val_loss=9111.61621\n",
      "Epoch 4273: train_loss=8981.22461, val_loss=9111.23145\n",
      "Epoch 4274: train_loss=8980.85742, val_loss=9110.84961\n",
      "Epoch 4275: train_loss=8980.49121, val_loss=9110.46582\n",
      "Epoch 4276: train_loss=8980.12402, val_loss=9110.08398\n",
      "Epoch 4277: train_loss=8979.75684, val_loss=9109.70215\n",
      "Epoch 4278: train_loss=8979.38965, val_loss=9109.31836\n",
      "Epoch 4279: train_loss=8979.02246, val_loss=9108.93457\n",
      "Epoch 4280: train_loss=8978.65527, val_loss=9108.55078\n",
      "Epoch 4281: train_loss=8978.28906, val_loss=9108.16895\n",
      "Epoch 4282: train_loss=8977.92188, val_loss=9107.78613\n",
      "Epoch 4283: train_loss=8977.55469, val_loss=9107.40332\n",
      "Epoch 4284: train_loss=8977.18750, val_loss=9107.01953\n",
      "Epoch 4285: train_loss=8976.82031, val_loss=9106.63672\n",
      "Epoch 4286: train_loss=8976.45312, val_loss=9106.25488\n",
      "Epoch 4287: train_loss=8976.08594, val_loss=9105.87109\n",
      "Epoch 4288: train_loss=8975.71777, val_loss=9105.48730\n",
      "Epoch 4289: train_loss=8975.35254, val_loss=9105.10449\n",
      "Epoch 4290: train_loss=8974.98438, val_loss=9104.72266\n",
      "Epoch 4291: train_loss=8974.61816, val_loss=9104.33984\n",
      "Epoch 4292: train_loss=8974.25098, val_loss=9103.95703\n",
      "Epoch 4293: train_loss=8973.88477, val_loss=9103.57422\n",
      "Epoch 4294: train_loss=8973.51855, val_loss=9103.19141\n",
      "Epoch 4295: train_loss=8973.15137, val_loss=9102.80957\n",
      "Epoch 4296: train_loss=8972.78613, val_loss=9102.42676\n",
      "Epoch 4297: train_loss=8972.41895, val_loss=9102.04492\n",
      "Epoch 4298: train_loss=8972.05273, val_loss=9101.66309\n",
      "Epoch 4299: train_loss=8971.68457, val_loss=9101.28027\n",
      "Epoch 4300: train_loss=8971.31836, val_loss=9100.89746\n",
      "Epoch 4301: train_loss=8970.95215, val_loss=9100.51660\n",
      "Epoch 4302: train_loss=8970.58496, val_loss=9100.13477\n",
      "Epoch 4303: train_loss=8970.21875, val_loss=9099.75195\n",
      "Epoch 4304: train_loss=8969.85156, val_loss=9099.36914\n",
      "Epoch 4305: train_loss=8969.48438, val_loss=9098.98730\n",
      "Epoch 4306: train_loss=8969.11621, val_loss=9098.60449\n",
      "Epoch 4307: train_loss=8968.75000, val_loss=9098.22070\n",
      "Epoch 4308: train_loss=8968.38281, val_loss=9097.83984\n",
      "Epoch 4309: train_loss=8968.01562, val_loss=9097.45801\n",
      "Epoch 4310: train_loss=8967.64746, val_loss=9097.07422\n",
      "Epoch 4311: train_loss=8967.28027, val_loss=9096.69141\n",
      "Epoch 4312: train_loss=8966.91309, val_loss=9096.30957\n",
      "Epoch 4313: train_loss=8966.54590, val_loss=9095.92871\n",
      "Epoch 4314: train_loss=8966.17871, val_loss=9095.54590\n",
      "Epoch 4315: train_loss=8965.81152, val_loss=9095.16309\n",
      "Epoch 4316: train_loss=8965.44336, val_loss=9094.78125\n",
      "Epoch 4317: train_loss=8965.07617, val_loss=9094.39844\n",
      "Epoch 4318: train_loss=8964.70898, val_loss=9094.01562\n",
      "Epoch 4319: train_loss=8964.34082, val_loss=9093.63281\n",
      "Epoch 4320: train_loss=8963.97363, val_loss=9093.25098\n",
      "Epoch 4321: train_loss=8963.60645, val_loss=9092.87012\n",
      "Epoch 4322: train_loss=8963.23828, val_loss=9092.48926\n",
      "Epoch 4323: train_loss=8962.87109, val_loss=9092.10449\n",
      "Epoch 4324: train_loss=8962.50293, val_loss=9091.72168\n",
      "Epoch 4325: train_loss=8962.13672, val_loss=9091.34082\n",
      "Epoch 4326: train_loss=8961.76855, val_loss=9090.95898\n",
      "Epoch 4327: train_loss=8961.39941, val_loss=9090.57910\n",
      "Epoch 4328: train_loss=8961.03223, val_loss=9090.19629\n",
      "Epoch 4329: train_loss=8960.66406, val_loss=9089.81250\n",
      "Epoch 4330: train_loss=8960.29688, val_loss=9089.42969\n",
      "Epoch 4331: train_loss=8959.92871, val_loss=9089.04785\n",
      "Epoch 4332: train_loss=8959.56055, val_loss=9088.66602\n",
      "Epoch 4333: train_loss=8959.19141, val_loss=9088.28418\n",
      "Epoch 4334: train_loss=8958.82422, val_loss=9087.90039\n",
      "Epoch 4335: train_loss=8958.45508, val_loss=9087.51953\n",
      "Epoch 4336: train_loss=8958.08691, val_loss=9087.13672\n",
      "Epoch 4337: train_loss=8957.71777, val_loss=9086.75391\n",
      "Epoch 4338: train_loss=8957.35156, val_loss=9086.37012\n",
      "Epoch 4339: train_loss=8956.98242, val_loss=9085.98926\n",
      "Epoch 4340: train_loss=8956.61328, val_loss=9085.60645\n",
      "Epoch 4341: train_loss=8956.24414, val_loss=9085.22461\n",
      "Epoch 4342: train_loss=8955.87500, val_loss=9084.84082\n",
      "Epoch 4343: train_loss=8955.50781, val_loss=9084.45898\n",
      "Epoch 4344: train_loss=8955.13770, val_loss=9084.07617\n",
      "Epoch 4345: train_loss=8954.76855, val_loss=9083.69336\n",
      "Epoch 4346: train_loss=8954.39941, val_loss=9083.30957\n",
      "Epoch 4347: train_loss=8954.03125, val_loss=9082.92773\n",
      "Epoch 4348: train_loss=8953.66113, val_loss=9082.54590\n",
      "Epoch 4349: train_loss=8953.29102, val_loss=9082.16309\n",
      "Epoch 4350: train_loss=8952.92188, val_loss=9081.77930\n",
      "Epoch 4351: train_loss=8952.55176, val_loss=9081.39551\n",
      "Epoch 4352: train_loss=8952.18262, val_loss=9081.01172\n",
      "Epoch 4353: train_loss=8951.81250, val_loss=9080.62891\n",
      "Epoch 4354: train_loss=8951.44141, val_loss=9080.24805\n",
      "Epoch 4355: train_loss=8951.07129, val_loss=9079.86621\n",
      "Epoch 4356: train_loss=8950.70117, val_loss=9079.48145\n",
      "Epoch 4357: train_loss=8950.33008, val_loss=9079.09766\n",
      "Epoch 4358: train_loss=8949.95898, val_loss=9078.71289\n",
      "Epoch 4359: train_loss=8949.58887, val_loss=9078.33008\n",
      "Epoch 4360: train_loss=8949.21680, val_loss=9077.94922\n",
      "Epoch 4361: train_loss=8948.84668, val_loss=9077.56738\n",
      "Epoch 4362: train_loss=8948.47559, val_loss=9077.18164\n",
      "Epoch 4363: train_loss=8948.10352, val_loss=9076.79590\n",
      "Epoch 4364: train_loss=8947.73242, val_loss=9076.41211\n",
      "Epoch 4365: train_loss=8947.36035, val_loss=9076.02832\n",
      "Epoch 4366: train_loss=8946.98828, val_loss=9075.64648\n",
      "Epoch 4367: train_loss=8946.61523, val_loss=9075.26367\n",
      "Epoch 4368: train_loss=8946.24316, val_loss=9074.87793\n",
      "Epoch 4369: train_loss=8945.87109, val_loss=9074.49121\n",
      "Epoch 4370: train_loss=8945.49707, val_loss=9074.10645\n",
      "Epoch 4371: train_loss=8945.12305, val_loss=9073.72070\n",
      "Epoch 4372: train_loss=8944.74902, val_loss=9073.33691\n",
      "Epoch 4373: train_loss=8944.37500, val_loss=9072.95020\n",
      "Epoch 4374: train_loss=8944.00000, val_loss=9072.56543\n",
      "Epoch 4375: train_loss=8943.62500, val_loss=9072.17969\n",
      "Epoch 4376: train_loss=8943.24707, val_loss=9071.79590\n",
      "Epoch 4377: train_loss=8942.87207, val_loss=9071.41113\n",
      "Epoch 4378: train_loss=8942.49609, val_loss=9071.02344\n",
      "Epoch 4379: train_loss=8942.11914, val_loss=9070.63672\n",
      "Epoch 4380: train_loss=8941.74219, val_loss=9070.25293\n",
      "Epoch 4381: train_loss=8941.36621, val_loss=9069.86816\n",
      "Epoch 4382: train_loss=8940.98828, val_loss=9069.48242\n",
      "Epoch 4383: train_loss=8940.61035, val_loss=9069.09375\n",
      "Epoch 4384: train_loss=8940.23340, val_loss=9068.70703\n",
      "Epoch 4385: train_loss=8939.85645, val_loss=9068.32031\n",
      "Epoch 4386: train_loss=8939.47949, val_loss=9067.93652\n",
      "Epoch 4387: train_loss=8939.10156, val_loss=9067.55176\n",
      "Epoch 4388: train_loss=8938.72559, val_loss=9067.16211\n",
      "Epoch 4389: train_loss=8938.34863, val_loss=9066.77344\n",
      "Epoch 4390: train_loss=8937.97070, val_loss=9066.38574\n",
      "Epoch 4391: train_loss=8937.59473, val_loss=9066.00195\n",
      "Epoch 4392: train_loss=8937.21777, val_loss=9065.61523\n",
      "Epoch 4393: train_loss=8936.84277, val_loss=9065.22656\n",
      "Epoch 4394: train_loss=8936.46680, val_loss=9064.83691\n",
      "Epoch 4395: train_loss=8936.09277, val_loss=9064.45020\n",
      "Epoch 4396: train_loss=8935.71777, val_loss=9064.06348\n",
      "Epoch 4397: train_loss=8935.34180, val_loss=9063.67773\n",
      "Epoch 4398: train_loss=8934.96680, val_loss=9063.28906\n",
      "Epoch 4399: train_loss=8934.59180, val_loss=9062.89844\n",
      "Epoch 4400: train_loss=8934.21680, val_loss=9062.50879\n",
      "Epoch 4401: train_loss=8933.84180, val_loss=9062.12109\n",
      "Epoch 4402: train_loss=8933.46582, val_loss=9061.73340\n",
      "Epoch 4403: train_loss=8933.09082, val_loss=9061.34668\n",
      "Epoch 4404: train_loss=8932.71484, val_loss=9060.95898\n",
      "Epoch 4405: train_loss=8932.33984, val_loss=9060.56836\n",
      "Epoch 4406: train_loss=8931.96289, val_loss=9060.17871\n",
      "Epoch 4407: train_loss=8931.58691, val_loss=9059.79102\n",
      "Epoch 4408: train_loss=8931.21191, val_loss=9059.40039\n",
      "Epoch 4409: train_loss=8930.83496, val_loss=9059.01270\n",
      "Epoch 4410: train_loss=8930.45801, val_loss=9058.62500\n",
      "Epoch 4411: train_loss=8930.08301, val_loss=9058.23340\n",
      "Epoch 4412: train_loss=8929.70508, val_loss=9057.84375\n",
      "Epoch 4413: train_loss=8929.32910, val_loss=9057.45410\n",
      "Epoch 4414: train_loss=8928.95117, val_loss=9057.06348\n",
      "Epoch 4415: train_loss=8928.57422, val_loss=9056.67480\n",
      "Epoch 4416: train_loss=8928.19727, val_loss=9056.28711\n",
      "Epoch 4417: train_loss=8927.82031, val_loss=9055.89746\n",
      "Epoch 4418: train_loss=8927.44238, val_loss=9055.50586\n",
      "Epoch 4419: train_loss=8927.06445, val_loss=9055.11816\n",
      "Epoch 4420: train_loss=8926.68750, val_loss=9054.72656\n",
      "Epoch 4421: train_loss=8926.30762, val_loss=9054.33594\n",
      "Epoch 4422: train_loss=8925.92969, val_loss=9053.94531\n",
      "Epoch 4423: train_loss=8925.55078, val_loss=9053.55469\n",
      "Epoch 4424: train_loss=8925.17188, val_loss=9053.16602\n",
      "Epoch 4425: train_loss=8924.79297, val_loss=9052.77637\n",
      "Epoch 4426: train_loss=8924.41504, val_loss=9052.38574\n",
      "Epoch 4427: train_loss=8924.03613, val_loss=9051.99512\n",
      "Epoch 4428: train_loss=8923.65723, val_loss=9051.60645\n",
      "Epoch 4429: train_loss=8923.27832, val_loss=9051.21582\n",
      "Epoch 4430: train_loss=8922.89746, val_loss=9050.82227\n",
      "Epoch 4431: train_loss=8922.51758, val_loss=9050.43164\n",
      "Epoch 4432: train_loss=8922.13965, val_loss=9050.04199\n",
      "Epoch 4433: train_loss=8921.76074, val_loss=9049.65039\n",
      "Epoch 4434: train_loss=8921.38086, val_loss=9049.25977\n",
      "Epoch 4435: train_loss=8921.00098, val_loss=9048.86816\n",
      "Epoch 4436: train_loss=8920.62012, val_loss=9048.47852\n",
      "Epoch 4437: train_loss=8920.24023, val_loss=9048.08789\n",
      "Epoch 4438: train_loss=8919.86035, val_loss=9047.69531\n",
      "Epoch 4439: train_loss=8919.47852, val_loss=9047.30273\n",
      "Epoch 4440: train_loss=8919.09766, val_loss=9046.91016\n",
      "Epoch 4441: train_loss=8918.71680, val_loss=9046.51953\n",
      "Epoch 4442: train_loss=8918.33594, val_loss=9046.12695\n",
      "Epoch 4443: train_loss=8917.95410, val_loss=9045.73242\n",
      "Epoch 4444: train_loss=8917.57227, val_loss=9045.33691\n",
      "Epoch 4445: train_loss=8917.18945, val_loss=9044.94434\n",
      "Epoch 4446: train_loss=8916.80762, val_loss=9044.54980\n",
      "Epoch 4447: train_loss=8916.42578, val_loss=9044.15723\n",
      "Epoch 4448: train_loss=8916.04297, val_loss=9043.76367\n",
      "Epoch 4449: train_loss=8915.66016, val_loss=9043.36719\n",
      "Epoch 4450: train_loss=8915.27734, val_loss=9042.97266\n",
      "Epoch 4451: train_loss=8914.89551, val_loss=9042.57715\n",
      "Epoch 4452: train_loss=8914.51270, val_loss=9042.18359\n",
      "Epoch 4453: train_loss=8914.12988, val_loss=9041.79297\n",
      "Epoch 4454: train_loss=8913.74902, val_loss=9041.40332\n",
      "Epoch 4455: train_loss=8913.36621, val_loss=9041.00684\n",
      "Epoch 4456: train_loss=8912.98438, val_loss=9040.61035\n",
      "Epoch 4457: train_loss=8912.60156, val_loss=9040.21484\n",
      "Epoch 4458: train_loss=8912.21875, val_loss=9039.82031\n",
      "Epoch 4459: train_loss=8911.83594, val_loss=9039.43066\n",
      "Epoch 4460: train_loss=8911.45215, val_loss=9039.03516\n",
      "Epoch 4461: train_loss=8911.07031, val_loss=9038.63477\n",
      "Epoch 4462: train_loss=8910.68555, val_loss=9038.23535\n",
      "Epoch 4463: train_loss=8910.30273, val_loss=9037.84180\n",
      "Epoch 4464: train_loss=8909.91895, val_loss=9037.44727\n",
      "Epoch 4465: train_loss=8909.53613, val_loss=9037.05176\n",
      "Epoch 4466: train_loss=8909.15137, val_loss=9036.65527\n",
      "Epoch 4467: train_loss=8908.76660, val_loss=9036.25586\n",
      "Epoch 4468: train_loss=8908.38184, val_loss=9035.85645\n",
      "Epoch 4469: train_loss=8907.99707, val_loss=9035.45898\n",
      "Epoch 4470: train_loss=8907.61133, val_loss=9035.06055\n",
      "Epoch 4471: train_loss=8907.22559, val_loss=9034.66016\n",
      "Epoch 4472: train_loss=8906.83984, val_loss=9034.25781\n",
      "Epoch 4473: train_loss=8906.45410, val_loss=9033.85645\n",
      "Epoch 4474: train_loss=8906.06543, val_loss=9033.45508\n",
      "Epoch 4475: train_loss=8905.67773, val_loss=9033.05176\n",
      "Epoch 4476: train_loss=8905.29004, val_loss=9032.64844\n",
      "Epoch 4477: train_loss=8904.90137, val_loss=9032.24609\n",
      "Epoch 4478: train_loss=8904.51172, val_loss=9031.84570\n",
      "Epoch 4479: train_loss=8904.12305, val_loss=9031.44434\n",
      "Epoch 4480: train_loss=8903.73242, val_loss=9031.04102\n",
      "Epoch 4481: train_loss=8903.34180, val_loss=9030.63672\n",
      "Epoch 4482: train_loss=8902.95117, val_loss=9030.23438\n",
      "Epoch 4483: train_loss=8902.55859, val_loss=9029.82617\n",
      "Epoch 4484: train_loss=8902.16309, val_loss=9029.41895\n",
      "Epoch 4485: train_loss=8901.76953, val_loss=9029.01465\n",
      "Epoch 4486: train_loss=8901.37793, val_loss=9028.61230\n",
      "Epoch 4487: train_loss=8900.98535, val_loss=9028.21094\n",
      "Epoch 4488: train_loss=8900.59375, val_loss=9027.80566\n",
      "Epoch 4489: train_loss=8900.20215, val_loss=9027.40234\n",
      "Epoch 4490: train_loss=8899.81250, val_loss=9027.00000\n",
      "Epoch 4491: train_loss=8899.42480, val_loss=9026.60059\n",
      "Epoch 4492: train_loss=8899.03711, val_loss=9026.20215\n",
      "Epoch 4493: train_loss=8898.65137, val_loss=9025.80176\n",
      "Epoch 4494: train_loss=8898.26660, val_loss=9025.40039\n",
      "Epoch 4495: train_loss=8897.87988, val_loss=9025.00195\n",
      "Epoch 4496: train_loss=8897.49414, val_loss=9024.60449\n",
      "Epoch 4497: train_loss=8897.11035, val_loss=9024.20703\n",
      "Epoch 4498: train_loss=8896.72559, val_loss=9023.80566\n",
      "Epoch 4499: train_loss=8896.34082, val_loss=9023.40430\n",
      "Epoch 4500: train_loss=8895.95508, val_loss=9023.00586\n",
      "Epoch 4501: train_loss=8895.56934, val_loss=9022.60840\n",
      "Epoch 4502: train_loss=8895.18359, val_loss=9022.20898\n",
      "Epoch 4503: train_loss=8894.79785, val_loss=9021.80762\n",
      "Epoch 4504: train_loss=8894.41211, val_loss=9021.40723\n",
      "Epoch 4505: train_loss=8894.02637, val_loss=9021.00684\n",
      "Epoch 4506: train_loss=8893.64062, val_loss=9020.60742\n",
      "Epoch 4507: train_loss=8893.25488, val_loss=9020.20801\n",
      "Epoch 4508: train_loss=8892.86816, val_loss=9019.80664\n",
      "Epoch 4509: train_loss=8892.48145, val_loss=9019.40625\n",
      "Epoch 4510: train_loss=8892.09473, val_loss=9019.00391\n",
      "Epoch 4511: train_loss=8891.70703, val_loss=9018.60449\n",
      "Epoch 4512: train_loss=8891.32129, val_loss=9018.20508\n",
      "Epoch 4513: train_loss=8890.93457, val_loss=9017.80469\n",
      "Epoch 4514: train_loss=8890.54688, val_loss=9017.40332\n",
      "Epoch 4515: train_loss=8890.16016, val_loss=9017.00098\n",
      "Epoch 4516: train_loss=8889.77246, val_loss=9016.59863\n",
      "Epoch 4517: train_loss=8889.38379, val_loss=9016.19531\n",
      "Epoch 4518: train_loss=8888.99707, val_loss=9015.79297\n",
      "Epoch 4519: train_loss=8888.60840, val_loss=9015.39258\n",
      "Epoch 4520: train_loss=8888.22070, val_loss=9014.99023\n",
      "Epoch 4521: train_loss=8887.83203, val_loss=9014.58496\n",
      "Epoch 4522: train_loss=8887.44336, val_loss=9014.18066\n",
      "Epoch 4523: train_loss=8887.05469, val_loss=9013.77637\n",
      "Epoch 4524: train_loss=8886.66504, val_loss=9013.37500\n",
      "Epoch 4525: train_loss=8886.27539, val_loss=9012.97168\n",
      "Epoch 4526: train_loss=8885.88672, val_loss=9012.56641\n",
      "Epoch 4527: train_loss=8885.49609, val_loss=9012.16113\n",
      "Epoch 4528: train_loss=8885.10645, val_loss=9011.75488\n",
      "Epoch 4529: train_loss=8884.71289, val_loss=9011.34863\n",
      "Epoch 4530: train_loss=8884.32129, val_loss=9010.94336\n",
      "Epoch 4531: train_loss=8883.92969, val_loss=9010.53516\n",
      "Epoch 4532: train_loss=8883.53809, val_loss=9010.12793\n",
      "Epoch 4533: train_loss=8883.14648, val_loss=9009.71973\n",
      "Epoch 4534: train_loss=8882.75391, val_loss=9009.31348\n",
      "Epoch 4535: train_loss=8882.36133, val_loss=9008.90625\n",
      "Epoch 4536: train_loss=8881.96875, val_loss=9008.49805\n",
      "Epoch 4537: train_loss=8881.57617, val_loss=9008.08887\n",
      "Epoch 4538: train_loss=8881.18164, val_loss=9007.67969\n",
      "Epoch 4539: train_loss=8880.78809, val_loss=9007.27246\n",
      "Epoch 4540: train_loss=8880.39355, val_loss=9006.86426\n",
      "Epoch 4541: train_loss=8879.99805, val_loss=9006.45508\n",
      "Epoch 4542: train_loss=8879.60352, val_loss=9006.04590\n",
      "Epoch 4543: train_loss=8879.20898, val_loss=9005.63965\n",
      "Epoch 4544: train_loss=8878.81738, val_loss=9005.23340\n",
      "Epoch 4545: train_loss=8878.42383, val_loss=9004.82715\n",
      "Epoch 4546: train_loss=8878.03125, val_loss=9004.42090\n",
      "Epoch 4547: train_loss=8877.63770, val_loss=9004.01758\n",
      "Epoch 4548: train_loss=8877.24512, val_loss=9003.61426\n",
      "Epoch 4549: train_loss=8876.85352, val_loss=9003.20801\n",
      "Epoch 4550: train_loss=8876.45898, val_loss=9002.79980\n",
      "Epoch 4551: train_loss=8876.06543, val_loss=9002.39453\n",
      "Epoch 4552: train_loss=8875.67285, val_loss=9001.98926\n",
      "Epoch 4553: train_loss=8875.27930, val_loss=9001.58594\n",
      "Epoch 4554: train_loss=8874.88574, val_loss=9001.18164\n",
      "Epoch 4555: train_loss=8874.49121, val_loss=9000.77539\n",
      "Epoch 4556: train_loss=8874.09570, val_loss=9000.36816\n",
      "Epoch 4557: train_loss=8873.70020, val_loss=8999.96191\n",
      "Epoch 4558: train_loss=8873.30469, val_loss=8999.55469\n",
      "Epoch 4559: train_loss=8872.90625, val_loss=8999.14551\n",
      "Epoch 4560: train_loss=8872.50781, val_loss=8998.73535\n",
      "Epoch 4561: train_loss=8872.10742, val_loss=8998.31934\n",
      "Epoch 4562: train_loss=8871.70215, val_loss=8997.89551\n",
      "Epoch 4563: train_loss=8871.29395, val_loss=8997.46387\n",
      "Epoch 4564: train_loss=8870.87500, val_loss=8997.03320\n",
      "Epoch 4565: train_loss=8870.45410, val_loss=8996.61133\n",
      "Epoch 4566: train_loss=8870.05371, val_loss=8996.19629\n",
      "Epoch 4567: train_loss=8869.65918, val_loss=8995.78125\n",
      "Epoch 4568: train_loss=8869.26367, val_loss=8995.36523\n",
      "Epoch 4569: train_loss=8868.86914, val_loss=8994.94824\n",
      "Epoch 4570: train_loss=8868.47168, val_loss=8994.53027\n",
      "Epoch 4571: train_loss=8868.07617, val_loss=8994.11426\n",
      "Epoch 4572: train_loss=8867.68262, val_loss=8993.70117\n",
      "Epoch 4573: train_loss=8867.29004, val_loss=8993.29395\n",
      "Epoch 4574: train_loss=8866.89941, val_loss=8992.88477\n",
      "Epoch 4575: train_loss=8866.50586, val_loss=8992.47461\n",
      "Epoch 4576: train_loss=8866.11230, val_loss=8992.06348\n",
      "Epoch 4577: train_loss=8865.71777, val_loss=8991.65332\n",
      "Epoch 4578: train_loss=8865.32422, val_loss=8991.24414\n",
      "Epoch 4579: train_loss=8864.92871, val_loss=8990.83398\n",
      "Epoch 4580: train_loss=8864.53320, val_loss=8990.42285\n",
      "Epoch 4581: train_loss=8864.13867, val_loss=8990.01270\n",
      "Epoch 4582: train_loss=8863.74219, val_loss=8989.60352\n",
      "Epoch 4583: train_loss=8863.34668, val_loss=8989.19434\n",
      "Epoch 4584: train_loss=8862.95117, val_loss=8988.78223\n",
      "Epoch 4585: train_loss=8862.55469, val_loss=8988.37207\n",
      "Epoch 4586: train_loss=8862.16016, val_loss=8987.96289\n",
      "Epoch 4587: train_loss=8861.76270, val_loss=8987.55566\n",
      "Epoch 4588: train_loss=8861.36719, val_loss=8987.14453\n",
      "Epoch 4589: train_loss=8860.97070, val_loss=8986.73145\n",
      "Epoch 4590: train_loss=8860.57422, val_loss=8986.32129\n",
      "Epoch 4591: train_loss=8860.17578, val_loss=8985.91113\n",
      "Epoch 4592: train_loss=8859.77930, val_loss=8985.49805\n",
      "Epoch 4593: train_loss=8859.38086, val_loss=8985.08594\n",
      "Epoch 4594: train_loss=8858.98438, val_loss=8984.67383\n",
      "Epoch 4595: train_loss=8858.58496, val_loss=8984.26074\n",
      "Epoch 4596: train_loss=8858.18750, val_loss=8983.84863\n",
      "Epoch 4597: train_loss=8857.78906, val_loss=8983.43555\n",
      "Epoch 4598: train_loss=8857.39160, val_loss=8983.02344\n",
      "Epoch 4599: train_loss=8856.99316, val_loss=8982.61035\n",
      "Epoch 4600: train_loss=8856.59570, val_loss=8982.19629\n",
      "Epoch 4601: train_loss=8856.19629, val_loss=8981.78516\n",
      "Epoch 4602: train_loss=8855.79785, val_loss=8981.37207\n",
      "Epoch 4603: train_loss=8855.39941, val_loss=8980.95898\n",
      "Epoch 4604: train_loss=8854.99902, val_loss=8980.54492\n",
      "Epoch 4605: train_loss=8854.60156, val_loss=8980.13086\n",
      "Epoch 4606: train_loss=8854.20020, val_loss=8979.71875\n",
      "Epoch 4607: train_loss=8853.79980, val_loss=8979.30762\n",
      "Epoch 4608: train_loss=8853.39941, val_loss=8978.89258\n",
      "Epoch 4609: train_loss=8852.99805, val_loss=8978.47754\n",
      "Epoch 4610: train_loss=8852.59766, val_loss=8978.06543\n",
      "Epoch 4611: train_loss=8852.19922, val_loss=8977.65527\n",
      "Epoch 4612: train_loss=8851.79980, val_loss=8977.24316\n",
      "Epoch 4613: train_loss=8851.40332, val_loss=8976.83301\n",
      "Epoch 4614: train_loss=8851.00488, val_loss=8976.42285\n",
      "Epoch 4615: train_loss=8850.60742, val_loss=8976.01270\n",
      "Epoch 4616: train_loss=8850.20996, val_loss=8975.60156\n",
      "Epoch 4617: train_loss=8849.81348, val_loss=8975.19336\n",
      "Epoch 4618: train_loss=8849.41895, val_loss=8974.78516\n",
      "Epoch 4619: train_loss=8849.02539, val_loss=8974.37500\n",
      "Epoch 4620: train_loss=8848.62988, val_loss=8973.96191\n",
      "Epoch 4621: train_loss=8848.23438, val_loss=8973.55078\n",
      "Epoch 4622: train_loss=8847.83789, val_loss=8973.13770\n",
      "Epoch 4623: train_loss=8847.44141, val_loss=8972.72461\n",
      "Epoch 4624: train_loss=8847.04492, val_loss=8972.30957\n",
      "Epoch 4625: train_loss=8846.64648, val_loss=8971.89160\n",
      "Epoch 4626: train_loss=8846.24805, val_loss=8971.47656\n",
      "Epoch 4627: train_loss=8845.85156, val_loss=8971.06348\n",
      "Epoch 4628: train_loss=8845.45508, val_loss=8970.65137\n",
      "Epoch 4629: train_loss=8845.05859, val_loss=8970.23730\n",
      "Epoch 4630: train_loss=8844.66113, val_loss=8969.82227\n",
      "Epoch 4631: train_loss=8844.26465, val_loss=8969.40918\n",
      "Epoch 4632: train_loss=8843.86816, val_loss=8968.99609\n",
      "Epoch 4633: train_loss=8843.47070, val_loss=8968.58594\n",
      "Epoch 4634: train_loss=8843.07422, val_loss=8968.17383\n",
      "Epoch 4635: train_loss=8842.67578, val_loss=8967.76074\n",
      "Epoch 4636: train_loss=8842.27930, val_loss=8967.34766\n",
      "Epoch 4637: train_loss=8841.88184, val_loss=8966.93555\n",
      "Epoch 4638: train_loss=8841.48535, val_loss=8966.52344\n",
      "Epoch 4639: train_loss=8841.08789, val_loss=8966.11133\n",
      "Epoch 4640: train_loss=8840.68848, val_loss=8965.70020\n",
      "Epoch 4641: train_loss=8840.29199, val_loss=8965.28711\n",
      "Epoch 4642: train_loss=8839.89355, val_loss=8964.87109\n",
      "Epoch 4643: train_loss=8839.49512, val_loss=8964.45703\n",
      "Epoch 4644: train_loss=8839.09766, val_loss=8964.04297\n",
      "Epoch 4645: train_loss=8838.70020, val_loss=8963.62891\n",
      "Epoch 4646: train_loss=8838.30273, val_loss=8963.21387\n",
      "Epoch 4647: train_loss=8837.90332, val_loss=8962.79785\n",
      "Epoch 4648: train_loss=8837.50488, val_loss=8962.38281\n",
      "Epoch 4649: train_loss=8837.10742, val_loss=8961.96777\n",
      "Epoch 4650: train_loss=8836.70801, val_loss=8961.55273\n",
      "Epoch 4651: train_loss=8836.30957, val_loss=8961.13867\n",
      "Epoch 4652: train_loss=8835.91113, val_loss=8960.72559\n",
      "Epoch 4653: train_loss=8835.51270, val_loss=8960.31152\n",
      "Epoch 4654: train_loss=8835.11426, val_loss=8959.89551\n",
      "Epoch 4655: train_loss=8834.71680, val_loss=8959.48145\n",
      "Epoch 4656: train_loss=8834.31738, val_loss=8959.06738\n",
      "Epoch 4657: train_loss=8833.91797, val_loss=8958.65332\n",
      "Epoch 4658: train_loss=8833.52051, val_loss=8958.23828\n",
      "Epoch 4659: train_loss=8833.12109, val_loss=8957.82227\n",
      "Epoch 4660: train_loss=8832.72363, val_loss=8957.40723\n",
      "Epoch 4661: train_loss=8832.32422, val_loss=8956.99121\n",
      "Epoch 4662: train_loss=8831.92578, val_loss=8956.57617\n",
      "Epoch 4663: train_loss=8831.52637, val_loss=8956.16113\n",
      "Epoch 4664: train_loss=8831.12891, val_loss=8955.74414\n",
      "Epoch 4665: train_loss=8830.72949, val_loss=8955.32910\n",
      "Epoch 4666: train_loss=8830.33008, val_loss=8954.91504\n",
      "Epoch 4667: train_loss=8829.93164, val_loss=8954.50000\n",
      "Epoch 4668: train_loss=8829.53223, val_loss=8954.08398\n",
      "Epoch 4669: train_loss=8829.13281, val_loss=8953.67090\n",
      "Epoch 4670: train_loss=8828.73340, val_loss=8953.25781\n",
      "Epoch 4671: train_loss=8828.33398, val_loss=8952.84375\n",
      "Epoch 4672: train_loss=8827.93457, val_loss=8952.42773\n",
      "Epoch 4673: train_loss=8827.53516, val_loss=8952.01270\n",
      "Epoch 4674: train_loss=8827.13770, val_loss=8951.59863\n",
      "Epoch 4675: train_loss=8826.73828, val_loss=8951.18457\n",
      "Epoch 4676: train_loss=8826.33887, val_loss=8950.76953\n",
      "Epoch 4677: train_loss=8825.94043, val_loss=8950.35449\n",
      "Epoch 4678: train_loss=8825.54102, val_loss=8949.94043\n",
      "Epoch 4679: train_loss=8825.14160, val_loss=8949.52637\n",
      "Epoch 4680: train_loss=8824.74219, val_loss=8949.11230\n",
      "Epoch 4681: train_loss=8824.34375, val_loss=8948.69824\n",
      "Epoch 4682: train_loss=8823.94336, val_loss=8948.28320\n",
      "Epoch 4683: train_loss=8823.54395, val_loss=8947.86816\n",
      "Epoch 4684: train_loss=8823.14453, val_loss=8947.45312\n",
      "Epoch 4685: train_loss=8822.74414, val_loss=8947.03809\n",
      "Epoch 4686: train_loss=8822.34473, val_loss=8946.62305\n",
      "Epoch 4687: train_loss=8821.94531, val_loss=8946.20898\n",
      "Epoch 4688: train_loss=8821.54590, val_loss=8945.79492\n",
      "Epoch 4689: train_loss=8821.14453, val_loss=8945.38086\n",
      "Epoch 4690: train_loss=8820.74414, val_loss=8944.96582\n",
      "Epoch 4691: train_loss=8820.34473, val_loss=8944.55078\n",
      "Epoch 4692: train_loss=8819.94336, val_loss=8944.13672\n",
      "Epoch 4693: train_loss=8819.54199, val_loss=8943.72168\n",
      "Epoch 4694: train_loss=8819.14160, val_loss=8943.30566\n",
      "Epoch 4695: train_loss=8818.73926, val_loss=8942.89258\n",
      "Epoch 4696: train_loss=8818.33789, val_loss=8942.47754\n",
      "Epoch 4697: train_loss=8817.93652, val_loss=8942.06348\n",
      "Epoch 4698: train_loss=8817.53516, val_loss=8941.65039\n",
      "Epoch 4699: train_loss=8817.13379, val_loss=8941.23828\n",
      "Epoch 4700: train_loss=8816.73047, val_loss=8940.82520\n",
      "Epoch 4701: train_loss=8816.32910, val_loss=8940.41016\n",
      "Epoch 4702: train_loss=8815.92676, val_loss=8939.99609\n",
      "Epoch 4703: train_loss=8815.52344, val_loss=8939.58105\n",
      "Epoch 4704: train_loss=8815.12109, val_loss=8939.16699\n",
      "Epoch 4705: train_loss=8814.71777, val_loss=8938.75098\n",
      "Epoch 4706: train_loss=8814.31348, val_loss=8938.33496\n",
      "Epoch 4707: train_loss=8813.90918, val_loss=8937.92285\n",
      "Epoch 4708: train_loss=8813.50488, val_loss=8937.50879\n",
      "Epoch 4709: train_loss=8813.09961, val_loss=8937.09277\n",
      "Epoch 4710: train_loss=8812.69434, val_loss=8936.67871\n",
      "Epoch 4711: train_loss=8812.28711, val_loss=8936.26270\n",
      "Epoch 4712: train_loss=8811.87988, val_loss=8935.84473\n",
      "Epoch 4713: train_loss=8811.47266, val_loss=8935.42773\n",
      "Epoch 4714: train_loss=8811.06543, val_loss=8935.01270\n",
      "Epoch 4715: train_loss=8810.65820, val_loss=8934.59473\n",
      "Epoch 4716: train_loss=8810.24902, val_loss=8934.17676\n",
      "Epoch 4717: train_loss=8809.84082, val_loss=8933.76172\n",
      "Epoch 4718: train_loss=8809.43457, val_loss=8933.34570\n",
      "Epoch 4719: train_loss=8809.03027, val_loss=8932.93066\n",
      "Epoch 4720: train_loss=8808.62598, val_loss=8932.51367\n",
      "Epoch 4721: train_loss=8808.22168, val_loss=8932.09766\n",
      "Epoch 4722: train_loss=8807.81738, val_loss=8931.68066\n",
      "Epoch 4723: train_loss=8807.41113, val_loss=8931.26367\n",
      "Epoch 4724: train_loss=8807.00586, val_loss=8930.84473\n",
      "Epoch 4725: train_loss=8806.59961, val_loss=8930.42578\n",
      "Epoch 4726: train_loss=8806.19336, val_loss=8930.00684\n",
      "Epoch 4727: train_loss=8805.78613, val_loss=8929.58594\n",
      "Epoch 4728: train_loss=8805.37891, val_loss=8929.16602\n",
      "Epoch 4729: train_loss=8804.97070, val_loss=8928.74512\n",
      "Epoch 4730: train_loss=8804.56250, val_loss=8928.32324\n",
      "Epoch 4731: train_loss=8804.15234, val_loss=8927.90039\n",
      "Epoch 4732: train_loss=8803.74219, val_loss=8927.47754\n",
      "Epoch 4733: train_loss=8803.33203, val_loss=8927.05371\n",
      "Epoch 4734: train_loss=8802.92285, val_loss=8926.62891\n",
      "Epoch 4735: train_loss=8802.51172, val_loss=8926.20312\n",
      "Epoch 4736: train_loss=8802.10059, val_loss=8925.77637\n",
      "Epoch 4737: train_loss=8801.68848, val_loss=8925.34668\n",
      "Epoch 4738: train_loss=8801.27539, val_loss=8924.91699\n",
      "Epoch 4739: train_loss=8800.86035, val_loss=8924.48535\n",
      "Epoch 4740: train_loss=8800.44434, val_loss=8924.05176\n",
      "Epoch 4741: train_loss=8800.02637, val_loss=8923.61914\n",
      "Epoch 4742: train_loss=8799.60645, val_loss=8923.18164\n",
      "Epoch 4743: train_loss=8799.18359, val_loss=8922.74121\n",
      "Epoch 4744: train_loss=8798.75586, val_loss=8922.29688\n",
      "Epoch 4745: train_loss=8798.32227, val_loss=8921.84570\n",
      "Epoch 4746: train_loss=8797.88672, val_loss=8921.40527\n",
      "Epoch 4747: train_loss=8797.46289, val_loss=8920.97266\n",
      "Epoch 4748: train_loss=8797.05078, val_loss=8920.54590\n",
      "Epoch 4749: train_loss=8796.64160, val_loss=8920.12109\n",
      "Epoch 4750: train_loss=8796.23145, val_loss=8919.69727\n",
      "Epoch 4751: train_loss=8795.82227, val_loss=8919.27246\n",
      "Epoch 4752: train_loss=8795.41309, val_loss=8918.84766\n",
      "Epoch 4753: train_loss=8795.00293, val_loss=8918.42188\n",
      "Epoch 4754: train_loss=8794.59277, val_loss=8917.99805\n",
      "Epoch 4755: train_loss=8794.18164, val_loss=8917.57129\n",
      "Epoch 4756: train_loss=8793.77051, val_loss=8917.14551\n",
      "Epoch 4757: train_loss=8793.35938, val_loss=8916.71875\n",
      "Epoch 4758: train_loss=8792.94727, val_loss=8916.29199\n",
      "Epoch 4759: train_loss=8792.53613, val_loss=8915.86621\n",
      "Epoch 4760: train_loss=8792.12402, val_loss=8915.44141\n",
      "Epoch 4761: train_loss=8791.71191, val_loss=8915.01465\n",
      "Epoch 4762: train_loss=8791.30078, val_loss=8914.58984\n",
      "Epoch 4763: train_loss=8790.88965, val_loss=8914.16309\n",
      "Epoch 4764: train_loss=8790.47852, val_loss=8913.73828\n",
      "Epoch 4765: train_loss=8790.06738, val_loss=8913.31152\n",
      "Epoch 4766: train_loss=8789.65625, val_loss=8912.88379\n",
      "Epoch 4767: train_loss=8789.24414, val_loss=8912.45605\n",
      "Epoch 4768: train_loss=8788.83301, val_loss=8912.02734\n",
      "Epoch 4769: train_loss=8788.42090, val_loss=8911.60059\n",
      "Epoch 4770: train_loss=8788.00781, val_loss=8911.17383\n",
      "Epoch 4771: train_loss=8787.59668, val_loss=8910.74512\n",
      "Epoch 4772: train_loss=8787.18359, val_loss=8910.31738\n",
      "Epoch 4773: train_loss=8786.77148, val_loss=8909.88770\n",
      "Epoch 4774: train_loss=8786.35840, val_loss=8909.46094\n",
      "Epoch 4775: train_loss=8785.94629, val_loss=8909.03223\n",
      "Epoch 4776: train_loss=8785.53320, val_loss=8908.60254\n",
      "Epoch 4777: train_loss=8785.11816, val_loss=8908.17285\n",
      "Epoch 4778: train_loss=8784.70410, val_loss=8907.74316\n",
      "Epoch 4779: train_loss=8784.29102, val_loss=8907.31641\n",
      "Epoch 4780: train_loss=8783.87695, val_loss=8906.88770\n",
      "Epoch 4781: train_loss=8783.46289, val_loss=8906.45508\n",
      "Epoch 4782: train_loss=8783.04688, val_loss=8906.02539\n",
      "Epoch 4783: train_loss=8782.63281, val_loss=8905.59570\n",
      "Epoch 4784: train_loss=8782.21875, val_loss=8905.16797\n",
      "Epoch 4785: train_loss=8781.80371, val_loss=8904.73828\n",
      "Epoch 4786: train_loss=8781.38770, val_loss=8904.30762\n",
      "Epoch 4787: train_loss=8780.97266, val_loss=8903.87793\n",
      "Epoch 4788: train_loss=8780.55859, val_loss=8903.44824\n",
      "Epoch 4789: train_loss=8780.14160, val_loss=8903.01855\n",
      "Epoch 4790: train_loss=8779.72656, val_loss=8902.58984\n",
      "Epoch 4791: train_loss=8779.30957, val_loss=8902.15625\n",
      "Epoch 4792: train_loss=8778.89160, val_loss=8901.72461\n",
      "Epoch 4793: train_loss=8778.47266, val_loss=8901.29102\n",
      "Epoch 4794: train_loss=8778.05176, val_loss=8900.85938\n",
      "Epoch 4795: train_loss=8777.63281, val_loss=8900.42480\n",
      "Epoch 4796: train_loss=8777.21191, val_loss=8899.98828\n",
      "Epoch 4797: train_loss=8776.78809, val_loss=8899.55176\n",
      "Epoch 4798: train_loss=8776.36523, val_loss=8899.11426\n",
      "Epoch 4799: train_loss=8775.94141, val_loss=8898.67969\n",
      "Epoch 4800: train_loss=8775.51758, val_loss=8898.24316\n",
      "Epoch 4801: train_loss=8775.09473, val_loss=8897.80566\n",
      "Epoch 4802: train_loss=8774.66992, val_loss=8897.36816\n",
      "Epoch 4803: train_loss=8774.24707, val_loss=8896.93164\n",
      "Epoch 4804: train_loss=8773.82227, val_loss=8896.49316\n",
      "Epoch 4805: train_loss=8773.39453, val_loss=8896.05566\n",
      "Epoch 4806: train_loss=8772.96973, val_loss=8895.61621\n",
      "Epoch 4807: train_loss=8772.54395, val_loss=8895.17676\n",
      "Epoch 4808: train_loss=8772.11816, val_loss=8894.73926\n",
      "Epoch 4809: train_loss=8771.69238, val_loss=8894.30078\n",
      "Epoch 4810: train_loss=8771.26660, val_loss=8893.86328\n",
      "Epoch 4811: train_loss=8770.84277, val_loss=8893.42676\n",
      "Epoch 4812: train_loss=8770.41797, val_loss=8892.99023\n",
      "Epoch 4813: train_loss=8769.99316, val_loss=8892.55566\n",
      "Epoch 4814: train_loss=8769.56836, val_loss=8892.11816\n",
      "Epoch 4815: train_loss=8769.14258, val_loss=8891.67871\n",
      "Epoch 4816: train_loss=8768.71875, val_loss=8891.24023\n",
      "Epoch 4817: train_loss=8768.29492, val_loss=8890.80371\n",
      "Epoch 4818: train_loss=8767.87012, val_loss=8890.36719\n",
      "Epoch 4819: train_loss=8767.44531, val_loss=8889.92676\n",
      "Epoch 4820: train_loss=8767.02246, val_loss=8889.48926\n",
      "Epoch 4821: train_loss=8766.60059, val_loss=8889.05176\n",
      "Epoch 4822: train_loss=8766.17676, val_loss=8888.61328\n",
      "Epoch 4823: train_loss=8765.75391, val_loss=8888.17676\n",
      "Epoch 4824: train_loss=8765.33008, val_loss=8887.73730\n",
      "Epoch 4825: train_loss=8764.90625, val_loss=8887.29883\n",
      "Epoch 4826: train_loss=8764.48242, val_loss=8886.86133\n",
      "Epoch 4827: train_loss=8764.05762, val_loss=8886.42383\n",
      "Epoch 4828: train_loss=8763.63184, val_loss=8885.98535\n",
      "Epoch 4829: train_loss=8763.20898, val_loss=8885.54590\n",
      "Epoch 4830: train_loss=8762.78418, val_loss=8885.10645\n",
      "Epoch 4831: train_loss=8762.36133, val_loss=8884.66699\n",
      "Epoch 4832: train_loss=8761.93750, val_loss=8884.23047\n",
      "Epoch 4833: train_loss=8761.51465, val_loss=8883.79004\n",
      "Epoch 4834: train_loss=8761.09180, val_loss=8883.34766\n",
      "Epoch 4835: train_loss=8760.66895, val_loss=8882.90820\n",
      "Epoch 4836: train_loss=8760.24414, val_loss=8882.46680\n",
      "Epoch 4837: train_loss=8759.81934, val_loss=8882.02539\n",
      "Epoch 4838: train_loss=8759.39355, val_loss=8881.58594\n",
      "Epoch 4839: train_loss=8758.96875, val_loss=8881.14160\n",
      "Epoch 4840: train_loss=8758.54492, val_loss=8880.69727\n",
      "Epoch 4841: train_loss=8758.11816, val_loss=8880.25391\n",
      "Epoch 4842: train_loss=8757.69434, val_loss=8879.81055\n",
      "Epoch 4843: train_loss=8757.26953, val_loss=8879.36719\n",
      "Epoch 4844: train_loss=8756.84473, val_loss=8878.92676\n",
      "Epoch 4845: train_loss=8756.41992, val_loss=8878.48633\n",
      "Epoch 4846: train_loss=8755.99609, val_loss=8878.04102\n",
      "Epoch 4847: train_loss=8755.57031, val_loss=8877.59570\n",
      "Epoch 4848: train_loss=8755.14453, val_loss=8877.15137\n",
      "Epoch 4849: train_loss=8754.71777, val_loss=8876.70703\n",
      "Epoch 4850: train_loss=8754.28906, val_loss=8876.26270\n",
      "Epoch 4851: train_loss=8753.86230, val_loss=8875.81641\n",
      "Epoch 4852: train_loss=8753.43457, val_loss=8875.37207\n",
      "Epoch 4853: train_loss=8753.00684, val_loss=8874.92480\n",
      "Epoch 4854: train_loss=8752.57715, val_loss=8874.47852\n",
      "Epoch 4855: train_loss=8752.14844, val_loss=8874.03027\n",
      "Epoch 4856: train_loss=8751.71973, val_loss=8873.58496\n",
      "Epoch 4857: train_loss=8751.29004, val_loss=8873.13965\n",
      "Epoch 4858: train_loss=8750.86035, val_loss=8872.69434\n",
      "Epoch 4859: train_loss=8750.42969, val_loss=8872.24707\n",
      "Epoch 4860: train_loss=8750.00000, val_loss=8871.79980\n",
      "Epoch 4861: train_loss=8749.57129, val_loss=8871.35352\n",
      "Epoch 4862: train_loss=8749.14160, val_loss=8870.90723\n",
      "Epoch 4863: train_loss=8748.71191, val_loss=8870.45898\n",
      "Epoch 4864: train_loss=8748.28125, val_loss=8870.01074\n",
      "Epoch 4865: train_loss=8747.85059, val_loss=8869.56348\n",
      "Epoch 4866: train_loss=8747.41992, val_loss=8869.11719\n",
      "Epoch 4867: train_loss=8746.99121, val_loss=8868.66992\n",
      "Epoch 4868: train_loss=8746.56055, val_loss=8868.22168\n",
      "Epoch 4869: train_loss=8746.13184, val_loss=8867.77246\n",
      "Epoch 4870: train_loss=8745.70117, val_loss=8867.32520\n",
      "Epoch 4871: train_loss=8745.27148, val_loss=8866.87598\n",
      "Epoch 4872: train_loss=8744.84082, val_loss=8866.42871\n",
      "Epoch 4873: train_loss=8744.41113, val_loss=8865.97754\n",
      "Epoch 4874: train_loss=8743.97949, val_loss=8865.52930\n",
      "Epoch 4875: train_loss=8743.54688, val_loss=8865.07910\n",
      "Epoch 4876: train_loss=8743.11523, val_loss=8864.62891\n",
      "Epoch 4877: train_loss=8742.68359, val_loss=8864.17871\n",
      "Epoch 4878: train_loss=8742.25195, val_loss=8863.72754\n",
      "Epoch 4879: train_loss=8741.81738, val_loss=8863.27734\n",
      "Epoch 4880: train_loss=8741.38477, val_loss=8862.82520\n",
      "Epoch 4881: train_loss=8740.95117, val_loss=8862.37500\n",
      "Epoch 4882: train_loss=8740.51660, val_loss=8861.92090\n",
      "Epoch 4883: train_loss=8740.08301, val_loss=8861.46973\n",
      "Epoch 4884: train_loss=8739.64746, val_loss=8861.01660\n",
      "Epoch 4885: train_loss=8739.21387, val_loss=8860.56543\n",
      "Epoch 4886: train_loss=8738.77930, val_loss=8860.11230\n",
      "Epoch 4887: train_loss=8738.34570, val_loss=8859.65918\n",
      "Epoch 4888: train_loss=8737.91016, val_loss=8859.20801\n",
      "Epoch 4889: train_loss=8737.47559, val_loss=8858.75293\n",
      "Epoch 4890: train_loss=8737.04004, val_loss=8858.30176\n",
      "Epoch 4891: train_loss=8736.60547, val_loss=8857.85059\n",
      "Epoch 4892: train_loss=8736.16992, val_loss=8857.39941\n",
      "Epoch 4893: train_loss=8735.73438, val_loss=8856.94531\n",
      "Epoch 4894: train_loss=8735.29688, val_loss=8856.48926\n",
      "Epoch 4895: train_loss=8734.86035, val_loss=8856.03516\n",
      "Epoch 4896: train_loss=8734.42383, val_loss=8855.58301\n",
      "Epoch 4897: train_loss=8733.98730, val_loss=8855.12988\n",
      "Epoch 4898: train_loss=8733.54785, val_loss=8854.67480\n",
      "Epoch 4899: train_loss=8733.10938, val_loss=8854.21875\n",
      "Epoch 4900: train_loss=8732.66992, val_loss=8853.75879\n",
      "Epoch 4901: train_loss=8732.22852, val_loss=8853.29980\n",
      "Epoch 4902: train_loss=8731.78809, val_loss=8852.83789\n",
      "Epoch 4903: train_loss=8731.34570, val_loss=8852.37500\n",
      "Epoch 4904: train_loss=8730.90332, val_loss=8851.91309\n",
      "Epoch 4905: train_loss=8730.46191, val_loss=8851.45508\n",
      "Epoch 4906: train_loss=8730.02246, val_loss=8850.99609\n",
      "Epoch 4907: train_loss=8729.58105, val_loss=8850.53516\n",
      "Epoch 4908: train_loss=8729.13965, val_loss=8850.07422\n",
      "Epoch 4909: train_loss=8728.69531, val_loss=8849.61133\n",
      "Epoch 4910: train_loss=8728.25293, val_loss=8849.14844\n",
      "Epoch 4911: train_loss=8727.80762, val_loss=8848.67383\n",
      "Epoch 4912: train_loss=8727.35449, val_loss=8848.19727\n",
      "Epoch 4913: train_loss=8726.89844, val_loss=8847.72656\n",
      "Epoch 4914: train_loss=8726.44141, val_loss=8847.25586\n",
      "Epoch 4915: train_loss=8725.98730, val_loss=8846.78809\n",
      "Epoch 4916: train_loss=8725.53516, val_loss=8846.31934\n",
      "Epoch 4917: train_loss=8725.08105, val_loss=8845.84766\n",
      "Epoch 4918: train_loss=8724.62793, val_loss=8845.37109\n",
      "Epoch 4919: train_loss=8724.16992, val_loss=8844.89453\n",
      "Epoch 4920: train_loss=8723.71094, val_loss=8844.41797\n",
      "Epoch 4921: train_loss=8723.25195, val_loss=8843.93555\n",
      "Epoch 4922: train_loss=8722.79102, val_loss=8843.45508\n",
      "Epoch 4923: train_loss=8722.33398, val_loss=8842.97168\n",
      "Epoch 4924: train_loss=8721.87402, val_loss=8842.48730\n",
      "Epoch 4925: train_loss=8721.41113, val_loss=8842.00195\n",
      "Epoch 4926: train_loss=8720.94824, val_loss=8841.51953\n",
      "Epoch 4927: train_loss=8720.48535, val_loss=8841.03809\n",
      "Epoch 4928: train_loss=8720.02441, val_loss=8840.55176\n",
      "Epoch 4929: train_loss=8719.56250, val_loss=8840.06250\n",
      "Epoch 4930: train_loss=8719.10352, val_loss=8839.57812\n",
      "Epoch 4931: train_loss=8718.65039, val_loss=8839.09473\n",
      "Epoch 4932: train_loss=8718.19141, val_loss=8838.61035\n",
      "Epoch 4933: train_loss=8717.73145, val_loss=8838.13477\n",
      "Epoch 4934: train_loss=8717.28027, val_loss=8837.66504\n",
      "Epoch 4935: train_loss=8716.83203, val_loss=8837.20117\n",
      "Epoch 4936: train_loss=8716.39062, val_loss=8836.74316\n",
      "Epoch 4937: train_loss=8715.95215, val_loss=8836.28516\n",
      "Epoch 4938: train_loss=8715.51172, val_loss=8835.82715\n",
      "Epoch 4939: train_loss=8715.07129, val_loss=8835.37109\n",
      "Epoch 4940: train_loss=8714.63184, val_loss=8834.91602\n",
      "Epoch 4941: train_loss=8714.19531, val_loss=8834.45996\n",
      "Epoch 4942: train_loss=8713.75781, val_loss=8834.00488\n",
      "Epoch 4943: train_loss=8713.31836, val_loss=8833.55078\n",
      "Epoch 4944: train_loss=8712.87793, val_loss=8833.09863\n",
      "Epoch 4945: train_loss=8712.43848, val_loss=8832.64062\n",
      "Epoch 4946: train_loss=8711.99609, val_loss=8832.18164\n",
      "Epoch 4947: train_loss=8711.55566, val_loss=8831.72656\n",
      "Epoch 4948: train_loss=8711.11230, val_loss=8831.26855\n",
      "Epoch 4949: train_loss=8710.66992, val_loss=8830.81250\n",
      "Epoch 4950: train_loss=8710.22559, val_loss=8830.35645\n",
      "Epoch 4951: train_loss=8709.78125, val_loss=8829.90137\n",
      "Epoch 4952: train_loss=8709.33691, val_loss=8829.44141\n",
      "Epoch 4953: train_loss=8708.88867, val_loss=8828.97949\n",
      "Epoch 4954: train_loss=8708.44238, val_loss=8828.51660\n",
      "Epoch 4955: train_loss=8707.99316, val_loss=8828.05469\n",
      "Epoch 4956: train_loss=8707.54590, val_loss=8827.59180\n",
      "Epoch 4957: train_loss=8707.09570, val_loss=8827.12988\n",
      "Epoch 4958: train_loss=8706.64648, val_loss=8826.66895\n",
      "Epoch 4959: train_loss=8706.19336, val_loss=8826.20703\n",
      "Epoch 4960: train_loss=8705.74121, val_loss=8825.74219\n",
      "Epoch 4961: train_loss=8705.28613, val_loss=8825.27246\n",
      "Epoch 4962: train_loss=8704.83203, val_loss=8824.80371\n",
      "Epoch 4963: train_loss=8704.37598, val_loss=8824.33496\n",
      "Epoch 4964: train_loss=8703.91797, val_loss=8823.86621\n",
      "Epoch 4965: train_loss=8703.46094, val_loss=8823.39648\n",
      "Epoch 4966: train_loss=8703.00195, val_loss=8822.92969\n",
      "Epoch 4967: train_loss=8702.54395, val_loss=8822.45703\n",
      "Epoch 4968: train_loss=8702.08398, val_loss=8821.98340\n",
      "Epoch 4969: train_loss=8701.62402, val_loss=8821.50977\n",
      "Epoch 4970: train_loss=8701.16406, val_loss=8821.03906\n",
      "Epoch 4971: train_loss=8700.70508, val_loss=8820.56641\n",
      "Epoch 4972: train_loss=8700.24414, val_loss=8820.09473\n",
      "Epoch 4973: train_loss=8699.78320, val_loss=8819.62207\n",
      "Epoch 4974: train_loss=8699.32129, val_loss=8819.14648\n",
      "Epoch 4975: train_loss=8698.85938, val_loss=8818.66895\n",
      "Epoch 4976: train_loss=8698.39648, val_loss=8818.18652\n",
      "Epoch 4977: train_loss=8697.93457, val_loss=8817.70508\n",
      "Epoch 4978: train_loss=8697.47266, val_loss=8817.22363\n",
      "Epoch 4979: train_loss=8697.00977, val_loss=8816.74316\n",
      "Epoch 4980: train_loss=8696.54785, val_loss=8816.26367\n",
      "Epoch 4981: train_loss=8696.08594, val_loss=8815.78711\n",
      "Epoch 4982: train_loss=8695.62500, val_loss=8815.30371\n",
      "Epoch 4983: train_loss=8695.16309, val_loss=8814.82031\n",
      "Epoch 4984: train_loss=8694.70117, val_loss=8814.33887\n",
      "Epoch 4985: train_loss=8694.23926, val_loss=8813.85742\n",
      "Epoch 4986: train_loss=8693.77832, val_loss=8813.37598\n",
      "Epoch 4987: train_loss=8693.31543, val_loss=8812.89258\n",
      "Epoch 4988: train_loss=8692.85156, val_loss=8812.41113\n",
      "Epoch 4989: train_loss=8692.38867, val_loss=8811.92871\n",
      "Epoch 4990: train_loss=8691.92383, val_loss=8811.44336\n",
      "Epoch 4991: train_loss=8691.45996, val_loss=8810.95703\n",
      "Epoch 4992: train_loss=8690.99609, val_loss=8810.47168\n",
      "Epoch 4993: train_loss=8690.53125, val_loss=8809.98535\n",
      "Epoch 4994: train_loss=8690.06543, val_loss=8809.50000\n",
      "Epoch 4995: train_loss=8689.60059, val_loss=8809.01562\n",
      "Epoch 4996: train_loss=8689.13477, val_loss=8808.53125\n",
      "Epoch 4997: train_loss=8688.66895, val_loss=8808.04492\n",
      "Epoch 4998: train_loss=8688.20410, val_loss=8807.55664\n",
      "Epoch 4999: train_loss=8687.73828, val_loss=8807.07129\n",
      "Epoch 5000: train_loss=8687.27441, val_loss=8806.58301\n",
      "Epoch 5001: train_loss=8686.80957, val_loss=8806.09473\n",
      "Epoch 5002: train_loss=8686.34473, val_loss=8805.60645\n",
      "Epoch 5003: train_loss=8685.87891, val_loss=8805.11816\n",
      "Epoch 5004: train_loss=8685.41406, val_loss=8804.62891\n",
      "Epoch 5005: train_loss=8684.94922, val_loss=8804.13965\n",
      "Epoch 5006: train_loss=8684.48340, val_loss=8803.64844\n",
      "Epoch 5007: train_loss=8684.01855, val_loss=8803.15625\n",
      "Epoch 5008: train_loss=8683.55273, val_loss=8802.66504\n",
      "Epoch 5009: train_loss=8683.08594, val_loss=8802.17480\n",
      "Epoch 5010: train_loss=8682.62012, val_loss=8801.68359\n",
      "Epoch 5011: train_loss=8682.15430, val_loss=8801.19629\n",
      "Epoch 5012: train_loss=8681.69043, val_loss=8800.70801\n",
      "Epoch 5013: train_loss=8681.22559, val_loss=8800.21680\n",
      "Epoch 5014: train_loss=8680.75879, val_loss=8799.72852\n",
      "Epoch 5015: train_loss=8680.29395, val_loss=8799.23926\n",
      "Epoch 5016: train_loss=8679.82812, val_loss=8798.74902\n",
      "Epoch 5017: train_loss=8679.36133, val_loss=8798.26074\n",
      "Epoch 5018: train_loss=8678.89453, val_loss=8797.76855\n",
      "Epoch 5019: train_loss=8678.42480, val_loss=8797.27148\n",
      "Epoch 5020: train_loss=8677.95605, val_loss=8796.77441\n",
      "Epoch 5021: train_loss=8677.48535, val_loss=8796.27441\n",
      "Epoch 5022: train_loss=8677.01367, val_loss=8795.77344\n",
      "Epoch 5023: train_loss=8676.54102, val_loss=8795.27344\n",
      "Epoch 5024: train_loss=8676.06836, val_loss=8794.77344\n",
      "Epoch 5025: train_loss=8675.59570, val_loss=8794.27246\n",
      "Epoch 5026: train_loss=8675.12109, val_loss=8793.77051\n",
      "Epoch 5027: train_loss=8674.64648, val_loss=8793.26367\n",
      "Epoch 5028: train_loss=8674.17090, val_loss=8792.75781\n",
      "Epoch 5029: train_loss=8673.69336, val_loss=8792.25195\n",
      "Epoch 5030: train_loss=8673.21680, val_loss=8791.74414\n",
      "Epoch 5031: train_loss=8672.73926, val_loss=8791.23730\n",
      "Epoch 5032: train_loss=8672.26074, val_loss=8790.72656\n",
      "Epoch 5033: train_loss=8671.78223, val_loss=8790.21582\n",
      "Epoch 5034: train_loss=8671.30273, val_loss=8789.70312\n",
      "Epoch 5035: train_loss=8670.82227, val_loss=8789.19141\n",
      "Epoch 5036: train_loss=8670.34180, val_loss=8788.67871\n",
      "Epoch 5037: train_loss=8669.85840, val_loss=8788.16504\n",
      "Epoch 5038: train_loss=8669.37500, val_loss=8787.65039\n",
      "Epoch 5039: train_loss=8668.89258, val_loss=8787.13281\n",
      "Epoch 5040: train_loss=8668.40625, val_loss=8786.61621\n",
      "Epoch 5041: train_loss=8667.92090, val_loss=8786.09961\n",
      "Epoch 5042: train_loss=8667.43457, val_loss=8785.58203\n",
      "Epoch 5043: train_loss=8666.94629, val_loss=8785.05957\n",
      "Epoch 5044: train_loss=8666.45996, val_loss=8784.54102\n",
      "Epoch 5045: train_loss=8665.97461, val_loss=8784.02246\n",
      "Epoch 5046: train_loss=8665.48828, val_loss=8783.50781\n",
      "Epoch 5047: train_loss=8665.00195, val_loss=8782.99902\n",
      "Epoch 5048: train_loss=8664.52051, val_loss=8782.48633\n",
      "Epoch 5049: train_loss=8664.03711, val_loss=8781.97852\n",
      "Epoch 5050: train_loss=8663.55469, val_loss=8781.47168\n",
      "Epoch 5051: train_loss=8663.07031, val_loss=8780.96582\n",
      "Epoch 5052: train_loss=8662.58496, val_loss=8780.45703\n",
      "Epoch 5053: train_loss=8662.10059, val_loss=8779.94629\n",
      "Epoch 5054: train_loss=8661.61230, val_loss=8779.43652\n",
      "Epoch 5055: train_loss=8661.12207, val_loss=8778.92578\n",
      "Epoch 5056: train_loss=8660.62891, val_loss=8778.41113\n",
      "Epoch 5057: train_loss=8660.13184, val_loss=8777.89648\n",
      "Epoch 5058: train_loss=8659.63574, val_loss=8777.38184\n",
      "Epoch 5059: train_loss=8659.13672, val_loss=8776.87012\n",
      "Epoch 5060: train_loss=8658.64062, val_loss=8776.35547\n",
      "Epoch 5061: train_loss=8658.14746, val_loss=8775.84375\n",
      "Epoch 5062: train_loss=8657.65723, val_loss=8775.33301\n",
      "Epoch 5063: train_loss=8657.17090, val_loss=8774.83203\n",
      "Epoch 5064: train_loss=8656.68652, val_loss=8774.33008\n",
      "Epoch 5065: train_loss=8656.20508, val_loss=8773.83105\n",
      "Epoch 5066: train_loss=8655.72559, val_loss=8773.33203\n",
      "Epoch 5067: train_loss=8655.24512, val_loss=8772.83496\n",
      "Epoch 5068: train_loss=8654.76562, val_loss=8772.33301\n",
      "Epoch 5069: train_loss=8654.28613, val_loss=8771.83398\n",
      "Epoch 5070: train_loss=8653.80566, val_loss=8771.33203\n",
      "Epoch 5071: train_loss=8653.32520, val_loss=8770.83203\n",
      "Epoch 5072: train_loss=8652.84570, val_loss=8770.33301\n",
      "Epoch 5073: train_loss=8652.36426, val_loss=8769.82812\n",
      "Epoch 5074: train_loss=8651.88184, val_loss=8769.32422\n",
      "Epoch 5075: train_loss=8651.39941, val_loss=8768.82031\n",
      "Epoch 5076: train_loss=8650.91699, val_loss=8768.31738\n",
      "Epoch 5077: train_loss=8650.43457, val_loss=8767.81641\n",
      "Epoch 5078: train_loss=8649.95410, val_loss=8767.31348\n",
      "Epoch 5079: train_loss=8649.47168, val_loss=8766.81250\n",
      "Epoch 5080: train_loss=8648.99121, val_loss=8766.31250\n",
      "Epoch 5081: train_loss=8648.51074, val_loss=8765.81348\n",
      "Epoch 5082: train_loss=8648.02832, val_loss=8765.31738\n",
      "Epoch 5083: train_loss=8647.54785, val_loss=8764.81836\n",
      "Epoch 5084: train_loss=8647.06543, val_loss=8764.32227\n",
      "Epoch 5085: train_loss=8646.58398, val_loss=8763.82520\n",
      "Epoch 5086: train_loss=8646.10156, val_loss=8763.32910\n",
      "Epoch 5087: train_loss=8645.62012, val_loss=8762.83496\n",
      "Epoch 5088: train_loss=8645.13867, val_loss=8762.33691\n",
      "Epoch 5089: train_loss=8644.65723, val_loss=8761.84180\n",
      "Epoch 5090: train_loss=8644.17578, val_loss=8761.34668\n",
      "Epoch 5091: train_loss=8643.69434, val_loss=8760.85352\n",
      "Epoch 5092: train_loss=8643.21289, val_loss=8760.36035\n",
      "Epoch 5093: train_loss=8642.73047, val_loss=8759.86426\n",
      "Epoch 5094: train_loss=8642.24902, val_loss=8759.36719\n",
      "Epoch 5095: train_loss=8641.76660, val_loss=8758.87012\n",
      "Epoch 5096: train_loss=8641.28418, val_loss=8758.37500\n",
      "Epoch 5097: train_loss=8640.80176, val_loss=8757.87891\n",
      "Epoch 5098: train_loss=8640.31738, val_loss=8757.38184\n",
      "Epoch 5099: train_loss=8639.83398, val_loss=8756.88574\n",
      "Epoch 5100: train_loss=8639.34961, val_loss=8756.38672\n",
      "Epoch 5101: train_loss=8638.86230, val_loss=8755.88672\n",
      "Epoch 5102: train_loss=8638.37305, val_loss=8755.38477\n",
      "Epoch 5103: train_loss=8637.87988, val_loss=8754.88281\n",
      "Epoch 5104: train_loss=8637.38281, val_loss=8754.38086\n",
      "Epoch 5105: train_loss=8636.88672, val_loss=8753.87500\n",
      "Epoch 5106: train_loss=8636.38770, val_loss=8753.37305\n",
      "Epoch 5107: train_loss=8635.88867, val_loss=8752.87109\n",
      "Epoch 5108: train_loss=8635.38965, val_loss=8752.36133\n",
      "Epoch 5109: train_loss=8634.88477, val_loss=8751.84863\n",
      "Epoch 5110: train_loss=8634.37695, val_loss=8751.34375\n",
      "Epoch 5111: train_loss=8633.87500, val_loss=8750.84180\n",
      "Epoch 5112: train_loss=8633.37500, val_loss=8750.33984\n",
      "Epoch 5113: train_loss=8632.87598, val_loss=8749.84180\n",
      "Epoch 5114: train_loss=8632.37988, val_loss=8749.34668\n",
      "Epoch 5115: train_loss=8631.88477, val_loss=8748.85352\n",
      "Epoch 5116: train_loss=8631.38965, val_loss=8748.36328\n",
      "Epoch 5117: train_loss=8630.89648, val_loss=8747.87305\n",
      "Epoch 5118: train_loss=8630.39941, val_loss=8747.37793\n",
      "Epoch 5119: train_loss=8629.90039, val_loss=8746.88477\n",
      "Epoch 5120: train_loss=8629.40137, val_loss=8746.39355\n",
      "Epoch 5121: train_loss=8628.90430, val_loss=8745.90234\n",
      "Epoch 5122: train_loss=8628.40723, val_loss=8745.41211\n",
      "Epoch 5123: train_loss=8627.91016, val_loss=8744.92188\n",
      "Epoch 5124: train_loss=8627.41113, val_loss=8744.43359\n",
      "Epoch 5125: train_loss=8626.91113, val_loss=8743.94629\n",
      "Epoch 5126: train_loss=8626.41211, val_loss=8743.45996\n",
      "Epoch 5127: train_loss=8625.91016, val_loss=8742.97266\n",
      "Epoch 5128: train_loss=8625.40625, val_loss=8742.48633\n",
      "Epoch 5129: train_loss=8624.90723, val_loss=8742.00195\n",
      "Epoch 5130: train_loss=8624.40723, val_loss=8741.51367\n",
      "Epoch 5131: train_loss=8623.90820, val_loss=8741.02637\n",
      "Epoch 5132: train_loss=8623.40918, val_loss=8740.54004\n",
      "Epoch 5133: train_loss=8622.91016, val_loss=8740.04980\n",
      "Epoch 5134: train_loss=8622.41016, val_loss=8739.55859\n",
      "Epoch 5135: train_loss=8621.91016, val_loss=8739.06738\n",
      "Epoch 5136: train_loss=8621.41016, val_loss=8738.57227\n",
      "Epoch 5137: train_loss=8620.90820, val_loss=8738.07520\n",
      "Epoch 5138: train_loss=8620.40234, val_loss=8737.58105\n",
      "Epoch 5139: train_loss=8619.89844, val_loss=8737.08691\n",
      "Epoch 5140: train_loss=8619.39746, val_loss=8736.59180\n",
      "Epoch 5141: train_loss=8618.89355, val_loss=8736.09180\n",
      "Epoch 5142: train_loss=8618.38672, val_loss=8735.59082\n",
      "Epoch 5143: train_loss=8617.88086, val_loss=8735.08984\n",
      "Epoch 5144: train_loss=8617.37500, val_loss=8734.58691\n",
      "Epoch 5145: train_loss=8616.86719, val_loss=8734.08203\n",
      "Epoch 5146: train_loss=8616.35645, val_loss=8733.57617\n",
      "Epoch 5147: train_loss=8615.84375, val_loss=8733.06934\n",
      "Epoch 5148: train_loss=8615.33398, val_loss=8732.56445\n",
      "Epoch 5149: train_loss=8614.82422, val_loss=8732.05566\n",
      "Epoch 5150: train_loss=8614.31738, val_loss=8731.53125\n",
      "Epoch 5151: train_loss=8613.78906, val_loss=8731.00000\n",
      "Epoch 5152: train_loss=8613.25879, val_loss=8730.44727\n",
      "Epoch 5153: train_loss=8612.70898, val_loss=8729.89258\n",
      "Epoch 5154: train_loss=8612.16016, val_loss=8729.35938\n",
      "Epoch 5155: train_loss=8611.63672, val_loss=8728.83203\n",
      "Epoch 5156: train_loss=8611.12109, val_loss=8728.30664\n",
      "Epoch 5157: train_loss=8610.60547, val_loss=8727.77637\n",
      "Epoch 5158: train_loss=8610.08691, val_loss=8727.24023\n",
      "Epoch 5159: train_loss=8609.56445, val_loss=8726.69727\n",
      "Epoch 5160: train_loss=8609.03809, val_loss=8726.14844\n",
      "Epoch 5161: train_loss=8608.50586, val_loss=8725.59473\n",
      "Epoch 5162: train_loss=8607.96582, val_loss=8725.03613\n",
      "Epoch 5163: train_loss=8607.41895, val_loss=8724.46875\n",
      "Epoch 5164: train_loss=8606.86328, val_loss=8723.90039\n",
      "Epoch 5165: train_loss=8606.29980, val_loss=8723.32715\n",
      "Epoch 5166: train_loss=8605.72559, val_loss=8722.75000\n",
      "Epoch 5167: train_loss=8605.14355, val_loss=8722.16895\n",
      "Epoch 5168: train_loss=8604.54980, val_loss=8721.58203\n",
      "Epoch 5169: train_loss=8603.94629, val_loss=8720.99121\n",
      "Epoch 5170: train_loss=8603.33105, val_loss=8720.39941\n",
      "Epoch 5171: train_loss=8602.70801, val_loss=8719.80469\n",
      "Epoch 5172: train_loss=8602.08398, val_loss=8719.21191\n",
      "Epoch 5173: train_loss=8601.46094, val_loss=8718.62207\n",
      "Epoch 5174: train_loss=8600.83887, val_loss=8718.04102\n",
      "Epoch 5175: train_loss=8600.22168, val_loss=8717.45117\n",
      "Epoch 5176: train_loss=8599.59766, val_loss=8716.85254\n",
      "Epoch 5177: train_loss=8598.95996, val_loss=8716.26172\n",
      "Epoch 5178: train_loss=8598.32617, val_loss=8715.67480\n",
      "Epoch 5179: train_loss=8597.69141, val_loss=8715.09180\n",
      "Epoch 5180: train_loss=8597.05957, val_loss=8714.53320\n",
      "Epoch 5181: train_loss=8596.43750, val_loss=8713.96973\n",
      "Epoch 5182: train_loss=8595.81543, val_loss=8713.40137\n",
      "Epoch 5183: train_loss=8595.19922, val_loss=8712.82520\n",
      "Epoch 5184: train_loss=8594.57715, val_loss=8712.24414\n",
      "Epoch 5185: train_loss=8593.94238, val_loss=8711.66309\n",
      "Epoch 5186: train_loss=8593.30469, val_loss=8711.08691\n",
      "Epoch 5187: train_loss=8592.67480, val_loss=8710.51367\n",
      "Epoch 5188: train_loss=8592.05176, val_loss=8709.93066\n",
      "Epoch 5189: train_loss=8591.42480, val_loss=8709.33301\n",
      "Epoch 5190: train_loss=8590.77734, val_loss=8708.72754\n",
      "Epoch 5191: train_loss=8590.11914, val_loss=8708.09766\n",
      "Epoch 5192: train_loss=8589.45703, val_loss=8707.44043\n",
      "Epoch 5193: train_loss=8588.77441, val_loss=8706.76465\n",
      "Epoch 5194: train_loss=8588.07031, val_loss=8706.08984\n",
      "Epoch 5195: train_loss=8587.36035, val_loss=8705.43945\n",
      "Epoch 5196: train_loss=8586.66699, val_loss=8704.82227\n",
      "Epoch 5197: train_loss=8586.01758, val_loss=8704.23340\n",
      "Epoch 5198: train_loss=8585.40332, val_loss=8703.66699\n",
      "Epoch 5199: train_loss=8584.80762, val_loss=8703.13574\n",
      "Epoch 5200: train_loss=8584.24805, val_loss=8702.61133\n",
      "Epoch 5201: train_loss=8583.70312, val_loss=8702.09473\n",
      "Epoch 5202: train_loss=8583.16504, val_loss=8701.57422\n",
      "Epoch 5203: train_loss=8582.62695, val_loss=8701.05176\n",
      "Epoch 5204: train_loss=8582.09180, val_loss=8700.52734\n",
      "Epoch 5205: train_loss=8581.55762, val_loss=8699.99023\n",
      "Epoch 5206: train_loss=8581.01562, val_loss=8699.44824\n",
      "Epoch 5207: train_loss=8580.47070, val_loss=8698.90234\n",
      "Epoch 5208: train_loss=8579.92383, val_loss=8698.35449\n",
      "Epoch 5209: train_loss=8579.37695, val_loss=8697.80371\n",
      "Epoch 5210: train_loss=8578.83008, val_loss=8697.25684\n",
      "Epoch 5211: train_loss=8578.28223, val_loss=8696.71191\n",
      "Epoch 5212: train_loss=8577.73438, val_loss=8696.17188\n",
      "Epoch 5213: train_loss=8577.19141, val_loss=8695.63867\n",
      "Epoch 5214: train_loss=8576.65234, val_loss=8695.10449\n",
      "Epoch 5215: train_loss=8576.11816, val_loss=8694.56836\n",
      "Epoch 5216: train_loss=8575.58496, val_loss=8694.03320\n",
      "Epoch 5217: train_loss=8575.05176, val_loss=8693.49121\n",
      "Epoch 5218: train_loss=8574.51172, val_loss=8692.94629\n",
      "Epoch 5219: train_loss=8573.96875, val_loss=8692.39746\n",
      "Epoch 5220: train_loss=8573.42480, val_loss=8691.84668\n",
      "Epoch 5221: train_loss=8572.87793, val_loss=8691.28613\n",
      "Epoch 5222: train_loss=8572.32910, val_loss=8690.72461\n",
      "Epoch 5223: train_loss=8571.77832, val_loss=8690.16211\n",
      "Epoch 5224: train_loss=8571.22754, val_loss=8689.59766\n",
      "Epoch 5225: train_loss=8570.67871, val_loss=8689.02734\n",
      "Epoch 5226: train_loss=8570.12695, val_loss=8688.45020\n",
      "Epoch 5227: train_loss=8569.57520, val_loss=8687.86914\n",
      "Epoch 5228: train_loss=8569.02148, val_loss=8687.28613\n",
      "Epoch 5229: train_loss=8568.46875, val_loss=8686.70215\n",
      "Epoch 5230: train_loss=8567.91602, val_loss=8686.11719\n",
      "Epoch 5231: train_loss=8567.36230, val_loss=8685.53320\n",
      "Epoch 5232: train_loss=8566.80957, val_loss=8684.94824\n",
      "Epoch 5233: train_loss=8566.25586, val_loss=8684.36328\n",
      "Epoch 5234: train_loss=8565.69922, val_loss=8683.77734\n",
      "Epoch 5235: train_loss=8565.13867, val_loss=8683.19141\n",
      "Epoch 5236: train_loss=8564.57617, val_loss=8682.59473\n",
      "Epoch 5237: train_loss=8564.00488, val_loss=8681.98926\n",
      "Epoch 5238: train_loss=8563.42383, val_loss=8681.37109\n",
      "Epoch 5239: train_loss=8562.83594, val_loss=8680.75098\n",
      "Epoch 5240: train_loss=8562.25000, val_loss=8680.12793\n",
      "Epoch 5241: train_loss=8561.66309, val_loss=8679.49805\n",
      "Epoch 5242: train_loss=8561.07520, val_loss=8678.86426\n",
      "Epoch 5243: train_loss=8560.48633, val_loss=8678.22461\n",
      "Epoch 5244: train_loss=8559.89746, val_loss=8677.58887\n",
      "Epoch 5245: train_loss=8559.31348, val_loss=8676.95508\n",
      "Epoch 5246: train_loss=8558.72852, val_loss=8676.32324\n",
      "Epoch 5247: train_loss=8558.14648, val_loss=8675.69238\n",
      "Epoch 5248: train_loss=8557.56152, val_loss=8675.06055\n",
      "Epoch 5249: train_loss=8556.97754, val_loss=8674.42578\n",
      "Epoch 5250: train_loss=8556.38770, val_loss=8673.77734\n",
      "Epoch 5251: train_loss=8555.79297, val_loss=8673.12793\n",
      "Epoch 5252: train_loss=8555.19531, val_loss=8672.50684\n",
      "Epoch 5253: train_loss=8554.61719, val_loss=8671.91504\n",
      "Epoch 5254: train_loss=8554.05371, val_loss=8671.33203\n",
      "Epoch 5255: train_loss=8553.47656, val_loss=8670.75000\n",
      "Epoch 5256: train_loss=8552.88965, val_loss=8670.16504\n",
      "Epoch 5257: train_loss=8552.28906, val_loss=8669.57129\n",
      "Epoch 5258: train_loss=8551.67773, val_loss=8668.97656\n",
      "Epoch 5259: train_loss=8551.05859, val_loss=8668.38477\n",
      "Epoch 5260: train_loss=8550.43848, val_loss=8667.79688\n",
      "Epoch 5261: train_loss=8549.82031, val_loss=8667.21973\n",
      "Epoch 5262: train_loss=8549.21973, val_loss=8666.64160\n",
      "Epoch 5263: train_loss=8548.61719, val_loss=8666.06348\n",
      "Epoch 5264: train_loss=8548.01660, val_loss=8665.47949\n",
      "Epoch 5265: train_loss=8547.41797, val_loss=8664.88867\n",
      "Epoch 5266: train_loss=8546.81836, val_loss=8664.29004\n",
      "Epoch 5267: train_loss=8546.21777, val_loss=8663.67285\n",
      "Epoch 5268: train_loss=8545.61523, val_loss=8663.04395\n",
      "Epoch 5269: train_loss=8545.00781, val_loss=8662.40527\n",
      "Epoch 5270: train_loss=8544.40137, val_loss=8661.76660\n",
      "Epoch 5271: train_loss=8543.79590, val_loss=8661.11914\n",
      "Epoch 5272: train_loss=8543.19141, val_loss=8660.47754\n",
      "Epoch 5273: train_loss=8542.59570, val_loss=8659.84277\n",
      "Epoch 5274: train_loss=8541.99609, val_loss=8659.21094\n",
      "Epoch 5275: train_loss=8541.39258, val_loss=8658.58105\n",
      "Epoch 5276: train_loss=8540.78711, val_loss=8657.95117\n",
      "Epoch 5277: train_loss=8540.18164, val_loss=8657.32617\n",
      "Epoch 5278: train_loss=8539.58594, val_loss=8656.70605\n",
      "Epoch 5279: train_loss=8538.99414, val_loss=8656.08301\n",
      "Epoch 5280: train_loss=8538.39941, val_loss=8655.45117\n",
      "Epoch 5281: train_loss=8537.80469, val_loss=8654.81250\n",
      "Epoch 5282: train_loss=8537.20996, val_loss=8654.17285\n",
      "Epoch 5283: train_loss=8536.62109, val_loss=8653.53223\n",
      "Epoch 5284: train_loss=8536.03613, val_loss=8652.89355\n",
      "Epoch 5285: train_loss=8535.45020, val_loss=8652.24902\n",
      "Epoch 5286: train_loss=8534.86328, val_loss=8651.60059\n",
      "Epoch 5287: train_loss=8534.27637, val_loss=8650.95605\n",
      "Epoch 5288: train_loss=8533.68945, val_loss=8650.31445\n",
      "Epoch 5289: train_loss=8533.09961, val_loss=8649.67871\n",
      "Epoch 5290: train_loss=8532.51367, val_loss=8649.04297\n",
      "Epoch 5291: train_loss=8531.92969, val_loss=8648.40918\n",
      "Epoch 5292: train_loss=8531.34570, val_loss=8647.77051\n",
      "Epoch 5293: train_loss=8530.75879, val_loss=8647.12793\n",
      "Epoch 5294: train_loss=8530.16992, val_loss=8646.47656\n",
      "Epoch 5295: train_loss=8529.57520, val_loss=8645.83301\n",
      "Epoch 5296: train_loss=8528.98340, val_loss=8645.18945\n",
      "Epoch 5297: train_loss=8528.39355, val_loss=8644.54980\n",
      "Epoch 5298: train_loss=8527.80469, val_loss=8643.91113\n",
      "Epoch 5299: train_loss=8527.20898, val_loss=8643.27637\n",
      "Epoch 5300: train_loss=8526.61328, val_loss=8642.65234\n",
      "Epoch 5301: train_loss=8526.02344, val_loss=8642.02832\n",
      "Epoch 5302: train_loss=8525.43750, val_loss=8641.41211\n",
      "Epoch 5303: train_loss=8524.85742, val_loss=8640.81250\n",
      "Epoch 5304: train_loss=8524.29199, val_loss=8640.21289\n",
      "Epoch 5305: train_loss=8523.72070, val_loss=8639.61621\n",
      "Epoch 5306: train_loss=8523.14258, val_loss=8639.01758\n",
      "Epoch 5307: train_loss=8522.55664, val_loss=8638.42285\n",
      "Epoch 5308: train_loss=8521.96484, val_loss=8637.82910\n",
      "Epoch 5309: train_loss=8521.37305, val_loss=8637.24023\n",
      "Epoch 5310: train_loss=8520.79297, val_loss=8636.64941\n",
      "Epoch 5311: train_loss=8520.21387, val_loss=8636.05371\n",
      "Epoch 5312: train_loss=8519.63672, val_loss=8635.45312\n",
      "Epoch 5313: train_loss=8519.05566, val_loss=8634.84570\n",
      "Epoch 5314: train_loss=8518.47559, val_loss=8634.23340\n",
      "Epoch 5315: train_loss=8517.89258, val_loss=8633.61914\n",
      "Epoch 5316: train_loss=8517.31055, val_loss=8632.99414\n",
      "Epoch 5317: train_loss=8516.72559, val_loss=8632.35156\n",
      "Epoch 5318: train_loss=8516.12793, val_loss=8631.70410\n",
      "Epoch 5319: train_loss=8515.53125, val_loss=8631.04980\n",
      "Epoch 5320: train_loss=8514.93555, val_loss=8630.39355\n",
      "Epoch 5321: train_loss=8514.34082, val_loss=8629.73633\n",
      "Epoch 5322: train_loss=8513.74707, val_loss=8629.07715\n",
      "Epoch 5323: train_loss=8513.14844, val_loss=8628.42383\n",
      "Epoch 5324: train_loss=8512.55566, val_loss=8627.77441\n",
      "Epoch 5325: train_loss=8511.96387, val_loss=8627.12500\n",
      "Epoch 5326: train_loss=8511.36328, val_loss=8626.48047\n",
      "Epoch 5327: train_loss=8510.76367, val_loss=8625.84570\n",
      "Epoch 5328: train_loss=8510.17383, val_loss=8625.21875\n",
      "Epoch 5329: train_loss=8509.58789, val_loss=8624.59375\n",
      "Epoch 5330: train_loss=8509.00391, val_loss=8623.96387\n",
      "Epoch 5331: train_loss=8508.42090, val_loss=8623.33008\n",
      "Epoch 5332: train_loss=8507.83984, val_loss=8622.69043\n",
      "Epoch 5333: train_loss=8507.25391, val_loss=8622.04980\n",
      "Epoch 5334: train_loss=8506.66895, val_loss=8621.41016\n",
      "Epoch 5335: train_loss=8506.08594, val_loss=8620.77344\n",
      "Epoch 5336: train_loss=8505.50098, val_loss=8620.13867\n",
      "Epoch 5337: train_loss=8504.91895, val_loss=8619.50293\n",
      "Epoch 5338: train_loss=8504.33691, val_loss=8618.86523\n",
      "Epoch 5339: train_loss=8503.75195, val_loss=8618.21973\n",
      "Epoch 5340: train_loss=8503.15723, val_loss=8617.56641\n",
      "Epoch 5341: train_loss=8502.55859, val_loss=8616.91016\n",
      "Epoch 5342: train_loss=8501.95508, val_loss=8616.24805\n",
      "Epoch 5343: train_loss=8501.34961, val_loss=8615.58105\n",
      "Epoch 5344: train_loss=8500.74023, val_loss=8614.90723\n",
      "Epoch 5345: train_loss=8500.12695, val_loss=8614.23145\n",
      "Epoch 5346: train_loss=8499.50977, val_loss=8613.56055\n",
      "Epoch 5347: train_loss=8498.89355, val_loss=8612.88770\n",
      "Epoch 5348: train_loss=8498.27441, val_loss=8612.21484\n",
      "Epoch 5349: train_loss=8497.65234, val_loss=8611.54395\n",
      "Epoch 5350: train_loss=8497.02539, val_loss=8610.87598\n",
      "Epoch 5351: train_loss=8496.41211, val_loss=8610.20215\n",
      "Epoch 5352: train_loss=8495.79785, val_loss=8609.52441\n",
      "Epoch 5353: train_loss=8495.18457, val_loss=8608.84668\n",
      "Epoch 5354: train_loss=8494.56738, val_loss=8608.16797\n",
      "Epoch 5355: train_loss=8493.94922, val_loss=8607.49414\n",
      "Epoch 5356: train_loss=8493.33008, val_loss=8606.82031\n",
      "Epoch 5357: train_loss=8492.71289, val_loss=8606.14746\n",
      "Epoch 5358: train_loss=8492.09473, val_loss=8605.47559\n",
      "Epoch 5359: train_loss=8491.47949, val_loss=8604.79980\n",
      "Epoch 5360: train_loss=8490.86133, val_loss=8604.12988\n",
      "Epoch 5361: train_loss=8490.24609, val_loss=8603.49121\n",
      "Epoch 5362: train_loss=8489.64648, val_loss=8602.86523\n",
      "Epoch 5363: train_loss=8489.05859, val_loss=8602.24414\n",
      "Epoch 5364: train_loss=8488.47266, val_loss=8601.62402\n",
      "Epoch 5365: train_loss=8487.88770, val_loss=8601.00488\n",
      "Epoch 5366: train_loss=8487.30566, val_loss=8600.38867\n",
      "Epoch 5367: train_loss=8486.72461, val_loss=8599.77539\n",
      "Epoch 5368: train_loss=8486.14160, val_loss=8599.16016\n",
      "Epoch 5369: train_loss=8485.55859, val_loss=8598.54199\n",
      "Epoch 5370: train_loss=8484.97266, val_loss=8597.91895\n",
      "Epoch 5371: train_loss=8484.38184, val_loss=8597.29785\n",
      "Epoch 5372: train_loss=8483.79004, val_loss=8596.67676\n",
      "Epoch 5373: train_loss=8483.19824, val_loss=8596.05566\n",
      "Epoch 5374: train_loss=8482.60449, val_loss=8595.43457\n",
      "Epoch 5375: train_loss=8482.01074, val_loss=8594.81055\n",
      "Epoch 5376: train_loss=8481.41602, val_loss=8594.18555\n",
      "Epoch 5377: train_loss=8480.82129, val_loss=8593.56152\n",
      "Epoch 5378: train_loss=8480.22559, val_loss=8592.94238\n",
      "Epoch 5379: train_loss=8479.62891, val_loss=8592.32227\n",
      "Epoch 5380: train_loss=8479.02930, val_loss=8591.69531\n",
      "Epoch 5381: train_loss=8478.42480, val_loss=8591.06348\n",
      "Epoch 5382: train_loss=8477.81738, val_loss=8590.42773\n",
      "Epoch 5383: train_loss=8477.20703, val_loss=8589.79102\n",
      "Epoch 5384: train_loss=8476.59375, val_loss=8589.15625\n",
      "Epoch 5385: train_loss=8475.97949, val_loss=8588.52051\n",
      "Epoch 5386: train_loss=8475.36230, val_loss=8587.88574\n",
      "Epoch 5387: train_loss=8474.74805, val_loss=8587.25293\n",
      "Epoch 5388: train_loss=8474.13379, val_loss=8586.61426\n",
      "Epoch 5389: train_loss=8473.51562, val_loss=8585.97656\n",
      "Epoch 5390: train_loss=8472.89844, val_loss=8585.33691\n",
      "Epoch 5391: train_loss=8472.27930, val_loss=8584.69531\n",
      "Epoch 5392: train_loss=8471.65625, val_loss=8584.04980\n",
      "Epoch 5393: train_loss=8471.03027, val_loss=8583.40918\n",
      "Epoch 5394: train_loss=8470.40234, val_loss=8582.76660\n",
      "Epoch 5395: train_loss=8469.78027, val_loss=8582.12500\n",
      "Epoch 5396: train_loss=8469.16602, val_loss=8581.48535\n",
      "Epoch 5397: train_loss=8468.55859, val_loss=8580.86035\n",
      "Epoch 5398: train_loss=8467.95605, val_loss=8580.23730\n",
      "Epoch 5399: train_loss=8467.35742, val_loss=8579.61719\n",
      "Epoch 5400: train_loss=8466.75781, val_loss=8578.99902\n",
      "Epoch 5401: train_loss=8466.16211, val_loss=8578.38086\n",
      "Epoch 5402: train_loss=8465.56836, val_loss=8577.76270\n",
      "Epoch 5403: train_loss=8464.97461, val_loss=8577.14844\n",
      "Epoch 5404: train_loss=8464.38477, val_loss=8576.54492\n",
      "Epoch 5405: train_loss=8463.79980, val_loss=8575.93945\n",
      "Epoch 5406: train_loss=8463.21387, val_loss=8575.33105\n",
      "Epoch 5407: train_loss=8462.62695, val_loss=8574.71875\n",
      "Epoch 5408: train_loss=8462.03809, val_loss=8574.10742\n",
      "Epoch 5409: train_loss=8461.44922, val_loss=8573.49609\n",
      "Epoch 5410: train_loss=8460.85742, val_loss=8572.88281\n",
      "Epoch 5411: train_loss=8460.26465, val_loss=8572.26562\n",
      "Epoch 5412: train_loss=8459.67090, val_loss=8571.64844\n",
      "Epoch 5413: train_loss=8459.07715, val_loss=8571.03125\n",
      "Epoch 5414: train_loss=8458.48145, val_loss=8570.41504\n",
      "Epoch 5415: train_loss=8457.88477, val_loss=8569.79688\n",
      "Epoch 5416: train_loss=8457.28809, val_loss=8569.17578\n",
      "Epoch 5417: train_loss=8456.68848, val_loss=8568.55566\n",
      "Epoch 5418: train_loss=8456.08887, val_loss=8567.93457\n",
      "Epoch 5419: train_loss=8455.48730, val_loss=8567.31152\n",
      "Epoch 5420: train_loss=8454.88086, val_loss=8566.68457\n",
      "Epoch 5421: train_loss=8454.27344, val_loss=8566.06152\n",
      "Epoch 5422: train_loss=8453.66113, val_loss=8565.44141\n",
      "Epoch 5423: train_loss=8453.05078, val_loss=8564.82129\n",
      "Epoch 5424: train_loss=8452.44238, val_loss=8564.20215\n",
      "Epoch 5425: train_loss=8451.83203, val_loss=8563.58398\n",
      "Epoch 5426: train_loss=8451.22070, val_loss=8562.95801\n",
      "Epoch 5427: train_loss=8450.60840, val_loss=8562.33203\n",
      "Epoch 5428: train_loss=8449.99512, val_loss=8561.70703\n",
      "Epoch 5429: train_loss=8449.38184, val_loss=8561.08203\n",
      "Epoch 5430: train_loss=8448.76660, val_loss=8560.45410\n",
      "Epoch 5431: train_loss=8448.15234, val_loss=8559.82129\n",
      "Epoch 5432: train_loss=8447.53613, val_loss=8559.18652\n",
      "Epoch 5433: train_loss=8446.92090, val_loss=8558.55273\n",
      "Epoch 5434: train_loss=8446.30664, val_loss=8557.92090\n",
      "Epoch 5435: train_loss=8445.69141, val_loss=8557.29102\n",
      "Epoch 5436: train_loss=8445.07715, val_loss=8556.65625\n",
      "Epoch 5437: train_loss=8444.46094, val_loss=8556.01660\n",
      "Epoch 5438: train_loss=8443.84375, val_loss=8555.37891\n",
      "Epoch 5439: train_loss=8443.22754, val_loss=8554.74316\n",
      "Epoch 5440: train_loss=8442.60840, val_loss=8554.10547\n",
      "Epoch 5441: train_loss=8441.99121, val_loss=8553.46484\n",
      "Epoch 5442: train_loss=8441.37402, val_loss=8552.82617\n",
      "Epoch 5443: train_loss=8440.75195, val_loss=8552.18457\n",
      "Epoch 5444: train_loss=8440.12793, val_loss=8551.53711\n",
      "Epoch 5445: train_loss=8439.50000, val_loss=8550.88477\n",
      "Epoch 5446: train_loss=8438.86816, val_loss=8550.22559\n",
      "Epoch 5447: train_loss=8438.23438, val_loss=8549.56152\n",
      "Epoch 5448: train_loss=8437.59766, val_loss=8548.90234\n",
      "Epoch 5449: train_loss=8436.96484, val_loss=8548.24805\n",
      "Epoch 5450: train_loss=8436.33398, val_loss=8547.58789\n",
      "Epoch 5451: train_loss=8435.70117, val_loss=8546.92871\n",
      "Epoch 5452: train_loss=8435.06543, val_loss=8546.27051\n",
      "Epoch 5453: train_loss=8434.42969, val_loss=8545.61523\n",
      "Epoch 5454: train_loss=8433.79199, val_loss=8544.95898\n",
      "Epoch 5455: train_loss=8433.15234, val_loss=8544.30762\n",
      "Epoch 5456: train_loss=8432.51465, val_loss=8543.65820\n",
      "Epoch 5457: train_loss=8431.87793, val_loss=8543.01270\n",
      "Epoch 5458: train_loss=8431.24414, val_loss=8542.36328\n",
      "Epoch 5459: train_loss=8430.61426, val_loss=8541.71582\n",
      "Epoch 5460: train_loss=8429.98438, val_loss=8541.06934\n",
      "Epoch 5461: train_loss=8429.35547, val_loss=8540.42188\n",
      "Epoch 5462: train_loss=8428.72559, val_loss=8539.77051\n",
      "Epoch 5463: train_loss=8428.09570, val_loss=8539.12109\n",
      "Epoch 5464: train_loss=8427.46680, val_loss=8538.47070\n",
      "Epoch 5465: train_loss=8426.83691, val_loss=8537.82227\n",
      "Epoch 5466: train_loss=8426.20996, val_loss=8537.17578\n",
      "Epoch 5467: train_loss=8425.58496, val_loss=8536.53027\n",
      "Epoch 5468: train_loss=8424.95801, val_loss=8535.88281\n",
      "Epoch 5469: train_loss=8424.33008, val_loss=8535.23828\n",
      "Epoch 5470: train_loss=8423.70020, val_loss=8534.59863\n",
      "Epoch 5471: train_loss=8423.07031, val_loss=8533.95605\n",
      "Epoch 5472: train_loss=8422.44043, val_loss=8533.31445\n",
      "Epoch 5473: train_loss=8421.80957, val_loss=8532.67285\n",
      "Epoch 5474: train_loss=8421.17773, val_loss=8532.03613\n",
      "Epoch 5475: train_loss=8420.54883, val_loss=8531.39746\n",
      "Epoch 5476: train_loss=8419.91992, val_loss=8530.75586\n",
      "Epoch 5477: train_loss=8419.29102, val_loss=8530.10938\n",
      "Epoch 5478: train_loss=8418.66113, val_loss=8529.46875\n",
      "Epoch 5479: train_loss=8418.03125, val_loss=8528.82910\n",
      "Epoch 5480: train_loss=8417.39941, val_loss=8528.19043\n",
      "Epoch 5481: train_loss=8416.76953, val_loss=8527.54785\n",
      "Epoch 5482: train_loss=8416.13672, val_loss=8526.90527\n",
      "Epoch 5483: train_loss=8415.50488, val_loss=8526.26562\n",
      "Epoch 5484: train_loss=8414.87207, val_loss=8525.62988\n",
      "Epoch 5485: train_loss=8414.23926, val_loss=8524.99414\n",
      "Epoch 5486: train_loss=8413.60938, val_loss=8524.35742\n",
      "Epoch 5487: train_loss=8412.97852, val_loss=8523.71875\n",
      "Epoch 5488: train_loss=8412.34668, val_loss=8523.08301\n",
      "Epoch 5489: train_loss=8411.71680, val_loss=8522.44824\n",
      "Epoch 5490: train_loss=8411.08594, val_loss=8521.81445\n",
      "Epoch 5491: train_loss=8410.45410, val_loss=8521.18066\n",
      "Epoch 5492: train_loss=8409.82129, val_loss=8520.54297\n",
      "Epoch 5493: train_loss=8409.18652, val_loss=8519.90527\n",
      "Epoch 5494: train_loss=8408.55078, val_loss=8519.26953\n",
      "Epoch 5495: train_loss=8407.91211, val_loss=8518.63574\n",
      "Epoch 5496: train_loss=8407.26855, val_loss=8517.99805\n",
      "Epoch 5497: train_loss=8406.62305, val_loss=8517.36328\n",
      "Epoch 5498: train_loss=8405.97754, val_loss=8516.72852\n",
      "Epoch 5499: train_loss=8405.33105, val_loss=8516.09570\n",
      "Epoch 5500: train_loss=8404.68359, val_loss=8515.45898\n",
      "Epoch 5501: train_loss=8404.03418, val_loss=8514.82617\n",
      "Epoch 5502: train_loss=8403.38574, val_loss=8514.19238\n",
      "Epoch 5503: train_loss=8402.73438, val_loss=8513.55566\n",
      "Epoch 5504: train_loss=8402.08301, val_loss=8512.92188\n",
      "Epoch 5505: train_loss=8401.43262, val_loss=8512.28809\n",
      "Epoch 5506: train_loss=8400.78027, val_loss=8511.65332\n",
      "Epoch 5507: train_loss=8400.12891, val_loss=8511.01465\n",
      "Epoch 5508: train_loss=8399.47656, val_loss=8510.37109\n",
      "Epoch 5509: train_loss=8398.82324, val_loss=8509.72852\n",
      "Epoch 5510: train_loss=8398.17090, val_loss=8509.09180\n",
      "Epoch 5511: train_loss=8397.51855, val_loss=8508.45996\n",
      "Epoch 5512: train_loss=8396.87500, val_loss=8507.83789\n",
      "Epoch 5513: train_loss=8396.23828, val_loss=8507.20996\n",
      "Epoch 5514: train_loss=8395.60156, val_loss=8506.57715\n",
      "Epoch 5515: train_loss=8394.96484, val_loss=8505.94336\n",
      "Epoch 5516: train_loss=8394.32715, val_loss=8505.30664\n",
      "Epoch 5517: train_loss=8393.68750, val_loss=8504.66895\n",
      "Epoch 5518: train_loss=8393.04590, val_loss=8504.02930\n",
      "Epoch 5519: train_loss=8392.40332, val_loss=8503.38770\n",
      "Epoch 5520: train_loss=8391.75781, val_loss=8502.73926\n",
      "Epoch 5521: train_loss=8391.11230, val_loss=8502.08789\n",
      "Epoch 5522: train_loss=8390.46484, val_loss=8501.43652\n",
      "Epoch 5523: train_loss=8389.81738, val_loss=8500.78516\n",
      "Epoch 5524: train_loss=8389.16992, val_loss=8500.12988\n",
      "Epoch 5525: train_loss=8388.52148, val_loss=8499.47461\n",
      "Epoch 5526: train_loss=8387.87402, val_loss=8498.82227\n",
      "Epoch 5527: train_loss=8387.22656, val_loss=8498.16699\n",
      "Epoch 5528: train_loss=8386.57910, val_loss=8497.51074\n",
      "Epoch 5529: train_loss=8385.93164, val_loss=8496.85547\n",
      "Epoch 5530: train_loss=8385.28516, val_loss=8496.19922\n",
      "Epoch 5531: train_loss=8384.63574, val_loss=8495.54590\n",
      "Epoch 5532: train_loss=8383.98730, val_loss=8494.88965\n",
      "Epoch 5533: train_loss=8383.33594, val_loss=8494.23340\n",
      "Epoch 5534: train_loss=8382.68262, val_loss=8493.57129\n",
      "Epoch 5535: train_loss=8382.02441, val_loss=8492.90527\n",
      "Epoch 5536: train_loss=8381.36426, val_loss=8492.23633\n",
      "Epoch 5537: train_loss=8380.70117, val_loss=8491.57031\n",
      "Epoch 5538: train_loss=8380.04199, val_loss=8490.90039\n",
      "Epoch 5539: train_loss=8379.37598, val_loss=8490.22949\n",
      "Epoch 5540: train_loss=8378.70703, val_loss=8489.56152\n",
      "Epoch 5541: train_loss=8378.03613, val_loss=8488.89941\n",
      "Epoch 5542: train_loss=8377.36816, val_loss=8488.23828\n",
      "Epoch 5543: train_loss=8376.69922, val_loss=8487.57227\n",
      "Epoch 5544: train_loss=8376.02637, val_loss=8486.90527\n",
      "Epoch 5545: train_loss=8375.35059, val_loss=8486.24414\n",
      "Epoch 5546: train_loss=8374.66992, val_loss=8485.59082\n",
      "Epoch 5547: train_loss=8373.98828, val_loss=8484.93262\n",
      "Epoch 5548: train_loss=8373.30859, val_loss=8484.27148\n",
      "Epoch 5549: train_loss=8372.62695, val_loss=8483.60938\n",
      "Epoch 5550: train_loss=8371.95020, val_loss=8482.95996\n",
      "Epoch 5551: train_loss=8371.28223, val_loss=8482.30273\n",
      "Epoch 5552: train_loss=8370.60742, val_loss=8481.63867\n",
      "Epoch 5553: train_loss=8369.93164, val_loss=8480.97266\n",
      "Epoch 5554: train_loss=8369.25488, val_loss=8480.30371\n",
      "Epoch 5555: train_loss=8368.57520, val_loss=8479.63477\n",
      "Epoch 5556: train_loss=8367.89551, val_loss=8478.96387\n",
      "Epoch 5557: train_loss=8367.21289, val_loss=8478.29102\n",
      "Epoch 5558: train_loss=8366.52930, val_loss=8477.61230\n",
      "Epoch 5559: train_loss=8365.84375, val_loss=8476.93164\n",
      "Epoch 5560: train_loss=8365.15430, val_loss=8476.24023\n",
      "Epoch 5561: train_loss=8364.45996, val_loss=8475.54102\n",
      "Epoch 5562: train_loss=8363.76270, val_loss=8474.83984\n",
      "Epoch 5563: train_loss=8363.06348, val_loss=8474.14160\n",
      "Epoch 5564: train_loss=8362.36133, val_loss=8473.44336\n",
      "Epoch 5565: train_loss=8361.66113, val_loss=8472.73730\n",
      "Epoch 5566: train_loss=8360.96191, val_loss=8472.02344\n",
      "Epoch 5567: train_loss=8360.25977, val_loss=8471.30078\n",
      "Epoch 5568: train_loss=8359.55566, val_loss=8470.58105\n",
      "Epoch 5569: train_loss=8358.84863, val_loss=8469.86328\n",
      "Epoch 5570: train_loss=8358.14160, val_loss=8469.14746\n",
      "Epoch 5571: train_loss=8357.43457, val_loss=8468.43945\n",
      "Epoch 5572: train_loss=8356.73242, val_loss=8467.75391\n",
      "Epoch 5573: train_loss=8356.04980, val_loss=8467.06445\n",
      "Epoch 5574: train_loss=8355.36719, val_loss=8466.36914\n",
      "Epoch 5575: train_loss=8354.68457, val_loss=8465.67188\n",
      "Epoch 5576: train_loss=8354.00098, val_loss=8464.97168\n",
      "Epoch 5577: train_loss=8353.31543, val_loss=8464.26953\n",
      "Epoch 5578: train_loss=8352.63086, val_loss=8463.56738\n",
      "Epoch 5579: train_loss=8351.94727, val_loss=8462.86621\n",
      "Epoch 5580: train_loss=8351.26465, val_loss=8462.16016\n",
      "Epoch 5581: train_loss=8350.58203, val_loss=8461.45117\n",
      "Epoch 5582: train_loss=8349.89648, val_loss=8460.74121\n",
      "Epoch 5583: train_loss=8349.21094, val_loss=8460.02930\n",
      "Epoch 5584: train_loss=8348.51953, val_loss=8459.31836\n",
      "Epoch 5585: train_loss=8347.82910, val_loss=8458.60645\n",
      "Epoch 5586: train_loss=8347.13672, val_loss=8457.89258\n",
      "Epoch 5587: train_loss=8346.44238, val_loss=8457.17285\n",
      "Epoch 5588: train_loss=8345.74707, val_loss=8456.45215\n",
      "Epoch 5589: train_loss=8345.04883, val_loss=8455.72656\n",
      "Epoch 5590: train_loss=8344.34863, val_loss=8455.00098\n",
      "Epoch 5591: train_loss=8343.64941, val_loss=8454.26855\n",
      "Epoch 5592: train_loss=8342.94727, val_loss=8453.52832\n",
      "Epoch 5593: train_loss=8342.23926, val_loss=8452.78906\n",
      "Epoch 5594: train_loss=8341.53223, val_loss=8452.04785\n",
      "Epoch 5595: train_loss=8340.82227, val_loss=8451.30078\n",
      "Epoch 5596: train_loss=8340.11328, val_loss=8450.55273\n",
      "Epoch 5597: train_loss=8339.40527, val_loss=8449.80078\n",
      "Epoch 5598: train_loss=8338.70117, val_loss=8449.04883\n",
      "Epoch 5599: train_loss=8337.99707, val_loss=8448.29883\n",
      "Epoch 5600: train_loss=8337.29980, val_loss=8447.55469\n",
      "Epoch 5601: train_loss=8336.61621, val_loss=8446.81152\n",
      "Epoch 5602: train_loss=8335.93359, val_loss=8446.06543\n",
      "Epoch 5603: train_loss=8335.24805, val_loss=8445.31152\n",
      "Epoch 5604: train_loss=8334.55957, val_loss=8444.56055\n",
      "Epoch 5605: train_loss=8333.87305, val_loss=8443.81055\n",
      "Epoch 5606: train_loss=8333.18750, val_loss=8443.05566\n",
      "Epoch 5607: train_loss=8332.49414, val_loss=8442.29883\n",
      "Epoch 5608: train_loss=8331.79492, val_loss=8441.54004\n",
      "Epoch 5609: train_loss=8331.09375, val_loss=8440.77832\n",
      "Epoch 5610: train_loss=8330.39160, val_loss=8440.01758\n",
      "Epoch 5611: train_loss=8329.68945, val_loss=8439.25293\n",
      "Epoch 5612: train_loss=8328.98535, val_loss=8438.49316\n",
      "Epoch 5613: train_loss=8328.28516, val_loss=8437.73535\n",
      "Epoch 5614: train_loss=8327.58496, val_loss=8436.97559\n",
      "Epoch 5615: train_loss=8326.88184, val_loss=8436.21191\n",
      "Epoch 5616: train_loss=8326.17480, val_loss=8435.44336\n",
      "Epoch 5617: train_loss=8325.46387, val_loss=8434.66699\n",
      "Epoch 5618: train_loss=8324.74316, val_loss=8433.87598\n",
      "Epoch 5619: train_loss=8324.00098, val_loss=8433.07812\n",
      "Epoch 5620: train_loss=8323.24805, val_loss=8432.28027\n",
      "Epoch 5621: train_loss=8322.49805, val_loss=8431.48633\n",
      "Epoch 5622: train_loss=8321.75293, val_loss=8430.69727\n",
      "Epoch 5623: train_loss=8321.01074, val_loss=8429.91602\n",
      "Epoch 5624: train_loss=8320.27539, val_loss=8429.14062\n",
      "Epoch 5625: train_loss=8319.54297, val_loss=8428.36914\n",
      "Epoch 5626: train_loss=8318.81250, val_loss=8427.59863\n",
      "Epoch 5627: train_loss=8318.09180, val_loss=8426.82715\n",
      "Epoch 5628: train_loss=8317.37402, val_loss=8426.05469\n",
      "Epoch 5629: train_loss=8316.65527, val_loss=8425.28320\n",
      "Epoch 5630: train_loss=8315.93945, val_loss=8424.51660\n",
      "Epoch 5631: train_loss=8315.22363, val_loss=8423.75195\n",
      "Epoch 5632: train_loss=8314.50781, val_loss=8422.98438\n",
      "Epoch 5633: train_loss=8313.79102, val_loss=8422.22266\n",
      "Epoch 5634: train_loss=8313.07617, val_loss=8421.46680\n",
      "Epoch 5635: train_loss=8312.36328, val_loss=8420.70996\n",
      "Epoch 5636: train_loss=8311.65527, val_loss=8419.95898\n",
      "Epoch 5637: train_loss=8310.95996, val_loss=8419.20605\n",
      "Epoch 5638: train_loss=8310.26172, val_loss=8418.45605\n",
      "Epoch 5639: train_loss=8309.56543, val_loss=8417.70410\n",
      "Epoch 5640: train_loss=8308.86719, val_loss=8416.94824\n",
      "Epoch 5641: train_loss=8308.16797, val_loss=8416.19336\n",
      "Epoch 5642: train_loss=8307.46875, val_loss=8415.43945\n",
      "Epoch 5643: train_loss=8306.76855, val_loss=8414.68457\n",
      "Epoch 5644: train_loss=8306.06738, val_loss=8413.93066\n",
      "Epoch 5645: train_loss=8305.36719, val_loss=8413.17773\n",
      "Epoch 5646: train_loss=8304.66406, val_loss=8412.42383\n",
      "Epoch 5647: train_loss=8303.96289, val_loss=8411.66602\n",
      "Epoch 5648: train_loss=8303.26074, val_loss=8410.90918\n",
      "Epoch 5649: train_loss=8302.55762, val_loss=8410.15625\n",
      "Epoch 5650: train_loss=8301.85352, val_loss=8409.40039\n",
      "Epoch 5651: train_loss=8301.15039, val_loss=8408.64258\n",
      "Epoch 5652: train_loss=8300.44824, val_loss=8407.88281\n",
      "Epoch 5653: train_loss=8299.74121, val_loss=8407.12109\n",
      "Epoch 5654: train_loss=8299.03125, val_loss=8406.35938\n",
      "Epoch 5655: train_loss=8298.32129, val_loss=8405.59277\n",
      "Epoch 5656: train_loss=8297.61035, val_loss=8404.82422\n",
      "Epoch 5657: train_loss=8296.89941, val_loss=8404.05664\n",
      "Epoch 5658: train_loss=8296.18652, val_loss=8403.28906\n",
      "Epoch 5659: train_loss=8295.47168, val_loss=8402.51855\n",
      "Epoch 5660: train_loss=8294.75684, val_loss=8401.74512\n",
      "Epoch 5661: train_loss=8294.04297, val_loss=8400.96777\n",
      "Epoch 5662: train_loss=8293.32812, val_loss=8400.19727\n",
      "Epoch 5663: train_loss=8292.61621, val_loss=8399.42773\n",
      "Epoch 5664: train_loss=8291.90625, val_loss=8398.65625\n",
      "Epoch 5665: train_loss=8291.19629, val_loss=8397.88379\n",
      "Epoch 5666: train_loss=8290.48926, val_loss=8397.10938\n",
      "Epoch 5667: train_loss=8289.77734, val_loss=8396.33398\n",
      "Epoch 5668: train_loss=8289.06348, val_loss=8395.54980\n",
      "Epoch 5669: train_loss=8288.34375, val_loss=8394.75586\n",
      "Epoch 5670: train_loss=8287.61816, val_loss=8393.95605\n",
      "Epoch 5671: train_loss=8286.88477, val_loss=8393.16309\n",
      "Epoch 5672: train_loss=8286.15332, val_loss=8392.36816\n",
      "Epoch 5673: train_loss=8285.41406, val_loss=8391.57324\n",
      "Epoch 5674: train_loss=8284.67383, val_loss=8390.75488\n",
      "Epoch 5675: train_loss=8283.91895, val_loss=8389.93848\n",
      "Epoch 5676: train_loss=8283.16797, val_loss=8389.12598\n",
      "Epoch 5677: train_loss=8282.42871, val_loss=8388.32031\n",
      "Epoch 5678: train_loss=8281.69434, val_loss=8387.52148\n",
      "Epoch 5679: train_loss=8280.96094, val_loss=8386.72070\n",
      "Epoch 5680: train_loss=8280.22461, val_loss=8385.91211\n",
      "Epoch 5681: train_loss=8279.47949, val_loss=8385.10156\n",
      "Epoch 5682: train_loss=8278.73340, val_loss=8384.28809\n",
      "Epoch 5683: train_loss=8277.98535, val_loss=8383.47852\n",
      "Epoch 5684: train_loss=8277.23828, val_loss=8382.66602\n",
      "Epoch 5685: train_loss=8276.49121, val_loss=8381.85254\n",
      "Epoch 5686: train_loss=8275.74121, val_loss=8381.04492\n",
      "Epoch 5687: train_loss=8274.99805, val_loss=8380.23926\n",
      "Epoch 5688: train_loss=8274.25879, val_loss=8379.43359\n",
      "Epoch 5689: train_loss=8273.52148, val_loss=8378.63184\n",
      "Epoch 5690: train_loss=8272.78418, val_loss=8377.83008\n",
      "Epoch 5691: train_loss=8272.04785, val_loss=8377.03418\n",
      "Epoch 5692: train_loss=8271.31348, val_loss=8376.23730\n",
      "Epoch 5693: train_loss=8270.58301, val_loss=8375.44629\n",
      "Epoch 5694: train_loss=8269.85352, val_loss=8374.66211\n",
      "Epoch 5695: train_loss=8269.12598, val_loss=8373.88086\n",
      "Epoch 5696: train_loss=8268.39844, val_loss=8373.09668\n",
      "Epoch 5697: train_loss=8267.67188, val_loss=8372.31641\n",
      "Epoch 5698: train_loss=8266.94531, val_loss=8371.53418\n",
      "Epoch 5699: train_loss=8266.21973, val_loss=8370.75488\n",
      "Epoch 5700: train_loss=8265.49316, val_loss=8369.97461\n",
      "Epoch 5701: train_loss=8264.76660, val_loss=8369.19238\n",
      "Epoch 5702: train_loss=8264.03906, val_loss=8368.41016\n",
      "Epoch 5703: train_loss=8263.31152, val_loss=8367.63086\n",
      "Epoch 5704: train_loss=8262.58496, val_loss=8366.85156\n",
      "Epoch 5705: train_loss=8261.85840, val_loss=8366.06738\n",
      "Epoch 5706: train_loss=8261.13184, val_loss=8365.28320\n",
      "Epoch 5707: train_loss=8260.40430, val_loss=8364.49902\n",
      "Epoch 5708: train_loss=8259.67578, val_loss=8363.71582\n",
      "Epoch 5709: train_loss=8258.94629, val_loss=8362.92871\n",
      "Epoch 5710: train_loss=8258.21875, val_loss=8362.14551\n",
      "Epoch 5711: train_loss=8257.49121, val_loss=8361.36523\n",
      "Epoch 5712: train_loss=8256.76660, val_loss=8360.58789\n",
      "Epoch 5713: train_loss=8256.04199, val_loss=8359.81152\n",
      "Epoch 5714: train_loss=8255.31738, val_loss=8359.03223\n",
      "Epoch 5715: train_loss=8254.59277, val_loss=8358.25391\n",
      "Epoch 5716: train_loss=8253.86719, val_loss=8357.47656\n",
      "Epoch 5717: train_loss=8253.14258, val_loss=8356.69727\n",
      "Epoch 5718: train_loss=8252.41699, val_loss=8355.91895\n",
      "Epoch 5719: train_loss=8251.69141, val_loss=8355.13867\n",
      "Epoch 5720: train_loss=8250.96582, val_loss=8354.36426\n",
      "Epoch 5721: train_loss=8250.24219, val_loss=8353.58984\n",
      "Epoch 5722: train_loss=8249.51855, val_loss=8352.81641\n",
      "Epoch 5723: train_loss=8248.79590, val_loss=8352.04492\n",
      "Epoch 5724: train_loss=8248.07129, val_loss=8351.26855\n",
      "Epoch 5725: train_loss=8247.34766, val_loss=8350.49414\n",
      "Epoch 5726: train_loss=8246.62305, val_loss=8349.71973\n",
      "Epoch 5727: train_loss=8245.89941, val_loss=8348.94434\n",
      "Epoch 5728: train_loss=8245.17383, val_loss=8348.16797\n",
      "Epoch 5729: train_loss=8244.44727, val_loss=8347.38574\n",
      "Epoch 5730: train_loss=8243.72168, val_loss=8346.60547\n",
      "Epoch 5731: train_loss=8242.99316, val_loss=8345.82617\n",
      "Epoch 5732: train_loss=8242.26660, val_loss=8345.04688\n",
      "Epoch 5733: train_loss=8241.53906, val_loss=8344.26758\n",
      "Epoch 5734: train_loss=8240.81152, val_loss=8343.48535\n",
      "Epoch 5735: train_loss=8240.08398, val_loss=8342.70215\n",
      "Epoch 5736: train_loss=8239.35449, val_loss=8341.91895\n",
      "Epoch 5737: train_loss=8238.62793, val_loss=8341.13770\n",
      "Epoch 5738: train_loss=8237.90039, val_loss=8340.35547\n",
      "Epoch 5739: train_loss=8237.17188, val_loss=8339.56934\n",
      "Epoch 5740: train_loss=8236.44336, val_loss=8338.78613\n",
      "Epoch 5741: train_loss=8235.71484, val_loss=8338.00488\n",
      "Epoch 5742: train_loss=8234.98535, val_loss=8337.22559\n",
      "Epoch 5743: train_loss=8234.25684, val_loss=8336.44727\n",
      "Epoch 5744: train_loss=8233.52637, val_loss=8335.66602\n",
      "Epoch 5745: train_loss=8232.79688, val_loss=8334.88574\n",
      "Epoch 5746: train_loss=8232.06641, val_loss=8334.10840\n",
      "Epoch 5747: train_loss=8231.33496, val_loss=8333.33105\n",
      "Epoch 5748: train_loss=8230.60547, val_loss=8332.55371\n",
      "Epoch 5749: train_loss=8229.87402, val_loss=8331.77441\n",
      "Epoch 5750: train_loss=8229.14355, val_loss=8330.99121\n",
      "Epoch 5751: train_loss=8228.41113, val_loss=8330.20898\n",
      "Epoch 5752: train_loss=8227.67969, val_loss=8329.42676\n",
      "Epoch 5753: train_loss=8226.94629, val_loss=8328.64551\n",
      "Epoch 5754: train_loss=8226.21387, val_loss=8327.86426\n",
      "Epoch 5755: train_loss=8225.48047, val_loss=8327.08301\n",
      "Epoch 5756: train_loss=8224.74609, val_loss=8326.30078\n",
      "Epoch 5757: train_loss=8224.01270, val_loss=8325.51953\n",
      "Epoch 5758: train_loss=8223.27930, val_loss=8324.73633\n",
      "Epoch 5759: train_loss=8222.54492, val_loss=8323.95312\n",
      "Epoch 5760: train_loss=8221.80957, val_loss=8323.16797\n",
      "Epoch 5761: train_loss=8221.07520, val_loss=8322.38477\n",
      "Epoch 5762: train_loss=8220.33887, val_loss=8321.60254\n",
      "Epoch 5763: train_loss=8219.60352, val_loss=8320.82031\n",
      "Epoch 5764: train_loss=8218.86816, val_loss=8320.03711\n",
      "Epoch 5765: train_loss=8218.13184, val_loss=8319.25098\n",
      "Epoch 5766: train_loss=8217.39453, val_loss=8318.46484\n",
      "Epoch 5767: train_loss=8216.65820, val_loss=8317.68066\n",
      "Epoch 5768: train_loss=8215.92090, val_loss=8316.90137\n",
      "Epoch 5769: train_loss=8215.18457, val_loss=8316.12109\n",
      "Epoch 5770: train_loss=8214.44727, val_loss=8315.33789\n",
      "Epoch 5771: train_loss=8213.70898, val_loss=8314.55469\n",
      "Epoch 5772: train_loss=8212.97070, val_loss=8313.77148\n",
      "Epoch 5773: train_loss=8212.23242, val_loss=8312.99121\n",
      "Epoch 5774: train_loss=8211.49316, val_loss=8312.21094\n",
      "Epoch 5775: train_loss=8210.75391, val_loss=8311.42871\n",
      "Epoch 5776: train_loss=8210.01465, val_loss=8310.64453\n",
      "Epoch 5777: train_loss=8209.27246, val_loss=8309.86133\n",
      "Epoch 5778: train_loss=8208.53125, val_loss=8309.07812\n",
      "Epoch 5779: train_loss=8207.78711, val_loss=8308.29785\n",
      "Epoch 5780: train_loss=8207.04492, val_loss=8307.51660\n",
      "Epoch 5781: train_loss=8206.29980, val_loss=8306.73145\n",
      "Epoch 5782: train_loss=8205.55371, val_loss=8305.94336\n",
      "Epoch 5783: train_loss=8204.80664, val_loss=8305.15430\n",
      "Epoch 5784: train_loss=8204.05859, val_loss=8304.36230\n",
      "Epoch 5785: train_loss=8203.30859, val_loss=8303.56934\n",
      "Epoch 5786: train_loss=8202.55664, val_loss=8302.77734\n",
      "Epoch 5787: train_loss=8201.80566, val_loss=8301.97852\n",
      "Epoch 5788: train_loss=8201.05371, val_loss=8301.17871\n",
      "Epoch 5789: train_loss=8200.29883, val_loss=8300.37695\n",
      "Epoch 5790: train_loss=8199.54395, val_loss=8299.57520\n",
      "Epoch 5791: train_loss=8198.78613, val_loss=8298.77051\n",
      "Epoch 5792: train_loss=8198.02734, val_loss=8297.96680\n",
      "Epoch 5793: train_loss=8197.26758, val_loss=8297.16211\n",
      "Epoch 5794: train_loss=8196.50586, val_loss=8296.35547\n",
      "Epoch 5795: train_loss=8195.74121, val_loss=8295.54785\n",
      "Epoch 5796: train_loss=8194.97559, val_loss=8294.73926\n",
      "Epoch 5797: train_loss=8194.20898, val_loss=8293.93164\n",
      "Epoch 5798: train_loss=8193.44043, val_loss=8293.12500\n",
      "Epoch 5799: train_loss=8192.66992, val_loss=8292.31836\n",
      "Epoch 5800: train_loss=8191.89697, val_loss=8291.50977\n",
      "Epoch 5801: train_loss=8191.12158, val_loss=8290.70215\n",
      "Epoch 5802: train_loss=8190.34619, val_loss=8289.89258\n",
      "Epoch 5803: train_loss=8189.56885, val_loss=8289.08301\n",
      "Epoch 5804: train_loss=8188.79053, val_loss=8288.27344\n",
      "Epoch 5805: train_loss=8188.01025, val_loss=8287.46582\n",
      "Epoch 5806: train_loss=8187.22998, val_loss=8286.65430\n",
      "Epoch 5807: train_loss=8186.45068, val_loss=8285.84375\n",
      "Epoch 5808: train_loss=8185.67041, val_loss=8285.03418\n",
      "Epoch 5809: train_loss=8184.88867, val_loss=8284.22363\n",
      "Epoch 5810: train_loss=8184.10498, val_loss=8283.41309\n",
      "Epoch 5811: train_loss=8183.31885, val_loss=8282.60742\n",
      "Epoch 5812: train_loss=8182.53467, val_loss=8281.80566\n",
      "Epoch 5813: train_loss=8181.76074, val_loss=8281.00488\n",
      "Epoch 5814: train_loss=8180.99463, val_loss=8280.20410\n",
      "Epoch 5815: train_loss=8180.22607, val_loss=8279.40137\n",
      "Epoch 5816: train_loss=8179.45508, val_loss=8278.59863\n",
      "Epoch 5817: train_loss=8178.68359, val_loss=8277.79395\n",
      "Epoch 5818: train_loss=8177.91064, val_loss=8276.98438\n",
      "Epoch 5819: train_loss=8177.13623, val_loss=8276.17285\n",
      "Epoch 5820: train_loss=8176.35938, val_loss=8275.35840\n",
      "Epoch 5821: train_loss=8175.58301, val_loss=8274.54492\n",
      "Epoch 5822: train_loss=8174.80420, val_loss=8273.73145\n",
      "Epoch 5823: train_loss=8174.02539, val_loss=8272.91797\n",
      "Epoch 5824: train_loss=8173.24512, val_loss=8272.10645\n",
      "Epoch 5825: train_loss=8172.47021, val_loss=8271.29395\n",
      "Epoch 5826: train_loss=8171.69434, val_loss=8270.47949\n",
      "Epoch 5827: train_loss=8170.91895, val_loss=8269.66504\n",
      "Epoch 5828: train_loss=8170.14551, val_loss=8268.84766\n",
      "Epoch 5829: train_loss=8169.37012, val_loss=8268.03027\n",
      "Epoch 5830: train_loss=8168.59570, val_loss=8267.21289\n",
      "Epoch 5831: train_loss=8167.81982, val_loss=8266.39355\n",
      "Epoch 5832: train_loss=8167.04248, val_loss=8265.57227\n",
      "Epoch 5833: train_loss=8166.26465, val_loss=8264.74707\n",
      "Epoch 5834: train_loss=8165.48340, val_loss=8263.92090\n",
      "Epoch 5835: train_loss=8164.70068, val_loss=8263.09375\n",
      "Epoch 5836: train_loss=8163.92236, val_loss=8262.26855\n",
      "Epoch 5837: train_loss=8163.14648, val_loss=8261.43848\n",
      "Epoch 5838: train_loss=8162.37012, val_loss=8260.60840\n",
      "Epoch 5839: train_loss=8161.59131, val_loss=8259.77441\n",
      "Epoch 5840: train_loss=8160.80908, val_loss=8258.93750\n",
      "Epoch 5841: train_loss=8160.02295, val_loss=8258.10156\n",
      "Epoch 5842: train_loss=8159.23486, val_loss=8257.26660\n",
      "Epoch 5843: train_loss=8158.44824, val_loss=8256.43164\n",
      "Epoch 5844: train_loss=8157.66455, val_loss=8255.60059\n",
      "Epoch 5845: train_loss=8156.88281, val_loss=8254.77051\n",
      "Epoch 5846: train_loss=8156.09814, val_loss=8253.93457\n",
      "Epoch 5847: train_loss=8155.30615, val_loss=8253.09961\n",
      "Epoch 5848: train_loss=8154.50977, val_loss=8252.26270\n",
      "Epoch 5849: train_loss=8153.71338, val_loss=8251.42480\n",
      "Epoch 5850: train_loss=8152.91455, val_loss=8250.58301\n",
      "Epoch 5851: train_loss=8152.11572, val_loss=8249.75000\n",
      "Epoch 5852: train_loss=8151.31836, val_loss=8248.92188\n",
      "Epoch 5853: train_loss=8150.52295, val_loss=8248.09375\n",
      "Epoch 5854: train_loss=8149.73047, val_loss=8247.26367\n",
      "Epoch 5855: train_loss=8148.93457, val_loss=8246.43262\n",
      "Epoch 5856: train_loss=8148.13672, val_loss=8245.60547\n",
      "Epoch 5857: train_loss=8147.34277, val_loss=8244.78027\n",
      "Epoch 5858: train_loss=8146.55225, val_loss=8243.95410\n",
      "Epoch 5859: train_loss=8145.76416, val_loss=8243.12109\n",
      "Epoch 5860: train_loss=8144.97070, val_loss=8242.28125\n",
      "Epoch 5861: train_loss=8144.17383, val_loss=8241.44336\n",
      "Epoch 5862: train_loss=8143.37842, val_loss=8240.60645\n",
      "Epoch 5863: train_loss=8142.58105, val_loss=8239.76855\n",
      "Epoch 5864: train_loss=8141.78369, val_loss=8238.93066\n",
      "Epoch 5865: train_loss=8140.98486, val_loss=8238.09180\n",
      "Epoch 5866: train_loss=8140.18555, val_loss=8237.25195\n",
      "Epoch 5867: train_loss=8139.38281, val_loss=8236.41016\n",
      "Epoch 5868: train_loss=8138.58008, val_loss=8235.56152\n",
      "Epoch 5869: train_loss=8137.77197, val_loss=8234.71191\n",
      "Epoch 5870: train_loss=8136.95996, val_loss=8233.86133\n",
      "Epoch 5871: train_loss=8136.14600, val_loss=8233.00781\n",
      "Epoch 5872: train_loss=8135.32812, val_loss=8232.15332\n",
      "Epoch 5873: train_loss=8134.50830, val_loss=8231.29492\n",
      "Epoch 5874: train_loss=8133.68506, val_loss=8230.43555\n",
      "Epoch 5875: train_loss=8132.85693, val_loss=8229.57129\n",
      "Epoch 5876: train_loss=8132.02637, val_loss=8228.70605\n",
      "Epoch 5877: train_loss=8131.19385, val_loss=8227.84375\n",
      "Epoch 5878: train_loss=8130.35840, val_loss=8226.98242\n",
      "Epoch 5879: train_loss=8129.52148, val_loss=8226.12109\n",
      "Epoch 5880: train_loss=8128.68408, val_loss=8225.25879\n",
      "Epoch 5881: train_loss=8127.84717, val_loss=8224.39746\n",
      "Epoch 5882: train_loss=8127.01562, val_loss=8223.54688\n",
      "Epoch 5883: train_loss=8126.18652, val_loss=8222.69629\n",
      "Epoch 5884: train_loss=8125.35693, val_loss=8221.84180\n",
      "Epoch 5885: train_loss=8124.52734, val_loss=8220.97949\n",
      "Epoch 5886: train_loss=8123.69238, val_loss=8220.11426\n",
      "Epoch 5887: train_loss=8122.85400, val_loss=8219.24609\n",
      "Epoch 5888: train_loss=8122.01318, val_loss=8218.37012\n",
      "Epoch 5889: train_loss=8121.16895, val_loss=8217.49414\n",
      "Epoch 5890: train_loss=8120.32568, val_loss=8216.61914\n",
      "Epoch 5891: train_loss=8119.48096, val_loss=8215.74512\n",
      "Epoch 5892: train_loss=8118.63477, val_loss=8214.87207\n",
      "Epoch 5893: train_loss=8117.78418, val_loss=8213.99609\n",
      "Epoch 5894: train_loss=8116.93311, val_loss=8213.11914\n",
      "Epoch 5895: train_loss=8116.08203, val_loss=8212.23535\n",
      "Epoch 5896: train_loss=8115.22803, val_loss=8211.35352\n",
      "Epoch 5897: train_loss=8114.37402, val_loss=8210.47070\n",
      "Epoch 5898: train_loss=8113.51904, val_loss=8209.58594\n",
      "Epoch 5899: train_loss=8112.66650, val_loss=8208.69922\n",
      "Epoch 5900: train_loss=8111.81689, val_loss=8207.80762\n",
      "Epoch 5901: train_loss=8110.96338, val_loss=8206.91211\n",
      "Epoch 5902: train_loss=8110.10938, val_loss=8206.01270\n",
      "Epoch 5903: train_loss=8109.25586, val_loss=8205.11035\n",
      "Epoch 5904: train_loss=8108.40186, val_loss=8204.20410\n",
      "Epoch 5905: train_loss=8107.54639, val_loss=8203.29590\n",
      "Epoch 5906: train_loss=8106.68945, val_loss=8202.38281\n",
      "Epoch 5907: train_loss=8105.83252, val_loss=8201.46680\n",
      "Epoch 5908: train_loss=8104.97510, val_loss=8200.54590\n",
      "Epoch 5909: train_loss=8104.11475, val_loss=8199.62109\n",
      "Epoch 5910: train_loss=8103.25342, val_loss=8198.70215\n",
      "Epoch 5911: train_loss=8102.39795, val_loss=8197.79492\n",
      "Epoch 5912: train_loss=8101.54736, val_loss=8196.88770\n",
      "Epoch 5913: train_loss=8100.69629, val_loss=8195.97949\n",
      "Epoch 5914: train_loss=8099.84521, val_loss=8195.07031\n",
      "Epoch 5915: train_loss=8098.99316, val_loss=8194.16309\n",
      "Epoch 5916: train_loss=8098.14209, val_loss=8193.25391\n",
      "Epoch 5917: train_loss=8097.28857, val_loss=8192.34277\n",
      "Epoch 5918: train_loss=8096.43262, val_loss=8191.43164\n",
      "Epoch 5919: train_loss=8095.57324, val_loss=8190.51904\n",
      "Epoch 5920: train_loss=8094.71338, val_loss=8189.60449\n",
      "Epoch 5921: train_loss=8093.85254, val_loss=8188.68408\n",
      "Epoch 5922: train_loss=8092.98633, val_loss=8187.76367\n",
      "Epoch 5923: train_loss=8092.11914, val_loss=8186.84131\n",
      "Epoch 5924: train_loss=8091.25293, val_loss=8185.91895\n",
      "Epoch 5925: train_loss=8090.38574, val_loss=8184.99365\n",
      "Epoch 5926: train_loss=8089.51904, val_loss=8184.06396\n",
      "Epoch 5927: train_loss=8088.64795, val_loss=8183.13037\n",
      "Epoch 5928: train_loss=8087.77197, val_loss=8182.19531\n",
      "Epoch 5929: train_loss=8086.89600, val_loss=8181.25781\n",
      "Epoch 5930: train_loss=8086.01514, val_loss=8180.31299\n",
      "Epoch 5931: train_loss=8085.13232, val_loss=8179.36963\n",
      "Epoch 5932: train_loss=8084.25391, val_loss=8178.43066\n",
      "Epoch 5933: train_loss=8083.38867, val_loss=8177.49463\n",
      "Epoch 5934: train_loss=8082.52686, val_loss=8176.55469\n",
      "Epoch 5935: train_loss=8081.66602, val_loss=8175.61084\n",
      "Epoch 5936: train_loss=8080.80127, val_loss=8174.66357\n",
      "Epoch 5937: train_loss=8079.93018, val_loss=8173.71436\n",
      "Epoch 5938: train_loss=8079.05762, val_loss=8172.76123\n",
      "Epoch 5939: train_loss=8078.18408, val_loss=8171.80566\n",
      "Epoch 5940: train_loss=8077.31006, val_loss=8170.85010\n",
      "Epoch 5941: train_loss=8076.43408, val_loss=8169.89111\n",
      "Epoch 5942: train_loss=8075.55713, val_loss=8168.93115\n",
      "Epoch 5943: train_loss=8074.67725, val_loss=8167.96729\n",
      "Epoch 5944: train_loss=8073.79541, val_loss=8167.00000\n",
      "Epoch 5945: train_loss=8072.91064, val_loss=8166.03125\n",
      "Epoch 5946: train_loss=8072.02588, val_loss=8165.06592\n",
      "Epoch 5947: train_loss=8071.13770, val_loss=8164.10400\n",
      "Epoch 5948: train_loss=8070.24951, val_loss=8163.14160\n",
      "Epoch 5949: train_loss=8069.35938, val_loss=8162.17773\n",
      "Epoch 5950: train_loss=8068.46826, val_loss=8161.21338\n",
      "Epoch 5951: train_loss=8067.57324, val_loss=8160.25342\n",
      "Epoch 5952: train_loss=8066.67822, val_loss=8159.29980\n",
      "Epoch 5953: train_loss=8065.79248, val_loss=8158.34473\n",
      "Epoch 5954: train_loss=8064.91553, val_loss=8157.39209\n",
      "Epoch 5955: train_loss=8064.03857, val_loss=8156.44092\n",
      "Epoch 5956: train_loss=8063.16309, val_loss=8155.49170\n",
      "Epoch 5957: train_loss=8062.28711, val_loss=8154.54053\n",
      "Epoch 5958: train_loss=8061.40918, val_loss=8153.59082\n",
      "Epoch 5959: train_loss=8060.52930, val_loss=8152.64453\n",
      "Epoch 5960: train_loss=8059.65088, val_loss=8151.69775\n",
      "Epoch 5961: train_loss=8058.76660, val_loss=8150.74658\n",
      "Epoch 5962: train_loss=8057.87744, val_loss=8149.79639\n",
      "Epoch 5963: train_loss=8056.98633, val_loss=8148.84521\n",
      "Epoch 5964: train_loss=8056.09277, val_loss=8147.88965\n",
      "Epoch 5965: train_loss=8055.19580, val_loss=8146.93262\n",
      "Epoch 5966: train_loss=8054.29639, val_loss=8145.97754\n",
      "Epoch 5967: train_loss=8053.39551, val_loss=8145.02441\n",
      "Epoch 5968: train_loss=8052.49219, val_loss=8144.07422\n",
      "Epoch 5969: train_loss=8051.58594, val_loss=8143.12451\n",
      "Epoch 5970: train_loss=8050.67383, val_loss=8142.17871\n",
      "Epoch 5971: train_loss=8049.75781, val_loss=8141.23291\n",
      "Epoch 5972: train_loss=8048.83887, val_loss=8140.28662\n",
      "Epoch 5973: train_loss=8047.91943, val_loss=8139.33496\n",
      "Epoch 5974: train_loss=8046.99805, val_loss=8138.37891\n",
      "Epoch 5975: train_loss=8046.07373, val_loss=8137.42627\n",
      "Epoch 5976: train_loss=8045.14941, val_loss=8136.47949\n",
      "Epoch 5977: train_loss=8044.23291, val_loss=8135.52441\n",
      "Epoch 5978: train_loss=8043.31055, val_loss=8134.56299\n",
      "Epoch 5979: train_loss=8042.38428, val_loss=8133.59961\n",
      "Epoch 5980: train_loss=8041.46680, val_loss=8132.63184\n",
      "Epoch 5981: train_loss=8040.55176, val_loss=8131.66895\n",
      "Epoch 5982: train_loss=8039.63721, val_loss=8130.70410\n",
      "Epoch 5983: train_loss=8038.72266, val_loss=8129.74170\n",
      "Epoch 5984: train_loss=8037.80566, val_loss=8128.77881\n",
      "Epoch 5985: train_loss=8036.88965, val_loss=8127.80908\n",
      "Epoch 5986: train_loss=8035.97314, val_loss=8126.83398\n",
      "Epoch 5987: train_loss=8035.05273, val_loss=8125.85400\n",
      "Epoch 5988: train_loss=8034.12842, val_loss=8124.87549\n",
      "Epoch 5989: train_loss=8033.20117, val_loss=8123.89648\n",
      "Epoch 5990: train_loss=8032.27197, val_loss=8122.91895\n",
      "Epoch 5991: train_loss=8031.33936, val_loss=8121.94189\n",
      "Epoch 5992: train_loss=8030.40527, val_loss=8120.96582\n",
      "Epoch 5993: train_loss=8029.46875, val_loss=8119.99121\n",
      "Epoch 5994: train_loss=8028.53125, val_loss=8119.02100\n",
      "Epoch 5995: train_loss=8027.59326, val_loss=8118.05371\n",
      "Epoch 5996: train_loss=8026.65430, val_loss=8117.08496\n",
      "Epoch 5997: train_loss=8025.71338, val_loss=8116.13428\n",
      "Epoch 5998: train_loss=8024.78516, val_loss=8115.18311\n",
      "Epoch 5999: train_loss=8023.85889, val_loss=8114.23389\n",
      "Epoch 6000: train_loss=8022.93311, val_loss=8113.28369\n",
      "Epoch 6001: train_loss=8022.00684, val_loss=8112.33252\n",
      "Epoch 6002: train_loss=8021.08105, val_loss=8111.37939\n",
      "Epoch 6003: train_loss=8020.15430, val_loss=8110.42773\n",
      "Epoch 6004: train_loss=8019.22949, val_loss=8109.47021\n",
      "Epoch 6005: train_loss=8018.30566, val_loss=8108.51074\n",
      "Epoch 6006: train_loss=8017.38428, val_loss=8107.54883\n",
      "Epoch 6007: train_loss=8016.46436, val_loss=8106.58154\n",
      "Epoch 6008: train_loss=8015.54346, val_loss=8105.61133\n",
      "Epoch 6009: train_loss=8014.62158, val_loss=8104.64355\n",
      "Epoch 6010: train_loss=8013.69727, val_loss=8103.68115\n",
      "Epoch 6011: train_loss=8012.77344, val_loss=8102.71631\n",
      "Epoch 6012: train_loss=8011.84912, val_loss=8101.74609\n",
      "Epoch 6013: train_loss=8010.92432, val_loss=8100.77344\n",
      "Epoch 6014: train_loss=8009.99463, val_loss=8099.78711\n",
      "Epoch 6015: train_loss=8009.05762, val_loss=8098.79102\n",
      "Epoch 6016: train_loss=8008.11084, val_loss=8097.78320\n",
      "Epoch 6017: train_loss=8007.15820, val_loss=8096.77441\n",
      "Epoch 6018: train_loss=8006.20361, val_loss=8095.76611\n",
      "Epoch 6019: train_loss=8005.24902, val_loss=8094.75244\n",
      "Epoch 6020: train_loss=8004.29102, val_loss=8093.72510\n",
      "Epoch 6021: train_loss=8003.31787, val_loss=8092.65381\n",
      "Epoch 6022: train_loss=8002.30762, val_loss=8091.60400\n",
      "Epoch 6023: train_loss=8001.32373, val_loss=8090.58008\n",
      "Epoch 6024: train_loss=8000.37354, val_loss=8089.56592\n",
      "Epoch 6025: train_loss=7999.43408, val_loss=8088.56055\n",
      "Epoch 6026: train_loss=7998.50439, val_loss=8087.55518\n",
      "Epoch 6027: train_loss=7997.57764, val_loss=8086.54785\n",
      "Epoch 6028: train_loss=7996.65283, val_loss=8085.54248\n",
      "Epoch 6029: train_loss=7995.72900, val_loss=8084.52783\n",
      "Epoch 6030: train_loss=7994.79883, val_loss=8083.50830\n",
      "Epoch 6031: train_loss=7993.86230, val_loss=8082.48584\n",
      "Epoch 6032: train_loss=7992.92383, val_loss=8081.46143\n",
      "Epoch 6033: train_loss=7991.98438, val_loss=8080.43164\n",
      "Epoch 6034: train_loss=7991.04150, val_loss=8079.39014\n",
      "Epoch 6035: train_loss=7990.09619, val_loss=8078.34619\n",
      "Epoch 6036: train_loss=7989.14844, val_loss=8077.30127\n",
      "Epoch 6037: train_loss=7988.19873, val_loss=8076.25781\n",
      "Epoch 6038: train_loss=7987.24854, val_loss=8075.21387\n",
      "Epoch 6039: train_loss=7986.29883, val_loss=8074.16797\n",
      "Epoch 6040: train_loss=7985.34619, val_loss=8073.12012\n",
      "Epoch 6041: train_loss=7984.39209, val_loss=8072.06641\n",
      "Epoch 6042: train_loss=7983.43457, val_loss=8071.00879\n",
      "Epoch 6043: train_loss=7982.47656, val_loss=8069.94971\n",
      "Epoch 6044: train_loss=7981.51709, val_loss=8068.88965\n",
      "Epoch 6045: train_loss=7980.55566, val_loss=8067.82861\n",
      "Epoch 6046: train_loss=7979.59180, val_loss=8066.76904\n",
      "Epoch 6047: train_loss=7978.62939, val_loss=8065.71045\n",
      "Epoch 6048: train_loss=7977.66699, val_loss=8064.65137\n",
      "Epoch 6049: train_loss=7976.70410, val_loss=8063.60352\n",
      "Epoch 6050: train_loss=7975.75244, val_loss=8062.56494\n",
      "Epoch 6051: train_loss=7974.81885, val_loss=8061.52588\n",
      "Epoch 6052: train_loss=7973.88281, val_loss=8060.48877\n",
      "Epoch 6053: train_loss=7972.94580, val_loss=8059.44824\n",
      "Epoch 6054: train_loss=7972.00635, val_loss=8058.40674\n",
      "Epoch 6055: train_loss=7971.06641, val_loss=8057.36768\n",
      "Epoch 6056: train_loss=7970.12451, val_loss=8056.34521\n",
      "Epoch 6057: train_loss=7969.18799, val_loss=8055.33008\n",
      "Epoch 6058: train_loss=7968.25684, val_loss=8054.31543\n",
      "Epoch 6059: train_loss=7967.32617, val_loss=8053.30176\n",
      "Epoch 6060: train_loss=7966.39795, val_loss=8052.28809\n",
      "Epoch 6061: train_loss=7965.47021, val_loss=8051.27344\n",
      "Epoch 6062: train_loss=7964.54150, val_loss=8050.25879\n",
      "Epoch 6063: train_loss=7963.61133, val_loss=8049.24170\n",
      "Epoch 6064: train_loss=7962.67578, val_loss=8048.22314\n",
      "Epoch 6065: train_loss=7961.74072, val_loss=8047.20312\n",
      "Epoch 6066: train_loss=7960.80176, val_loss=8046.18164\n",
      "Epoch 6067: train_loss=7959.86182, val_loss=8045.16406\n",
      "Epoch 6068: train_loss=7958.92188, val_loss=8044.14551\n",
      "Epoch 6069: train_loss=7957.98096, val_loss=8043.12891\n",
      "Epoch 6070: train_loss=7957.03857, val_loss=8042.11279\n",
      "Epoch 6071: train_loss=7956.09570, val_loss=8041.09668\n",
      "Epoch 6072: train_loss=7955.15137, val_loss=8040.07861\n",
      "Epoch 6073: train_loss=7954.20605, val_loss=8039.06006\n",
      "Epoch 6074: train_loss=7953.26221, val_loss=8038.04004\n",
      "Epoch 6075: train_loss=7952.31787, val_loss=8037.02148\n",
      "Epoch 6076: train_loss=7951.37158, val_loss=8035.99951\n",
      "Epoch 6077: train_loss=7950.42578, val_loss=8034.97559\n",
      "Epoch 6078: train_loss=7949.47754, val_loss=8033.95020\n",
      "Epoch 6079: train_loss=7948.52881, val_loss=8032.92383\n",
      "Epoch 6080: train_loss=7947.58154, val_loss=8031.89697\n",
      "Epoch 6081: train_loss=7946.63281, val_loss=8030.86670\n",
      "Epoch 6082: train_loss=7945.68262, val_loss=8029.83643\n",
      "Epoch 6083: train_loss=7944.73145, val_loss=8028.80518\n",
      "Epoch 6084: train_loss=7943.77881, val_loss=8027.77295\n",
      "Epoch 6085: train_loss=7942.82373, val_loss=8026.74658\n",
      "Epoch 6086: train_loss=7941.86816, val_loss=8025.72363\n",
      "Epoch 6087: train_loss=7940.91211, val_loss=8024.70215\n",
      "Epoch 6088: train_loss=7939.95410, val_loss=8023.68018\n",
      "Epoch 6089: train_loss=7938.99463, val_loss=8022.66309\n",
      "Epoch 6090: train_loss=7938.03662, val_loss=8021.64404\n",
      "Epoch 6091: train_loss=7937.08008, val_loss=8020.62256\n",
      "Epoch 6092: train_loss=7936.12109, val_loss=8019.59912\n",
      "Epoch 6093: train_loss=7935.16016, val_loss=8018.57275\n",
      "Epoch 6094: train_loss=7934.19922, val_loss=8017.54590\n",
      "Epoch 6095: train_loss=7933.23633, val_loss=8016.51807\n",
      "Epoch 6096: train_loss=7932.27344, val_loss=8015.48682\n",
      "Epoch 6097: train_loss=7931.30762, val_loss=8014.45264\n",
      "Epoch 6098: train_loss=7930.34229, val_loss=8013.41748\n",
      "Epoch 6099: train_loss=7929.37793, val_loss=8012.37939\n",
      "Epoch 6100: train_loss=7928.41162, val_loss=8011.34033\n",
      "Epoch 6101: train_loss=7927.44434, val_loss=8010.30127\n",
      "Epoch 6102: train_loss=7926.47559, val_loss=8009.26172\n",
      "Epoch 6103: train_loss=7925.50879, val_loss=8008.22266\n",
      "Epoch 6104: train_loss=7924.54248, val_loss=8007.19043\n",
      "Epoch 6105: train_loss=7923.58447, val_loss=8006.16162\n",
      "Epoch 6106: train_loss=7922.62842, val_loss=8005.13379\n",
      "Epoch 6107: train_loss=7921.66992, val_loss=8004.10352\n",
      "Epoch 6108: train_loss=7920.70898, val_loss=8003.07812\n",
      "Epoch 6109: train_loss=7919.74414, val_loss=8002.05664\n",
      "Epoch 6110: train_loss=7918.77490, val_loss=8001.03516\n",
      "Epoch 6111: train_loss=7917.80371, val_loss=8000.01611\n",
      "Epoch 6112: train_loss=7916.83105, val_loss=7999.00000\n",
      "Epoch 6113: train_loss=7915.85352, val_loss=7997.98730\n",
      "Epoch 6114: train_loss=7914.87744, val_loss=7996.97803\n",
      "Epoch 6115: train_loss=7913.90430, val_loss=7995.97168\n",
      "Epoch 6116: train_loss=7912.93066, val_loss=7994.96777\n",
      "Epoch 6117: train_loss=7911.95898, val_loss=7993.95996\n",
      "Epoch 6118: train_loss=7910.99219, val_loss=7992.94873\n",
      "Epoch 6119: train_loss=7910.02344, val_loss=7991.93213\n",
      "Epoch 6120: train_loss=7909.05127, val_loss=7990.91113\n",
      "Epoch 6121: train_loss=7908.07812, val_loss=7989.88086\n",
      "Epoch 6122: train_loss=7907.09863, val_loss=7988.84961\n",
      "Epoch 6123: train_loss=7906.11914, val_loss=7987.81885\n",
      "Epoch 6124: train_loss=7905.13867, val_loss=7986.78711\n",
      "Epoch 6125: train_loss=7904.15430, val_loss=7985.75439\n",
      "Epoch 6126: train_loss=7903.16895, val_loss=7984.72021\n",
      "Epoch 6127: train_loss=7902.18164, val_loss=7983.68115\n",
      "Epoch 6128: train_loss=7901.19238, val_loss=7982.64404\n",
      "Epoch 6129: train_loss=7900.20459, val_loss=7981.60498\n",
      "Epoch 6130: train_loss=7899.21436, val_loss=7980.56592\n",
      "Epoch 6131: train_loss=7898.22510, val_loss=7979.52832\n",
      "Epoch 6132: train_loss=7897.23340, val_loss=7978.48242\n",
      "Epoch 6133: train_loss=7896.23633, val_loss=7977.42871\n",
      "Epoch 6134: train_loss=7895.23096, val_loss=7976.38037\n",
      "Epoch 6135: train_loss=7894.22559, val_loss=7975.33350\n",
      "Epoch 6136: train_loss=7893.22021, val_loss=7974.28662\n",
      "Epoch 6137: train_loss=7892.21484, val_loss=7973.21777\n",
      "Epoch 6138: train_loss=7891.19873, val_loss=7972.14697\n",
      "Epoch 6139: train_loss=7890.18555, val_loss=7971.07471\n",
      "Epoch 6140: train_loss=7889.17480, val_loss=7969.99658\n",
      "Epoch 6141: train_loss=7888.16113, val_loss=7968.91357\n",
      "Epoch 6142: train_loss=7887.14355, val_loss=7967.82812\n",
      "Epoch 6143: train_loss=7886.12207, val_loss=7966.73633\n",
      "Epoch 6144: train_loss=7885.09473, val_loss=7965.64697\n",
      "Epoch 6145: train_loss=7884.06592, val_loss=7964.55322\n",
      "Epoch 6146: train_loss=7883.03223, val_loss=7963.45557\n",
      "Epoch 6147: train_loss=7881.99268, val_loss=7962.34814\n",
      "Epoch 6148: train_loss=7880.94482, val_loss=7961.24121\n",
      "Epoch 6149: train_loss=7879.89502, val_loss=7960.13232\n",
      "Epoch 6150: train_loss=7878.84326, val_loss=7959.02490\n",
      "Epoch 6151: train_loss=7877.79199, val_loss=7957.93799\n",
      "Epoch 6152: train_loss=7876.75488, val_loss=7956.85010\n",
      "Epoch 6153: train_loss=7875.72021, val_loss=7955.76074\n",
      "Epoch 6154: train_loss=7874.68115, val_loss=7954.67188\n",
      "Epoch 6155: train_loss=7873.64209, val_loss=7953.58984\n",
      "Epoch 6156: train_loss=7872.59863, val_loss=7952.51074\n",
      "Epoch 6157: train_loss=7871.55322, val_loss=7951.42773\n",
      "Epoch 6158: train_loss=7870.50488, val_loss=7950.31787\n",
      "Epoch 6159: train_loss=7869.44775, val_loss=7949.19922\n",
      "Epoch 6160: train_loss=7868.38672, val_loss=7948.06641\n",
      "Epoch 6161: train_loss=7867.32227, val_loss=7946.90771\n",
      "Epoch 6162: train_loss=7866.23975, val_loss=7945.72803\n",
      "Epoch 6163: train_loss=7865.11963, val_loss=7944.53857\n",
      "Epoch 6164: train_loss=7863.98438, val_loss=7943.33887\n",
      "Epoch 6165: train_loss=7862.85791, val_loss=7942.12891\n",
      "Epoch 6166: train_loss=7861.71826, val_loss=7940.91846\n",
      "Epoch 6167: train_loss=7860.57178, val_loss=7939.70215\n",
      "Epoch 6168: train_loss=7859.41504, val_loss=7938.48096\n",
      "Epoch 6169: train_loss=7858.24756, val_loss=7937.26660\n",
      "Epoch 6170: train_loss=7857.08301, val_loss=7936.04785\n",
      "Epoch 6171: train_loss=7855.91309, val_loss=7934.82227\n",
      "Epoch 6172: train_loss=7854.73486, val_loss=7933.59326\n",
      "Epoch 6173: train_loss=7853.55273, val_loss=7932.35938\n",
      "Epoch 6174: train_loss=7852.37842, val_loss=7931.11963\n",
      "Epoch 6175: train_loss=7851.20312, val_loss=7929.87109\n",
      "Epoch 6176: train_loss=7850.02295, val_loss=7928.61475\n",
      "Epoch 6177: train_loss=7848.83789, val_loss=7927.35498\n",
      "Epoch 6178: train_loss=7847.65430, val_loss=7926.09277\n",
      "Epoch 6179: train_loss=7846.47119, val_loss=7924.84521\n",
      "Epoch 6180: train_loss=7845.31494, val_loss=7923.60156\n",
      "Epoch 6181: train_loss=7844.14600, val_loss=7922.35791\n",
      "Epoch 6182: train_loss=7842.97754, val_loss=7921.11865\n",
      "Epoch 6183: train_loss=7841.81152, val_loss=7919.88086\n",
      "Epoch 6184: train_loss=7840.64746, val_loss=7918.64209\n",
      "Epoch 6185: train_loss=7839.49219, val_loss=7917.38965\n",
      "Epoch 6186: train_loss=7838.33301, val_loss=7916.13574\n",
      "Epoch 6187: train_loss=7837.17773, val_loss=7914.88232\n",
      "Epoch 6188: train_loss=7836.03174, val_loss=7913.67090\n",
      "Epoch 6189: train_loss=7834.90918, val_loss=7912.45166\n",
      "Epoch 6190: train_loss=7833.78369, val_loss=7911.22803\n",
      "Epoch 6191: train_loss=7832.65186, val_loss=7910.00488\n",
      "Epoch 6192: train_loss=7831.52051, val_loss=7908.78369\n",
      "Epoch 6193: train_loss=7830.38477, val_loss=7907.55273\n",
      "Epoch 6194: train_loss=7829.23877, val_loss=7906.32178\n",
      "Epoch 6195: train_loss=7828.09131, val_loss=7905.08887\n",
      "Epoch 6196: train_loss=7826.94189, val_loss=7903.85254\n",
      "Epoch 6197: train_loss=7825.78662, val_loss=7902.61084\n",
      "Epoch 6198: train_loss=7824.62061, val_loss=7901.36865\n",
      "Epoch 6199: train_loss=7823.46045, val_loss=7900.12988\n",
      "Epoch 6200: train_loss=7822.30713, val_loss=7898.88867\n",
      "Epoch 6201: train_loss=7821.15625, val_loss=7897.64502\n",
      "Epoch 6202: train_loss=7820.00830, val_loss=7896.39697\n",
      "Epoch 6203: train_loss=7818.85938, val_loss=7895.14307\n",
      "Epoch 6204: train_loss=7817.70996, val_loss=7893.87842\n",
      "Epoch 6205: train_loss=7816.55322, val_loss=7892.61133\n",
      "Epoch 6206: train_loss=7815.39258, val_loss=7891.34326\n",
      "Epoch 6207: train_loss=7814.22510, val_loss=7890.07373\n",
      "Epoch 6208: train_loss=7813.05127, val_loss=7888.80176\n",
      "Epoch 6209: train_loss=7811.87354, val_loss=7887.53076\n",
      "Epoch 6210: train_loss=7810.69629, val_loss=7886.26709\n",
      "Epoch 6211: train_loss=7809.52441, val_loss=7885.01562\n",
      "Epoch 6212: train_loss=7808.37451, val_loss=7883.76465\n",
      "Epoch 6213: train_loss=7807.22998, val_loss=7882.51367\n",
      "Epoch 6214: train_loss=7806.08545, val_loss=7881.26123\n",
      "Epoch 6215: train_loss=7804.94092, val_loss=7880.00732\n",
      "Epoch 6216: train_loss=7803.79736, val_loss=7878.75635\n",
      "Epoch 6217: train_loss=7802.65723, val_loss=7877.50537\n",
      "Epoch 6218: train_loss=7801.51660, val_loss=7876.25537\n",
      "Epoch 6219: train_loss=7800.37402, val_loss=7875.00684\n",
      "Epoch 6220: train_loss=7799.23291, val_loss=7873.75928\n",
      "Epoch 6221: train_loss=7798.09424, val_loss=7872.50879\n",
      "Epoch 6222: train_loss=7796.95166, val_loss=7871.26318\n",
      "Epoch 6223: train_loss=7795.81152, val_loss=7870.01221\n",
      "Epoch 6224: train_loss=7794.66699, val_loss=7868.75342\n",
      "Epoch 6225: train_loss=7793.51611, val_loss=7867.48486\n",
      "Epoch 6226: train_loss=7792.36475, val_loss=7866.22363\n",
      "Epoch 6227: train_loss=7791.22021, val_loss=7864.96777\n",
      "Epoch 6228: train_loss=7790.08789, val_loss=7863.71875\n",
      "Epoch 6229: train_loss=7788.97119, val_loss=7862.47510\n",
      "Epoch 6230: train_loss=7787.85059, val_loss=7861.22168\n",
      "Epoch 6231: train_loss=7786.72607, val_loss=7859.96533\n",
      "Epoch 6232: train_loss=7785.59521, val_loss=7858.70312\n",
      "Epoch 6233: train_loss=7784.44678, val_loss=7857.43066\n",
      "Epoch 6234: train_loss=7783.29150, val_loss=7856.15332\n",
      "Epoch 6235: train_loss=7782.13037, val_loss=7854.87109\n",
      "Epoch 6236: train_loss=7780.96631, val_loss=7853.58643\n",
      "Epoch 6237: train_loss=7779.80078, val_loss=7852.29785\n",
      "Epoch 6238: train_loss=7778.62939, val_loss=7851.00537\n",
      "Epoch 6239: train_loss=7777.45557, val_loss=7849.71191\n",
      "Epoch 6240: train_loss=7776.28027, val_loss=7848.41650\n",
      "Epoch 6241: train_loss=7775.10498, val_loss=7847.11914\n",
      "Epoch 6242: train_loss=7773.92676, val_loss=7845.81641\n",
      "Epoch 6243: train_loss=7772.74707, val_loss=7844.51758\n",
      "Epoch 6244: train_loss=7771.56934, val_loss=7843.21680\n",
      "Epoch 6245: train_loss=7770.38818, val_loss=7841.91260\n",
      "Epoch 6246: train_loss=7769.20117, val_loss=7840.60107\n",
      "Epoch 6247: train_loss=7768.01074, val_loss=7839.28223\n",
      "Epoch 6248: train_loss=7766.81641, val_loss=7837.95752\n",
      "Epoch 6249: train_loss=7765.61670, val_loss=7836.62695\n",
      "Epoch 6250: train_loss=7764.41211, val_loss=7835.29346\n",
      "Epoch 6251: train_loss=7763.20410, val_loss=7833.96387\n",
      "Epoch 6252: train_loss=7762.00342, val_loss=7832.63135\n",
      "Epoch 6253: train_loss=7760.80078, val_loss=7831.31982\n",
      "Epoch 6254: train_loss=7759.61475, val_loss=7830.02148\n",
      "Epoch 6255: train_loss=7758.42920, val_loss=7828.72510\n",
      "Epoch 6256: train_loss=7757.24463, val_loss=7827.43066\n",
      "Epoch 6257: train_loss=7756.05713, val_loss=7826.14160\n",
      "Epoch 6258: train_loss=7754.86670, val_loss=7824.85352\n",
      "Epoch 6259: train_loss=7753.67334, val_loss=7823.56201\n",
      "Epoch 6260: train_loss=7752.47607, val_loss=7822.26562\n",
      "Epoch 6261: train_loss=7751.27637, val_loss=7820.96924\n",
      "Epoch 6262: train_loss=7750.07715, val_loss=7819.67432\n",
      "Epoch 6263: train_loss=7748.87109, val_loss=7818.38037\n",
      "Epoch 6264: train_loss=7747.66309, val_loss=7817.09375\n",
      "Epoch 6265: train_loss=7746.46094, val_loss=7815.81152\n",
      "Epoch 6266: train_loss=7745.26367, val_loss=7814.53320\n",
      "Epoch 6267: train_loss=7744.07080, val_loss=7813.25439\n",
      "Epoch 6268: train_loss=7742.88281, val_loss=7811.97656\n",
      "Epoch 6269: train_loss=7741.69727, val_loss=7810.70166\n",
      "Epoch 6270: train_loss=7740.51660, val_loss=7809.43066\n",
      "Epoch 6271: train_loss=7739.33740, val_loss=7808.16699\n",
      "Epoch 6272: train_loss=7738.16064, val_loss=7806.90674\n",
      "Epoch 6273: train_loss=7736.98682, val_loss=7805.65088\n",
      "Epoch 6274: train_loss=7735.81592, val_loss=7804.38525\n",
      "Epoch 6275: train_loss=7734.64502, val_loss=7803.11328\n",
      "Epoch 6276: train_loss=7733.47314, val_loss=7801.84473\n",
      "Epoch 6277: train_loss=7732.30127, val_loss=7800.57812\n",
      "Epoch 6278: train_loss=7731.13037, val_loss=7799.31299\n",
      "Epoch 6279: train_loss=7729.95947, val_loss=7798.05127\n",
      "Epoch 6280: train_loss=7728.78906, val_loss=7796.78809\n",
      "Epoch 6281: train_loss=7727.61768, val_loss=7795.52490\n",
      "Epoch 6282: train_loss=7726.44482, val_loss=7794.26318\n",
      "Epoch 6283: train_loss=7725.27246, val_loss=7793.00098\n",
      "Epoch 6284: train_loss=7724.09961, val_loss=7791.73633\n",
      "Epoch 6285: train_loss=7722.92529, val_loss=7790.46143\n",
      "Epoch 6286: train_loss=7721.75244, val_loss=7789.18896\n",
      "Epoch 6287: train_loss=7720.57373, val_loss=7787.90967\n",
      "Epoch 6288: train_loss=7719.38818, val_loss=7786.63135\n",
      "Epoch 6289: train_loss=7718.19971, val_loss=7785.35156\n",
      "Epoch 6290: train_loss=7717.01123, val_loss=7784.07227\n",
      "Epoch 6291: train_loss=7715.82227, val_loss=7782.80029\n",
      "Epoch 6292: train_loss=7714.63525, val_loss=7781.52637\n",
      "Epoch 6293: train_loss=7713.44629, val_loss=7780.24414\n",
      "Epoch 6294: train_loss=7712.25146, val_loss=7778.95264\n",
      "Epoch 6295: train_loss=7711.05273, val_loss=7777.65918\n",
      "Epoch 6296: train_loss=7709.85156, val_loss=7776.36279\n",
      "Epoch 6297: train_loss=7708.64453, val_loss=7775.05566\n",
      "Epoch 6298: train_loss=7707.42090, val_loss=7773.73877\n",
      "Epoch 6299: train_loss=7706.18750, val_loss=7772.42969\n",
      "Epoch 6300: train_loss=7704.95947, val_loss=7771.13086\n",
      "Epoch 6301: train_loss=7703.73779, val_loss=7769.83838\n",
      "Epoch 6302: train_loss=7702.52148, val_loss=7768.55078\n",
      "Epoch 6303: train_loss=7701.31055, val_loss=7767.27490\n",
      "Epoch 6304: train_loss=7700.10303, val_loss=7766.00098\n",
      "Epoch 6305: train_loss=7698.89795, val_loss=7764.73096\n",
      "Epoch 6306: train_loss=7697.69775, val_loss=7763.46338\n",
      "Epoch 6307: train_loss=7696.49854, val_loss=7762.20947\n",
      "Epoch 6308: train_loss=7695.30420, val_loss=7760.95361\n",
      "Epoch 6309: train_loss=7694.11084, val_loss=7759.69385\n",
      "Epoch 6310: train_loss=7692.91699, val_loss=7758.43018\n",
      "Epoch 6311: train_loss=7691.72021, val_loss=7757.16260\n",
      "Epoch 6312: train_loss=7690.51953, val_loss=7755.89502\n",
      "Epoch 6313: train_loss=7689.31982, val_loss=7754.62793\n",
      "Epoch 6314: train_loss=7688.11963, val_loss=7753.35889\n",
      "Epoch 6315: train_loss=7686.91895, val_loss=7752.08887\n",
      "Epoch 6316: train_loss=7685.71826, val_loss=7750.82275\n",
      "Epoch 6317: train_loss=7684.51758, val_loss=7749.56006\n",
      "Epoch 6318: train_loss=7683.31641, val_loss=7748.30176\n",
      "Epoch 6319: train_loss=7682.11670, val_loss=7747.04492\n",
      "Epoch 6320: train_loss=7680.91846, val_loss=7745.78320\n",
      "Epoch 6321: train_loss=7679.72168, val_loss=7744.51953\n",
      "Epoch 6322: train_loss=7678.52588, val_loss=7743.25732\n",
      "Epoch 6323: train_loss=7677.33154, val_loss=7741.99707\n",
      "Epoch 6324: train_loss=7676.13916, val_loss=7740.73730\n",
      "Epoch 6325: train_loss=7674.94580, val_loss=7739.47754\n",
      "Epoch 6326: train_loss=7673.75439, val_loss=7738.21875\n",
      "Epoch 6327: train_loss=7672.56396, val_loss=7736.95752\n",
      "Epoch 6328: train_loss=7671.37207, val_loss=7735.69629\n",
      "Epoch 6329: train_loss=7670.17871, val_loss=7734.43262\n",
      "Epoch 6330: train_loss=7668.98486, val_loss=7733.16895\n",
      "Epoch 6331: train_loss=7667.79102, val_loss=7731.90967\n",
      "Epoch 6332: train_loss=7666.59766, val_loss=7730.64990\n",
      "Epoch 6333: train_loss=7665.40137, val_loss=7729.37793\n",
      "Epoch 6334: train_loss=7664.20117, val_loss=7728.09961\n",
      "Epoch 6335: train_loss=7662.99951, val_loss=7726.81738\n",
      "Epoch 6336: train_loss=7661.79443, val_loss=7725.53027\n",
      "Epoch 6337: train_loss=7660.58691, val_loss=7724.24170\n",
      "Epoch 6338: train_loss=7659.37891, val_loss=7722.94922\n",
      "Epoch 6339: train_loss=7658.16602, val_loss=7721.65039\n",
      "Epoch 6340: train_loss=7656.95264, val_loss=7720.34375\n",
      "Epoch 6341: train_loss=7655.73535, val_loss=7719.03223\n",
      "Epoch 6342: train_loss=7654.51562, val_loss=7717.71729\n",
      "Epoch 6343: train_loss=7653.29590, val_loss=7716.39990\n",
      "Epoch 6344: train_loss=7652.07178, val_loss=7715.08350\n",
      "Epoch 6345: train_loss=7650.84619, val_loss=7713.76758\n",
      "Epoch 6346: train_loss=7649.62061, val_loss=7712.44971\n",
      "Epoch 6347: train_loss=7648.39209, val_loss=7711.13477\n",
      "Epoch 6348: train_loss=7647.16406, val_loss=7709.81885\n",
      "Epoch 6349: train_loss=7645.93408, val_loss=7708.49756\n",
      "Epoch 6350: train_loss=7644.70215, val_loss=7707.17480\n",
      "Epoch 6351: train_loss=7643.46582, val_loss=7705.84961\n",
      "Epoch 6352: train_loss=7642.22754, val_loss=7704.52148\n",
      "Epoch 6353: train_loss=7640.98535, val_loss=7703.19287\n",
      "Epoch 6354: train_loss=7639.74121, val_loss=7701.86475\n",
      "Epoch 6355: train_loss=7638.49512, val_loss=7700.53320\n",
      "Epoch 6356: train_loss=7637.24707, val_loss=7699.20166\n",
      "Epoch 6357: train_loss=7635.99902, val_loss=7697.86865\n",
      "Epoch 6358: train_loss=7634.74609, val_loss=7696.53076\n",
      "Epoch 6359: train_loss=7633.49414, val_loss=7695.19141\n",
      "Epoch 6360: train_loss=7632.23828, val_loss=7693.85156\n",
      "Epoch 6361: train_loss=7630.98340, val_loss=7692.51123\n",
      "Epoch 6362: train_loss=7629.72559, val_loss=7691.16748\n",
      "Epoch 6363: train_loss=7628.46875, val_loss=7689.82080\n",
      "Epoch 6364: train_loss=7627.21143, val_loss=7688.47168\n",
      "Epoch 6365: train_loss=7625.95459, val_loss=7687.12012\n",
      "Epoch 6366: train_loss=7624.69775, val_loss=7685.76758\n",
      "Epoch 6367: train_loss=7623.43994, val_loss=7684.41357\n",
      "Epoch 6368: train_loss=7622.18115, val_loss=7683.06299\n",
      "Epoch 6369: train_loss=7620.92285, val_loss=7681.71240\n",
      "Epoch 6370: train_loss=7619.66309, val_loss=7680.36035\n",
      "Epoch 6371: train_loss=7618.40576, val_loss=7679.01660\n",
      "Epoch 6372: train_loss=7617.15576, val_loss=7677.67725\n",
      "Epoch 6373: train_loss=7615.90967, val_loss=7676.34180\n",
      "Epoch 6374: train_loss=7614.66211, val_loss=7675.00781\n",
      "Epoch 6375: train_loss=7613.41699, val_loss=7673.67773\n",
      "Epoch 6376: train_loss=7612.17383, val_loss=7672.34863\n",
      "Epoch 6377: train_loss=7610.92578, val_loss=7671.02100\n",
      "Epoch 6378: train_loss=7609.67578, val_loss=7669.69043\n",
      "Epoch 6379: train_loss=7608.42773, val_loss=7668.35840\n",
      "Epoch 6380: train_loss=7607.17822, val_loss=7667.02832\n",
      "Epoch 6381: train_loss=7605.92578, val_loss=7665.69678\n",
      "Epoch 6382: train_loss=7604.67236, val_loss=7664.36279\n",
      "Epoch 6383: train_loss=7603.41943, val_loss=7663.03223\n",
      "Epoch 6384: train_loss=7602.16602, val_loss=7661.70459\n",
      "Epoch 6385: train_loss=7600.91846, val_loss=7660.37891\n",
      "Epoch 6386: train_loss=7599.67188, val_loss=7659.05713\n",
      "Epoch 6387: train_loss=7598.42725, val_loss=7657.73535\n",
      "Epoch 6388: train_loss=7597.18359, val_loss=7656.41797\n",
      "Epoch 6389: train_loss=7595.94141, val_loss=7655.09912\n",
      "Epoch 6390: train_loss=7594.69873, val_loss=7653.78271\n",
      "Epoch 6391: train_loss=7593.45605, val_loss=7652.46973\n",
      "Epoch 6392: train_loss=7592.21631, val_loss=7651.15479\n",
      "Epoch 6393: train_loss=7590.97510, val_loss=7649.83838\n",
      "Epoch 6394: train_loss=7589.73291, val_loss=7648.52832\n",
      "Epoch 6395: train_loss=7588.49463, val_loss=7647.22510\n",
      "Epoch 6396: train_loss=7587.25830, val_loss=7645.92822\n",
      "Epoch 6397: train_loss=7586.02148, val_loss=7644.63037\n",
      "Epoch 6398: train_loss=7584.78223, val_loss=7643.33301\n",
      "Epoch 6399: train_loss=7583.54248, val_loss=7642.03662\n",
      "Epoch 6400: train_loss=7582.30127, val_loss=7640.74023\n",
      "Epoch 6401: train_loss=7581.05762, val_loss=7639.44238\n",
      "Epoch 6402: train_loss=7579.81152, val_loss=7638.14404\n",
      "Epoch 6403: train_loss=7578.56445, val_loss=7636.84619\n",
      "Epoch 6404: train_loss=7577.31543, val_loss=7635.54248\n",
      "Epoch 6405: train_loss=7576.06396, val_loss=7634.23584\n",
      "Epoch 6406: train_loss=7574.81104, val_loss=7632.92285\n",
      "Epoch 6407: train_loss=7573.55713, val_loss=7631.61475\n",
      "Epoch 6408: train_loss=7572.30078, val_loss=7630.30469\n",
      "Epoch 6409: train_loss=7571.04590, val_loss=7628.98828\n",
      "Epoch 6410: train_loss=7569.78955, val_loss=7627.66943\n",
      "Epoch 6411: train_loss=7568.53613, val_loss=7626.35059\n",
      "Epoch 6412: train_loss=7567.28760, val_loss=7625.03076\n",
      "Epoch 6413: train_loss=7566.04346, val_loss=7623.71240\n",
      "Epoch 6414: train_loss=7564.80420, val_loss=7622.39502\n",
      "Epoch 6415: train_loss=7563.56104, val_loss=7621.08008\n",
      "Epoch 6416: train_loss=7562.31836, val_loss=7619.76367\n",
      "Epoch 6417: train_loss=7561.07471, val_loss=7618.44531\n",
      "Epoch 6418: train_loss=7559.83350, val_loss=7617.12500\n",
      "Epoch 6419: train_loss=7558.59082, val_loss=7615.80615\n",
      "Epoch 6420: train_loss=7557.34668, val_loss=7614.48926\n",
      "Epoch 6421: train_loss=7556.10156, val_loss=7613.16602\n",
      "Epoch 6422: train_loss=7554.85596, val_loss=7611.83887\n",
      "Epoch 6423: train_loss=7553.61035, val_loss=7610.51123\n",
      "Epoch 6424: train_loss=7552.36572, val_loss=7609.18701\n",
      "Epoch 6425: train_loss=7551.11963, val_loss=7607.86328\n",
      "Epoch 6426: train_loss=7549.87305, val_loss=7606.53467\n",
      "Epoch 6427: train_loss=7548.62549, val_loss=7605.20557\n",
      "Epoch 6428: train_loss=7547.37695, val_loss=7603.87646\n",
      "Epoch 6429: train_loss=7546.12793, val_loss=7602.54541\n",
      "Epoch 6430: train_loss=7544.87793, val_loss=7601.21338\n",
      "Epoch 6431: train_loss=7543.62500, val_loss=7599.87939\n",
      "Epoch 6432: train_loss=7542.37012, val_loss=7598.54297\n",
      "Epoch 6433: train_loss=7541.11475, val_loss=7597.20898\n",
      "Epoch 6434: train_loss=7539.85840, val_loss=7595.87646\n",
      "Epoch 6435: train_loss=7538.60205, val_loss=7594.54492\n",
      "Epoch 6436: train_loss=7537.34570, val_loss=7593.21143\n",
      "Epoch 6437: train_loss=7536.08838, val_loss=7591.87842\n",
      "Epoch 6438: train_loss=7534.83350, val_loss=7590.55127\n",
      "Epoch 6439: train_loss=7533.58008, val_loss=7589.22607\n",
      "Epoch 6440: train_loss=7532.33154, val_loss=7587.89258\n",
      "Epoch 6441: train_loss=7531.08203, val_loss=7586.55518\n",
      "Epoch 6442: train_loss=7529.83252, val_loss=7585.21680\n",
      "Epoch 6443: train_loss=7528.58350, val_loss=7583.88037\n",
      "Epoch 6444: train_loss=7527.33350, val_loss=7582.54346\n",
      "Epoch 6445: train_loss=7526.08301, val_loss=7581.20850\n",
      "Epoch 6446: train_loss=7524.83594, val_loss=7579.87402\n",
      "Epoch 6447: train_loss=7523.59570, val_loss=7578.53613\n",
      "Epoch 6448: train_loss=7522.35352, val_loss=7577.19922\n",
      "Epoch 6449: train_loss=7521.11084, val_loss=7575.85938\n",
      "Epoch 6450: train_loss=7519.86816, val_loss=7574.51562\n",
      "Epoch 6451: train_loss=7518.62012, val_loss=7573.17188\n",
      "Epoch 6452: train_loss=7517.37256, val_loss=7571.83057\n",
      "Epoch 6453: train_loss=7516.12500, val_loss=7570.48779\n",
      "Epoch 6454: train_loss=7514.87500, val_loss=7569.14307\n",
      "Epoch 6455: train_loss=7513.62305, val_loss=7567.79346\n",
      "Epoch 6456: train_loss=7512.37158, val_loss=7566.44189\n",
      "Epoch 6457: train_loss=7511.12012, val_loss=7565.08936\n",
      "Epoch 6458: train_loss=7509.86621, val_loss=7563.73193\n",
      "Epoch 6459: train_loss=7508.60840, val_loss=7562.37158\n",
      "Epoch 6460: train_loss=7507.34326, val_loss=7561.01416\n",
      "Epoch 6461: train_loss=7506.07617, val_loss=7559.65381\n",
      "Epoch 6462: train_loss=7504.80566, val_loss=7558.29199\n",
      "Epoch 6463: train_loss=7503.53125, val_loss=7556.92188\n",
      "Epoch 6464: train_loss=7502.25439, val_loss=7555.54883\n",
      "Epoch 6465: train_loss=7500.97363, val_loss=7554.17334\n",
      "Epoch 6466: train_loss=7499.69287, val_loss=7552.79688\n",
      "Epoch 6467: train_loss=7498.41211, val_loss=7551.41602\n",
      "Epoch 6468: train_loss=7497.12988, val_loss=7550.02979\n",
      "Epoch 6469: train_loss=7495.84424, val_loss=7548.64795\n",
      "Epoch 6470: train_loss=7494.55713, val_loss=7547.26904\n",
      "Epoch 6471: train_loss=7493.27051, val_loss=7545.88379\n",
      "Epoch 6472: train_loss=7491.98145, val_loss=7544.49121\n",
      "Epoch 6473: train_loss=7490.68994, val_loss=7543.09375\n",
      "Epoch 6474: train_loss=7489.39111, val_loss=7541.69580\n",
      "Epoch 6475: train_loss=7488.08691, val_loss=7540.29932\n",
      "Epoch 6476: train_loss=7486.78369, val_loss=7538.90186\n",
      "Epoch 6477: train_loss=7485.48242, val_loss=7537.50586\n",
      "Epoch 6478: train_loss=7484.18311, val_loss=7536.10059\n",
      "Epoch 6479: train_loss=7482.87695, val_loss=7534.69092\n",
      "Epoch 6480: train_loss=7481.56982, val_loss=7533.28174\n",
      "Epoch 6481: train_loss=7480.26318, val_loss=7531.87207\n",
      "Epoch 6482: train_loss=7478.95898, val_loss=7530.46387\n",
      "Epoch 6483: train_loss=7477.65381, val_loss=7529.05371\n",
      "Epoch 6484: train_loss=7476.35010, val_loss=7527.64502\n",
      "Epoch 6485: train_loss=7475.04639, val_loss=7526.23438\n",
      "Epoch 6486: train_loss=7473.74805, val_loss=7524.82520\n",
      "Epoch 6487: train_loss=7472.44873, val_loss=7523.41602\n",
      "Epoch 6488: train_loss=7471.15137, val_loss=7522.00830\n",
      "Epoch 6489: train_loss=7469.85645, val_loss=7520.60547\n",
      "Epoch 6490: train_loss=7468.56055, val_loss=7519.20361\n",
      "Epoch 6491: train_loss=7467.26465, val_loss=7517.80371\n",
      "Epoch 6492: train_loss=7465.97021, val_loss=7516.40088\n",
      "Epoch 6493: train_loss=7464.68115, val_loss=7514.99902\n",
      "Epoch 6494: train_loss=7463.39746, val_loss=7513.59619\n",
      "Epoch 6495: train_loss=7462.11475, val_loss=7512.19189\n",
      "Epoch 6496: train_loss=7460.83301, val_loss=7510.78516\n",
      "Epoch 6497: train_loss=7459.55029, val_loss=7509.37744\n",
      "Epoch 6498: train_loss=7458.26514, val_loss=7507.96631\n",
      "Epoch 6499: train_loss=7456.97754, val_loss=7506.55518\n",
      "Epoch 6500: train_loss=7455.68799, val_loss=7505.14404\n",
      "Epoch 6501: train_loss=7454.40039, val_loss=7503.73145\n",
      "Epoch 6502: train_loss=7453.10889, val_loss=7502.31982\n",
      "Epoch 6503: train_loss=7451.81641, val_loss=7500.91162\n",
      "Epoch 6504: train_loss=7450.52441, val_loss=7499.50537\n",
      "Epoch 6505: train_loss=7449.23193, val_loss=7498.10059\n",
      "Epoch 6506: train_loss=7447.94141, val_loss=7496.69922\n",
      "Epoch 6507: train_loss=7446.64844, val_loss=7495.29736\n",
      "Epoch 6508: train_loss=7445.35547, val_loss=7493.89404\n",
      "Epoch 6509: train_loss=7444.06055, val_loss=7492.49365\n",
      "Epoch 6510: train_loss=7442.76562, val_loss=7491.09717\n",
      "Epoch 6511: train_loss=7441.47412, val_loss=7489.70312\n",
      "Epoch 6512: train_loss=7440.18408, val_loss=7488.30566\n",
      "Epoch 6513: train_loss=7438.89258, val_loss=7486.90430\n",
      "Epoch 6514: train_loss=7437.59863, val_loss=7485.49951\n",
      "Epoch 6515: train_loss=7436.30371, val_loss=7484.08984\n",
      "Epoch 6516: train_loss=7435.00146, val_loss=7482.67432\n",
      "Epoch 6517: train_loss=7433.69580, val_loss=7481.25342\n",
      "Epoch 6518: train_loss=7432.38721, val_loss=7479.83301\n",
      "Epoch 6519: train_loss=7431.07422, val_loss=7478.41260\n",
      "Epoch 6520: train_loss=7429.75977, val_loss=7476.99023\n",
      "Epoch 6521: train_loss=7428.43896, val_loss=7475.56885\n",
      "Epoch 6522: train_loss=7427.11377, val_loss=7474.14600\n",
      "Epoch 6523: train_loss=7425.78271, val_loss=7472.71143\n",
      "Epoch 6524: train_loss=7424.44092, val_loss=7471.27539\n",
      "Epoch 6525: train_loss=7423.09912, val_loss=7469.83301\n",
      "Epoch 6526: train_loss=7421.75098, val_loss=7468.37695\n",
      "Epoch 6527: train_loss=7420.39648, val_loss=7466.90869\n",
      "Epoch 6528: train_loss=7419.03125, val_loss=7465.43799\n",
      "Epoch 6529: train_loss=7417.66650, val_loss=7463.96973\n",
      "Epoch 6530: train_loss=7416.30127, val_loss=7462.49902\n",
      "Epoch 6531: train_loss=7414.93262, val_loss=7461.01562\n",
      "Epoch 6532: train_loss=7413.55273, val_loss=7459.52393\n",
      "Epoch 6533: train_loss=7412.16455, val_loss=7458.01465\n",
      "Epoch 6534: train_loss=7410.76025, val_loss=7456.49707\n",
      "Epoch 6535: train_loss=7409.35010, val_loss=7454.98730\n",
      "Epoch 6536: train_loss=7407.94434, val_loss=7453.48340\n",
      "Epoch 6537: train_loss=7406.55322, val_loss=7451.98291\n",
      "Epoch 6538: train_loss=7405.16846, val_loss=7450.48975\n",
      "Epoch 6539: train_loss=7403.78369, val_loss=7449.00977\n",
      "Epoch 6540: train_loss=7402.40723, val_loss=7447.52930\n",
      "Epoch 6541: train_loss=7401.03467, val_loss=7446.05176\n",
      "Epoch 6542: train_loss=7399.66260, val_loss=7444.57910\n",
      "Epoch 6543: train_loss=7398.29443, val_loss=7443.11768\n",
      "Epoch 6544: train_loss=7396.93018, val_loss=7441.65918\n",
      "Epoch 6545: train_loss=7395.56885, val_loss=7440.19873\n",
      "Epoch 6546: train_loss=7394.20801, val_loss=7438.72949\n",
      "Epoch 6547: train_loss=7392.85352, val_loss=7437.26074\n",
      "Epoch 6548: train_loss=7391.50000, val_loss=7435.79346\n",
      "Epoch 6549: train_loss=7390.14551, val_loss=7434.32715\n",
      "Epoch 6550: train_loss=7388.78955, val_loss=7432.85498\n",
      "Epoch 6551: train_loss=7387.43018, val_loss=7431.37988\n",
      "Epoch 6552: train_loss=7386.07178, val_loss=7429.90283\n",
      "Epoch 6553: train_loss=7384.71387, val_loss=7428.42041\n",
      "Epoch 6554: train_loss=7383.35498, val_loss=7426.93164\n",
      "Epoch 6555: train_loss=7381.99902, val_loss=7425.43945\n",
      "Epoch 6556: train_loss=7380.63623, val_loss=7423.93896\n",
      "Epoch 6557: train_loss=7379.26758, val_loss=7422.43115\n",
      "Epoch 6558: train_loss=7377.89648, val_loss=7420.93555\n",
      "Epoch 6559: train_loss=7376.52393, val_loss=7419.44287\n",
      "Epoch 6560: train_loss=7375.14551, val_loss=7417.94141\n",
      "Epoch 6561: train_loss=7373.75781, val_loss=7416.43066\n",
      "Epoch 6562: train_loss=7372.36279, val_loss=7414.89307\n",
      "Epoch 6563: train_loss=7370.95361, val_loss=7413.34229\n",
      "Epoch 6564: train_loss=7369.52441, val_loss=7411.76416\n",
      "Epoch 6565: train_loss=7368.08008, val_loss=7410.17090\n",
      "Epoch 6566: train_loss=7366.64014, val_loss=7408.56201\n",
      "Epoch 6567: train_loss=7365.18945, val_loss=7406.94092\n",
      "Epoch 6568: train_loss=7363.72754, val_loss=7405.37988\n",
      "Epoch 6569: train_loss=7362.30615, val_loss=7403.94043\n",
      "Epoch 6570: train_loss=7360.93359, val_loss=7402.51221\n",
      "Epoch 6571: train_loss=7359.55664, val_loss=7401.08691\n",
      "Epoch 6572: train_loss=7358.17578, val_loss=7399.66553\n",
      "Epoch 6573: train_loss=7356.79053, val_loss=7398.24609\n",
      "Epoch 6574: train_loss=7355.39941, val_loss=7396.82812\n",
      "Epoch 6575: train_loss=7354.00146, val_loss=7395.40723\n",
      "Epoch 6576: train_loss=7352.59961, val_loss=7393.98291\n",
      "Epoch 6577: train_loss=7351.19434, val_loss=7392.55078\n",
      "Epoch 6578: train_loss=7349.78418, val_loss=7391.11426\n",
      "Epoch 6579: train_loss=7348.37451, val_loss=7389.67676\n",
      "Epoch 6580: train_loss=7346.96631, val_loss=7388.24219\n",
      "Epoch 6581: train_loss=7345.55811, val_loss=7386.80859\n",
      "Epoch 6582: train_loss=7344.14941, val_loss=7385.37842\n",
      "Epoch 6583: train_loss=7342.74268, val_loss=7383.93848\n",
      "Epoch 6584: train_loss=7341.33496, val_loss=7382.48047\n",
      "Epoch 6585: train_loss=7339.92236, val_loss=7381.00586\n",
      "Epoch 6586: train_loss=7338.50537, val_loss=7379.52393\n",
      "Epoch 6587: train_loss=7337.08057, val_loss=7378.02930\n",
      "Epoch 6588: train_loss=7335.64697, val_loss=7376.51709\n",
      "Epoch 6589: train_loss=7334.20117, val_loss=7374.98291\n",
      "Epoch 6590: train_loss=7332.74268, val_loss=7373.43994\n",
      "Epoch 6591: train_loss=7331.27344, val_loss=7371.88770\n",
      "Epoch 6592: train_loss=7329.78906, val_loss=7370.33789\n",
      "Epoch 6593: train_loss=7328.29248, val_loss=7368.78418\n",
      "Epoch 6594: train_loss=7326.78906, val_loss=7367.22070\n",
      "Epoch 6595: train_loss=7325.27441, val_loss=7365.64062\n",
      "Epoch 6596: train_loss=7323.74854, val_loss=7364.05859\n",
      "Epoch 6597: train_loss=7322.21729, val_loss=7362.47852\n",
      "Epoch 6598: train_loss=7320.68262, val_loss=7360.89014\n",
      "Epoch 6599: train_loss=7319.15332, val_loss=7359.31152\n",
      "Epoch 6600: train_loss=7317.64160, val_loss=7357.74609\n",
      "Epoch 6601: train_loss=7316.15576, val_loss=7356.22168\n",
      "Epoch 6602: train_loss=7314.69727, val_loss=7354.70068\n",
      "Epoch 6603: train_loss=7313.24365, val_loss=7353.17578\n",
      "Epoch 6604: train_loss=7311.78516, val_loss=7351.64600\n",
      "Epoch 6605: train_loss=7310.32324, val_loss=7350.10498\n",
      "Epoch 6606: train_loss=7308.85596, val_loss=7348.54785\n",
      "Epoch 6607: train_loss=7307.37354, val_loss=7346.97900\n",
      "Epoch 6608: train_loss=7305.89062, val_loss=7345.41260\n",
      "Epoch 6609: train_loss=7304.40430, val_loss=7343.83936\n",
      "Epoch 6610: train_loss=7302.90771, val_loss=7342.26953\n",
      "Epoch 6611: train_loss=7301.41992, val_loss=7340.69336\n",
      "Epoch 6612: train_loss=7299.93164, val_loss=7339.11475\n",
      "Epoch 6613: train_loss=7298.44238, val_loss=7337.54248\n",
      "Epoch 6614: train_loss=7296.95068, val_loss=7335.96631\n",
      "Epoch 6615: train_loss=7295.46582, val_loss=7334.37891\n",
      "Epoch 6616: train_loss=7293.97363, val_loss=7332.77490\n",
      "Epoch 6617: train_loss=7292.47070, val_loss=7331.17041\n",
      "Epoch 6618: train_loss=7290.96826, val_loss=7329.57568\n",
      "Epoch 6619: train_loss=7289.48242, val_loss=7327.99268\n",
      "Epoch 6620: train_loss=7288.01807, val_loss=7326.40820\n",
      "Epoch 6621: train_loss=7286.55762, val_loss=7324.81738\n",
      "Epoch 6622: train_loss=7285.08740, val_loss=7323.22070\n",
      "Epoch 6623: train_loss=7283.60303, val_loss=7321.63623\n",
      "Epoch 6624: train_loss=7282.12207, val_loss=7320.05273\n",
      "Epoch 6625: train_loss=7280.63623, val_loss=7318.46533\n",
      "Epoch 6626: train_loss=7279.14404, val_loss=7316.87402\n",
      "Epoch 6627: train_loss=7277.64453, val_loss=7315.28027\n",
      "Epoch 6628: train_loss=7276.13965, val_loss=7313.68799\n",
      "Epoch 6629: train_loss=7274.63135, val_loss=7312.09180\n",
      "Epoch 6630: train_loss=7273.12500, val_loss=7310.50488\n",
      "Epoch 6631: train_loss=7271.64697, val_loss=7308.91602\n",
      "Epoch 6632: train_loss=7270.17188, val_loss=7307.33789\n",
      "Epoch 6633: train_loss=7268.71777, val_loss=7305.76270\n",
      "Epoch 6634: train_loss=7267.26709, val_loss=7304.18848\n",
      "Epoch 6635: train_loss=7265.81982, val_loss=7302.60889\n",
      "Epoch 6636: train_loss=7264.37451, val_loss=7301.02344\n",
      "Epoch 6637: train_loss=7262.92383, val_loss=7299.42920\n",
      "Epoch 6638: train_loss=7261.46777, val_loss=7297.83447\n",
      "Epoch 6639: train_loss=7260.00928, val_loss=7296.23730\n",
      "Epoch 6640: train_loss=7258.54590, val_loss=7294.63135\n",
      "Epoch 6641: train_loss=7257.07031, val_loss=7293.01465\n",
      "Epoch 6642: train_loss=7255.58838, val_loss=7291.39062\n",
      "Epoch 6643: train_loss=7254.11084, val_loss=7289.77197\n",
      "Epoch 6644: train_loss=7252.63135, val_loss=7288.13818\n",
      "Epoch 6645: train_loss=7251.13184, val_loss=7286.48779\n",
      "Epoch 6646: train_loss=7249.62451, val_loss=7284.83887\n",
      "Epoch 6647: train_loss=7248.11523, val_loss=7283.19238\n",
      "Epoch 6648: train_loss=7246.60645, val_loss=7281.55225\n",
      "Epoch 6649: train_loss=7245.11572, val_loss=7279.89844\n",
      "Epoch 6650: train_loss=7243.60742, val_loss=7278.23682\n",
      "Epoch 6651: train_loss=7242.10303, val_loss=7276.57959\n",
      "Epoch 6652: train_loss=7240.60205, val_loss=7274.93164\n",
      "Epoch 6653: train_loss=7239.10498, val_loss=7273.28271\n",
      "Epoch 6654: train_loss=7237.60107, val_loss=7271.62793\n",
      "Epoch 6655: train_loss=7236.09473, val_loss=7269.95508\n",
      "Epoch 6656: train_loss=7234.57129, val_loss=7268.26660\n",
      "Epoch 6657: train_loss=7233.03760, val_loss=7266.57373\n",
      "Epoch 6658: train_loss=7231.49951, val_loss=7264.89404\n",
      "Epoch 6659: train_loss=7229.98730, val_loss=7263.19189\n",
      "Epoch 6660: train_loss=7228.44482, val_loss=7261.46875\n",
      "Epoch 6661: train_loss=7226.88086, val_loss=7259.73291\n",
      "Epoch 6662: train_loss=7225.29590, val_loss=7257.97754\n",
      "Epoch 6663: train_loss=7223.70898, val_loss=7256.21729\n",
      "Epoch 6664: train_loss=7222.11279, val_loss=7254.45654\n",
      "Epoch 6665: train_loss=7220.51318, val_loss=7252.69189\n",
      "Epoch 6666: train_loss=7218.90332, val_loss=7250.92627\n",
      "Epoch 6667: train_loss=7217.29199, val_loss=7249.13086\n",
      "Epoch 6668: train_loss=7215.68066, val_loss=7247.32617\n",
      "Epoch 6669: train_loss=7214.10205, val_loss=7245.50635\n",
      "Epoch 6670: train_loss=7212.51807, val_loss=7243.67627\n",
      "Epoch 6671: train_loss=7210.92627, val_loss=7241.85742\n",
      "Epoch 6672: train_loss=7209.33447, val_loss=7240.05713\n",
      "Epoch 6673: train_loss=7207.74902, val_loss=7238.25684\n",
      "Epoch 6674: train_loss=7206.16992, val_loss=7236.45850\n",
      "Epoch 6675: train_loss=7204.59668, val_loss=7234.71924\n",
      "Epoch 6676: train_loss=7203.05908, val_loss=7232.99658\n",
      "Epoch 6677: train_loss=7201.52881, val_loss=7231.27490\n",
      "Epoch 6678: train_loss=7199.99951, val_loss=7229.56104\n",
      "Epoch 6679: train_loss=7198.46484, val_loss=7227.84375\n",
      "Epoch 6680: train_loss=7196.92920, val_loss=7226.12354\n",
      "Epoch 6681: train_loss=7195.39209, val_loss=7224.40283\n",
      "Epoch 6682: train_loss=7193.85400, val_loss=7222.67676\n",
      "Epoch 6683: train_loss=7192.31494, val_loss=7220.94434\n",
      "Epoch 6684: train_loss=7190.77490, val_loss=7219.21240\n",
      "Epoch 6685: train_loss=7189.22998, val_loss=7217.47510\n",
      "Epoch 6686: train_loss=7187.68262, val_loss=7215.70361\n",
      "Epoch 6687: train_loss=7186.12451, val_loss=7213.91455\n",
      "Epoch 6688: train_loss=7184.56104, val_loss=7212.12158\n",
      "Epoch 6689: train_loss=7182.99414, val_loss=7210.32764\n",
      "Epoch 6690: train_loss=7181.42676, val_loss=7208.52002\n",
      "Epoch 6691: train_loss=7179.85693, val_loss=7206.70117\n",
      "Epoch 6692: train_loss=7178.28320, val_loss=7204.88086\n",
      "Epoch 6693: train_loss=7176.70898, val_loss=7203.06445\n",
      "Epoch 6694: train_loss=7175.13379, val_loss=7201.25244\n",
      "Epoch 6695: train_loss=7173.55225, val_loss=7199.43896\n",
      "Epoch 6696: train_loss=7171.96973, val_loss=7197.62207\n",
      "Epoch 6697: train_loss=7170.38721, val_loss=7195.80713\n",
      "Epoch 6698: train_loss=7168.79541, val_loss=7193.99854\n",
      "Epoch 6699: train_loss=7167.19824, val_loss=7192.19092\n",
      "Epoch 6700: train_loss=7165.59863, val_loss=7190.38232\n",
      "Epoch 6701: train_loss=7163.99707, val_loss=7188.57031\n",
      "Epoch 6702: train_loss=7162.39404, val_loss=7186.76318\n",
      "Epoch 6703: train_loss=7160.79248, val_loss=7184.95801\n",
      "Epoch 6704: train_loss=7159.19141, val_loss=7183.15430\n",
      "Epoch 6705: train_loss=7157.59082, val_loss=7181.35010\n",
      "Epoch 6706: train_loss=7155.99023, val_loss=7179.55615\n",
      "Epoch 6707: train_loss=7154.39258, val_loss=7177.76611\n",
      "Epoch 6708: train_loss=7152.79688, val_loss=7175.97559\n",
      "Epoch 6709: train_loss=7151.20166, val_loss=7174.19043\n",
      "Epoch 6710: train_loss=7149.61328, val_loss=7172.41846\n",
      "Epoch 6711: train_loss=7148.02930, val_loss=7170.65869\n",
      "Epoch 6712: train_loss=7146.45508, val_loss=7168.90332\n",
      "Epoch 6713: train_loss=7144.88477, val_loss=7167.15430\n",
      "Epoch 6714: train_loss=7143.31494, val_loss=7165.40967\n",
      "Epoch 6715: train_loss=7141.74609, val_loss=7163.66113\n",
      "Epoch 6716: train_loss=7140.17822, val_loss=7161.89844\n",
      "Epoch 6717: train_loss=7138.60889, val_loss=7160.14307\n",
      "Epoch 6718: train_loss=7137.03906, val_loss=7158.39502\n",
      "Epoch 6719: train_loss=7135.46338, val_loss=7156.65576\n",
      "Epoch 6720: train_loss=7133.88867, val_loss=7154.91260\n",
      "Epoch 6721: train_loss=7132.31494, val_loss=7153.18359\n",
      "Epoch 6722: train_loss=7130.74951, val_loss=7151.45410\n",
      "Epoch 6723: train_loss=7129.18408, val_loss=7149.72656\n",
      "Epoch 6724: train_loss=7127.61523, val_loss=7147.98975\n",
      "Epoch 6725: train_loss=7126.04248, val_loss=7146.25488\n",
      "Epoch 6726: train_loss=7124.46045, val_loss=7144.50684\n",
      "Epoch 6727: train_loss=7122.86133, val_loss=7142.74902\n",
      "Epoch 6728: train_loss=7121.25146, val_loss=7141.00586\n",
      "Epoch 6729: train_loss=7119.63623, val_loss=7139.25879\n",
      "Epoch 6730: train_loss=7118.01562, val_loss=7137.49316\n",
      "Epoch 6731: train_loss=7116.38770, val_loss=7135.71240\n",
      "Epoch 6732: train_loss=7114.75781, val_loss=7133.94336\n",
      "Epoch 6733: train_loss=7113.12256, val_loss=7132.18115\n",
      "Epoch 6734: train_loss=7111.48584, val_loss=7130.41211\n",
      "Epoch 6735: train_loss=7109.84717, val_loss=7128.64355\n",
      "Epoch 6736: train_loss=7108.20361, val_loss=7126.86377\n",
      "Epoch 6737: train_loss=7106.56152, val_loss=7125.08594\n",
      "Epoch 6738: train_loss=7104.91992, val_loss=7123.30273\n",
      "Epoch 6739: train_loss=7103.27588, val_loss=7121.51221\n",
      "Epoch 6740: train_loss=7101.62500, val_loss=7119.70654\n",
      "Epoch 6741: train_loss=7099.97119, val_loss=7117.91455\n",
      "Epoch 6742: train_loss=7098.32227, val_loss=7116.12598\n",
      "Epoch 6743: train_loss=7096.67871, val_loss=7114.34619\n",
      "Epoch 6744: train_loss=7095.03857, val_loss=7112.56348\n",
      "Epoch 6745: train_loss=7093.39941, val_loss=7110.78662\n",
      "Epoch 6746: train_loss=7091.76660, val_loss=7109.01758\n",
      "Epoch 6747: train_loss=7090.14014, val_loss=7107.26172\n",
      "Epoch 6748: train_loss=7088.52881, val_loss=7105.50293\n",
      "Epoch 6749: train_loss=7086.92334, val_loss=7103.75146\n",
      "Epoch 6750: train_loss=7085.32471, val_loss=7102.00830\n",
      "Epoch 6751: train_loss=7083.73096, val_loss=7100.27441\n",
      "Epoch 6752: train_loss=7082.13672, val_loss=7098.54004\n",
      "Epoch 6753: train_loss=7080.54395, val_loss=7096.79443\n",
      "Epoch 6754: train_loss=7078.95166, val_loss=7095.04639\n",
      "Epoch 6755: train_loss=7077.36182, val_loss=7093.30566\n",
      "Epoch 6756: train_loss=7075.77100, val_loss=7091.57275\n",
      "Epoch 6757: train_loss=7074.18018, val_loss=7089.84082\n",
      "Epoch 6758: train_loss=7072.59229, val_loss=7088.09033\n",
      "Epoch 6759: train_loss=7071.00342, val_loss=7086.33545\n",
      "Epoch 6760: train_loss=7069.41553, val_loss=7084.59473\n",
      "Epoch 6761: train_loss=7067.82227, val_loss=7082.86182\n",
      "Epoch 6762: train_loss=7066.22803, val_loss=7081.12793\n",
      "Epoch 6763: train_loss=7064.63330, val_loss=7079.37988\n",
      "Epoch 6764: train_loss=7063.03662, val_loss=7077.63281\n",
      "Epoch 6765: train_loss=7061.43652, val_loss=7075.89502\n",
      "Epoch 6766: train_loss=7059.83447, val_loss=7074.14697\n",
      "Epoch 6767: train_loss=7058.23389, val_loss=7072.39795\n",
      "Epoch 6768: train_loss=7056.63379, val_loss=7070.66016\n",
      "Epoch 6769: train_loss=7055.03174, val_loss=7068.92432\n",
      "Epoch 6770: train_loss=7053.42969, val_loss=7067.16846\n",
      "Epoch 6771: train_loss=7051.82471, val_loss=7065.41699\n",
      "Epoch 6772: train_loss=7050.21924, val_loss=7063.67139\n",
      "Epoch 6773: train_loss=7048.60938, val_loss=7061.92676\n",
      "Epoch 6774: train_loss=7046.99658, val_loss=7060.17627\n",
      "Epoch 6775: train_loss=7045.38037, val_loss=7058.42969\n",
      "Epoch 6776: train_loss=7043.75977, val_loss=7056.68701\n",
      "Epoch 6777: train_loss=7042.13818, val_loss=7054.92969\n",
      "Epoch 6778: train_loss=7040.51416, val_loss=7053.16406\n",
      "Epoch 6779: train_loss=7038.88623, val_loss=7051.40527\n",
      "Epoch 6780: train_loss=7037.25635, val_loss=7049.65527\n",
      "Epoch 6781: train_loss=7035.62500, val_loss=7047.88965\n",
      "Epoch 6782: train_loss=7033.99072, val_loss=7046.11035\n",
      "Epoch 6783: train_loss=7032.35107, val_loss=7044.33691\n",
      "Epoch 6784: train_loss=7030.70605, val_loss=7042.56396\n",
      "Epoch 6785: train_loss=7029.05029, val_loss=7040.79199\n",
      "Epoch 6786: train_loss=7027.38916, val_loss=7039.00000\n",
      "Epoch 6787: train_loss=7025.72412, val_loss=7037.19531\n",
      "Epoch 6788: train_loss=7024.05322, val_loss=7035.39600\n",
      "Epoch 6789: train_loss=7022.37695, val_loss=7033.60742\n",
      "Epoch 6790: train_loss=7020.69482, val_loss=7031.81299\n",
      "Epoch 6791: train_loss=7019.00537, val_loss=7030.00195\n",
      "Epoch 6792: train_loss=7017.31592, val_loss=7028.17578\n",
      "Epoch 6793: train_loss=7015.62256, val_loss=7026.33643\n",
      "Epoch 6794: train_loss=7013.92529, val_loss=7024.51270\n",
      "Epoch 6795: train_loss=7012.22314, val_loss=7022.69531\n",
      "Epoch 6796: train_loss=7010.52051, val_loss=7020.88135\n",
      "Epoch 6797: train_loss=7008.82178, val_loss=7019.08838\n",
      "Epoch 6798: train_loss=7007.13281, val_loss=7017.28613\n",
      "Epoch 6799: train_loss=7005.44092, val_loss=7015.50195\n",
      "Epoch 6800: train_loss=7003.74170, val_loss=7013.72998\n",
      "Epoch 6801: train_loss=7002.04590, val_loss=7011.94678\n",
      "Epoch 6802: train_loss=7000.35107, val_loss=7010.15234\n",
      "Epoch 6803: train_loss=6998.64697, val_loss=7008.36523\n",
      "Epoch 6804: train_loss=6996.93115, val_loss=7006.57812\n",
      "Epoch 6805: train_loss=6995.20703, val_loss=7004.76611\n",
      "Epoch 6806: train_loss=6993.48096, val_loss=7002.94141\n",
      "Epoch 6807: train_loss=6991.75098, val_loss=7001.12451\n",
      "Epoch 6808: train_loss=6990.01611, val_loss=6999.31689\n",
      "Epoch 6809: train_loss=6988.28320, val_loss=6997.48779\n",
      "Epoch 6810: train_loss=6986.54639, val_loss=6995.64160\n",
      "Epoch 6811: train_loss=6984.81006, val_loss=6993.80469\n",
      "Epoch 6812: train_loss=6983.08203, val_loss=6991.97217\n",
      "Epoch 6813: train_loss=6981.35498, val_loss=6990.12012\n",
      "Epoch 6814: train_loss=6979.62988, val_loss=6988.28174\n",
      "Epoch 6815: train_loss=6977.90527, val_loss=6986.45068\n",
      "Epoch 6816: train_loss=6976.17725, val_loss=6984.62305\n",
      "Epoch 6817: train_loss=6974.44727, val_loss=6982.77686\n",
      "Epoch 6818: train_loss=6972.71729, val_loss=6980.92529\n",
      "Epoch 6819: train_loss=6970.98486, val_loss=6979.09082\n",
      "Epoch 6820: train_loss=6969.25098, val_loss=6977.26611\n",
      "Epoch 6821: train_loss=6967.51611, val_loss=6975.43506\n",
      "Epoch 6822: train_loss=6965.78223, val_loss=6973.59082\n",
      "Epoch 6823: train_loss=6964.04736, val_loss=6971.73438\n",
      "Epoch 6824: train_loss=6962.30518, val_loss=6969.88379\n",
      "Epoch 6825: train_loss=6960.56250, val_loss=6968.02246\n",
      "Epoch 6826: train_loss=6958.81982, val_loss=6966.16406\n",
      "Epoch 6827: train_loss=6957.09180, val_loss=6964.30957\n",
      "Epoch 6828: train_loss=6955.36084, val_loss=6962.44971\n",
      "Epoch 6829: train_loss=6953.62695, val_loss=6960.57227\n",
      "Epoch 6830: train_loss=6951.89209, val_loss=6958.69238\n",
      "Epoch 6831: train_loss=6950.15625, val_loss=6956.82080\n",
      "Epoch 6832: train_loss=6948.41748, val_loss=6954.93652\n",
      "Epoch 6833: train_loss=6946.67773, val_loss=6953.04297\n",
      "Epoch 6834: train_loss=6944.93848, val_loss=6951.14746\n",
      "Epoch 6835: train_loss=6943.20312, val_loss=6949.24316\n",
      "Epoch 6836: train_loss=6941.46533, val_loss=6947.34033\n",
      "Epoch 6837: train_loss=6939.72266, val_loss=6945.43457\n",
      "Epoch 6838: train_loss=6937.97559, val_loss=6943.51611\n",
      "Epoch 6839: train_loss=6936.22461, val_loss=6941.59424\n",
      "Epoch 6840: train_loss=6934.46826, val_loss=6939.67139\n",
      "Epoch 6841: train_loss=6932.70508, val_loss=6937.73975\n",
      "Epoch 6842: train_loss=6930.93457, val_loss=6935.79688\n",
      "Epoch 6843: train_loss=6929.16113, val_loss=6933.85645\n",
      "Epoch 6844: train_loss=6927.38428, val_loss=6931.92529\n",
      "Epoch 6845: train_loss=6925.60254, val_loss=6929.99805\n",
      "Epoch 6846: train_loss=6923.82031, val_loss=6928.06543\n",
      "Epoch 6847: train_loss=6922.03857, val_loss=6926.13525\n",
      "Epoch 6848: train_loss=6920.25732, val_loss=6924.20703\n",
      "Epoch 6849: train_loss=6918.46973, val_loss=6922.28662\n",
      "Epoch 6850: train_loss=6916.67529, val_loss=6920.35205\n",
      "Epoch 6851: train_loss=6914.87109, val_loss=6918.41016\n",
      "Epoch 6852: train_loss=6913.06396, val_loss=6916.47266\n",
      "Epoch 6853: train_loss=6911.25830, val_loss=6914.53174\n",
      "Epoch 6854: train_loss=6909.44922, val_loss=6912.58203\n",
      "Epoch 6855: train_loss=6907.64014, val_loss=6910.63867\n",
      "Epoch 6856: train_loss=6905.82861, val_loss=6908.70020\n",
      "Epoch 6857: train_loss=6904.01514, val_loss=6906.76953\n",
      "Epoch 6858: train_loss=6902.19727, val_loss=6904.83008\n",
      "Epoch 6859: train_loss=6900.37891, val_loss=6902.88818\n",
      "Epoch 6860: train_loss=6898.56055, val_loss=6900.94727\n",
      "Epoch 6861: train_loss=6896.74023, val_loss=6899.01660\n",
      "Epoch 6862: train_loss=6894.92822, val_loss=6897.07715\n",
      "Epoch 6863: train_loss=6893.11572, val_loss=6895.13086\n",
      "Epoch 6864: train_loss=6891.29932, val_loss=6893.18896\n",
      "Epoch 6865: train_loss=6889.48291, val_loss=6891.25391\n",
      "Epoch 6866: train_loss=6887.66211, val_loss=6889.31396\n",
      "Epoch 6867: train_loss=6885.83203, val_loss=6887.36523\n",
      "Epoch 6868: train_loss=6883.99609, val_loss=6885.41357\n",
      "Epoch 6869: train_loss=6882.16113, val_loss=6883.46680\n",
      "Epoch 6870: train_loss=6880.33008, val_loss=6881.51953\n",
      "Epoch 6871: train_loss=6878.49902, val_loss=6879.56396\n",
      "Epoch 6872: train_loss=6876.66699, val_loss=6877.60547\n",
      "Epoch 6873: train_loss=6874.83252, val_loss=6875.65430\n",
      "Epoch 6874: train_loss=6872.99561, val_loss=6873.71729\n",
      "Epoch 6875: train_loss=6871.15625, val_loss=6871.78027\n",
      "Epoch 6876: train_loss=6869.31543, val_loss=6869.83154\n",
      "Epoch 6877: train_loss=6867.47021, val_loss=6867.88525\n",
      "Epoch 6878: train_loss=6865.62451, val_loss=6865.95020\n",
      "Epoch 6879: train_loss=6863.77686, val_loss=6864.02002\n",
      "Epoch 6880: train_loss=6861.92432, val_loss=6862.07520\n",
      "Epoch 6881: train_loss=6860.06641, val_loss=6860.13184\n",
      "Epoch 6882: train_loss=6858.20215, val_loss=6858.18750\n",
      "Epoch 6883: train_loss=6856.33105, val_loss=6856.24463\n",
      "Epoch 6884: train_loss=6854.45459, val_loss=6854.31201\n",
      "Epoch 6885: train_loss=6852.57861, val_loss=6852.37012\n",
      "Epoch 6886: train_loss=6850.70117, val_loss=6850.43213\n",
      "Epoch 6887: train_loss=6848.82031, val_loss=6848.47998\n",
      "Epoch 6888: train_loss=6846.93457, val_loss=6846.51807\n",
      "Epoch 6889: train_loss=6845.04346, val_loss=6844.54004\n",
      "Epoch 6890: train_loss=6843.15527, val_loss=6842.55127\n",
      "Epoch 6891: train_loss=6841.27539, val_loss=6840.49170\n",
      "Epoch 6892: train_loss=6839.39502, val_loss=6838.37695\n",
      "Epoch 6893: train_loss=6837.50195, val_loss=6836.24805\n",
      "Epoch 6894: train_loss=6835.61865, val_loss=6834.15479\n",
      "Epoch 6895: train_loss=6833.74365, val_loss=6832.07910\n",
      "Epoch 6896: train_loss=6831.86133, val_loss=6830.01367\n",
      "Epoch 6897: train_loss=6829.97461, val_loss=6827.97070\n",
      "Epoch 6898: train_loss=6828.08936, val_loss=6825.94141\n",
      "Epoch 6899: train_loss=6826.19775, val_loss=6823.93213\n",
      "Epoch 6900: train_loss=6824.30176, val_loss=6821.93701\n",
      "Epoch 6901: train_loss=6822.40137, val_loss=6819.93604\n",
      "Epoch 6902: train_loss=6820.50195, val_loss=6817.91260\n",
      "Epoch 6903: train_loss=6818.60107, val_loss=6815.88818\n",
      "Epoch 6904: train_loss=6816.69971, val_loss=6813.85400\n",
      "Epoch 6905: train_loss=6814.79736, val_loss=6811.81348\n",
      "Epoch 6906: train_loss=6812.88623, val_loss=6809.75391\n",
      "Epoch 6907: train_loss=6810.97412, val_loss=6807.68604\n",
      "Epoch 6908: train_loss=6809.05811, val_loss=6805.61426\n",
      "Epoch 6909: train_loss=6807.14258, val_loss=6803.53613\n",
      "Epoch 6910: train_loss=6805.22217, val_loss=6801.45361\n",
      "Epoch 6911: train_loss=6803.29541, val_loss=6799.36133\n",
      "Epoch 6912: train_loss=6801.36475, val_loss=6797.27539\n",
      "Epoch 6913: train_loss=6799.42969, val_loss=6795.19873\n",
      "Epoch 6914: train_loss=6797.49561, val_loss=6793.12939\n",
      "Epoch 6915: train_loss=6795.56250, val_loss=6791.05127\n",
      "Epoch 6916: train_loss=6793.62598, val_loss=6788.96924\n",
      "Epoch 6917: train_loss=6791.69238, val_loss=6786.89111\n",
      "Epoch 6918: train_loss=6789.76465, val_loss=6784.81836\n",
      "Epoch 6919: train_loss=6787.83447, val_loss=6782.75000\n",
      "Epoch 6920: train_loss=6785.90039, val_loss=6780.69580\n",
      "Epoch 6921: train_loss=6783.96143, val_loss=6778.66016\n",
      "Epoch 6922: train_loss=6782.01855, val_loss=6776.62939\n",
      "Epoch 6923: train_loss=6780.07129, val_loss=6774.59814\n",
      "Epoch 6924: train_loss=6778.11621, val_loss=6772.56494\n",
      "Epoch 6925: train_loss=6776.15674, val_loss=6770.53760\n",
      "Epoch 6926: train_loss=6774.19385, val_loss=6768.51318\n",
      "Epoch 6927: train_loss=6772.23193, val_loss=6766.47510\n",
      "Epoch 6928: train_loss=6770.27002, val_loss=6764.43604\n",
      "Epoch 6929: train_loss=6768.30859, val_loss=6762.39600\n",
      "Epoch 6930: train_loss=6766.34766, val_loss=6760.35400\n",
      "Epoch 6931: train_loss=6764.38623, val_loss=6758.30859\n",
      "Epoch 6932: train_loss=6762.42725, val_loss=6756.27344\n",
      "Epoch 6933: train_loss=6760.47021, val_loss=6754.23633\n",
      "Epoch 6934: train_loss=6758.52686, val_loss=6752.20312\n",
      "Epoch 6935: train_loss=6756.58203, val_loss=6750.16406\n",
      "Epoch 6936: train_loss=6754.63330, val_loss=6748.11084\n",
      "Epoch 6937: train_loss=6752.68115, val_loss=6746.05176\n",
      "Epoch 6938: train_loss=6750.72803, val_loss=6743.98389\n",
      "Epoch 6939: train_loss=6748.76904, val_loss=6741.90820\n",
      "Epoch 6940: train_loss=6746.80615, val_loss=6739.82227\n",
      "Epoch 6941: train_loss=6744.83398, val_loss=6737.71973\n",
      "Epoch 6942: train_loss=6742.85693, val_loss=6735.61475\n",
      "Epoch 6943: train_loss=6740.88086, val_loss=6733.50586\n",
      "Epoch 6944: train_loss=6738.90234, val_loss=6731.38330\n",
      "Epoch 6945: train_loss=6736.91846, val_loss=6729.24756\n",
      "Epoch 6946: train_loss=6734.92969, val_loss=6727.11719\n",
      "Epoch 6947: train_loss=6732.93701, val_loss=6724.98340\n",
      "Epoch 6948: train_loss=6730.93848, val_loss=6722.85156\n",
      "Epoch 6949: train_loss=6728.92822, val_loss=6720.71631\n",
      "Epoch 6950: train_loss=6726.91260, val_loss=6718.55664\n",
      "Epoch 6951: train_loss=6724.87842, val_loss=6716.36719\n",
      "Epoch 6952: train_loss=6722.82471, val_loss=6714.15820\n",
      "Epoch 6953: train_loss=6720.76318, val_loss=6711.93311\n",
      "Epoch 6954: train_loss=6718.69287, val_loss=6709.68604\n",
      "Epoch 6955: train_loss=6716.62061, val_loss=6707.42578\n",
      "Epoch 6956: train_loss=6714.53955, val_loss=6705.23486\n",
      "Epoch 6957: train_loss=6712.49951, val_loss=6703.12598\n",
      "Epoch 6958: train_loss=6710.48779, val_loss=6701.00830\n",
      "Epoch 6959: train_loss=6708.47363, val_loss=6698.87061\n",
      "Epoch 6960: train_loss=6706.46289, val_loss=6696.72803\n",
      "Epoch 6961: train_loss=6704.46240, val_loss=6694.59180\n",
      "Epoch 6962: train_loss=6702.44873, val_loss=6692.46094\n",
      "Epoch 6963: train_loss=6700.42627, val_loss=6690.32617\n",
      "Epoch 6964: train_loss=6698.40332, val_loss=6688.19971\n",
      "Epoch 6965: train_loss=6696.38281, val_loss=6686.07617\n",
      "Epoch 6966: train_loss=6694.35498, val_loss=6683.94141\n",
      "Epoch 6967: train_loss=6692.32324, val_loss=6681.79834\n",
      "Epoch 6968: train_loss=6690.28613, val_loss=6679.65430\n",
      "Epoch 6969: train_loss=6688.24365, val_loss=6677.51025\n",
      "Epoch 6970: train_loss=6686.19727, val_loss=6675.36963\n",
      "Epoch 6971: train_loss=6684.14941, val_loss=6673.23438\n",
      "Epoch 6972: train_loss=6682.10059, val_loss=6671.09912\n",
      "Epoch 6973: train_loss=6680.04688, val_loss=6668.97168\n",
      "Epoch 6974: train_loss=6677.99170, val_loss=6666.84912\n",
      "Epoch 6975: train_loss=6675.93506, val_loss=6664.72363\n",
      "Epoch 6976: train_loss=6673.87842, val_loss=6662.59619\n",
      "Epoch 6977: train_loss=6671.81689, val_loss=6660.46240\n",
      "Epoch 6978: train_loss=6669.75000, val_loss=6658.32666\n",
      "Epoch 6979: train_loss=6667.67969, val_loss=6656.19336\n",
      "Epoch 6980: train_loss=6665.60449, val_loss=6654.06250\n",
      "Epoch 6981: train_loss=6663.52783, val_loss=6651.92676\n",
      "Epoch 6982: train_loss=6661.44824, val_loss=6649.78564\n",
      "Epoch 6983: train_loss=6659.36475, val_loss=6647.63965\n",
      "Epoch 6984: train_loss=6657.28076, val_loss=6645.48779\n",
      "Epoch 6985: train_loss=6655.19238, val_loss=6643.33301\n",
      "Epoch 6986: train_loss=6653.10303, val_loss=6641.17627\n",
      "Epoch 6987: train_loss=6651.00781, val_loss=6639.01123\n",
      "Epoch 6988: train_loss=6648.90869, val_loss=6636.84961\n",
      "Epoch 6989: train_loss=6646.80908, val_loss=6634.68604\n",
      "Epoch 6990: train_loss=6644.70459, val_loss=6632.51807\n",
      "Epoch 6991: train_loss=6642.59766, val_loss=6630.34277\n",
      "Epoch 6992: train_loss=6640.48779, val_loss=6628.16455\n",
      "Epoch 6993: train_loss=6638.37549, val_loss=6625.97656\n",
      "Epoch 6994: train_loss=6636.25879, val_loss=6623.78613\n",
      "Epoch 6995: train_loss=6634.13672, val_loss=6621.60547\n",
      "Epoch 6996: train_loss=6632.01270, val_loss=6619.42725\n",
      "Epoch 6997: train_loss=6629.88574, val_loss=6617.24609\n",
      "Epoch 6998: train_loss=6627.75537, val_loss=6615.07520\n",
      "Epoch 6999: train_loss=6625.62256, val_loss=6612.89355\n",
      "Epoch 7000: train_loss=6623.48779, val_loss=6610.69629\n",
      "Epoch 7001: train_loss=6621.34912, val_loss=6608.49561\n",
      "Epoch 7002: train_loss=6619.20605, val_loss=6606.30078\n",
      "Epoch 7003: train_loss=6617.06006, val_loss=6604.10645\n",
      "Epoch 7004: train_loss=6614.90869, val_loss=6601.90576\n",
      "Epoch 7005: train_loss=6612.75488, val_loss=6599.70557\n",
      "Epoch 7006: train_loss=6610.59717, val_loss=6597.50830\n",
      "Epoch 7007: train_loss=6608.43506, val_loss=6595.31299\n",
      "Epoch 7008: train_loss=6606.26660, val_loss=6593.11816\n",
      "Epoch 7009: train_loss=6604.09131, val_loss=6590.92188\n",
      "Epoch 7010: train_loss=6601.90918, val_loss=6588.72461\n",
      "Epoch 7011: train_loss=6599.71777, val_loss=6586.53223\n",
      "Epoch 7012: train_loss=6597.51807, val_loss=6584.34424\n",
      "Epoch 7013: train_loss=6595.30957, val_loss=6582.15527\n",
      "Epoch 7014: train_loss=6593.09375, val_loss=6579.95361\n",
      "Epoch 7015: train_loss=6590.86426, val_loss=6577.73828\n",
      "Epoch 7016: train_loss=6588.63037, val_loss=6575.53564\n",
      "Epoch 7017: train_loss=6586.41162, val_loss=6573.33545\n",
      "Epoch 7018: train_loss=6584.20508, val_loss=6571.11572\n",
      "Epoch 7019: train_loss=6581.99805, val_loss=6568.87354\n",
      "Epoch 7020: train_loss=6579.78711, val_loss=6566.60938\n",
      "Epoch 7021: train_loss=6577.56885, val_loss=6564.34521\n",
      "Epoch 7022: train_loss=6575.34229, val_loss=6562.07617\n",
      "Epoch 7023: train_loss=6573.11719, val_loss=6559.78662\n",
      "Epoch 7024: train_loss=6570.88965, val_loss=6557.48145\n",
      "Epoch 7025: train_loss=6568.65527, val_loss=6555.18115\n",
      "Epoch 7026: train_loss=6566.41211, val_loss=6552.87891\n",
      "Epoch 7027: train_loss=6564.15479, val_loss=6550.57422\n",
      "Epoch 7028: train_loss=6561.88379, val_loss=6548.26709\n",
      "Epoch 7029: train_loss=6559.60498, val_loss=6545.95898\n",
      "Epoch 7030: train_loss=6557.31543, val_loss=6543.64746\n",
      "Epoch 7031: train_loss=6555.01709, val_loss=6541.31934\n",
      "Epoch 7032: train_loss=6552.70801, val_loss=6538.97705\n",
      "Epoch 7033: train_loss=6550.39111, val_loss=6536.60547\n",
      "Epoch 7034: train_loss=6548.07324, val_loss=6534.22314\n",
      "Epoch 7035: train_loss=6545.76318, val_loss=6531.83105\n",
      "Epoch 7036: train_loss=6543.44336, val_loss=6529.43945\n",
      "Epoch 7037: train_loss=6541.10840, val_loss=6527.04883\n",
      "Epoch 7038: train_loss=6538.75928, val_loss=6524.65625\n",
      "Epoch 7039: train_loss=6536.39844, val_loss=6522.25000\n",
      "Epoch 7040: train_loss=6534.03076, val_loss=6519.82422\n",
      "Epoch 7041: train_loss=6531.65332, val_loss=6517.39111\n",
      "Epoch 7042: train_loss=6529.27441, val_loss=6514.95508\n",
      "Epoch 7043: train_loss=6526.89160, val_loss=6512.57520\n",
      "Epoch 7044: train_loss=6524.50830, val_loss=6510.24316\n",
      "Epoch 7045: train_loss=6522.16064, val_loss=6507.89355\n",
      "Epoch 7046: train_loss=6519.84082, val_loss=6505.50391\n",
      "Epoch 7047: train_loss=6517.52197, val_loss=6503.09082\n",
      "Epoch 7048: train_loss=6515.20215, val_loss=6500.66113\n",
      "Epoch 7049: train_loss=6512.88037, val_loss=6498.22754\n",
      "Epoch 7050: train_loss=6510.55322, val_loss=6495.79443\n",
      "Epoch 7051: train_loss=6508.21826, val_loss=6493.34277\n",
      "Epoch 7052: train_loss=6505.88672, val_loss=6490.87500\n",
      "Epoch 7053: train_loss=6503.55029, val_loss=6488.40674\n",
      "Epoch 7054: train_loss=6501.20410, val_loss=6485.93701\n",
      "Epoch 7055: train_loss=6498.84961, val_loss=6483.47217\n",
      "Epoch 7056: train_loss=6496.49268, val_loss=6481.00781\n",
      "Epoch 7057: train_loss=6494.13330, val_loss=6478.54102\n",
      "Epoch 7058: train_loss=6491.77148, val_loss=6476.07959\n",
      "Epoch 7059: train_loss=6489.39990, val_loss=6473.61572\n",
      "Epoch 7060: train_loss=6487.02490, val_loss=6471.14990\n",
      "Epoch 7061: train_loss=6484.64258, val_loss=6468.67822\n",
      "Epoch 7062: train_loss=6482.25635, val_loss=6466.19971\n",
      "Epoch 7063: train_loss=6479.86572, val_loss=6463.72754\n",
      "Epoch 7064: train_loss=6477.46045, val_loss=6461.24414\n",
      "Epoch 7065: train_loss=6475.05518, val_loss=6458.75195\n",
      "Epoch 7066: train_loss=6472.64746, val_loss=6456.25098\n",
      "Epoch 7067: train_loss=6470.22510, val_loss=6453.75732\n",
      "Epoch 7068: train_loss=6467.77783, val_loss=6451.26025\n",
      "Epoch 7069: train_loss=6465.31641, val_loss=6448.76807\n",
      "Epoch 7070: train_loss=6462.83691, val_loss=6446.26807\n",
      "Epoch 7071: train_loss=6460.33496, val_loss=6443.75732\n",
      "Epoch 7072: train_loss=6457.81885, val_loss=6441.24023\n",
      "Epoch 7073: train_loss=6455.29102, val_loss=6438.71143\n",
      "Epoch 7074: train_loss=6452.74951, val_loss=6436.18555\n",
      "Epoch 7075: train_loss=6450.19775, val_loss=6433.62744\n",
      "Epoch 7076: train_loss=6447.63525, val_loss=6431.07031\n",
      "Epoch 7077: train_loss=6445.10498, val_loss=6428.52686\n",
      "Epoch 7078: train_loss=6442.59424, val_loss=6425.99512\n",
      "Epoch 7079: train_loss=6440.09082, val_loss=6423.46143\n",
      "Epoch 7080: train_loss=6437.58740, val_loss=6420.91406\n",
      "Epoch 7081: train_loss=6435.08008, val_loss=6418.34180\n",
      "Epoch 7082: train_loss=6432.56152, val_loss=6415.75537\n",
      "Epoch 7083: train_loss=6430.04590, val_loss=6413.17041\n",
      "Epoch 7084: train_loss=6427.53174, val_loss=6410.57178\n",
      "Epoch 7085: train_loss=6425.01758, val_loss=6407.96729\n",
      "Epoch 7086: train_loss=6422.50293, val_loss=6405.35303\n",
      "Epoch 7087: train_loss=6419.97998, val_loss=6402.75146\n",
      "Epoch 7088: train_loss=6417.44727, val_loss=6400.16553\n",
      "Epoch 7089: train_loss=6414.91895, val_loss=6397.59570\n",
      "Epoch 7090: train_loss=6412.39062, val_loss=6395.02930\n",
      "Epoch 7091: train_loss=6409.85986, val_loss=6392.46191\n",
      "Epoch 7092: train_loss=6407.32422, val_loss=6389.89355\n",
      "Epoch 7093: train_loss=6404.78857, val_loss=6387.31934\n",
      "Epoch 7094: train_loss=6402.24951, val_loss=6384.73828\n",
      "Epoch 7095: train_loss=6399.70459, val_loss=6382.15527\n",
      "Epoch 7096: train_loss=6397.15332, val_loss=6379.56934\n",
      "Epoch 7097: train_loss=6394.59814, val_loss=6376.95264\n",
      "Epoch 7098: train_loss=6392.03516, val_loss=6374.31396\n",
      "Epoch 7099: train_loss=6389.46680, val_loss=6371.72021\n",
      "Epoch 7100: train_loss=6386.89600, val_loss=6369.14551\n",
      "Epoch 7101: train_loss=6384.32227, val_loss=6366.59961\n",
      "Epoch 7102: train_loss=6381.74023, val_loss=6364.02832\n",
      "Epoch 7103: train_loss=6379.14014, val_loss=6361.44336\n",
      "Epoch 7104: train_loss=6376.51172, val_loss=6358.87744\n",
      "Epoch 7105: train_loss=6373.86670, val_loss=6356.32812\n",
      "Epoch 7106: train_loss=6371.21631, val_loss=6353.76318\n",
      "Epoch 7107: train_loss=6368.57520, val_loss=6351.17822\n",
      "Epoch 7108: train_loss=6365.92920, val_loss=6348.56543\n",
      "Epoch 7109: train_loss=6363.27930, val_loss=6345.91064\n",
      "Epoch 7110: train_loss=6360.61963, val_loss=6343.25342\n",
      "Epoch 7111: train_loss=6357.94629, val_loss=6340.57422\n",
      "Epoch 7112: train_loss=6355.24072, val_loss=6337.90723\n",
      "Epoch 7113: train_loss=6352.51953, val_loss=6335.24072\n",
      "Epoch 7114: train_loss=6349.77295, val_loss=6332.57910\n",
      "Epoch 7115: train_loss=6347.01807, val_loss=6329.92822\n",
      "Epoch 7116: train_loss=6344.24854, val_loss=6327.28467\n",
      "Epoch 7117: train_loss=6341.45557, val_loss=6324.64697\n",
      "Epoch 7118: train_loss=6338.65186, val_loss=6322.00781\n",
      "Epoch 7119: train_loss=6335.84717, val_loss=6319.35791\n",
      "Epoch 7120: train_loss=6333.03760, val_loss=6316.69580\n",
      "Epoch 7121: train_loss=6330.22266, val_loss=6314.02539\n",
      "Epoch 7122: train_loss=6327.39941, val_loss=6311.30811\n",
      "Epoch 7123: train_loss=6324.56104, val_loss=6308.52197\n",
      "Epoch 7124: train_loss=6321.69971, val_loss=6305.72607\n",
      "Epoch 7125: train_loss=6318.86963, val_loss=6302.94775\n",
      "Epoch 7126: train_loss=6316.06055, val_loss=6300.08887\n",
      "Epoch 7127: train_loss=6313.25049, val_loss=6297.18604\n",
      "Epoch 7128: train_loss=6310.41504, val_loss=6294.29980\n",
      "Epoch 7129: train_loss=6307.57471, val_loss=6291.40820\n",
      "Epoch 7130: train_loss=6304.72998, val_loss=6288.49561\n",
      "Epoch 7131: train_loss=6301.87402, val_loss=6285.57178\n",
      "Epoch 7132: train_loss=6299.00781, val_loss=6282.63037\n",
      "Epoch 7133: train_loss=6296.12500, val_loss=6279.70654\n",
      "Epoch 7134: train_loss=6293.23438, val_loss=6276.76758\n",
      "Epoch 7135: train_loss=6290.33252, val_loss=6273.83447\n",
      "Epoch 7136: train_loss=6287.42041, val_loss=6270.88428\n",
      "Epoch 7137: train_loss=6284.49609, val_loss=6267.93213\n",
      "Epoch 7138: train_loss=6281.57861, val_loss=6264.98242\n",
      "Epoch 7139: train_loss=6278.64746, val_loss=6262.00195\n",
      "Epoch 7140: train_loss=6275.68799, val_loss=6259.00293\n",
      "Epoch 7141: train_loss=6272.67529, val_loss=6255.99170\n",
      "Epoch 7142: train_loss=6269.64600, val_loss=6252.96826\n",
      "Epoch 7143: train_loss=6266.64355, val_loss=6249.93262\n",
      "Epoch 7144: train_loss=6263.64893, val_loss=6246.89844\n",
      "Epoch 7145: train_loss=6260.63574, val_loss=6243.87646\n",
      "Epoch 7146: train_loss=6257.62549, val_loss=6240.85010\n",
      "Epoch 7147: train_loss=6254.61914, val_loss=6237.80566\n",
      "Epoch 7148: train_loss=6251.61230, val_loss=6234.74951\n",
      "Epoch 7149: train_loss=6248.60742, val_loss=6231.69482\n",
      "Epoch 7150: train_loss=6245.58740, val_loss=6228.64453\n",
      "Epoch 7151: train_loss=6242.55713, val_loss=6225.57666\n",
      "Epoch 7152: train_loss=6239.50293, val_loss=6222.52686\n",
      "Epoch 7153: train_loss=6236.38721, val_loss=6219.45850\n",
      "Epoch 7154: train_loss=6233.24170, val_loss=6216.37012\n",
      "Epoch 7155: train_loss=6230.06885, val_loss=6213.28564\n",
      "Epoch 7156: train_loss=6226.84863, val_loss=6210.18311\n",
      "Epoch 7157: train_loss=6223.63037, val_loss=6207.08398\n",
      "Epoch 7158: train_loss=6220.40771, val_loss=6204.00000\n",
      "Epoch 7159: train_loss=6217.19727, val_loss=6200.94385\n",
      "Epoch 7160: train_loss=6214.01221, val_loss=6197.91602\n",
      "Epoch 7161: train_loss=6210.88623, val_loss=6194.89404\n",
      "Epoch 7162: train_loss=6207.78223, val_loss=6191.88086\n",
      "Epoch 7163: train_loss=6204.67578, val_loss=6188.83154\n",
      "Epoch 7164: train_loss=6201.54492, val_loss=6185.77197\n",
      "Epoch 7165: train_loss=6198.40918, val_loss=6182.69385\n",
      "Epoch 7166: train_loss=6195.27295, val_loss=6179.55908\n",
      "Epoch 7167: train_loss=6192.13086, val_loss=6176.40576\n",
      "Epoch 7168: train_loss=6188.97217, val_loss=6173.24756\n",
      "Epoch 7169: train_loss=6185.76074, val_loss=6170.06299\n",
      "Epoch 7170: train_loss=6182.53174, val_loss=6166.85303\n",
      "Epoch 7171: train_loss=6179.29199, val_loss=6163.63721\n",
      "Epoch 7172: train_loss=6176.04736, val_loss=6160.41602\n",
      "Epoch 7173: train_loss=6172.78467, val_loss=6157.17822\n",
      "Epoch 7174: train_loss=6169.50977, val_loss=6153.92480\n",
      "Epoch 7175: train_loss=6166.25098, val_loss=6150.64697\n",
      "Epoch 7176: train_loss=6163.00732, val_loss=6147.37256\n",
      "Epoch 7177: train_loss=6159.75488, val_loss=6144.14160\n",
      "Epoch 7178: train_loss=6156.50830, val_loss=6140.94873\n",
      "Epoch 7179: train_loss=6153.26709, val_loss=6137.76562\n",
      "Epoch 7180: train_loss=6150.05957, val_loss=6134.59570\n",
      "Epoch 7181: train_loss=6146.90869, val_loss=6131.41211\n",
      "Epoch 7182: train_loss=6143.75635, val_loss=6128.21631\n",
      "Epoch 7183: train_loss=6140.61475, val_loss=6124.98682\n",
      "Epoch 7184: train_loss=6137.46533, val_loss=6121.73926\n",
      "Epoch 7185: train_loss=6134.31445, val_loss=6118.49170\n",
      "Epoch 7186: train_loss=6131.15967, val_loss=6115.19482\n",
      "Epoch 7187: train_loss=6127.98291, val_loss=6111.82422\n",
      "Epoch 7188: train_loss=6124.77832, val_loss=6108.42725\n",
      "Epoch 7189: train_loss=6121.56104, val_loss=6105.05420\n",
      "Epoch 7190: train_loss=6118.33350, val_loss=6101.65723\n",
      "Epoch 7191: train_loss=6115.09082, val_loss=6098.23584\n",
      "Epoch 7192: train_loss=6111.84961, val_loss=6094.77393\n",
      "Epoch 7193: train_loss=6108.59082, val_loss=6091.30908\n",
      "Epoch 7194: train_loss=6105.33545, val_loss=6087.89355\n",
      "Epoch 7195: train_loss=6102.10498, val_loss=6084.48877\n",
      "Epoch 7196: train_loss=6098.88037, val_loss=6081.09131\n",
      "Epoch 7197: train_loss=6095.66113, val_loss=6077.69873\n",
      "Epoch 7198: train_loss=6092.43848, val_loss=6074.31104\n",
      "Epoch 7199: train_loss=6089.21094, val_loss=6070.92578\n",
      "Epoch 7200: train_loss=6085.97266, val_loss=6067.53076\n",
      "Epoch 7201: train_loss=6082.72559, val_loss=6064.13672\n",
      "Epoch 7202: train_loss=6079.47559, val_loss=6060.77100\n",
      "Epoch 7203: train_loss=6076.22607, val_loss=6057.39062\n",
      "Epoch 7204: train_loss=6072.95947, val_loss=6054.00146\n",
      "Epoch 7205: train_loss=6069.68408, val_loss=6050.58887\n",
      "Epoch 7206: train_loss=6066.39990, val_loss=6047.16748\n",
      "Epoch 7207: train_loss=6063.10547, val_loss=6043.78125\n",
      "Epoch 7208: train_loss=6059.82715, val_loss=6040.42041\n",
      "Epoch 7209: train_loss=6056.55078, val_loss=6037.04150\n",
      "Epoch 7210: train_loss=6053.26562, val_loss=6033.63428\n",
      "Epoch 7211: train_loss=6049.96289, val_loss=6030.21191\n",
      "Epoch 7212: train_loss=6046.63525, val_loss=6026.79590\n",
      "Epoch 7213: train_loss=6043.29590, val_loss=6023.36523\n",
      "Epoch 7214: train_loss=6039.95557, val_loss=6019.93799\n",
      "Epoch 7215: train_loss=6036.62793, val_loss=6016.53857\n",
      "Epoch 7216: train_loss=6033.29736, val_loss=6013.17188\n",
      "Epoch 7217: train_loss=6029.96289, val_loss=6009.78467\n",
      "Epoch 7218: train_loss=6026.63672, val_loss=6006.38379\n",
      "Epoch 7219: train_loss=6023.29932, val_loss=6002.98779\n",
      "Epoch 7220: train_loss=6019.95605, val_loss=5999.59033\n",
      "Epoch 7221: train_loss=6016.60254, val_loss=5996.20898\n",
      "Epoch 7222: train_loss=6013.23047, val_loss=5992.83643\n",
      "Epoch 7223: train_loss=6009.85596, val_loss=5989.43750\n",
      "Epoch 7224: train_loss=6006.47266, val_loss=5986.02783\n",
      "Epoch 7225: train_loss=6003.08350, val_loss=5982.62891\n",
      "Epoch 7226: train_loss=5999.68652, val_loss=5979.23438\n",
      "Epoch 7227: train_loss=5996.28320, val_loss=5975.82861\n",
      "Epoch 7228: train_loss=5992.86230, val_loss=5972.39697\n",
      "Epoch 7229: train_loss=5989.42529, val_loss=5968.97119\n",
      "Epoch 7230: train_loss=5985.98145, val_loss=5965.54102\n",
      "Epoch 7231: train_loss=5982.52979, val_loss=5962.10303\n",
      "Epoch 7232: train_loss=5979.08350, val_loss=5958.65039\n",
      "Epoch 7233: train_loss=5975.63037, val_loss=5955.17627\n",
      "Epoch 7234: train_loss=5972.17529, val_loss=5951.68896\n",
      "Epoch 7235: train_loss=5968.72510, val_loss=5948.17529\n",
      "Epoch 7236: train_loss=5965.27051, val_loss=5944.68018\n",
      "Epoch 7237: train_loss=5961.81348, val_loss=5941.18164\n",
      "Epoch 7238: train_loss=5958.34961, val_loss=5937.66406\n",
      "Epoch 7239: train_loss=5954.86670, val_loss=5934.15527\n",
      "Epoch 7240: train_loss=5951.38086, val_loss=5930.63770\n",
      "Epoch 7241: train_loss=5947.88672, val_loss=5927.12891\n",
      "Epoch 7242: train_loss=5944.38867, val_loss=5923.62842\n",
      "Epoch 7243: train_loss=5940.88721, val_loss=5920.12793\n",
      "Epoch 7244: train_loss=5937.38281, val_loss=5916.62939\n",
      "Epoch 7245: train_loss=5933.87549, val_loss=5913.11182\n",
      "Epoch 7246: train_loss=5930.35986, val_loss=5909.59180\n",
      "Epoch 7247: train_loss=5926.84131, val_loss=5906.07080\n",
      "Epoch 7248: train_loss=5923.31201, val_loss=5902.56201\n",
      "Epoch 7249: train_loss=5919.78516, val_loss=5899.04199\n",
      "Epoch 7250: train_loss=5916.25342, val_loss=5895.53564\n",
      "Epoch 7251: train_loss=5912.72070, val_loss=5892.04639\n",
      "Epoch 7252: train_loss=5909.18408, val_loss=5888.55762\n",
      "Epoch 7253: train_loss=5905.64258, val_loss=5885.04590\n",
      "Epoch 7254: train_loss=5902.10303, val_loss=5881.52588\n",
      "Epoch 7255: train_loss=5898.55469, val_loss=5878.00488\n",
      "Epoch 7256: train_loss=5894.99658, val_loss=5874.45605\n",
      "Epoch 7257: train_loss=5891.42285, val_loss=5870.88818\n",
      "Epoch 7258: train_loss=5887.83545, val_loss=5867.31689\n",
      "Epoch 7259: train_loss=5884.23828, val_loss=5863.73877\n",
      "Epoch 7260: train_loss=5880.63135, val_loss=5860.13037\n",
      "Epoch 7261: train_loss=5877.01807, val_loss=5856.51562\n",
      "Epoch 7262: train_loss=5873.39746, val_loss=5852.91406\n",
      "Epoch 7263: train_loss=5869.76465, val_loss=5849.29639\n",
      "Epoch 7264: train_loss=5866.12109, val_loss=5845.66357\n",
      "Epoch 7265: train_loss=5862.47070, val_loss=5842.01270\n",
      "Epoch 7266: train_loss=5858.80859, val_loss=5838.36621\n",
      "Epoch 7267: train_loss=5855.14111, val_loss=5834.71631\n",
      "Epoch 7268: train_loss=5851.45605, val_loss=5831.04639\n",
      "Epoch 7269: train_loss=5847.75635, val_loss=5827.36426\n",
      "Epoch 7270: train_loss=5844.04346, val_loss=5823.66504\n",
      "Epoch 7271: train_loss=5840.32568, val_loss=5819.94141\n",
      "Epoch 7272: train_loss=5836.60010, val_loss=5816.22314\n",
      "Epoch 7273: train_loss=5832.86084, val_loss=5812.50488\n",
      "Epoch 7274: train_loss=5829.10449, val_loss=5808.75439\n",
      "Epoch 7275: train_loss=5825.33154, val_loss=5804.98633\n",
      "Epoch 7276: train_loss=5821.53809, val_loss=5801.20166\n",
      "Epoch 7277: train_loss=5817.72852, val_loss=5797.40381\n",
      "Epoch 7278: train_loss=5813.90430, val_loss=5793.58008\n",
      "Epoch 7279: train_loss=5810.06543, val_loss=5789.77393\n",
      "Epoch 7280: train_loss=5806.22998, val_loss=5785.94141\n",
      "Epoch 7281: train_loss=5802.39648, val_loss=5782.08252\n",
      "Epoch 7282: train_loss=5798.56592, val_loss=5778.23242\n",
      "Epoch 7283: train_loss=5794.73730, val_loss=5774.36133\n",
      "Epoch 7284: train_loss=5790.90088, val_loss=5770.47363\n",
      "Epoch 7285: train_loss=5787.05225, val_loss=5766.57080\n",
      "Epoch 7286: train_loss=5783.18213, val_loss=5762.65137\n",
      "Epoch 7287: train_loss=5779.27344, val_loss=5758.73877\n",
      "Epoch 7288: train_loss=5775.34717, val_loss=5754.79834\n",
      "Epoch 7289: train_loss=5771.40967, val_loss=5750.81934\n",
      "Epoch 7290: train_loss=5767.46338, val_loss=5746.85010\n",
      "Epoch 7291: train_loss=5763.49316, val_loss=5742.88867\n",
      "Epoch 7292: train_loss=5759.51807, val_loss=5738.90137\n",
      "Epoch 7293: train_loss=5755.52979, val_loss=5734.89111\n",
      "Epoch 7294: train_loss=5751.52979, val_loss=5730.89062\n",
      "Epoch 7295: train_loss=5747.50635, val_loss=5726.86670\n",
      "Epoch 7296: train_loss=5743.46631, val_loss=5722.79980\n",
      "Epoch 7297: train_loss=5739.40430, val_loss=5718.75146\n",
      "Epoch 7298: train_loss=5735.35693, val_loss=5714.67480\n",
      "Epoch 7299: train_loss=5731.31787, val_loss=5710.54443\n",
      "Epoch 7300: train_loss=5727.23438, val_loss=5706.36816\n",
      "Epoch 7301: train_loss=5723.11670, val_loss=5702.18896\n",
      "Epoch 7302: train_loss=5718.98584, val_loss=5698.00391\n",
      "Epoch 7303: train_loss=5714.85059, val_loss=5693.80664\n",
      "Epoch 7304: train_loss=5710.71289, val_loss=5689.59131\n",
      "Epoch 7305: train_loss=5706.58008, val_loss=5685.41992\n",
      "Epoch 7306: train_loss=5702.50391, val_loss=5681.31250\n",
      "Epoch 7307: train_loss=5698.48389, val_loss=5677.19482\n",
      "Epoch 7308: train_loss=5694.46094, val_loss=5673.06055\n",
      "Epoch 7309: train_loss=5690.42236, val_loss=5668.90918\n",
      "Epoch 7310: train_loss=5686.34277, val_loss=5664.72803\n",
      "Epoch 7311: train_loss=5682.23926, val_loss=5660.54150\n",
      "Epoch 7312: train_loss=5678.10791, val_loss=5656.31836\n",
      "Epoch 7313: train_loss=5673.93506, val_loss=5652.06641\n",
      "Epoch 7314: train_loss=5669.73535, val_loss=5647.90283\n",
      "Epoch 7315: train_loss=5665.58691, val_loss=5643.79004\n",
      "Epoch 7316: train_loss=5661.48682, val_loss=5639.66113\n",
      "Epoch 7317: train_loss=5657.38916, val_loss=5635.51123\n",
      "Epoch 7318: train_loss=5653.30029, val_loss=5631.36572\n",
      "Epoch 7319: train_loss=5649.20020, val_loss=5627.23389\n",
      "Epoch 7320: train_loss=5645.08984, val_loss=5623.09131\n",
      "Epoch 7321: train_loss=5640.97021, val_loss=5618.92334\n",
      "Epoch 7322: train_loss=5636.84229, val_loss=5614.76660\n",
      "Epoch 7323: train_loss=5632.70898, val_loss=5610.62695\n",
      "Epoch 7324: train_loss=5628.57031, val_loss=5606.47021\n",
      "Epoch 7325: train_loss=5624.42676, val_loss=5602.30518\n",
      "Epoch 7326: train_loss=5620.27637, val_loss=5598.13770\n",
      "Epoch 7327: train_loss=5616.12061, val_loss=5593.97168\n",
      "Epoch 7328: train_loss=5611.95898, val_loss=5589.80127\n",
      "Epoch 7329: train_loss=5607.79053, val_loss=5585.61963\n",
      "Epoch 7330: train_loss=5603.62256, val_loss=5581.43799\n",
      "Epoch 7331: train_loss=5599.44434, val_loss=5577.27002\n",
      "Epoch 7332: train_loss=5595.25684, val_loss=5573.09229\n",
      "Epoch 7333: train_loss=5591.05957, val_loss=5568.89844\n",
      "Epoch 7334: train_loss=5586.85449, val_loss=5564.71191\n",
      "Epoch 7335: train_loss=5582.64014, val_loss=5560.51562\n",
      "Epoch 7336: train_loss=5578.41602, val_loss=5556.28320\n",
      "Epoch 7337: train_loss=5574.18213, val_loss=5552.07031\n",
      "Epoch 7338: train_loss=5569.93945, val_loss=5547.86279\n",
      "Epoch 7339: train_loss=5565.68506, val_loss=5543.64258\n",
      "Epoch 7340: train_loss=5561.42480, val_loss=5539.38721\n",
      "Epoch 7341: train_loss=5557.15625, val_loss=5535.13281\n",
      "Epoch 7342: train_loss=5552.87842, val_loss=5530.87549\n",
      "Epoch 7343: train_loss=5548.59180, val_loss=5526.60059\n",
      "Epoch 7344: train_loss=5544.29639, val_loss=5522.31738\n",
      "Epoch 7345: train_loss=5539.99219, val_loss=5518.04736\n",
      "Epoch 7346: train_loss=5535.68018, val_loss=5513.75928\n",
      "Epoch 7347: train_loss=5531.35938, val_loss=5509.44434\n",
      "Epoch 7348: train_loss=5527.02783, val_loss=5505.12207\n",
      "Epoch 7349: train_loss=5522.68799, val_loss=5500.82031\n",
      "Epoch 7350: train_loss=5518.33936, val_loss=5496.47998\n",
      "Epoch 7351: train_loss=5513.98242, val_loss=5492.13477\n",
      "Epoch 7352: train_loss=5509.61963, val_loss=5487.78467\n",
      "Epoch 7353: train_loss=5505.24707, val_loss=5483.42480\n",
      "Epoch 7354: train_loss=5500.86621, val_loss=5479.04443\n",
      "Epoch 7355: train_loss=5496.47656, val_loss=5474.66357\n",
      "Epoch 7356: train_loss=5492.07715, val_loss=5470.28076\n",
      "Epoch 7357: train_loss=5487.66943, val_loss=5465.89551\n",
      "Epoch 7358: train_loss=5483.25732, val_loss=5461.49414\n",
      "Epoch 7359: train_loss=5478.83398, val_loss=5457.08057\n",
      "Epoch 7360: train_loss=5474.40137, val_loss=5452.64062\n",
      "Epoch 7361: train_loss=5469.95508, val_loss=5448.18848\n",
      "Epoch 7362: train_loss=5465.49854, val_loss=5443.74609\n",
      "Epoch 7363: train_loss=5461.03516, val_loss=5439.29297\n",
      "Epoch 7364: train_loss=5456.56299, val_loss=5434.83838\n",
      "Epoch 7365: train_loss=5452.08057, val_loss=5430.39600\n",
      "Epoch 7366: train_loss=5447.58984, val_loss=5425.93359\n",
      "Epoch 7367: train_loss=5443.08789, val_loss=5421.46143\n",
      "Epoch 7368: train_loss=5438.57568, val_loss=5416.98633\n",
      "Epoch 7369: train_loss=5434.05371, val_loss=5412.50488\n",
      "Epoch 7370: train_loss=5429.52295, val_loss=5407.99756\n",
      "Epoch 7371: train_loss=5424.98145, val_loss=5403.47754\n",
      "Epoch 7372: train_loss=5420.43066, val_loss=5398.96240\n",
      "Epoch 7373: train_loss=5415.86914, val_loss=5394.43652\n",
      "Epoch 7374: train_loss=5411.29883, val_loss=5389.89062\n",
      "Epoch 7375: train_loss=5406.71729, val_loss=5385.35645\n",
      "Epoch 7376: train_loss=5402.12695, val_loss=5380.80127\n",
      "Epoch 7377: train_loss=5397.52588, val_loss=5376.25488\n",
      "Epoch 7378: train_loss=5392.91748, val_loss=5371.69678\n",
      "Epoch 7379: train_loss=5388.30176, val_loss=5367.12646\n",
      "Epoch 7380: train_loss=5383.67725, val_loss=5362.54297\n",
      "Epoch 7381: train_loss=5379.04248, val_loss=5357.95850\n",
      "Epoch 7382: train_loss=5374.40039, val_loss=5353.37744\n",
      "Epoch 7383: train_loss=5369.75000, val_loss=5348.77930\n",
      "Epoch 7384: train_loss=5365.09229, val_loss=5344.16699\n",
      "Epoch 7385: train_loss=5360.42432, val_loss=5339.57275\n",
      "Epoch 7386: train_loss=5355.74658, val_loss=5334.94580\n",
      "Epoch 7387: train_loss=5351.05469, val_loss=5330.30518\n",
      "Epoch 7388: train_loss=5346.35303, val_loss=5325.67285\n",
      "Epoch 7389: train_loss=5341.64502, val_loss=5321.03711\n",
      "Epoch 7390: train_loss=5336.93115, val_loss=5316.37207\n",
      "Epoch 7391: train_loss=5332.20996, val_loss=5311.71631\n",
      "Epoch 7392: train_loss=5327.47900, val_loss=5307.04248\n",
      "Epoch 7393: train_loss=5322.73926, val_loss=5302.34521\n",
      "Epoch 7394: train_loss=5317.98682, val_loss=5297.65137\n",
      "Epoch 7395: train_loss=5313.22314, val_loss=5292.94287\n",
      "Epoch 7396: train_loss=5308.44824, val_loss=5288.21631\n",
      "Epoch 7397: train_loss=5303.66406, val_loss=5283.48730\n",
      "Epoch 7398: train_loss=5298.87305, val_loss=5278.75635\n",
      "Epoch 7399: train_loss=5294.07471, val_loss=5274.00928\n",
      "Epoch 7400: train_loss=5289.26855, val_loss=5269.25684\n",
      "Epoch 7401: train_loss=5284.45605, val_loss=5264.49316\n",
      "Epoch 7402: train_loss=5279.63574, val_loss=5259.70312\n",
      "Epoch 7403: train_loss=5274.80713, val_loss=5254.94531\n",
      "Epoch 7404: train_loss=5269.96875, val_loss=5250.16016\n",
      "Epoch 7405: train_loss=5265.12158, val_loss=5245.34473\n",
      "Epoch 7406: train_loss=5260.26562, val_loss=5240.53369\n",
      "Epoch 7407: train_loss=5255.39990, val_loss=5235.72656\n",
      "Epoch 7408: train_loss=5250.52637, val_loss=5230.86328\n",
      "Epoch 7409: train_loss=5245.64062, val_loss=5226.01172\n",
      "Epoch 7410: train_loss=5240.74023, val_loss=5221.12207\n",
      "Epoch 7411: train_loss=5235.82617, val_loss=5216.20459\n",
      "Epoch 7412: train_loss=5230.89746, val_loss=5211.27295\n",
      "Epoch 7413: train_loss=5225.94580, val_loss=5206.31348\n",
      "Epoch 7414: train_loss=5220.97754, val_loss=5201.35303\n",
      "Epoch 7415: train_loss=5215.99268, val_loss=5196.40137\n",
      "Epoch 7416: train_loss=5210.98535, val_loss=5191.40479\n",
      "Epoch 7417: train_loss=5205.94629, val_loss=5186.38037\n",
      "Epoch 7418: train_loss=5200.88965, val_loss=5181.33643\n",
      "Epoch 7419: train_loss=5195.80127, val_loss=5176.32080\n",
      "Epoch 7420: train_loss=5190.74414, val_loss=5171.38281\n",
      "Epoch 7421: train_loss=5185.74805, val_loss=5166.43896\n",
      "Epoch 7422: train_loss=5180.76221, val_loss=5161.49805\n",
      "Epoch 7423: train_loss=5175.76514, val_loss=5156.53711\n",
      "Epoch 7424: train_loss=5170.75488, val_loss=5151.57471\n",
      "Epoch 7425: train_loss=5165.73340, val_loss=5146.59766\n",
      "Epoch 7426: train_loss=5160.69824, val_loss=5141.62793\n",
      "Epoch 7427: train_loss=5155.65137, val_loss=5136.65869\n",
      "Epoch 7428: train_loss=5150.59375, val_loss=5131.66602\n",
      "Epoch 7429: train_loss=5145.52344, val_loss=5126.67627\n",
      "Epoch 7430: train_loss=5140.44141, val_loss=5121.65381\n",
      "Epoch 7431: train_loss=5135.34668, val_loss=5116.61816\n",
      "Epoch 7432: train_loss=5130.24219, val_loss=5111.59668\n",
      "Epoch 7433: train_loss=5125.12500, val_loss=5106.55811\n",
      "Epoch 7434: train_loss=5119.99658, val_loss=5101.49561\n",
      "Epoch 7435: train_loss=5114.85547, val_loss=5096.41797\n",
      "Epoch 7436: train_loss=5109.70068, val_loss=5091.32666\n",
      "Epoch 7437: train_loss=5104.53369, val_loss=5086.20752\n",
      "Epoch 7438: train_loss=5099.35449, val_loss=5081.07764\n",
      "Epoch 7439: train_loss=5094.16113, val_loss=5075.95459\n",
      "Epoch 7440: train_loss=5088.95361, val_loss=5070.79736\n",
      "Epoch 7441: train_loss=5083.73389, val_loss=5065.62500\n",
      "Epoch 7442: train_loss=5078.50195, val_loss=5060.46631\n",
      "Epoch 7443: train_loss=5073.25830, val_loss=5055.24707\n",
      "Epoch 7444: train_loss=5068.00293, val_loss=5050.02295\n",
      "Epoch 7445: train_loss=5062.74219, val_loss=5044.80957\n",
      "Epoch 7446: train_loss=5057.47021, val_loss=5039.55811\n",
      "Epoch 7447: train_loss=5052.19678, val_loss=5034.30127\n",
      "Epoch 7448: train_loss=5046.91797, val_loss=5029.08154\n",
      "Epoch 7449: train_loss=5041.62305, val_loss=5023.76416\n",
      "Epoch 7450: train_loss=5036.30664, val_loss=5018.46387\n",
      "Epoch 7451: train_loss=5030.97656, val_loss=5013.17188\n",
      "Epoch 7452: train_loss=5025.63574, val_loss=5007.85010\n",
      "Epoch 7453: train_loss=5020.29102, val_loss=5002.52979\n",
      "Epoch 7454: train_loss=5014.94629, val_loss=4997.22998\n",
      "Epoch 7455: train_loss=5009.59082, val_loss=4991.85547\n",
      "Epoch 7456: train_loss=5004.21924, val_loss=4986.49219\n",
      "Epoch 7457: train_loss=4998.83398, val_loss=4981.14307\n",
      "Epoch 7458: train_loss=4993.43408, val_loss=4975.73926\n",
      "Epoch 7459: train_loss=4988.01807, val_loss=4970.33936\n",
      "Epoch 7460: train_loss=4982.59131, val_loss=4964.95361\n",
      "Epoch 7461: train_loss=4977.14844, val_loss=4959.53906\n",
      "Epoch 7462: train_loss=4971.69385, val_loss=4954.08594\n",
      "Epoch 7463: train_loss=4966.21338, val_loss=4948.64600\n",
      "Epoch 7464: train_loss=4960.71436, val_loss=4943.17139\n",
      "Epoch 7465: train_loss=4955.19775, val_loss=4937.67529\n",
      "Epoch 7466: train_loss=4949.66797, val_loss=4932.16455\n",
      "Epoch 7467: train_loss=4944.11963, val_loss=4926.63721\n",
      "Epoch 7468: train_loss=4938.55469, val_loss=4921.09326\n",
      "Epoch 7469: train_loss=4932.97119, val_loss=4915.53125\n",
      "Epoch 7470: train_loss=4927.36914, val_loss=4909.97168\n",
      "Epoch 7471: train_loss=4921.75684, val_loss=4904.39990\n",
      "Epoch 7472: train_loss=4916.14111, val_loss=4898.78662\n",
      "Epoch 7473: train_loss=4910.51611, val_loss=4893.19727\n",
      "Epoch 7474: train_loss=4904.87988, val_loss=4887.59375\n",
      "Epoch 7475: train_loss=4899.23633, val_loss=4881.97705\n",
      "Epoch 7476: train_loss=4893.58545, val_loss=4876.37305\n",
      "Epoch 7477: train_loss=4887.93262, val_loss=4870.74707\n",
      "Epoch 7478: train_loss=4882.25684, val_loss=4865.11230\n",
      "Epoch 7479: train_loss=4876.56543, val_loss=4859.45947\n",
      "Epoch 7480: train_loss=4870.87207, val_loss=4853.80176\n",
      "Epoch 7481: train_loss=4865.16992, val_loss=4848.14062\n",
      "Epoch 7482: train_loss=4859.46240, val_loss=4842.46191\n",
      "Epoch 7483: train_loss=4853.74561, val_loss=4836.79297\n",
      "Epoch 7484: train_loss=4848.01270, val_loss=4831.09668\n",
      "Epoch 7485: train_loss=4842.26318, val_loss=4825.40039\n",
      "Epoch 7486: train_loss=4836.50391, val_loss=4819.70801\n",
      "Epoch 7487: train_loss=4830.73828, val_loss=4814.01172\n",
      "Epoch 7488: train_loss=4824.96094, val_loss=4808.31104\n",
      "Epoch 7489: train_loss=4819.16846, val_loss=4802.58008\n",
      "Epoch 7490: train_loss=4813.35938, val_loss=4796.81689\n",
      "Epoch 7491: train_loss=4807.52002, val_loss=4791.04395\n",
      "Epoch 7492: train_loss=4801.65674, val_loss=4785.23340\n",
      "Epoch 7493: train_loss=4795.76221, val_loss=4779.39014\n",
      "Epoch 7494: train_loss=4789.84180, val_loss=4773.53857\n",
      "Epoch 7495: train_loss=4783.90576, val_loss=4767.68555\n",
      "Epoch 7496: train_loss=4777.95361, val_loss=4761.81543\n",
      "Epoch 7497: train_loss=4771.99414, val_loss=4755.92676\n",
      "Epoch 7498: train_loss=4766.02930, val_loss=4750.06689\n",
      "Epoch 7499: train_loss=4760.05664, val_loss=4744.18408\n",
      "Epoch 7500: train_loss=4754.08643, val_loss=4738.30127\n",
      "Epoch 7501: train_loss=4748.11719, val_loss=4732.42432\n",
      "Epoch 7502: train_loss=4742.14795, val_loss=4726.53320\n",
      "Epoch 7503: train_loss=4736.18066, val_loss=4720.63428\n",
      "Epoch 7504: train_loss=4730.20752, val_loss=4714.73340\n",
      "Epoch 7505: train_loss=4724.22412, val_loss=4708.79834\n",
      "Epoch 7506: train_loss=4718.22998, val_loss=4702.86621\n",
      "Epoch 7507: train_loss=4712.21875, val_loss=4696.92920\n",
      "Epoch 7508: train_loss=4706.19434, val_loss=4690.94580\n",
      "Epoch 7509: train_loss=4700.15332, val_loss=4684.95898\n",
      "Epoch 7510: train_loss=4694.10400, val_loss=4678.96533\n",
      "Epoch 7511: train_loss=4688.04639, val_loss=4672.94727\n",
      "Epoch 7512: train_loss=4681.98389, val_loss=4666.95361\n",
      "Epoch 7513: train_loss=4675.91650, val_loss=4660.95020\n",
      "Epoch 7514: train_loss=4669.83789, val_loss=4654.93555\n",
      "Epoch 7515: train_loss=4663.74365, val_loss=4648.90771\n",
      "Epoch 7516: train_loss=4657.63232, val_loss=4642.88037\n",
      "Epoch 7517: train_loss=4651.50146, val_loss=4636.84326\n",
      "Epoch 7518: train_loss=4645.35742, val_loss=4630.79102\n",
      "Epoch 7519: train_loss=4639.20068, val_loss=4624.69922\n",
      "Epoch 7520: train_loss=4633.02979, val_loss=4618.62451\n",
      "Epoch 7521: train_loss=4626.84668, val_loss=4612.52100\n",
      "Epoch 7522: train_loss=4620.65137, val_loss=4606.41553\n",
      "Epoch 7523: train_loss=4614.45410, val_loss=4600.32959\n",
      "Epoch 7524: train_loss=4608.25684, val_loss=4594.23486\n",
      "Epoch 7525: train_loss=4602.05518, val_loss=4588.12646\n",
      "Epoch 7526: train_loss=4595.84521, val_loss=4582.02979\n",
      "Epoch 7527: train_loss=4589.62744, val_loss=4575.92334\n",
      "Epoch 7528: train_loss=4583.39746, val_loss=4569.82227\n",
      "Epoch 7529: train_loss=4577.16406, val_loss=4563.70898\n",
      "Epoch 7530: train_loss=4570.92480, val_loss=4557.56982\n",
      "Epoch 7531: train_loss=4564.69092, val_loss=4551.41797\n",
      "Epoch 7532: train_loss=4558.45557, val_loss=4545.25684\n",
      "Epoch 7533: train_loss=4552.20996, val_loss=4539.10205\n",
      "Epoch 7534: train_loss=4545.95801, val_loss=4532.95703\n",
      "Epoch 7535: train_loss=4539.69580, val_loss=4526.81738\n",
      "Epoch 7536: train_loss=4533.43115, val_loss=4520.67871\n",
      "Epoch 7537: train_loss=4527.16064, val_loss=4514.54297\n",
      "Epoch 7538: train_loss=4520.88477, val_loss=4508.40479\n",
      "Epoch 7539: train_loss=4514.59961, val_loss=4502.24561\n",
      "Epoch 7540: train_loss=4508.30469, val_loss=4496.09082\n",
      "Epoch 7541: train_loss=4502.00098, val_loss=4489.92334\n",
      "Epoch 7542: train_loss=4495.68799, val_loss=4483.73535\n",
      "Epoch 7543: train_loss=4489.36279, val_loss=4477.56982\n",
      "Epoch 7544: train_loss=4483.03076, val_loss=4471.36865\n",
      "Epoch 7545: train_loss=4476.68799, val_loss=4465.17920\n",
      "Epoch 7546: train_loss=4470.32764, val_loss=4458.95801\n",
      "Epoch 7547: train_loss=4463.94873, val_loss=4452.71729\n",
      "Epoch 7548: train_loss=4457.55566, val_loss=4446.47363\n",
      "Epoch 7549: train_loss=4451.14893, val_loss=4440.21436\n",
      "Epoch 7550: train_loss=4444.73340, val_loss=4433.95898\n",
      "Epoch 7551: train_loss=4438.30371, val_loss=4427.67871\n",
      "Epoch 7552: train_loss=4431.85986, val_loss=4421.39648\n",
      "Epoch 7553: train_loss=4425.40869, val_loss=4415.08350\n",
      "Epoch 7554: train_loss=4418.95264, val_loss=4408.78418\n",
      "Epoch 7555: train_loss=4412.48486, val_loss=4402.46143\n",
      "Epoch 7556: train_loss=4406.00586, val_loss=4396.13623\n",
      "Epoch 7557: train_loss=4399.51074, val_loss=4389.80176\n",
      "Epoch 7558: train_loss=4392.99707, val_loss=4383.40967\n",
      "Epoch 7559: train_loss=4386.45947, val_loss=4377.05127\n",
      "Epoch 7560: train_loss=4379.90918, val_loss=4370.63721\n",
      "Epoch 7561: train_loss=4373.33887, val_loss=4364.25146\n",
      "Epoch 7562: train_loss=4366.74561, val_loss=4357.83887\n",
      "Epoch 7563: train_loss=4360.13135, val_loss=4351.38623\n",
      "Epoch 7564: train_loss=4353.50684, val_loss=4344.97119\n",
      "Epoch 7565: train_loss=4346.87842, val_loss=4338.54053\n",
      "Epoch 7566: train_loss=4340.25049, val_loss=4332.14795\n",
      "Epoch 7567: train_loss=4333.62012, val_loss=4325.74902\n",
      "Epoch 7568: train_loss=4326.95898, val_loss=4319.34229\n",
      "Epoch 7569: train_loss=4320.27881, val_loss=4312.96777\n",
      "Epoch 7570: train_loss=4313.60254, val_loss=4306.56738\n",
      "Epoch 7571: train_loss=4306.92334, val_loss=4300.17188\n",
      "Epoch 7572: train_loss=4300.22852, val_loss=4293.74170\n",
      "Epoch 7573: train_loss=4293.51416, val_loss=4287.32812\n",
      "Epoch 7574: train_loss=4286.78857, val_loss=4280.85693\n",
      "Epoch 7575: train_loss=4280.05029, val_loss=4274.42236\n",
      "Epoch 7576: train_loss=4273.31250, val_loss=4267.96338\n",
      "Epoch 7577: train_loss=4266.57471, val_loss=4261.48828\n",
      "Epoch 7578: train_loss=4259.83447, val_loss=4255.04443\n",
      "Epoch 7579: train_loss=4253.08691, val_loss=4248.53760\n",
      "Epoch 7580: train_loss=4246.33643, val_loss=4242.07617\n",
      "Epoch 7581: train_loss=4239.57715, val_loss=4235.56201\n",
      "Epoch 7582: train_loss=4232.80664, val_loss=4229.04639\n",
      "Epoch 7583: train_loss=4226.03027, val_loss=4222.53467\n",
      "Epoch 7584: train_loss=4219.26318, val_loss=4215.96338\n",
      "Epoch 7585: train_loss=4212.49951, val_loss=4209.40723\n",
      "Epoch 7586: train_loss=4205.73145, val_loss=4202.80371\n",
      "Epoch 7587: train_loss=4198.96045, val_loss=4196.22803\n",
      "Epoch 7588: train_loss=4192.19092, val_loss=4189.63135\n",
      "Epoch 7589: train_loss=4185.41309, val_loss=4183.02783\n",
      "Epoch 7590: train_loss=4178.60742, val_loss=4176.40869\n",
      "Epoch 7591: train_loss=4171.79102, val_loss=4169.76807\n",
      "Epoch 7592: train_loss=4164.95020, val_loss=4163.13281\n",
      "Epoch 7593: train_loss=4158.09033, val_loss=4156.46191\n",
      "Epoch 7594: train_loss=4151.22900, val_loss=4149.82471\n",
      "Epoch 7595: train_loss=4144.37109, val_loss=4143.15381\n",
      "Epoch 7596: train_loss=4137.50342, val_loss=4136.51904\n",
      "Epoch 7597: train_loss=4130.62109, val_loss=4129.87012\n",
      "Epoch 7598: train_loss=4123.72852, val_loss=4123.19482\n",
      "Epoch 7599: train_loss=4116.82666, val_loss=4116.51562\n",
      "Epoch 7600: train_loss=4109.92188, val_loss=4109.79053\n",
      "Epoch 7601: train_loss=4103.02979, val_loss=4103.09473\n",
      "Epoch 7602: train_loss=4096.13965, val_loss=4096.35889\n",
      "Epoch 7603: train_loss=4089.25146, val_loss=4089.68091\n",
      "Epoch 7604: train_loss=4082.38135, val_loss=4082.96460\n",
      "Epoch 7605: train_loss=4075.50854, val_loss=4076.24756\n",
      "Epoch 7606: train_loss=4068.62891, val_loss=4069.51587\n",
      "Epoch 7607: train_loss=4061.75049, val_loss=4062.75195\n",
      "Epoch 7608: train_loss=4054.86011, val_loss=4055.97485\n",
      "Epoch 7609: train_loss=4047.95312, val_loss=4049.19556\n",
      "Epoch 7610: train_loss=4041.04541, val_loss=4042.42700\n",
      "Epoch 7611: train_loss=4034.14331, val_loss=4035.66309\n",
      "Epoch 7612: train_loss=4027.23926, val_loss=4028.91162\n",
      "Epoch 7613: train_loss=4020.33228, val_loss=4022.17847\n",
      "Epoch 7614: train_loss=4013.42383, val_loss=4015.41626\n",
      "Epoch 7615: train_loss=4006.50757, val_loss=4008.69312\n",
      "Epoch 7616: train_loss=3999.58081, val_loss=4001.90869\n",
      "Epoch 7617: train_loss=3992.64014, val_loss=3995.17871\n",
      "Epoch 7618: train_loss=3985.68384, val_loss=3988.37329\n",
      "Epoch 7619: train_loss=3978.71509, val_loss=3981.61768\n",
      "Epoch 7620: train_loss=3971.73486, val_loss=3974.81567\n",
      "Epoch 7621: train_loss=3964.74512, val_loss=3968.03638\n",
      "Epoch 7622: train_loss=3957.75391, val_loss=3961.27563\n",
      "Epoch 7623: train_loss=3950.76978, val_loss=3954.48853\n",
      "Epoch 7624: train_loss=3943.78027, val_loss=3947.76733\n",
      "Epoch 7625: train_loss=3936.77954, val_loss=3940.95508\n",
      "Epoch 7626: train_loss=3929.76343, val_loss=3934.23047\n",
      "Epoch 7627: train_loss=3922.72876, val_loss=3927.38354\n",
      "Epoch 7628: train_loss=3915.66992, val_loss=3920.61621\n",
      "Epoch 7629: train_loss=3908.60522, val_loss=3913.73340\n",
      "Epoch 7630: train_loss=3901.51562, val_loss=3906.86865\n",
      "Epoch 7631: train_loss=3894.42505, val_loss=3900.03638\n",
      "Epoch 7632: train_loss=3887.33594, val_loss=3893.17017\n",
      "Epoch 7633: train_loss=3880.25073, val_loss=3886.35913\n",
      "Epoch 7634: train_loss=3873.16138, val_loss=3879.46973\n",
      "Epoch 7635: train_loss=3866.06909, val_loss=3872.63550\n",
      "Epoch 7636: train_loss=3858.95801, val_loss=3865.72119\n",
      "Epoch 7637: train_loss=3851.83203, val_loss=3858.85376\n",
      "Epoch 7638: train_loss=3844.69019, val_loss=3851.93848\n",
      "Epoch 7639: train_loss=3837.53906, val_loss=3845.01587\n",
      "Epoch 7640: train_loss=3830.38916, val_loss=3838.08130\n",
      "Epoch 7641: train_loss=3823.23120, val_loss=3831.12134\n",
      "Epoch 7642: train_loss=3816.07178, val_loss=3824.20361\n",
      "Epoch 7643: train_loss=3808.92676, val_loss=3817.24121\n",
      "Epoch 7644: train_loss=3801.79077, val_loss=3810.31250\n",
      "Epoch 7645: train_loss=3794.63965, val_loss=3803.28223\n",
      "Epoch 7646: train_loss=3787.47974, val_loss=3796.32153\n",
      "Epoch 7647: train_loss=3780.30713, val_loss=3789.24927\n",
      "Epoch 7648: train_loss=3773.10767, val_loss=3782.22803\n",
      "Epoch 7649: train_loss=3765.88013, val_loss=3775.09937\n",
      "Epoch 7650: train_loss=3758.62427, val_loss=3767.99487\n",
      "Epoch 7651: train_loss=3751.36157, val_loss=3760.84546\n",
      "Epoch 7652: train_loss=3744.09473, val_loss=3753.68823\n",
      "Epoch 7653: train_loss=3736.81982, val_loss=3746.55933\n",
      "Epoch 7654: train_loss=3729.54395, val_loss=3739.38574\n",
      "Epoch 7655: train_loss=3722.27148, val_loss=3732.29395\n",
      "Epoch 7656: train_loss=3715.01562, val_loss=3725.10107\n",
      "Epoch 7657: train_loss=3707.74829, val_loss=3718.01953\n",
      "Epoch 7658: train_loss=3700.46533, val_loss=3710.73193\n",
      "Epoch 7659: train_loss=3693.13916, val_loss=3703.57397\n",
      "Epoch 7660: train_loss=3685.78613, val_loss=3696.31348\n",
      "Epoch 7661: train_loss=3678.41162, val_loss=3689.17090\n",
      "Epoch 7662: train_loss=3671.09351, val_loss=3682.03662\n",
      "Epoch 7663: train_loss=3663.79395, val_loss=3674.96655\n",
      "Epoch 7664: train_loss=3656.52368, val_loss=3667.96558\n",
      "Epoch 7665: train_loss=3649.29102, val_loss=3660.88281\n",
      "Epoch 7666: train_loss=3642.07178, val_loss=3653.86865\n",
      "Epoch 7667: train_loss=3634.86157, val_loss=3646.73706\n",
      "Epoch 7668: train_loss=3627.64795, val_loss=3639.71362\n",
      "Epoch 7669: train_loss=3620.44604, val_loss=3632.57104\n",
      "Epoch 7670: train_loss=3613.24170, val_loss=3625.52661\n",
      "Epoch 7671: train_loss=3606.03418, val_loss=3618.40356\n",
      "Epoch 7672: train_loss=3598.82690, val_loss=3611.35571\n",
      "Epoch 7673: train_loss=3591.62695, val_loss=3604.27930\n",
      "Epoch 7674: train_loss=3584.43677, val_loss=3597.23535\n",
      "Epoch 7675: train_loss=3577.24976, val_loss=3590.20459\n",
      "Epoch 7676: train_loss=3570.06421, val_loss=3583.13623\n",
      "Epoch 7677: train_loss=3562.87354, val_loss=3576.11157\n",
      "Epoch 7678: train_loss=3555.68970, val_loss=3569.04199\n",
      "Epoch 7679: train_loss=3548.50806, val_loss=3562.02222\n",
      "Epoch 7680: train_loss=3541.33081, val_loss=3554.90454\n",
      "Epoch 7681: train_loss=3534.13818, val_loss=3547.85107\n",
      "Epoch 7682: train_loss=3526.91528, val_loss=3540.67261\n",
      "Epoch 7683: train_loss=3519.65723, val_loss=3533.55444\n",
      "Epoch 7684: train_loss=3512.38135, val_loss=3526.40723\n",
      "Epoch 7685: train_loss=3505.10645, val_loss=3519.28711\n",
      "Epoch 7686: train_loss=3497.84424, val_loss=3512.21606\n",
      "Epoch 7687: train_loss=3490.60229, val_loss=3505.09546\n",
      "Epoch 7688: train_loss=3483.36255, val_loss=3498.03491\n",
      "Epoch 7689: train_loss=3476.10327, val_loss=3490.86304\n",
      "Epoch 7690: train_loss=3468.81616, val_loss=3483.74390\n",
      "Epoch 7691: train_loss=3461.50903, val_loss=3476.54663\n",
      "Epoch 7692: train_loss=3454.18213, val_loss=3469.39917\n",
      "Epoch 7693: train_loss=3446.87036, val_loss=3462.27075\n",
      "Epoch 7694: train_loss=3439.59814, val_loss=3455.15356\n",
      "Epoch 7695: train_loss=3432.35400, val_loss=3448.02759\n",
      "Epoch 7696: train_loss=3425.10083, val_loss=3440.87866\n",
      "Epoch 7697: train_loss=3417.83960, val_loss=3433.76758\n",
      "Epoch 7698: train_loss=3410.56543, val_loss=3426.62769\n",
      "Epoch 7699: train_loss=3403.27808, val_loss=3419.52222\n",
      "Epoch 7700: train_loss=3395.96973, val_loss=3412.37573\n",
      "Epoch 7701: train_loss=3388.63086, val_loss=3405.23804\n",
      "Epoch 7702: train_loss=3381.26587, val_loss=3398.09375\n",
      "Epoch 7703: train_loss=3373.86914, val_loss=3390.96240\n",
      "Epoch 7704: train_loss=3366.44800, val_loss=3383.83179\n",
      "Epoch 7705: train_loss=3359.00391, val_loss=3376.66138\n",
      "Epoch 7706: train_loss=3351.51123, val_loss=3369.42065\n",
      "Epoch 7707: train_loss=3343.98853, val_loss=3362.07007\n",
      "Epoch 7708: train_loss=3336.36768, val_loss=3354.66846\n",
      "Epoch 7709: train_loss=3328.69873, val_loss=3347.34277\n",
      "Epoch 7710: train_loss=3321.05029, val_loss=3340.05713\n",
      "Epoch 7711: train_loss=3313.40771, val_loss=3332.89282\n",
      "Epoch 7712: train_loss=3305.81616, val_loss=3325.61938\n",
      "Epoch 7713: train_loss=3298.32007, val_loss=3318.28589\n",
      "Epoch 7714: train_loss=3290.76025, val_loss=3310.96460\n",
      "Epoch 7715: train_loss=3283.15991, val_loss=3303.58496\n",
      "Epoch 7716: train_loss=3275.54443, val_loss=3296.37720\n",
      "Epoch 7717: train_loss=3267.96265, val_loss=3289.00171\n",
      "Epoch 7718: train_loss=3260.33496, val_loss=3281.79175\n",
      "Epoch 7719: train_loss=3252.75024, val_loss=3274.52686\n",
      "Epoch 7720: train_loss=3245.20239, val_loss=3267.27466\n",
      "Epoch 7721: train_loss=3237.70874, val_loss=3260.17627\n",
      "Epoch 7722: train_loss=3230.32739, val_loss=3252.93994\n",
      "Epoch 7723: train_loss=3222.93457, val_loss=3245.79517\n",
      "Epoch 7724: train_loss=3215.57300, val_loss=3238.45581\n",
      "Epoch 7725: train_loss=3208.19116, val_loss=3231.20020\n",
      "Epoch 7726: train_loss=3200.78589, val_loss=3223.74658\n",
      "Epoch 7727: train_loss=3193.32812, val_loss=3216.33667\n",
      "Epoch 7728: train_loss=3185.85449, val_loss=3208.93799\n",
      "Epoch 7729: train_loss=3178.43750, val_loss=3201.52344\n",
      "Epoch 7730: train_loss=3171.02466, val_loss=3194.17603\n",
      "Epoch 7731: train_loss=3163.63477, val_loss=3186.80908\n",
      "Epoch 7732: train_loss=3156.27417, val_loss=3179.60571\n",
      "Epoch 7733: train_loss=3148.95557, val_loss=3172.32935\n",
      "Epoch 7734: train_loss=3141.66577, val_loss=3165.22876\n",
      "Epoch 7735: train_loss=3134.40186, val_loss=3158.09546\n",
      "Epoch 7736: train_loss=3127.16797, val_loss=3151.05688\n",
      "Epoch 7737: train_loss=3119.97168, val_loss=3144.00317\n",
      "Epoch 7738: train_loss=3112.78931, val_loss=3136.95679\n",
      "Epoch 7739: train_loss=3105.63184, val_loss=3130.00439\n",
      "Epoch 7740: train_loss=3098.49463, val_loss=3123.00293\n",
      "Epoch 7741: train_loss=3091.39062, val_loss=3116.20728\n",
      "Epoch 7742: train_loss=3084.34741, val_loss=3109.22070\n",
      "Epoch 7743: train_loss=3077.34595, val_loss=3102.61401\n",
      "Epoch 7744: train_loss=3070.39258, val_loss=3095.59937\n",
      "Epoch 7745: train_loss=3063.49243, val_loss=3089.14160\n",
      "Epoch 7746: train_loss=3056.57471, val_loss=3081.91846\n",
      "Epoch 7747: train_loss=3049.56665, val_loss=3075.26953\n",
      "Epoch 7748: train_loss=3042.45239, val_loss=3068.02271\n",
      "Epoch 7749: train_loss=3035.32178, val_loss=3061.23975\n",
      "Epoch 7750: train_loss=3028.32788, val_loss=3054.67285\n",
      "Epoch 7751: train_loss=3021.49561, val_loss=3047.80054\n",
      "Epoch 7752: train_loss=3014.66968, val_loss=3041.29956\n",
      "Epoch 7753: train_loss=3007.72607, val_loss=3034.20801\n",
      "Epoch 7754: train_loss=3000.66431, val_loss=3027.48413\n",
      "Epoch 7755: train_loss=2993.59424, val_loss=3020.79175\n",
      "Epoch 7756: train_loss=2986.66577, val_loss=3014.08936\n",
      "Epoch 7757: train_loss=2979.89282, val_loss=3007.63257\n",
      "Epoch 7758: train_loss=2972.99756, val_loss=3000.60498\n",
      "Epoch 7759: train_loss=2966.01123, val_loss=2994.01855\n",
      "Epoch 7760: train_loss=2959.02271, val_loss=2987.25342\n",
      "Epoch 7761: train_loss=2952.02588, val_loss=2980.45679\n",
      "Epoch 7762: train_loss=2945.06812, val_loss=2973.94312\n",
      "Epoch 7763: train_loss=2938.10059, val_loss=2966.99976\n",
      "Epoch 7764: train_loss=2931.13574, val_loss=2960.47998\n",
      "Epoch 7765: train_loss=2924.22681, val_loss=2953.64209\n",
      "Epoch 7766: train_loss=2917.33447, val_loss=2947.02588\n",
      "Epoch 7767: train_loss=2910.50391, val_loss=2940.52271\n",
      "Epoch 7768: train_loss=2903.74658, val_loss=2933.84155\n",
      "Epoch 7769: train_loss=2897.03271, val_loss=2927.53760\n",
      "Epoch 7770: train_loss=2890.37476, val_loss=2920.81885\n",
      "Epoch 7771: train_loss=2883.63745, val_loss=2914.31372\n",
      "Epoch 7772: train_loss=2876.79541, val_loss=2907.47705\n",
      "Epoch 7773: train_loss=2869.92969, val_loss=2900.71216\n",
      "Epoch 7774: train_loss=2863.01733, val_loss=2894.06689\n",
      "Epoch 7775: train_loss=2856.24561, val_loss=2887.18408\n",
      "Epoch 7776: train_loss=2849.59180, val_loss=2880.56982\n",
      "Epoch 7777: train_loss=2842.92114, val_loss=2873.77588\n",
      "Epoch 7778: train_loss=2836.31738, val_loss=2867.58032\n",
      "Epoch 7779: train_loss=2829.85083, val_loss=2860.95947\n",
      "Epoch 7780: train_loss=2823.41040, val_loss=2854.71973\n",
      "Epoch 7781: train_loss=2816.96655, val_loss=2848.23340\n",
      "Epoch 7782: train_loss=2810.54126, val_loss=2841.92310\n",
      "Epoch 7783: train_loss=2804.13745, val_loss=2835.63818\n",
      "Epoch 7784: train_loss=2797.75781, val_loss=2829.25854\n",
      "Epoch 7785: train_loss=2791.39990, val_loss=2823.13501\n",
      "Epoch 7786: train_loss=2785.05566, val_loss=2816.69604\n",
      "Epoch 7787: train_loss=2778.73975, val_loss=2810.71338\n",
      "Epoch 7788: train_loss=2772.42310, val_loss=2804.20703\n",
      "Epoch 7789: train_loss=2766.12695, val_loss=2798.27368\n",
      "Epoch 7790: train_loss=2759.81006, val_loss=2791.79541\n",
      "Epoch 7791: train_loss=2753.50342, val_loss=2785.83081\n",
      "Epoch 7792: train_loss=2747.19971, val_loss=2779.49780\n",
      "Epoch 7793: train_loss=2740.92065, val_loss=2773.45337\n",
      "Epoch 7794: train_loss=2734.66309, val_loss=2767.27100\n",
      "Epoch 7795: train_loss=2728.43286, val_loss=2761.19336\n",
      "Epoch 7796: train_loss=2722.22656, val_loss=2755.12524\n",
      "Epoch 7797: train_loss=2716.03979, val_loss=2748.97876\n",
      "Epoch 7798: train_loss=2709.86304, val_loss=2743.00513\n",
      "Epoch 7799: train_loss=2703.69775, val_loss=2736.82520\n",
      "Epoch 7800: train_loss=2697.54614, val_loss=2730.95728\n",
      "Epoch 7801: train_loss=2691.40088, val_loss=2724.75610\n",
      "Epoch 7802: train_loss=2685.26270, val_loss=2718.94702\n",
      "Epoch 7803: train_loss=2679.12915, val_loss=2712.74072\n",
      "Epoch 7804: train_loss=2673.01099, val_loss=2706.99829\n",
      "Epoch 7805: train_loss=2666.90430, val_loss=2700.73706\n",
      "Epoch 7806: train_loss=2660.82520, val_loss=2695.13403\n",
      "Epoch 7807: train_loss=2654.76636, val_loss=2688.81128\n",
      "Epoch 7808: train_loss=2648.74121, val_loss=2683.32397\n",
      "Epoch 7809: train_loss=2642.70825, val_loss=2676.95947\n",
      "Epoch 7810: train_loss=2636.69214, val_loss=2671.45654\n",
      "Epoch 7811: train_loss=2630.67578, val_loss=2665.15601\n",
      "Epoch 7812: train_loss=2624.66431, val_loss=2659.50000\n",
      "Epoch 7813: train_loss=2618.67334, val_loss=2653.44409\n",
      "Epoch 7814: train_loss=2612.71191, val_loss=2647.66431\n",
      "Epoch 7815: train_loss=2606.77173, val_loss=2641.81323\n",
      "Epoch 7816: train_loss=2600.85327, val_loss=2635.93408\n",
      "Epoch 7817: train_loss=2594.94751, val_loss=2630.26318\n",
      "Epoch 7818: train_loss=2589.04907, val_loss=2624.30322\n",
      "Epoch 7819: train_loss=2583.17188, val_loss=2618.88574\n",
      "Epoch 7820: train_loss=2577.31958, val_loss=2612.81299\n",
      "Epoch 7821: train_loss=2571.50879, val_loss=2607.73242\n",
      "Epoch 7822: train_loss=2565.74634, val_loss=2601.49170\n",
      "Epoch 7823: train_loss=2560.04150, val_loss=2596.78052\n",
      "Epoch 7824: train_loss=2554.32202, val_loss=2590.25684\n",
      "Epoch 7825: train_loss=2548.56104, val_loss=2585.45312\n",
      "Epoch 7826: train_loss=2542.66479, val_loss=2578.86621\n",
      "Epoch 7827: train_loss=2536.67554, val_loss=2573.53857\n",
      "Epoch 7828: train_loss=2530.74268, val_loss=2567.88354\n",
      "Epoch 7829: train_loss=2524.97217, val_loss=2562.07666\n",
      "Epoch 7830: train_loss=2519.34155, val_loss=2557.18774\n",
      "Epoch 7831: train_loss=2513.71704, val_loss=2550.96118\n",
      "Epoch 7832: train_loss=2508.01123, val_loss=2545.93604\n",
      "Epoch 7833: train_loss=2502.25952, val_loss=2539.91821\n",
      "Epoch 7834: train_loss=2496.51172, val_loss=2534.48071\n",
      "Epoch 7835: train_loss=2490.83765, val_loss=2529.15259\n",
      "Epoch 7836: train_loss=2485.24536, val_loss=2523.35791\n",
      "Epoch 7837: train_loss=2479.70142, val_loss=2518.42969\n",
      "Epoch 7838: train_loss=2474.16064, val_loss=2512.41455\n",
      "Epoch 7839: train_loss=2468.59961, val_loss=2507.45239\n",
      "Epoch 7840: train_loss=2462.99976, val_loss=2501.55933\n",
      "Epoch 7841: train_loss=2457.41162, val_loss=2496.33521\n",
      "Epoch 7842: train_loss=2451.84619, val_loss=2490.87036\n",
      "Epoch 7843: train_loss=2446.32837, val_loss=2485.31909\n",
      "Epoch 7844: train_loss=2440.85132, val_loss=2480.24414\n",
      "Epoch 7845: train_loss=2435.38477, val_loss=2474.44165\n",
      "Epoch 7846: train_loss=2429.91943, val_loss=2469.54028\n",
      "Epoch 7847: train_loss=2424.45654, val_loss=2463.65674\n",
      "Epoch 7848: train_loss=2418.96875, val_loss=2458.70312\n",
      "Epoch 7849: train_loss=2413.48975, val_loss=2452.93481\n",
      "Epoch 7850: train_loss=2408.00415, val_loss=2447.82422\n",
      "Epoch 7851: train_loss=2402.54541, val_loss=2442.29468\n",
      "Epoch 7852: train_loss=2397.10303, val_loss=2437.03979\n",
      "Epoch 7853: train_loss=2391.67139, val_loss=2431.68823\n",
      "Epoch 7854: train_loss=2386.24146, val_loss=2426.35864\n",
      "Epoch 7855: train_loss=2380.80957, val_loss=2421.07544\n",
      "Epoch 7856: train_loss=2375.37769, val_loss=2415.61816\n",
      "Epoch 7857: train_loss=2369.92334, val_loss=2410.35107\n",
      "Epoch 7858: train_loss=2364.48218, val_loss=2404.83423\n",
      "Epoch 7859: train_loss=2359.05981, val_loss=2399.67676\n",
      "Epoch 7860: train_loss=2353.65063, val_loss=2394.05762\n",
      "Epoch 7861: train_loss=2348.24292, val_loss=2389.04663\n",
      "Epoch 7862: train_loss=2342.84668, val_loss=2383.28809\n",
      "Epoch 7863: train_loss=2337.46826, val_loss=2378.54907\n",
      "Epoch 7864: train_loss=2332.14062, val_loss=2372.70264\n",
      "Epoch 7865: train_loss=2326.84521, val_loss=2368.23975\n",
      "Epoch 7866: train_loss=2321.56299, val_loss=2362.21655\n",
      "Epoch 7867: train_loss=2316.24316, val_loss=2357.76245\n",
      "Epoch 7868: train_loss=2310.90527, val_loss=2351.76685\n",
      "Epoch 7869: train_loss=2305.54321, val_loss=2347.03101\n",
      "Epoch 7870: train_loss=2300.22314, val_loss=2341.60986\n",
      "Epoch 7871: train_loss=2294.98364, val_loss=2336.49292\n",
      "Epoch 7872: train_loss=2289.82739, val_loss=2331.74780\n",
      "Epoch 7873: train_loss=2284.73584, val_loss=2326.29517\n",
      "Epoch 7874: train_loss=2279.67798, val_loss=2322.00439\n",
      "Epoch 7875: train_loss=2274.65405, val_loss=2316.23462\n",
      "Epoch 7876: train_loss=2269.58350, val_loss=2311.97217\n",
      "Epoch 7877: train_loss=2264.46045, val_loss=2306.13135\n",
      "Epoch 7878: train_loss=2259.29468, val_loss=2301.59351\n",
      "Epoch 7879: train_loss=2254.13477, val_loss=2296.12158\n",
      "Epoch 7880: train_loss=2249.02588, val_loss=2291.30225\n",
      "Epoch 7881: train_loss=2243.96069, val_loss=2286.27905\n",
      "Epoch 7882: train_loss=2238.91968, val_loss=2281.19116\n",
      "Epoch 7883: train_loss=2233.92432, val_loss=2276.52930\n",
      "Epoch 7884: train_loss=2228.96631, val_loss=2271.22192\n",
      "Epoch 7885: train_loss=2224.05054, val_loss=2266.82104\n",
      "Epoch 7886: train_loss=2219.15723, val_loss=2261.32983\n",
      "Epoch 7887: train_loss=2214.28418, val_loss=2257.18091\n",
      "Epoch 7888: train_loss=2209.42969, val_loss=2251.64795\n",
      "Epoch 7889: train_loss=2204.55859, val_loss=2247.48462\n",
      "Epoch 7890: train_loss=2199.66040, val_loss=2242.01514\n",
      "Epoch 7891: train_loss=2194.75146, val_loss=2237.63354\n",
      "Epoch 7892: train_loss=2189.83594, val_loss=2232.42236\n",
      "Epoch 7893: train_loss=2184.91870, val_loss=2227.73511\n",
      "Epoch 7894: train_loss=2180.00562, val_loss=2222.88037\n",
      "Epoch 7895: train_loss=2175.09448, val_loss=2217.78516\n",
      "Epoch 7896: train_loss=2170.15430, val_loss=2213.12817\n",
      "Epoch 7897: train_loss=2165.09741, val_loss=2207.70532\n",
      "Epoch 7898: train_loss=2159.96948, val_loss=2203.66455\n",
      "Epoch 7899: train_loss=2155.36328, val_loss=2198.58545\n",
      "Epoch 7900: train_loss=2150.85327, val_loss=2194.90771\n",
      "Epoch 7901: train_loss=2146.32007, val_loss=2189.57520\n",
      "Epoch 7902: train_loss=2141.72803, val_loss=2185.88257\n",
      "Epoch 7903: train_loss=2137.08789, val_loss=2180.49927\n",
      "Epoch 7904: train_loss=2132.36816, val_loss=2176.40430\n",
      "Epoch 7905: train_loss=2127.64941, val_loss=2171.44946\n",
      "Epoch 7906: train_loss=2122.97119, val_loss=2166.95410\n",
      "Epoch 7907: train_loss=2118.35986, val_loss=2162.59619\n",
      "Epoch 7908: train_loss=2113.81567, val_loss=2157.70288\n",
      "Epoch 7909: train_loss=2109.31348, val_loss=2153.76807\n",
      "Epoch 7910: train_loss=2104.82617, val_loss=2148.55786\n",
      "Epoch 7911: train_loss=2100.34277, val_loss=2144.71094\n",
      "Epoch 7912: train_loss=2095.80737, val_loss=2139.45703\n",
      "Epoch 7913: train_loss=2091.24341, val_loss=2135.34399\n",
      "Epoch 7914: train_loss=2086.68652, val_loss=2130.50000\n",
      "Epoch 7915: train_loss=2082.16895, val_loss=2126.05322\n",
      "Epoch 7916: train_loss=2077.69678, val_loss=2121.76196\n",
      "Epoch 7917: train_loss=2073.26807, val_loss=2117.01782\n",
      "Epoch 7918: train_loss=2068.87012, val_loss=2113.08936\n",
      "Epoch 7919: train_loss=2064.47778, val_loss=2108.16064\n",
      "Epoch 7920: train_loss=2060.10840, val_loss=2104.34692\n",
      "Epoch 7921: train_loss=2055.70410, val_loss=2099.37354\n",
      "Epoch 7922: train_loss=2051.30713, val_loss=2095.46851\n",
      "Epoch 7923: train_loss=2046.90271, val_loss=2090.74512\n",
      "Epoch 7924: train_loss=2042.51746, val_loss=2086.63623\n",
      "Epoch 7925: train_loss=2038.13989, val_loss=2082.21289\n",
      "Epoch 7926: train_loss=2033.78711, val_loss=2077.96558\n",
      "Epoch 7927: train_loss=2029.46265, val_loss=2073.79932\n",
      "Epoch 7928: train_loss=2025.15881, val_loss=2069.38916\n",
      "Epoch 7929: train_loss=2020.87256, val_loss=2065.45483\n",
      "Epoch 7930: train_loss=2016.61450, val_loss=2060.83569\n",
      "Epoch 7931: train_loss=2012.39795, val_loss=2057.32568\n",
      "Epoch 7932: train_loss=2008.23145, val_loss=2052.45435\n",
      "Epoch 7933: train_loss=2004.12427, val_loss=2049.33154\n",
      "Epoch 7934: train_loss=2000.00269, val_loss=2044.16821\n",
      "Epoch 7935: train_loss=1995.87598, val_loss=2040.98035\n",
      "Epoch 7936: train_loss=1991.64343, val_loss=2035.83472\n",
      "Epoch 7937: train_loss=1987.41455, val_loss=2032.25916\n",
      "Epoch 7938: train_loss=1983.16687, val_loss=2027.67090\n",
      "Epoch 7939: train_loss=1978.99207, val_loss=2023.63464\n",
      "Epoch 7940: train_loss=1974.90015, val_loss=2019.80945\n",
      "Epoch 7941: train_loss=1970.87732, val_loss=2015.38086\n",
      "Epoch 7942: train_loss=1966.90613, val_loss=2012.11230\n",
      "Epoch 7943: train_loss=1962.96655, val_loss=2007.32788\n",
      "Epoch 7944: train_loss=1959.01111, val_loss=2004.21680\n",
      "Epoch 7945: train_loss=1955.02246, val_loss=1999.28796\n",
      "Epoch 7946: train_loss=1950.99451, val_loss=1995.98535\n",
      "Epoch 7947: train_loss=1946.92749, val_loss=1991.34241\n",
      "Epoch 7948: train_loss=1942.86182, val_loss=1987.61975\n",
      "Epoch 7949: train_loss=1938.85083, val_loss=1983.67761\n",
      "Epoch 7950: train_loss=1934.91016, val_loss=1979.54138\n",
      "Epoch 7951: train_loss=1931.03992, val_loss=1976.24670\n",
      "Epoch 7952: train_loss=1927.21619, val_loss=1971.71802\n",
      "Epoch 7953: train_loss=1923.40381, val_loss=1968.73254\n",
      "Epoch 7954: train_loss=1919.57947, val_loss=1963.97046\n",
      "Epoch 7955: train_loss=1915.72058, val_loss=1960.90320\n",
      "Epoch 7956: train_loss=1911.82556, val_loss=1956.28015\n",
      "Epoch 7957: train_loss=1907.92126, val_loss=1952.85083\n",
      "Epoch 7958: train_loss=1904.03320, val_loss=1948.80127\n",
      "Epoch 7959: train_loss=1900.20093, val_loss=1944.92737\n",
      "Epoch 7960: train_loss=1896.43201, val_loss=1941.55151\n",
      "Epoch 7961: train_loss=1892.72021, val_loss=1937.29065\n",
      "Epoch 7962: train_loss=1889.04126, val_loss=1934.38184\n",
      "Epoch 7963: train_loss=1885.38501, val_loss=1929.81885\n",
      "Epoch 7964: train_loss=1881.70740, val_loss=1927.07812\n",
      "Epoch 7965: train_loss=1878.04114, val_loss=1922.40576\n",
      "Epoch 7966: train_loss=1874.32910, val_loss=1919.57166\n",
      "Epoch 7967: train_loss=1870.62781, val_loss=1915.04382\n",
      "Epoch 7968: train_loss=1866.89160, val_loss=1911.89270\n",
      "Epoch 7969: train_loss=1863.19189, val_loss=1907.85474\n",
      "Epoch 7970: train_loss=1859.51880, val_loss=1904.27832\n",
      "Epoch 7971: train_loss=1855.90930, val_loss=1900.94885\n",
      "Epoch 7972: train_loss=1852.35608, val_loss=1896.97229\n",
      "Epoch 7973: train_loss=1848.83594, val_loss=1894.08423\n",
      "Epoch 7974: train_loss=1845.33008, val_loss=1889.82874\n",
      "Epoch 7975: train_loss=1841.81421, val_loss=1887.07703\n",
      "Epoch 7976: train_loss=1838.30090, val_loss=1882.75488\n",
      "Epoch 7977: train_loss=1834.76135, val_loss=1879.88928\n",
      "Epoch 7978: train_loss=1831.22754, val_loss=1875.76184\n",
      "Epoch 7979: train_loss=1827.70068, val_loss=1872.64294\n",
      "Epoch 7980: train_loss=1824.18665, val_loss=1868.91541\n",
      "Epoch 7981: train_loss=1820.70789, val_loss=1865.50647\n",
      "Epoch 7982: train_loss=1817.25989, val_loss=1862.16882\n",
      "Epoch 7983: train_loss=1813.83813, val_loss=1858.51233\n",
      "Epoch 7984: train_loss=1810.43738, val_loss=1855.45715\n",
      "Epoch 7985: train_loss=1807.05383, val_loss=1851.61755\n",
      "Epoch 7986: train_loss=1803.68530, val_loss=1848.78137\n",
      "Epoch 7987: train_loss=1800.33984, val_loss=1844.77747\n",
      "Epoch 7988: train_loss=1797.00891, val_loss=1842.18823\n",
      "Epoch 7989: train_loss=1793.71130, val_loss=1838.00439\n",
      "Epoch 7990: train_loss=1790.42871, val_loss=1835.63257\n",
      "Epoch 7991: train_loss=1787.14807, val_loss=1831.30286\n",
      "Epoch 7992: train_loss=1783.85339, val_loss=1828.90405\n",
      "Epoch 7993: train_loss=1780.53162, val_loss=1824.65979\n",
      "Epoch 7994: train_loss=1777.19678, val_loss=1821.96313\n",
      "Epoch 7995: train_loss=1773.85864, val_loss=1818.18835\n",
      "Epoch 7996: train_loss=1770.54944, val_loss=1815.01392\n",
      "Epoch 7997: train_loss=1767.29993, val_loss=1811.95288\n",
      "Epoch 7998: train_loss=1764.10742, val_loss=1808.35767\n",
      "Epoch 7999: train_loss=1760.94873, val_loss=1805.75562\n",
      "Epoch 8000: train_loss=1757.80396, val_loss=1801.86902\n",
      "Epoch 8001: train_loss=1754.66736, val_loss=1799.52661\n",
      "Epoch 8002: train_loss=1751.54553, val_loss=1795.46167\n",
      "Epoch 8003: train_loss=1748.43091, val_loss=1793.23230\n",
      "Epoch 8004: train_loss=1745.29285, val_loss=1789.11133\n",
      "Epoch 8005: train_loss=1742.15173, val_loss=1786.77942\n",
      "Epoch 8006: train_loss=1738.99451, val_loss=1782.83289\n",
      "Epoch 8007: train_loss=1735.83752, val_loss=1780.23767\n",
      "Epoch 8008: train_loss=1732.69995, val_loss=1776.69836\n",
      "Epoch 8009: train_loss=1729.57727, val_loss=1773.68591\n",
      "Epoch 8010: train_loss=1726.49719, val_loss=1770.74255\n",
      "Epoch 8011: train_loss=1723.45935, val_loss=1767.35974\n",
      "Epoch 8012: train_loss=1720.44812, val_loss=1764.79358\n",
      "Epoch 8013: train_loss=1717.45056, val_loss=1761.15857\n",
      "Epoch 8014: train_loss=1714.47034, val_loss=1758.87524\n",
      "Epoch 8015: train_loss=1711.51489, val_loss=1755.01868\n",
      "Epoch 8016: train_loss=1708.59497, val_loss=1753.03955\n",
      "Epoch 8017: train_loss=1705.67004, val_loss=1748.94153\n",
      "Epoch 8018: train_loss=1702.76538, val_loss=1747.07593\n",
      "Epoch 8019: train_loss=1699.79663, val_loss=1742.90332\n",
      "Epoch 8020: train_loss=1696.80811, val_loss=1740.76270\n",
      "Epoch 8021: train_loss=1693.77002, val_loss=1736.98169\n",
      "Epoch 8022: train_loss=1690.76782, val_loss=1734.39917\n",
      "Epoch 8023: train_loss=1687.79602, val_loss=1731.29846\n",
      "Epoch 8024: train_loss=1684.87427, val_loss=1728.18311\n",
      "Epoch 8025: train_loss=1682.00391, val_loss=1725.75659\n",
      "Epoch 8026: train_loss=1679.16455, val_loss=1722.21704\n",
      "Epoch 8027: train_loss=1676.33484, val_loss=1720.15564\n",
      "Epoch 8028: train_loss=1673.50317, val_loss=1716.35449\n",
      "Epoch 8029: train_loss=1670.66870, val_loss=1714.41785\n",
      "Epoch 8030: train_loss=1667.80933, val_loss=1710.53088\n",
      "Epoch 8031: train_loss=1664.94849, val_loss=1708.49878\n",
      "Epoch 8032: train_loss=1662.05701, val_loss=1704.75916\n",
      "Epoch 8033: train_loss=1659.16467, val_loss=1702.41272\n",
      "Epoch 8034: train_loss=1656.27441, val_loss=1699.14233\n",
      "Epoch 8035: train_loss=1653.39685, val_loss=1696.33618\n",
      "Epoch 8036: train_loss=1650.51123, val_loss=1693.65674\n",
      "Epoch 8037: train_loss=1647.64685, val_loss=1690.43420\n",
      "Epoch 8038: train_loss=1644.81348, val_loss=1688.25659\n",
      "Epoch 8039: train_loss=1642.02429, val_loss=1684.59143\n",
      "Epoch 8040: train_loss=1639.25122, val_loss=1682.67737\n",
      "Epoch 8041: train_loss=1636.45459, val_loss=1678.66797\n",
      "Epoch 8042: train_loss=1633.66907, val_loss=1676.90417\n",
      "Epoch 8043: train_loss=1630.84314, val_loss=1672.83423\n",
      "Epoch 8044: train_loss=1628.02844, val_loss=1670.93445\n",
      "Epoch 8045: train_loss=1625.16565, val_loss=1667.11658\n",
      "Epoch 8046: train_loss=1622.30701, val_loss=1664.81689\n",
      "Epoch 8047: train_loss=1619.43140, val_loss=1661.58838\n",
      "Epoch 8048: train_loss=1616.61414, val_loss=1658.77832\n",
      "Epoch 8049: train_loss=1613.85645, val_loss=1656.25330\n",
      "Epoch 8050: train_loss=1611.16541, val_loss=1653.02551\n",
      "Epoch 8051: train_loss=1608.53564, val_loss=1651.07275\n",
      "Epoch 8052: train_loss=1605.94165, val_loss=1647.54309\n",
      "Epoch 8053: train_loss=1603.33630, val_loss=1645.69055\n",
      "Epoch 8054: train_loss=1600.69666, val_loss=1642.09558\n",
      "Epoch 8055: train_loss=1598.03931, val_loss=1640.07874\n",
      "Epoch 8056: train_loss=1595.39563, val_loss=1636.85815\n",
      "Epoch 8057: train_loss=1592.77002, val_loss=1634.42664\n",
      "Epoch 8058: train_loss=1590.19348, val_loss=1631.82324\n",
      "Epoch 8059: train_loss=1587.65271, val_loss=1628.90540\n",
      "Epoch 8060: train_loss=1585.12390, val_loss=1626.74011\n",
      "Epoch 8061: train_loss=1582.60400, val_loss=1623.56152\n",
      "Epoch 8062: train_loss=1580.10193, val_loss=1621.55920\n",
      "Epoch 8063: train_loss=1577.60767, val_loss=1618.40100\n",
      "Epoch 8064: train_loss=1575.11975, val_loss=1616.29431\n",
      "Epoch 8065: train_loss=1572.62561, val_loss=1613.30225\n",
      "Epoch 8066: train_loss=1570.13086, val_loss=1611.02637\n",
      "Epoch 8067: train_loss=1567.62817, val_loss=1608.27917\n",
      "Epoch 8068: train_loss=1565.12695, val_loss=1605.78955\n",
      "Epoch 8069: train_loss=1562.64807, val_loss=1603.35205\n",
      "Epoch 8070: train_loss=1560.19666, val_loss=1600.71277\n",
      "Epoch 8071: train_loss=1557.76660, val_loss=1598.51086\n",
      "Epoch 8072: train_loss=1555.35486, val_loss=1595.72742\n",
      "Epoch 8073: train_loss=1552.96448, val_loss=1593.76233\n",
      "Epoch 8074: train_loss=1550.60022, val_loss=1590.79846\n",
      "Epoch 8075: train_loss=1548.25732, val_loss=1589.11633\n",
      "Epoch 8076: train_loss=1545.94299, val_loss=1585.93542\n",
      "Epoch 8077: train_loss=1543.65063, val_loss=1584.54248\n",
      "Epoch 8078: train_loss=1541.38782, val_loss=1581.15173\n",
      "Epoch 8079: train_loss=1539.11829, val_loss=1579.87500\n",
      "Epoch 8080: train_loss=1536.83740, val_loss=1576.41919\n",
      "Epoch 8081: train_loss=1534.52246, val_loss=1574.92676\n",
      "Epoch 8082: train_loss=1532.18420, val_loss=1571.80859\n",
      "Epoch 8083: train_loss=1529.85278, val_loss=1569.85632\n",
      "Epoch 8084: train_loss=1527.55359, val_loss=1567.38977\n",
      "Epoch 8085: train_loss=1525.29980, val_loss=1564.97693\n",
      "Epoch 8086: train_loss=1523.08936, val_loss=1563.10938\n",
      "Epoch 8087: train_loss=1520.91394, val_loss=1560.27222\n",
      "Epoch 8088: train_loss=1518.76990, val_loss=1558.89758\n",
      "Epoch 8089: train_loss=1516.63367, val_loss=1555.70105\n",
      "Epoch 8090: train_loss=1514.47607, val_loss=1554.45349\n",
      "Epoch 8091: train_loss=1512.29578, val_loss=1551.19250\n",
      "Epoch 8092: train_loss=1510.07922, val_loss=1549.70825\n",
      "Epoch 8093: train_loss=1507.85181, val_loss=1546.79919\n",
      "Epoch 8094: train_loss=1505.63696, val_loss=1544.90259\n",
      "Epoch 8095: train_loss=1503.44543, val_loss=1542.57178\n",
      "Epoch 8096: train_loss=1501.29089, val_loss=1540.25085\n",
      "Epoch 8097: train_loss=1499.16626, val_loss=1538.39185\n",
      "Epoch 8098: train_loss=1497.06055, val_loss=1535.75989\n",
      "Epoch 8099: train_loss=1494.97205, val_loss=1534.22400\n",
      "Epoch 8100: train_loss=1492.89075, val_loss=1531.36560\n",
      "Epoch 8101: train_loss=1490.81433, val_loss=1530.00439\n",
      "Epoch 8102: train_loss=1488.73840, val_loss=1527.02368\n",
      "Epoch 8103: train_loss=1486.66150, val_loss=1525.71716\n",
      "Epoch 8104: train_loss=1484.58557, val_loss=1522.72607\n",
      "Epoch 8105: train_loss=1482.51160, val_loss=1521.36890\n",
      "Epoch 8106: train_loss=1480.43225, val_loss=1518.49915\n",
      "Epoch 8107: train_loss=1478.34888, val_loss=1516.89221\n",
      "Epoch 8108: train_loss=1476.26465, val_loss=1514.37964\n",
      "Epoch 8109: train_loss=1474.20740, val_loss=1512.45679\n",
      "Epoch 8110: train_loss=1472.16797, val_loss=1510.35840\n",
      "Epoch 8111: train_loss=1470.15173, val_loss=1508.09692\n",
      "Epoch 8112: train_loss=1468.15833, val_loss=1506.38599\n",
      "Epoch 8113: train_loss=1466.18103, val_loss=1503.83838\n",
      "Epoch 8114: train_loss=1464.22827, val_loss=1502.54968\n",
      "Epoch 8115: train_loss=1462.31409, val_loss=1499.64355\n",
      "Epoch 8116: train_loss=1460.43164, val_loss=1498.87000\n",
      "Epoch 8117: train_loss=1458.57776, val_loss=1495.55237\n",
      "Epoch 8118: train_loss=1456.70654, val_loss=1495.00208\n",
      "Epoch 8119: train_loss=1454.79126, val_loss=1491.47070\n",
      "Epoch 8120: train_loss=1452.82886, val_loss=1490.71338\n",
      "Epoch 8121: train_loss=1450.80237, val_loss=1487.42053\n",
      "Epoch 8122: train_loss=1448.72119, val_loss=1486.00537\n",
      "Epoch 8123: train_loss=1446.67468, val_loss=1483.68689\n",
      "Epoch 8124: train_loss=1444.71777, val_loss=1481.56909\n",
      "Epoch 8125: train_loss=1442.84692, val_loss=1480.19226\n",
      "Epoch 8126: train_loss=1441.02832, val_loss=1477.49329\n",
      "Epoch 8127: train_loss=1439.22766, val_loss=1476.54114\n",
      "Epoch 8128: train_loss=1437.39160, val_loss=1473.54480\n",
      "Epoch 8129: train_loss=1435.50073, val_loss=1472.41882\n",
      "Epoch 8130: train_loss=1433.57935, val_loss=1469.67712\n",
      "Epoch 8131: train_loss=1431.65771, val_loss=1468.14343\n",
      "Epoch 8132: train_loss=1429.76221, val_loss=1465.97021\n",
      "Epoch 8133: train_loss=1427.89771, val_loss=1463.97839\n",
      "Epoch 8134: train_loss=1426.07202, val_loss=1462.41321\n",
      "Epoch 8135: train_loss=1424.28162, val_loss=1460.03320\n",
      "Epoch 8136: train_loss=1422.52551, val_loss=1459.00012\n",
      "Epoch 8137: train_loss=1420.80347, val_loss=1456.19666\n",
      "Epoch 8138: train_loss=1419.07605, val_loss=1455.50635\n",
      "Epoch 8139: train_loss=1417.34814, val_loss=1452.41602\n",
      "Epoch 8140: train_loss=1415.55457, val_loss=1451.59045\n",
      "Epoch 8141: train_loss=1413.71301, val_loss=1448.68311\n",
      "Epoch 8142: train_loss=1411.83887, val_loss=1447.32703\n",
      "Epoch 8143: train_loss=1409.98315, val_loss=1445.19116\n",
      "Epoch 8144: train_loss=1408.18823, val_loss=1443.21069\n",
      "Epoch 8145: train_loss=1406.46313, val_loss=1441.89307\n",
      "Epoch 8146: train_loss=1404.77991, val_loss=1439.41187\n",
      "Epoch 8147: train_loss=1403.11035, val_loss=1438.47400\n",
      "Epoch 8148: train_loss=1401.42346, val_loss=1435.72644\n",
      "Epoch 8149: train_loss=1399.69568, val_loss=1434.69788\n",
      "Epoch 8150: train_loss=1397.94128, val_loss=1432.11450\n",
      "Epoch 8151: train_loss=1396.16870, val_loss=1430.70337\n",
      "Epoch 8152: train_loss=1394.41492, val_loss=1428.69641\n",
      "Epoch 8153: train_loss=1392.69727, val_loss=1426.79871\n",
      "Epoch 8154: train_loss=1391.02209, val_loss=1425.40405\n",
      "Epoch 8155: train_loss=1389.37256, val_loss=1423.13635\n",
      "Epoch 8156: train_loss=1387.72632, val_loss=1422.03540\n",
      "Epoch 8157: train_loss=1386.08203, val_loss=1419.58118\n",
      "Epoch 8158: train_loss=1384.43115, val_loss=1418.59644\n",
      "Epoch 8159: train_loss=1382.78845, val_loss=1416.06995\n",
      "Epoch 8160: train_loss=1381.13110, val_loss=1415.04163\n",
      "Epoch 8161: train_loss=1379.46472, val_loss=1412.61145\n",
      "Epoch 8162: train_loss=1377.78735, val_loss=1411.35315\n",
      "Epoch 8163: train_loss=1376.11487, val_loss=1409.25696\n",
      "Epoch 8164: train_loss=1374.45142, val_loss=1407.64136\n",
      "Epoch 8165: train_loss=1372.81555, val_loss=1406.03198\n",
      "Epoch 8166: train_loss=1371.20532, val_loss=1404.08716\n",
      "Epoch 8167: train_loss=1369.61377, val_loss=1402.86523\n",
      "Epoch 8168: train_loss=1368.04675, val_loss=1400.62964\n",
      "Epoch 8169: train_loss=1366.49048, val_loss=1399.74805\n",
      "Epoch 8170: train_loss=1364.95825, val_loss=1397.23792\n",
      "Epoch 8171: train_loss=1363.42566, val_loss=1396.58069\n",
      "Epoch 8172: train_loss=1361.88635, val_loss=1393.89111\n",
      "Epoch 8173: train_loss=1360.30957, val_loss=1393.13000\n",
      "Epoch 8174: train_loss=1358.69397, val_loss=1390.59729\n",
      "Epoch 8175: train_loss=1357.06555, val_loss=1389.46741\n",
      "Epoch 8176: train_loss=1355.43774, val_loss=1387.48547\n",
      "Epoch 8177: train_loss=1353.84521, val_loss=1385.83398\n",
      "Epoch 8178: train_loss=1352.30933, val_loss=1384.54248\n",
      "Epoch 8179: train_loss=1350.81104, val_loss=1382.46179\n",
      "Epoch 8180: train_loss=1349.32727, val_loss=1381.54102\n",
      "Epoch 8181: train_loss=1347.84680, val_loss=1379.22241\n",
      "Epoch 8182: train_loss=1346.35583, val_loss=1378.39221\n",
      "Epoch 8183: train_loss=1344.84961, val_loss=1376.03320\n",
      "Epoch 8184: train_loss=1343.32434, val_loss=1375.08020\n",
      "Epoch 8185: train_loss=1341.80164, val_loss=1372.89722\n",
      "Epoch 8186: train_loss=1340.27539, val_loss=1371.69958\n",
      "Epoch 8187: train_loss=1338.75854, val_loss=1369.86292\n",
      "Epoch 8188: train_loss=1337.25818, val_loss=1368.35815\n",
      "Epoch 8189: train_loss=1335.77966, val_loss=1366.91895\n",
      "Epoch 8190: train_loss=1334.31982, val_loss=1365.12109\n",
      "Epoch 8191: train_loss=1332.88171, val_loss=1364.03125\n",
      "Epoch 8192: train_loss=1331.46191, val_loss=1361.96985\n",
      "Epoch 8193: train_loss=1330.05701, val_loss=1361.22632\n",
      "Epoch 8194: train_loss=1328.68164, val_loss=1358.88599\n",
      "Epoch 8195: train_loss=1327.31140, val_loss=1358.43372\n",
      "Epoch 8196: train_loss=1325.94250, val_loss=1355.85510\n",
      "Epoch 8197: train_loss=1324.52271, val_loss=1355.33716\n",
      "Epoch 8198: train_loss=1323.06213, val_loss=1352.84741\n",
      "Epoch 8199: train_loss=1321.55603, val_loss=1351.91785\n",
      "Epoch 8200: train_loss=1320.05481, val_loss=1350.00256\n",
      "Epoch 8201: train_loss=1318.59375, val_loss=1348.57471\n",
      "Epoch 8202: train_loss=1317.18896, val_loss=1347.33179\n",
      "Epoch 8203: train_loss=1315.82605, val_loss=1345.47888\n",
      "Epoch 8204: train_loss=1314.49158, val_loss=1344.67310\n",
      "Epoch 8205: train_loss=1313.16382, val_loss=1342.51855\n",
      "Epoch 8206: train_loss=1311.82788, val_loss=1341.85852\n",
      "Epoch 8207: train_loss=1310.47742, val_loss=1339.60522\n",
      "Epoch 8208: train_loss=1309.09753, val_loss=1338.81824\n",
      "Epoch 8209: train_loss=1307.70715, val_loss=1336.74573\n",
      "Epoch 8210: train_loss=1306.31006, val_loss=1335.68530\n",
      "Epoch 8211: train_loss=1304.93152, val_loss=1334.00317\n",
      "Epoch 8212: train_loss=1303.57068, val_loss=1332.62073\n",
      "Epoch 8213: train_loss=1302.23291, val_loss=1331.34680\n",
      "Epoch 8214: train_loss=1300.91345, val_loss=1329.69446\n",
      "Epoch 8215: train_loss=1299.61426, val_loss=1328.74390\n",
      "Epoch 8216: train_loss=1298.32410, val_loss=1326.86243\n",
      "Epoch 8217: train_loss=1297.03601, val_loss=1326.11230\n",
      "Epoch 8218: train_loss=1295.75684, val_loss=1324.07690\n",
      "Epoch 8219: train_loss=1294.46497, val_loss=1323.40686\n",
      "Epoch 8220: train_loss=1293.17859, val_loss=1321.33398\n",
      "Epoch 8221: train_loss=1291.88306, val_loss=1320.65637\n",
      "Epoch 8222: train_loss=1290.58765, val_loss=1318.65417\n",
      "Epoch 8223: train_loss=1289.27356, val_loss=1317.79602\n",
      "Epoch 8224: train_loss=1287.95618, val_loss=1316.07104\n",
      "Epoch 8225: train_loss=1286.64795, val_loss=1314.91296\n",
      "Epoch 8226: train_loss=1285.35864, val_loss=1313.58130\n",
      "Epoch 8227: train_loss=1284.09094, val_loss=1312.13550\n",
      "Epoch 8228: train_loss=1282.83936, val_loss=1311.10608\n",
      "Epoch 8229: train_loss=1281.59949, val_loss=1309.42139\n",
      "Epoch 8230: train_loss=1280.36584, val_loss=1308.62036\n",
      "Epoch 8231: train_loss=1279.13660, val_loss=1306.71802\n",
      "Epoch 8232: train_loss=1277.91907, val_loss=1306.16223\n",
      "Epoch 8233: train_loss=1276.71204, val_loss=1304.01770\n",
      "Epoch 8234: train_loss=1275.48804, val_loss=1303.58630\n",
      "Epoch 8235: train_loss=1274.24219, val_loss=1301.32410\n",
      "Epoch 8236: train_loss=1272.94873, val_loss=1300.76941\n",
      "Epoch 8237: train_loss=1271.62231, val_loss=1298.64172\n",
      "Epoch 8238: train_loss=1270.27295, val_loss=1297.76831\n",
      "Epoch 8239: train_loss=1268.91541, val_loss=1296.06506\n",
      "Epoch 8240: train_loss=1267.57507, val_loss=1294.88452\n",
      "Epoch 8241: train_loss=1266.26843, val_loss=1293.62891\n",
      "Epoch 8242: train_loss=1264.97546, val_loss=1292.15442\n",
      "Epoch 8243: train_loss=1263.69470, val_loss=1291.22717\n",
      "Epoch 8244: train_loss=1262.41833, val_loss=1289.50916\n",
      "Epoch 8245: train_loss=1261.14819, val_loss=1288.83289\n",
      "Epoch 8246: train_loss=1259.87646, val_loss=1286.91492\n",
      "Epoch 8247: train_loss=1258.59717, val_loss=1286.37769\n",
      "Epoch 8248: train_loss=1257.29810, val_loss=1284.35730\n",
      "Epoch 8249: train_loss=1255.98523, val_loss=1283.87048\n",
      "Epoch 8250: train_loss=1254.69104, val_loss=1281.90186\n",
      "Epoch 8251: train_loss=1253.38501, val_loss=1281.28674\n",
      "Epoch 8252: train_loss=1252.06836, val_loss=1279.47766\n",
      "Epoch 8253: train_loss=1250.75378, val_loss=1278.65808\n",
      "Epoch 8254: train_loss=1249.47510, val_loss=1277.12219\n",
      "Epoch 8255: train_loss=1248.24133, val_loss=1276.13428\n",
      "Epoch 8256: train_loss=1247.03564, val_loss=1274.85681\n",
      "Epoch 8257: train_loss=1245.86682, val_loss=1273.74243\n",
      "Epoch 8258: train_loss=1244.72449, val_loss=1272.60645\n",
      "Epoch 8259: train_loss=1243.58716, val_loss=1271.38293\n",
      "Epoch 8260: train_loss=1242.45239, val_loss=1270.32983\n",
      "Epoch 8261: train_loss=1241.31860, val_loss=1269.01221\n",
      "Epoch 8262: train_loss=1240.18811, val_loss=1268.04053\n",
      "Epoch 8263: train_loss=1239.06140, val_loss=1266.61096\n",
      "Epoch 8264: train_loss=1237.94226, val_loss=1265.78101\n",
      "Epoch 8265: train_loss=1236.83301, val_loss=1264.16858\n",
      "Epoch 8266: train_loss=1235.73486, val_loss=1263.59778\n",
      "Epoch 8267: train_loss=1234.65686, val_loss=1261.71875\n",
      "Epoch 8268: train_loss=1233.60229, val_loss=1261.51416\n",
      "Epoch 8269: train_loss=1232.56274, val_loss=1259.33069\n",
      "Epoch 8270: train_loss=1231.52405, val_loss=1259.35095\n",
      "Epoch 8271: train_loss=1230.45483, val_loss=1256.96375\n",
      "Epoch 8272: train_loss=1229.34546, val_loss=1256.83801\n",
      "Epoch 8273: train_loss=1228.16687, val_loss=1254.59680\n",
      "Epoch 8274: train_loss=1226.95813, val_loss=1254.00391\n",
      "Epoch 8275: train_loss=1225.74524, val_loss=1252.39062\n",
      "Epoch 8276: train_loss=1224.58240, val_loss=1251.26489\n",
      "Epoch 8277: train_loss=1223.47717, val_loss=1250.37244\n",
      "Epoch 8278: train_loss=1222.42407, val_loss=1248.76404\n",
      "Epoch 8279: train_loss=1221.40833, val_loss=1248.40137\n",
      "Epoch 8280: train_loss=1220.40332, val_loss=1246.40637\n",
      "Epoch 8281: train_loss=1219.39490, val_loss=1246.23828\n",
      "Epoch 8282: train_loss=1218.34216, val_loss=1244.06897\n",
      "Epoch 8283: train_loss=1217.26318, val_loss=1243.76208\n",
      "Epoch 8284: train_loss=1216.14111, val_loss=1241.75513\n",
      "Epoch 8285: train_loss=1215.01257, val_loss=1241.13708\n",
      "Epoch 8286: train_loss=1213.88879, val_loss=1239.54834\n",
      "Epoch 8287: train_loss=1212.78723, val_loss=1238.57312\n",
      "Epoch 8288: train_loss=1211.71484, val_loss=1237.43872\n",
      "Epoch 8289: train_loss=1210.66711, val_loss=1236.13916\n",
      "Epoch 8290: train_loss=1209.64099, val_loss=1235.38452\n",
      "Epoch 8291: train_loss=1208.63440, val_loss=1233.80225\n",
      "Epoch 8292: train_loss=1207.64526, val_loss=1233.38098\n",
      "Epoch 8293: train_loss=1206.67139, val_loss=1231.53809\n",
      "Epoch 8294: train_loss=1205.69849, val_loss=1231.32568\n",
      "Epoch 8295: train_loss=1204.72131, val_loss=1229.30249\n",
      "Epoch 8296: train_loss=1203.71851, val_loss=1229.08240\n",
      "Epoch 8297: train_loss=1202.69055, val_loss=1227.07520\n",
      "Epoch 8298: train_loss=1201.62903, val_loss=1226.64307\n",
      "Epoch 8299: train_loss=1200.56653, val_loss=1224.91016\n",
      "Epoch 8300: train_loss=1199.50378, val_loss=1224.18286\n",
      "Epoch 8301: train_loss=1198.45972, val_loss=1222.87170\n",
      "Epoch 8302: train_loss=1197.43921, val_loss=1221.81836\n",
      "Epoch 8303: train_loss=1196.44702, val_loss=1220.93518\n",
      "Epoch 8304: train_loss=1195.47632, val_loss=1219.59973\n",
      "Epoch 8305: train_loss=1194.52563, val_loss=1219.05908\n",
      "Epoch 8306: train_loss=1193.59082, val_loss=1217.48169\n",
      "Epoch 8307: train_loss=1192.67554, val_loss=1217.22119\n",
      "Epoch 8308: train_loss=1191.75696, val_loss=1215.42908\n",
      "Epoch 8309: train_loss=1190.84729, val_loss=1215.28503\n",
      "Epoch 8310: train_loss=1189.89331, val_loss=1213.39502\n",
      "Epoch 8311: train_loss=1188.92725, val_loss=1213.13293\n",
      "Epoch 8312: train_loss=1187.91980, val_loss=1211.37988\n",
      "Epoch 8313: train_loss=1186.90613, val_loss=1210.85461\n",
      "Epoch 8314: train_loss=1185.90015, val_loss=1209.45459\n",
      "Epoch 8315: train_loss=1184.91455, val_loss=1208.62585\n",
      "Epoch 8316: train_loss=1183.95593, val_loss=1207.63000\n",
      "Epoch 8317: train_loss=1183.02234, val_loss=1206.52246\n",
      "Epoch 8318: train_loss=1182.10840, val_loss=1205.87390\n",
      "Epoch 8319: train_loss=1181.21387, val_loss=1204.51550\n",
      "Epoch 8320: train_loss=1180.32996, val_loss=1204.12512\n",
      "Epoch 8321: train_loss=1179.45300, val_loss=1202.54700\n",
      "Epoch 8322: train_loss=1178.56396, val_loss=1202.21484\n",
      "Epoch 8323: train_loss=1177.64551, val_loss=1200.59033\n",
      "Epoch 8324: train_loss=1176.70923, val_loss=1200.11499\n",
      "Epoch 8325: train_loss=1175.75891, val_loss=1198.68628\n",
      "Epoch 8326: train_loss=1174.81934, val_loss=1198.01331\n",
      "Epoch 8327: train_loss=1173.89111, val_loss=1196.84973\n",
      "Epoch 8328: train_loss=1172.97949, val_loss=1195.99573\n",
      "Epoch 8329: train_loss=1172.07874, val_loss=1195.05444\n",
      "Epoch 8330: train_loss=1171.18848, val_loss=1194.03943\n",
      "Epoch 8331: train_loss=1170.30688, val_loss=1193.29114\n",
      "Epoch 8332: train_loss=1169.43164, val_loss=1192.13586\n",
      "Epoch 8333: train_loss=1168.56555, val_loss=1191.56738\n",
      "Epoch 8334: train_loss=1167.70532, val_loss=1190.23950\n",
      "Epoch 8335: train_loss=1166.85962, val_loss=1189.87097\n",
      "Epoch 8336: train_loss=1166.01416, val_loss=1188.36084\n",
      "Epoch 8337: train_loss=1165.16968, val_loss=1188.11267\n",
      "Epoch 8338: train_loss=1164.31458, val_loss=1186.49573\n",
      "Epoch 8339: train_loss=1163.43640, val_loss=1186.19958\n",
      "Epoch 8340: train_loss=1162.54456, val_loss=1184.64795\n",
      "Epoch 8341: train_loss=1161.63660, val_loss=1184.17712\n",
      "Epoch 8342: train_loss=1160.73254, val_loss=1182.86462\n",
      "Epoch 8343: train_loss=1159.83716, val_loss=1182.16443\n",
      "Epoch 8344: train_loss=1158.95337, val_loss=1181.17065\n",
      "Epoch 8345: train_loss=1158.08655, val_loss=1180.22852\n",
      "Epoch 8346: train_loss=1157.23743, val_loss=1179.54041\n",
      "Epoch 8347: train_loss=1156.40344, val_loss=1178.38745\n",
      "Epoch 8348: train_loss=1155.58093, val_loss=1177.91870\n",
      "Epoch 8349: train_loss=1154.76099, val_loss=1176.59497\n",
      "Epoch 8350: train_loss=1153.94739, val_loss=1176.26758\n",
      "Epoch 8351: train_loss=1153.12927, val_loss=1174.82568\n",
      "Epoch 8352: train_loss=1152.31396, val_loss=1174.58655\n",
      "Epoch 8353: train_loss=1151.49780, val_loss=1173.07007\n",
      "Epoch 8354: train_loss=1150.67004, val_loss=1172.81824\n",
      "Epoch 8355: train_loss=1149.82898, val_loss=1171.32593\n",
      "Epoch 8356: train_loss=1148.98071, val_loss=1170.96387\n",
      "Epoch 8357: train_loss=1148.12134, val_loss=1169.62988\n",
      "Epoch 8358: train_loss=1147.25842, val_loss=1169.04688\n",
      "Epoch 8359: train_loss=1146.40369, val_loss=1168.01978\n",
      "Epoch 8360: train_loss=1145.56592, val_loss=1167.18762\n",
      "Epoch 8361: train_loss=1144.74744, val_loss=1166.46667\n",
      "Epoch 8362: train_loss=1143.94482, val_loss=1165.41016\n",
      "Epoch 8363: train_loss=1143.15479, val_loss=1164.91614\n",
      "Epoch 8364: train_loss=1142.37207, val_loss=1163.68384\n",
      "Epoch 8365: train_loss=1141.59509, val_loss=1163.34082\n",
      "Epoch 8366: train_loss=1140.81287, val_loss=1161.98669\n",
      "Epoch 8367: train_loss=1140.02612, val_loss=1161.69824\n",
      "Epoch 8368: train_loss=1139.23096, val_loss=1160.30334\n",
      "Epoch 8369: train_loss=1138.43237, val_loss=1159.98425\n",
      "Epoch 8370: train_loss=1137.61902, val_loss=1158.63721\n",
      "Epoch 8371: train_loss=1136.80347, val_loss=1158.20312\n",
      "Epoch 8372: train_loss=1135.98193, val_loss=1157.00952\n",
      "Epoch 8373: train_loss=1135.16382, val_loss=1156.38745\n",
      "Epoch 8374: train_loss=1134.35425, val_loss=1155.45361\n",
      "Epoch 8375: train_loss=1133.55835, val_loss=1154.61902\n",
      "Epoch 8376: train_loss=1132.77747, val_loss=1153.94434\n",
      "Epoch 8377: train_loss=1132.00793, val_loss=1152.92200\n",
      "Epoch 8378: train_loss=1131.24695, val_loss=1152.44788\n",
      "Epoch 8379: train_loss=1130.49463, val_loss=1151.26892\n",
      "Epoch 8380: train_loss=1129.74670, val_loss=1150.94702\n",
      "Epoch 8381: train_loss=1129.00146, val_loss=1149.63831\n",
      "Epoch 8382: train_loss=1128.25110, val_loss=1149.39124\n",
      "Epoch 8383: train_loss=1127.49451, val_loss=1148.02051\n",
      "Epoch 8384: train_loss=1126.72632, val_loss=1147.74365\n",
      "Epoch 8385: train_loss=1125.94897, val_loss=1146.41809\n",
      "Epoch 8386: train_loss=1125.16309, val_loss=1146.00830\n",
      "Epoch 8387: train_loss=1124.36975, val_loss=1144.84973\n",
      "Epoch 8388: train_loss=1123.58472, val_loss=1144.26599\n",
      "Epoch 8389: train_loss=1122.80725, val_loss=1143.34302\n",
      "Epoch 8390: train_loss=1122.04224, val_loss=1142.57751\n",
      "Epoch 8391: train_loss=1121.28992, val_loss=1141.88293\n",
      "Epoch 8392: train_loss=1120.54871, val_loss=1140.93872\n",
      "Epoch 8393: train_loss=1119.81836, val_loss=1140.45789\n",
      "Epoch 8394: train_loss=1119.09827, val_loss=1139.34277\n",
      "Epoch 8395: train_loss=1118.38525, val_loss=1139.02795\n",
      "Epoch 8396: train_loss=1117.66602, val_loss=1137.78467\n",
      "Epoch 8397: train_loss=1116.94617, val_loss=1137.54614\n",
      "Epoch 8398: train_loss=1116.22070, val_loss=1136.24451\n",
      "Epoch 8399: train_loss=1115.48938, val_loss=1136.01160\n",
      "Epoch 8400: train_loss=1114.75098, val_loss=1134.72144\n",
      "Epoch 8401: train_loss=1114.00464, val_loss=1134.40601\n",
      "Epoch 8402: train_loss=1113.24792, val_loss=1133.21912\n",
      "Epoch 8403: train_loss=1112.48425, val_loss=1132.72107\n",
      "Epoch 8404: train_loss=1111.72559, val_loss=1131.76538\n",
      "Epoch 8405: train_loss=1110.97827, val_loss=1131.05554\n",
      "Epoch 8406: train_loss=1110.24573, val_loss=1130.35718\n",
      "Epoch 8407: train_loss=1109.52600, val_loss=1129.45947\n",
      "Epoch 8408: train_loss=1108.81567, val_loss=1128.96545\n",
      "Epoch 8409: train_loss=1108.11487, val_loss=1127.90710\n",
      "Epoch 8410: train_loss=1107.42334, val_loss=1127.60828\n",
      "Epoch 8411: train_loss=1106.73999, val_loss=1126.38708\n",
      "Epoch 8412: train_loss=1106.06372, val_loss=1126.25525\n",
      "Epoch 8413: train_loss=1105.38916, val_loss=1124.89453\n",
      "Epoch 8414: train_loss=1104.72803, val_loss=1124.89343\n",
      "Epoch 8415: train_loss=1104.04626, val_loss=1123.41650\n",
      "Epoch 8416: train_loss=1103.36377, val_loss=1123.43188\n",
      "Epoch 8417: train_loss=1102.64587, val_loss=1121.92773\n",
      "Epoch 8418: train_loss=1101.91370, val_loss=1121.80078\n",
      "Epoch 8419: train_loss=1101.14648, val_loss=1120.43872\n",
      "Epoch 8420: train_loss=1100.37524, val_loss=1120.05737\n",
      "Epoch 8421: train_loss=1099.60693, val_loss=1119.05249\n",
      "Epoch 8422: train_loss=1098.86499, val_loss=1118.37634\n",
      "Epoch 8423: train_loss=1098.15576, val_loss=1117.78992\n",
      "Epoch 8424: train_loss=1097.47559, val_loss=1116.84387\n",
      "Epoch 8425: train_loss=1096.81677, val_loss=1116.56812\n",
      "Epoch 8426: train_loss=1096.16870, val_loss=1115.39319\n",
      "Epoch 8427: train_loss=1095.51184, val_loss=1115.23975\n",
      "Epoch 8428: train_loss=1094.84094, val_loss=1113.95776\n",
      "Epoch 8429: train_loss=1094.15051, val_loss=1113.76770\n",
      "Epoch 8430: train_loss=1093.44507, val_loss=1112.52588\n",
      "Epoch 8431: train_loss=1092.72900, val_loss=1112.20520\n",
      "Epoch 8432: train_loss=1092.00659, val_loss=1111.13245\n",
      "Epoch 8433: train_loss=1091.28918, val_loss=1110.62891\n",
      "Epoch 8434: train_loss=1090.58020, val_loss=1109.80115\n",
      "Epoch 8435: train_loss=1089.88440, val_loss=1109.10217\n",
      "Epoch 8436: train_loss=1089.20215, val_loss=1108.50964\n",
      "Epoch 8437: train_loss=1088.53052, val_loss=1107.64539\n",
      "Epoch 8438: train_loss=1087.86841, val_loss=1107.25000\n",
      "Epoch 8439: train_loss=1087.21582, val_loss=1106.22937\n",
      "Epoch 8440: train_loss=1086.56958, val_loss=1105.98865\n",
      "Epoch 8441: train_loss=1085.92078, val_loss=1104.83936\n",
      "Epoch 8442: train_loss=1085.27087, val_loss=1104.66687\n",
      "Epoch 8443: train_loss=1084.60876, val_loss=1103.45886\n",
      "Epoch 8444: train_loss=1083.93933, val_loss=1103.25757\n",
      "Epoch 8445: train_loss=1083.25427, val_loss=1102.09290\n",
      "Epoch 8446: train_loss=1082.55469, val_loss=1101.73816\n",
      "Epoch 8447: train_loss=1081.85120, val_loss=1100.77856\n",
      "Epoch 8448: train_loss=1081.15503, val_loss=1100.20093\n",
      "Epoch 8449: train_loss=1080.47510, val_loss=1099.55054\n",
      "Epoch 8450: train_loss=1079.81677, val_loss=1098.75415\n",
      "Epoch 8451: train_loss=1079.17334, val_loss=1098.36450\n",
      "Epoch 8452: train_loss=1078.54114, val_loss=1097.37720\n",
      "Epoch 8453: train_loss=1077.91187, val_loss=1097.13525\n",
      "Epoch 8454: train_loss=1077.27454, val_loss=1096.02258\n",
      "Epoch 8455: train_loss=1076.62427, val_loss=1095.76794\n",
      "Epoch 8456: train_loss=1075.95361, val_loss=1094.67249\n",
      "Epoch 8457: train_loss=1075.27368, val_loss=1094.29041\n",
      "Epoch 8458: train_loss=1074.58862, val_loss=1093.35388\n",
      "Epoch 8459: train_loss=1073.90942, val_loss=1092.79297\n",
      "Epoch 8460: train_loss=1073.24121, val_loss=1092.08936\n",
      "Epoch 8461: train_loss=1072.58545, val_loss=1091.34668\n",
      "Epoch 8462: train_loss=1071.94421, val_loss=1090.86292\n",
      "Epoch 8463: train_loss=1071.31372, val_loss=1089.96741\n",
      "Epoch 8464: train_loss=1070.69324, val_loss=1089.67419\n",
      "Epoch 8465: train_loss=1070.07983, val_loss=1088.64111\n",
      "Epoch 8466: train_loss=1069.47339, val_loss=1088.48572\n",
      "Epoch 8467: train_loss=1068.86377, val_loss=1087.34229\n",
      "Epoch 8468: train_loss=1068.25183, val_loss=1087.23181\n",
      "Epoch 8469: train_loss=1067.62268, val_loss=1086.04199\n",
      "Epoch 8470: train_loss=1066.98267, val_loss=1085.86316\n",
      "Epoch 8471: train_loss=1066.32898, val_loss=1084.74719\n",
      "Epoch 8472: train_loss=1065.66919, val_loss=1084.40930\n",
      "Epoch 8473: train_loss=1065.00610, val_loss=1083.49023\n",
      "Epoch 8474: train_loss=1064.35315, val_loss=1082.94849\n",
      "Epoch 8475: train_loss=1063.71533, val_loss=1082.30005\n",
      "Epoch 8476: train_loss=1063.09363, val_loss=1081.56042\n",
      "Epoch 8477: train_loss=1062.48499, val_loss=1081.13196\n",
      "Epoch 8478: train_loss=1061.88477, val_loss=1080.23132\n",
      "Epoch 8479: train_loss=1061.28955, val_loss=1079.94141\n",
      "Epoch 8480: train_loss=1060.69128, val_loss=1078.93176\n",
      "Epoch 8481: train_loss=1060.08948, val_loss=1078.69348\n",
      "Epoch 8482: train_loss=1059.48291, val_loss=1077.65222\n",
      "Epoch 8483: train_loss=1058.87097, val_loss=1077.39612\n",
      "Epoch 8484: train_loss=1058.25574, val_loss=1076.38855\n",
      "Epoch 8485: train_loss=1057.63452, val_loss=1076.06726\n",
      "Epoch 8486: train_loss=1057.01331, val_loss=1075.14929\n",
      "Epoch 8487: train_loss=1056.39136, val_loss=1074.72998\n",
      "Epoch 8488: train_loss=1055.77283, val_loss=1073.94067\n",
      "Epoch 8489: train_loss=1055.15857, val_loss=1073.40906\n",
      "Epoch 8490: train_loss=1054.55164, val_loss=1072.76697\n",
      "Epoch 8491: train_loss=1053.95166, val_loss=1072.12646\n",
      "Epoch 8492: train_loss=1053.35803, val_loss=1071.61218\n",
      "Epoch 8493: train_loss=1052.76831, val_loss=1070.86780\n",
      "Epoch 8494: train_loss=1052.18311, val_loss=1070.46729\n",
      "Epoch 8495: train_loss=1051.60205, val_loss=1069.62085\n",
      "Epoch 8496: train_loss=1051.02649, val_loss=1069.34106\n",
      "Epoch 8497: train_loss=1050.45569, val_loss=1068.39075\n",
      "Epoch 8498: train_loss=1049.88635, val_loss=1068.21228\n",
      "Epoch 8499: train_loss=1049.31848, val_loss=1067.17896\n",
      "Epoch 8500: train_loss=1048.75146, val_loss=1067.07544\n",
      "Epoch 8501: train_loss=1048.18542, val_loss=1065.97559\n",
      "Epoch 8502: train_loss=1047.61426, val_loss=1065.90222\n",
      "Epoch 8503: train_loss=1047.03748, val_loss=1064.77490\n",
      "Epoch 8504: train_loss=1046.45068, val_loss=1064.66797\n",
      "Epoch 8505: train_loss=1045.85522, val_loss=1063.57959\n",
      "Epoch 8506: train_loss=1045.25012, val_loss=1063.36584\n",
      "Epoch 8507: train_loss=1044.64282, val_loss=1062.39966\n",
      "Epoch 8508: train_loss=1044.03394, val_loss=1062.03174\n",
      "Epoch 8509: train_loss=1043.42834, val_loss=1061.26208\n",
      "Epoch 8510: train_loss=1042.83301, val_loss=1060.72632\n",
      "Epoch 8511: train_loss=1042.24609, val_loss=1060.15857\n",
      "Epoch 8512: train_loss=1041.66870, val_loss=1059.46436\n",
      "Epoch 8513: train_loss=1041.09827, val_loss=1059.06506\n",
      "Epoch 8514: train_loss=1040.53345, val_loss=1058.24646\n",
      "Epoch 8515: train_loss=1039.97595, val_loss=1057.99878\n",
      "Epoch 8516: train_loss=1039.42358, val_loss=1057.06580\n",
      "Epoch 8517: train_loss=1038.87476, val_loss=1056.94409\n",
      "Epoch 8518: train_loss=1038.33118, val_loss=1055.91321\n",
      "Epoch 8519: train_loss=1037.79749, val_loss=1055.92371\n",
      "Epoch 8520: train_loss=1037.26587, val_loss=1054.78784\n",
      "Epoch 8521: train_loss=1036.73523, val_loss=1054.87280\n",
      "Epoch 8522: train_loss=1036.18835, val_loss=1053.66162\n",
      "Epoch 8523: train_loss=1035.62219, val_loss=1053.67847\n",
      "Epoch 8524: train_loss=1035.02588, val_loss=1052.52612\n",
      "Epoch 8525: train_loss=1034.41492, val_loss=1052.34912\n",
      "Epoch 8526: train_loss=1033.80261, val_loss=1051.44824\n",
      "Epoch 8527: train_loss=1033.20276, val_loss=1051.02905\n",
      "Epoch 8528: train_loss=1032.62134, val_loss=1050.46985\n",
      "Epoch 8529: train_loss=1032.06421, val_loss=1049.82068\n",
      "Epoch 8530: train_loss=1031.52466, val_loss=1049.51636\n",
      "Epoch 8531: train_loss=1030.99255, val_loss=1048.69324\n",
      "Epoch 8532: train_loss=1030.46045, val_loss=1048.50024\n",
      "Epoch 8533: train_loss=1029.92114, val_loss=1047.59119\n",
      "Epoch 8534: train_loss=1029.37256, val_loss=1047.39038\n",
      "Epoch 8535: train_loss=1028.81506, val_loss=1046.50256\n",
      "Epoch 8536: train_loss=1028.25647, val_loss=1046.24829\n",
      "Epoch 8537: train_loss=1027.69604, val_loss=1045.42786\n",
      "Epoch 8538: train_loss=1027.13794, val_loss=1045.11121\n",
      "Epoch 8539: train_loss=1026.58435, val_loss=1044.35657\n",
      "Epoch 8540: train_loss=1026.03406, val_loss=1044.00586\n",
      "Epoch 8541: train_loss=1025.48987, val_loss=1043.28577\n",
      "Epoch 8542: train_loss=1024.94897, val_loss=1042.96082\n",
      "Epoch 8543: train_loss=1024.41504, val_loss=1042.21008\n",
      "Epoch 8544: train_loss=1023.88940, val_loss=1041.98914\n",
      "Epoch 8545: train_loss=1023.37158, val_loss=1041.14648\n",
      "Epoch 8546: train_loss=1022.86407, val_loss=1041.06641\n",
      "Epoch 8547: train_loss=1022.36090, val_loss=1040.10742\n",
      "Epoch 8548: train_loss=1021.86005, val_loss=1040.12378\n",
      "Epoch 8549: train_loss=1021.35242, val_loss=1039.06946\n",
      "Epoch 8550: train_loss=1020.83154, val_loss=1039.07312\n",
      "Epoch 8551: train_loss=1020.29242, val_loss=1038.00623\n",
      "Epoch 8552: train_loss=1019.73102, val_loss=1037.87061\n",
      "Epoch 8553: train_loss=1019.15820, val_loss=1036.94141\n",
      "Epoch 8554: train_loss=1018.57220, val_loss=1036.60352\n",
      "Epoch 8555: train_loss=1018.00031, val_loss=1035.93250\n",
      "Epoch 8556: train_loss=1017.44366, val_loss=1035.40967\n",
      "Epoch 8557: train_loss=1016.90308, val_loss=1034.97607\n",
      "Epoch 8558: train_loss=1016.37555, val_loss=1034.28784\n",
      "Epoch 8559: train_loss=1015.85748, val_loss=1034.03479\n",
      "Epoch 8560: train_loss=1015.34546, val_loss=1033.21021\n",
      "Epoch 8561: train_loss=1014.83319, val_loss=1033.06018\n",
      "Epoch 8562: train_loss=1014.31915, val_loss=1032.15369\n",
      "Epoch 8563: train_loss=1013.79980, val_loss=1032.03455\n",
      "Epoch 8564: train_loss=1013.27612, val_loss=1031.10474\n",
      "Epoch 8565: train_loss=1012.75323, val_loss=1030.97583\n",
      "Epoch 8566: train_loss=1012.21979, val_loss=1030.07300\n",
      "Epoch 8567: train_loss=1011.68860, val_loss=1029.88843\n",
      "Epoch 8568: train_loss=1011.14673, val_loss=1029.05762\n",
      "Epoch 8569: train_loss=1010.60535, val_loss=1028.77454\n",
      "Epoch 8570: train_loss=1010.06317, val_loss=1028.09558\n",
      "Epoch 8571: train_loss=1009.53009, val_loss=1027.69055\n",
      "Epoch 8572: train_loss=1009.00555, val_loss=1027.16882\n",
      "Epoch 8573: train_loss=1008.49084, val_loss=1026.64539\n",
      "Epoch 8574: train_loss=1007.98792, val_loss=1026.25745\n",
      "Epoch 8575: train_loss=1007.49213, val_loss=1025.63196\n",
      "Epoch 8576: train_loss=1007.00305, val_loss=1025.36768\n",
      "Epoch 8577: train_loss=1006.52209, val_loss=1024.63733\n",
      "Epoch 8578: train_loss=1006.04907, val_loss=1024.50024\n",
      "Epoch 8579: train_loss=1005.57697, val_loss=1023.67010\n",
      "Epoch 8580: train_loss=1005.10852, val_loss=1023.62323\n",
      "Epoch 8581: train_loss=1004.63605, val_loss=1022.71356\n",
      "Epoch 8582: train_loss=1004.15363, val_loss=1022.66541\n",
      "Epoch 8583: train_loss=1003.64996, val_loss=1021.73132\n",
      "Epoch 8584: train_loss=1003.13617, val_loss=1021.59595\n",
      "Epoch 8585: train_loss=1002.60016, val_loss=1020.74207\n",
      "Epoch 8586: train_loss=1002.05859, val_loss=1020.43585\n",
      "Epoch 8587: train_loss=1001.52020, val_loss=1019.80377\n",
      "Epoch 8588: train_loss=1000.99847, val_loss=1019.30481\n",
      "Epoch 8589: train_loss=1000.49939, val_loss=1018.90021\n",
      "Epoch 8590: train_loss=1000.00824, val_loss=1018.22699\n",
      "Epoch 8591: train_loss=999.51666, val_loss=1017.94159\n",
      "Epoch 8592: train_loss=999.01569, val_loss=1017.17664\n",
      "Epoch 8593: train_loss=998.50323, val_loss=1016.88641\n",
      "Epoch 8594: train_loss=997.98053, val_loss=1016.12817\n",
      "Epoch 8595: train_loss=997.45221, val_loss=1015.77405\n",
      "Epoch 8596: train_loss=996.92047, val_loss=1015.07825\n",
      "Epoch 8597: train_loss=996.38855, val_loss=1014.64148\n",
      "Epoch 8598: train_loss=995.85748, val_loss=1014.04065\n",
      "Epoch 8599: train_loss=995.33032, val_loss=1013.54132\n",
      "Epoch 8600: train_loss=994.80688, val_loss=1013.01514\n",
      "Epoch 8601: train_loss=994.28699, val_loss=1012.47388\n",
      "Epoch 8602: train_loss=993.77118, val_loss=1012.00494\n",
      "Epoch 8603: train_loss=993.25653, val_loss=1011.42627\n",
      "Epoch 8604: train_loss=992.74908, val_loss=1011.03320\n",
      "Epoch 8605: train_loss=992.24823, val_loss=1010.39490\n",
      "Epoch 8606: train_loss=991.75458, val_loss=1010.10474\n",
      "Epoch 8607: train_loss=991.26874, val_loss=1009.39294\n",
      "Epoch 8608: train_loss=990.79510, val_loss=1009.21899\n",
      "Epoch 8609: train_loss=990.32812, val_loss=1008.42261\n",
      "Epoch 8610: train_loss=989.86865, val_loss=1008.34198\n",
      "Epoch 8611: train_loss=989.40735, val_loss=1007.46179\n",
      "Epoch 8612: train_loss=988.93732, val_loss=1007.39905\n",
      "Epoch 8613: train_loss=988.45264, val_loss=1006.47778\n",
      "Epoch 8614: train_loss=987.94849, val_loss=1006.32941\n",
      "Epoch 8615: train_loss=987.41888, val_loss=1005.46680\n",
      "Epoch 8616: train_loss=986.88062, val_loss=1005.18268\n",
      "Epoch 8617: train_loss=986.35052, val_loss=1004.51605\n",
      "Epoch 8618: train_loss=985.83710, val_loss=1004.08813\n",
      "Epoch 8619: train_loss=985.34308, val_loss=1003.63593\n",
      "Epoch 8620: train_loss=984.86713, val_loss=1003.07782\n",
      "Epoch 8621: train_loss=984.40533, val_loss=1002.78461\n",
      "Epoch 8622: train_loss=983.95184, val_loss=1002.09845\n",
      "Epoch 8623: train_loss=983.49463, val_loss=1001.91498\n",
      "Epoch 8624: train_loss=983.03876, val_loss=1001.13336\n",
      "Epoch 8625: train_loss=982.57684, val_loss=1000.98871\n",
      "Epoch 8626: train_loss=982.09998, val_loss=1000.15216\n",
      "Epoch 8627: train_loss=981.61121, val_loss=999.96088\n",
      "Epoch 8628: train_loss=981.10541, val_loss=999.14728\n",
      "Epoch 8629: train_loss=980.58942, val_loss=998.84784\n",
      "Epoch 8630: train_loss=980.07263, val_loss=998.16235\n",
      "Epoch 8631: train_loss=979.56445, val_loss=997.75104\n",
      "Epoch 8632: train_loss=979.07074, val_loss=997.23334\n",
      "Epoch 8633: train_loss=978.59021, val_loss=996.72009\n",
      "Epoch 8634: train_loss=978.12256, val_loss=996.35040\n",
      "Epoch 8635: train_loss=977.66382, val_loss=995.74292\n",
      "Epoch 8636: train_loss=977.20819, val_loss=995.46991\n",
      "Epoch 8637: train_loss=976.75635, val_loss=994.79803\n",
      "Epoch 8638: train_loss=976.30341, val_loss=994.59137\n",
      "Epoch 8639: train_loss=975.85620, val_loss=993.86261\n",
      "Epoch 8640: train_loss=975.40417, val_loss=993.69049\n",
      "Epoch 8641: train_loss=974.95020, val_loss=992.91205\n",
      "Epoch 8642: train_loss=974.48218, val_loss=992.71759\n",
      "Epoch 8643: train_loss=974.00800, val_loss=991.94550\n",
      "Epoch 8644: train_loss=973.51971, val_loss=991.67828\n",
      "Epoch 8645: train_loss=973.03088, val_loss=990.99109\n",
      "Epoch 8646: train_loss=972.54120, val_loss=990.62665\n",
      "Epoch 8647: train_loss=972.05933, val_loss=990.08453\n",
      "Epoch 8648: train_loss=971.58936, val_loss=989.61615\n",
      "Epoch 8649: train_loss=971.13556, val_loss=989.23029\n",
      "Epoch 8650: train_loss=970.69281, val_loss=988.66943\n",
      "Epoch 8651: train_loss=970.25470, val_loss=988.38055\n",
      "Epoch 8652: train_loss=969.81934, val_loss=987.75043\n",
      "Epoch 8653: train_loss=969.37939, val_loss=987.49615\n",
      "Epoch 8654: train_loss=968.93866, val_loss=986.83075\n",
      "Epoch 8655: train_loss=968.49261, val_loss=986.57520\n",
      "Epoch 8656: train_loss=968.04456, val_loss=985.91498\n",
      "Epoch 8657: train_loss=967.59180, val_loss=985.62354\n",
      "Epoch 8658: train_loss=967.13733, val_loss=985.01495\n",
      "Epoch 8659: train_loss=966.68378, val_loss=984.66528\n",
      "Epoch 8660: train_loss=966.23267, val_loss=984.13501\n",
      "Epoch 8661: train_loss=965.78552, val_loss=983.70850\n",
      "Epoch 8662: train_loss=965.34381, val_loss=983.26782\n",
      "Epoch 8663: train_loss=964.90741, val_loss=982.77417\n",
      "Epoch 8664: train_loss=964.47461, val_loss=982.40332\n",
      "Epoch 8665: train_loss=964.04510, val_loss=981.85205\n",
      "Epoch 8666: train_loss=963.61804, val_loss=981.54303\n",
      "Epoch 8667: train_loss=963.19507, val_loss=980.93939\n",
      "Epoch 8668: train_loss=962.77417, val_loss=980.68927\n",
      "Epoch 8669: train_loss=962.35803, val_loss=980.03778\n",
      "Epoch 8670: train_loss=961.94342, val_loss=979.84607\n",
      "Epoch 8671: train_loss=961.53528, val_loss=979.14148\n",
      "Epoch 8672: train_loss=961.12225, val_loss=978.99146\n",
      "Epoch 8673: train_loss=960.71375, val_loss=978.23907\n",
      "Epoch 8674: train_loss=960.28845, val_loss=978.07764\n",
      "Epoch 8675: train_loss=959.85809, val_loss=977.31482\n",
      "Epoch 8676: train_loss=959.41260, val_loss=977.09222\n",
      "Epoch 8677: train_loss=958.96338, val_loss=976.38599\n",
      "Epoch 8678: train_loss=958.50714, val_loss=976.06952\n",
      "Epoch 8679: train_loss=958.05750, val_loss=975.49091\n",
      "Epoch 8680: train_loss=957.61597, val_loss=975.08362\n",
      "Epoch 8681: train_loss=957.18738, val_loss=974.64282\n",
      "Epoch 8682: train_loss=956.76788, val_loss=974.15515\n",
      "Epoch 8683: train_loss=956.35602, val_loss=973.82214\n",
      "Epoch 8684: train_loss=955.94952, val_loss=973.26257\n",
      "Epoch 8685: train_loss=955.54572, val_loss=973.00049\n",
      "Epoch 8686: train_loss=955.14117, val_loss=972.38873\n",
      "Epoch 8687: train_loss=954.73157, val_loss=972.14978\n",
      "Epoch 8688: train_loss=954.31903, val_loss=971.51605\n",
      "Epoch 8689: train_loss=953.90057, val_loss=971.27106\n",
      "Epoch 8690: train_loss=953.48187, val_loss=970.64313\n",
      "Epoch 8691: train_loss=953.05823, val_loss=970.37305\n",
      "Epoch 8692: train_loss=952.63361, val_loss=969.76941\n",
      "Epoch 8693: train_loss=952.20825, val_loss=969.46478\n",
      "Epoch 8694: train_loss=951.78461, val_loss=968.89691\n",
      "Epoch 8695: train_loss=951.35992, val_loss=968.54846\n",
      "Epoch 8696: train_loss=950.93878, val_loss=968.03375\n",
      "Epoch 8697: train_loss=950.51947, val_loss=967.64423\n",
      "Epoch 8698: train_loss=950.10364, val_loss=967.18433\n",
      "Epoch 8699: train_loss=949.69043, val_loss=966.75696\n",
      "Epoch 8700: train_loss=949.27948, val_loss=966.33978\n",
      "Epoch 8701: train_loss=948.87061, val_loss=965.88068\n",
      "Epoch 8702: train_loss=948.46326, val_loss=965.49707\n",
      "Epoch 8703: train_loss=948.05719, val_loss=965.00250\n",
      "Epoch 8704: train_loss=947.65204, val_loss=964.65417\n",
      "Epoch 8705: train_loss=947.25018, val_loss=964.12238\n",
      "Epoch 8706: train_loss=946.85089, val_loss=963.82465\n",
      "Epoch 8707: train_loss=946.45941, val_loss=963.25537\n",
      "Epoch 8708: train_loss=946.07294, val_loss=963.04480\n",
      "Epoch 8709: train_loss=945.70020, val_loss=962.41711\n",
      "Epoch 8710: train_loss=945.33154, val_loss=962.30884\n",
      "Epoch 8711: train_loss=944.97559, val_loss=961.60864\n",
      "Epoch 8712: train_loss=944.61670, val_loss=961.57623\n",
      "Epoch 8713: train_loss=944.25879, val_loss=960.79688\n",
      "Epoch 8714: train_loss=943.87811, val_loss=960.74213\n",
      "Epoch 8715: train_loss=943.47400, val_loss=959.92761\n",
      "Epoch 8716: train_loss=943.04108, val_loss=959.77191\n",
      "Epoch 8717: train_loss=942.59387, val_loss=959.04285\n",
      "Epoch 8718: train_loss=942.14337, val_loss=958.76562\n",
      "Epoch 8719: train_loss=941.70337, val_loss=958.21991\n",
      "Epoch 8720: train_loss=941.28320, val_loss=957.83911\n",
      "Epoch 8721: train_loss=940.88336, val_loss=957.46478\n",
      "Epoch 8722: train_loss=940.49738, val_loss=956.99121\n",
      "Epoch 8723: train_loss=940.12390, val_loss=956.75232\n",
      "Epoch 8724: train_loss=939.75854, val_loss=956.18933\n",
      "Epoch 8725: train_loss=939.39502, val_loss=956.03522\n",
      "Epoch 8726: train_loss=939.02728, val_loss=955.40332\n",
      "Epoch 8727: train_loss=938.65118, val_loss=955.25598\n",
      "Epoch 8728: train_loss=938.26215, val_loss=954.60077\n",
      "Epoch 8729: train_loss=937.86377, val_loss=954.41034\n",
      "Epoch 8730: train_loss=937.45990, val_loss=953.79700\n",
      "Epoch 8731: train_loss=937.05573, val_loss=953.54980\n",
      "Epoch 8732: train_loss=936.65289, val_loss=953.00439\n",
      "Epoch 8733: train_loss=936.25598, val_loss=952.70245\n",
      "Epoch 8734: train_loss=935.86224, val_loss=952.22729\n",
      "Epoch 8735: train_loss=935.47314, val_loss=951.86359\n",
      "Epoch 8736: train_loss=935.08813, val_loss=951.46594\n",
      "Epoch 8737: train_loss=934.70764, val_loss=951.04077\n",
      "Epoch 8738: train_loss=934.33099, val_loss=950.70605\n",
      "Epoch 8739: train_loss=933.95740, val_loss=950.23004\n",
      "Epoch 8740: train_loss=933.58521, val_loss=949.94171\n",
      "Epoch 8741: train_loss=933.21423, val_loss=949.42548\n",
      "Epoch 8742: train_loss=932.84320, val_loss=949.17236\n",
      "Epoch 8743: train_loss=932.47382, val_loss=948.63422\n",
      "Epoch 8744: train_loss=932.10541, val_loss=948.40833\n",
      "Epoch 8745: train_loss=931.73584, val_loss=947.85382\n",
      "Epoch 8746: train_loss=931.36530, val_loss=947.64673\n",
      "Epoch 8747: train_loss=930.99591, val_loss=947.08112\n",
      "Epoch 8748: train_loss=930.62585, val_loss=946.88092\n",
      "Epoch 8749: train_loss=930.25446, val_loss=946.30646\n",
      "Epoch 8750: train_loss=929.88232, val_loss=946.10150\n",
      "Epoch 8751: train_loss=929.50885, val_loss=945.53052\n",
      "Epoch 8752: train_loss=929.13660, val_loss=945.31750\n",
      "Epoch 8753: train_loss=928.76208, val_loss=944.75671\n",
      "Epoch 8754: train_loss=928.38562, val_loss=944.52692\n",
      "Epoch 8755: train_loss=928.01123, val_loss=943.98590\n",
      "Epoch 8756: train_loss=927.63501, val_loss=943.73547\n",
      "Epoch 8757: train_loss=927.26294, val_loss=943.21625\n",
      "Epoch 8758: train_loss=926.89050, val_loss=942.95648\n",
      "Epoch 8759: train_loss=926.52301, val_loss=942.44684\n",
      "Epoch 8760: train_loss=926.15625, val_loss=942.19940\n",
      "Epoch 8761: train_loss=925.79529, val_loss=941.68073\n",
      "Epoch 8762: train_loss=925.43585, val_loss=941.46771\n",
      "Epoch 8763: train_loss=925.08289, val_loss=940.92938\n",
      "Epoch 8764: train_loss=924.73224, val_loss=940.77234\n",
      "Epoch 8765: train_loss=924.38892, val_loss=940.20331\n",
      "Epoch 8766: train_loss=924.05237, val_loss=940.11499\n",
      "Epoch 8767: train_loss=923.71924, val_loss=939.49707\n",
      "Epoch 8768: train_loss=923.39478, val_loss=939.47443\n",
      "Epoch 8769: train_loss=923.06805, val_loss=938.79340\n",
      "Epoch 8770: train_loss=922.73938, val_loss=938.78149\n",
      "Epoch 8771: train_loss=922.38586, val_loss=938.04645\n",
      "Epoch 8772: train_loss=922.01807, val_loss=937.96924\n",
      "Epoch 8773: train_loss=921.61963, val_loss=937.24976\n",
      "Epoch 8774: train_loss=921.21155, val_loss=937.05774\n",
      "Epoch 8775: train_loss=920.79193, val_loss=936.46387\n",
      "Epoch 8776: train_loss=920.38336, val_loss=936.15656\n",
      "Epoch 8777: train_loss=919.99756, val_loss=935.76233\n",
      "Epoch 8778: train_loss=919.63538, val_loss=935.35388\n",
      "Epoch 8779: train_loss=919.29028, val_loss=935.10925\n",
      "Epoch 8780: train_loss=918.95380, val_loss=934.61365\n",
      "Epoch 8781: train_loss=918.61865, val_loss=934.43842\n",
      "Epoch 8782: train_loss=918.27960, val_loss=933.88269\n",
      "Epoch 8783: train_loss=917.93256, val_loss=933.70142\n",
      "Epoch 8784: train_loss=917.57404, val_loss=933.13788\n",
      "Epoch 8785: train_loss=917.20642, val_loss=932.90179\n",
      "Epoch 8786: train_loss=916.83728, val_loss=932.39844\n",
      "Epoch 8787: train_loss=916.46869, val_loss=932.09222\n",
      "Epoch 8788: train_loss=916.10480, val_loss=931.69257\n",
      "Epoch 8789: train_loss=915.74878, val_loss=931.31750\n",
      "Epoch 8790: train_loss=915.39996, val_loss=931.01697\n",
      "Epoch 8791: train_loss=915.05585, val_loss=930.58319\n",
      "Epoch 8792: train_loss=914.71454, val_loss=930.35260\n",
      "Epoch 8793: train_loss=914.37537, val_loss=929.87360\n",
      "Epoch 8794: train_loss=914.03583, val_loss=929.69708\n",
      "Epoch 8795: train_loss=913.69983, val_loss=929.18213\n",
      "Epoch 8796: train_loss=913.36298, val_loss=929.04736\n",
      "Epoch 8797: train_loss=913.02704, val_loss=928.50256\n",
      "Epoch 8798: train_loss=912.69092, val_loss=928.39233\n",
      "Epoch 8799: train_loss=912.35004, val_loss=927.81812\n",
      "Epoch 8800: train_loss=912.00787, val_loss=927.70178\n",
      "Epoch 8801: train_loss=911.65735, val_loss=927.11108\n",
      "Epoch 8802: train_loss=911.30121, val_loss=926.95862\n",
      "Epoch 8803: train_loss=910.93756, val_loss=926.38586\n",
      "Epoch 8804: train_loss=910.57306, val_loss=926.18964\n",
      "Epoch 8805: train_loss=910.20593, val_loss=925.66339\n",
      "Epoch 8806: train_loss=909.83771, val_loss=925.41333\n",
      "Epoch 8807: train_loss=909.47406, val_loss=924.96045\n",
      "Epoch 8808: train_loss=909.11285, val_loss=924.65240\n",
      "Epoch 8809: train_loss=908.75726, val_loss=924.27844\n",
      "Epoch 8810: train_loss=908.40668, val_loss=923.91656\n",
      "Epoch 8811: train_loss=908.06006, val_loss=923.60864\n",
      "Epoch 8812: train_loss=907.71722, val_loss=923.20410\n",
      "Epoch 8813: train_loss=907.37604, val_loss=922.94531\n",
      "Epoch 8814: train_loss=907.03650, val_loss=922.50940\n",
      "Epoch 8815: train_loss=906.69806, val_loss=922.29028\n",
      "Epoch 8816: train_loss=906.36432, val_loss=921.82031\n",
      "Epoch 8817: train_loss=906.03363, val_loss=921.65375\n",
      "Epoch 8818: train_loss=905.70947, val_loss=921.14966\n",
      "Epoch 8819: train_loss=905.39062, val_loss=921.06055\n",
      "Epoch 8820: train_loss=905.08282, val_loss=920.51038\n",
      "Epoch 8821: train_loss=904.78180, val_loss=920.48468\n",
      "Epoch 8822: train_loss=904.47443, val_loss=919.86981\n",
      "Epoch 8823: train_loss=904.16101, val_loss=919.84387\n",
      "Epoch 8824: train_loss=903.82227, val_loss=919.17645\n",
      "Epoch 8825: train_loss=903.46515, val_loss=919.07007\n",
      "Epoch 8826: train_loss=903.07892, val_loss=918.42853\n",
      "Epoch 8827: train_loss=902.68695, val_loss=918.21552\n",
      "Epoch 8828: train_loss=902.29053, val_loss=917.70557\n",
      "Epoch 8829: train_loss=901.91034, val_loss=917.39746\n",
      "Epoch 8830: train_loss=901.55365, val_loss=917.06915\n",
      "Epoch 8831: train_loss=901.21759, val_loss=916.67480\n",
      "Epoch 8832: train_loss=900.89612, val_loss=916.47076\n",
      "Epoch 8833: train_loss=900.58221, val_loss=915.99860\n",
      "Epoch 8834: train_loss=900.26855, val_loss=915.85535\n",
      "Epoch 8835: train_loss=899.94562, val_loss=915.32709\n",
      "Epoch 8836: train_loss=899.61572, val_loss=915.17725\n",
      "Epoch 8837: train_loss=899.27423, val_loss=914.63318\n",
      "Epoch 8838: train_loss=898.92462, val_loss=914.44220\n",
      "Epoch 8839: train_loss=898.56989, val_loss=913.93835\n",
      "Epoch 8840: train_loss=898.21466, val_loss=913.69342\n",
      "Epoch 8841: train_loss=897.86182, val_loss=913.25946\n",
      "Epoch 8842: train_loss=897.51294, val_loss=912.95453\n",
      "Epoch 8843: train_loss=897.16986, val_loss=912.60065\n",
      "Epoch 8844: train_loss=896.83350, val_loss=912.23938\n",
      "Epoch 8845: train_loss=896.50214, val_loss=911.95483\n",
      "Epoch 8846: train_loss=896.17352, val_loss=911.54816\n",
      "Epoch 8847: train_loss=895.84741, val_loss=911.31842\n",
      "Epoch 8848: train_loss=895.52240, val_loss=910.87482\n",
      "Epoch 8849: train_loss=895.19678, val_loss=910.68500\n",
      "Epoch 8850: train_loss=894.87500, val_loss=910.21161\n",
      "Epoch 8851: train_loss=894.55365, val_loss=910.05664\n",
      "Epoch 8852: train_loss=894.23389, val_loss=909.55780\n",
      "Epoch 8853: train_loss=893.91370, val_loss=909.42346\n",
      "Epoch 8854: train_loss=893.59149, val_loss=908.90167\n",
      "Epoch 8855: train_loss=893.26581, val_loss=908.76312\n",
      "Epoch 8856: train_loss=892.93329, val_loss=908.22876\n",
      "Epoch 8857: train_loss=892.59650, val_loss=908.05194\n",
      "Epoch 8858: train_loss=892.25232, val_loss=907.52838\n",
      "Epoch 8859: train_loss=891.90393, val_loss=907.30811\n",
      "Epoch 8860: train_loss=891.55713, val_loss=906.83575\n",
      "Epoch 8861: train_loss=891.21112, val_loss=906.56970\n",
      "Epoch 8862: train_loss=890.87030, val_loss=906.16235\n",
      "Epoch 8863: train_loss=890.53400, val_loss=905.84863\n",
      "Epoch 8864: train_loss=890.20264, val_loss=905.50555\n",
      "Epoch 8865: train_loss=889.87610, val_loss=905.15179\n",
      "Epoch 8866: train_loss=889.55249, val_loss=904.86499\n",
      "Epoch 8867: train_loss=889.23193, val_loss=904.47748\n",
      "Epoch 8868: train_loss=888.91418, val_loss=904.24097\n",
      "Epoch 8869: train_loss=888.59912, val_loss=903.81921\n",
      "Epoch 8870: train_loss=888.28711, val_loss=903.63269\n",
      "Epoch 8871: train_loss=887.97760, val_loss=903.17053\n",
      "Epoch 8872: train_loss=887.66913, val_loss=903.02197\n",
      "Epoch 8873: train_loss=887.36298, val_loss=902.52844\n",
      "Epoch 8874: train_loss=887.05865, val_loss=902.40863\n",
      "Epoch 8875: train_loss=886.75067, val_loss=901.88770\n",
      "Epoch 8876: train_loss=886.44312, val_loss=901.77301\n",
      "Epoch 8877: train_loss=886.12408, val_loss=901.23309\n",
      "Epoch 8878: train_loss=885.80518, val_loss=901.10101\n",
      "Epoch 8879: train_loss=885.47272, val_loss=900.56470\n",
      "Epoch 8880: train_loss=885.14062, val_loss=900.39551\n",
      "Epoch 8881: train_loss=884.79651, val_loss=899.89020\n",
      "Epoch 8882: train_loss=884.45233, val_loss=899.66022\n",
      "Epoch 8883: train_loss=884.10785, val_loss=899.22345\n",
      "Epoch 8884: train_loss=883.77069, val_loss=898.93866\n",
      "Epoch 8885: train_loss=883.44165, val_loss=898.58527\n",
      "Epoch 8886: train_loss=883.12085, val_loss=898.25366\n",
      "Epoch 8887: train_loss=882.80774, val_loss=897.97736\n",
      "Epoch 8888: train_loss=882.49902, val_loss=897.60901\n",
      "Epoch 8889: train_loss=882.19324, val_loss=897.38611\n",
      "Epoch 8890: train_loss=881.89008, val_loss=896.98071\n",
      "Epoch 8891: train_loss=881.58716, val_loss=896.79297\n",
      "Epoch 8892: train_loss=881.28699, val_loss=896.35632\n",
      "Epoch 8893: train_loss=880.98804, val_loss=896.21002\n",
      "Epoch 8894: train_loss=880.69550, val_loss=895.74261\n",
      "Epoch 8895: train_loss=880.40607, val_loss=895.64392\n",
      "Epoch 8896: train_loss=880.12036, val_loss=895.14447\n",
      "Epoch 8897: train_loss=879.84088, val_loss=895.08264\n",
      "Epoch 8898: train_loss=879.55164, val_loss=894.53931\n",
      "Epoch 8899: train_loss=879.25653, val_loss=894.46320\n",
      "Epoch 8900: train_loss=878.93860, val_loss=893.89130\n",
      "Epoch 8901: train_loss=878.60699, val_loss=893.74622\n",
      "Epoch 8902: train_loss=878.25177, val_loss=893.20715\n",
      "Epoch 8903: train_loss=877.89606, val_loss=892.97992\n",
      "Epoch 8904: train_loss=877.54272, val_loss=892.55029\n",
      "Epoch 8905: train_loss=877.20355, val_loss=892.24786\n",
      "Epoch 8906: train_loss=876.88470, val_loss=891.96564\n",
      "Epoch 8907: train_loss=876.58569, val_loss=891.59845\n",
      "Epoch 8908: train_loss=876.29865, val_loss=891.42413\n",
      "Epoch 8909: train_loss=876.01642, val_loss=890.99689\n",
      "Epoch 8910: train_loss=875.72760, val_loss=890.85175\n",
      "Epoch 8911: train_loss=875.42920, val_loss=890.38654\n",
      "Epoch 8912: train_loss=875.12201, val_loss=890.21704\n",
      "Epoch 8913: train_loss=874.80402, val_loss=889.75098\n",
      "Epoch 8914: train_loss=874.48114, val_loss=889.53711\n",
      "Epoch 8915: train_loss=874.15735, val_loss=889.11084\n",
      "Epoch 8916: train_loss=873.83459, val_loss=888.84869\n",
      "Epoch 8917: train_loss=873.51556, val_loss=888.49695\n",
      "Epoch 8918: train_loss=873.20337, val_loss=888.19452\n",
      "Epoch 8919: train_loss=872.89777, val_loss=887.91272\n",
      "Epoch 8920: train_loss=872.59662, val_loss=887.57318\n",
      "Epoch 8921: train_loss=872.29895, val_loss=887.33685\n",
      "Epoch 8922: train_loss=872.00342, val_loss=886.96112\n",
      "Epoch 8923: train_loss=871.70911, val_loss=886.75739\n",
      "Epoch 8924: train_loss=871.41699, val_loss=886.35242\n",
      "Epoch 8925: train_loss=871.12659, val_loss=886.18103\n",
      "Epoch 8926: train_loss=870.83643, val_loss=885.74524\n",
      "Epoch 8927: train_loss=870.54523, val_loss=885.59076\n",
      "Epoch 8928: train_loss=870.25055, val_loss=885.13068\n",
      "Epoch 8929: train_loss=869.95343, val_loss=884.97278\n",
      "Epoch 8930: train_loss=869.64972, val_loss=884.50470\n",
      "Epoch 8931: train_loss=869.34265, val_loss=884.33191\n",
      "Epoch 8932: train_loss=869.03174, val_loss=883.88000\n",
      "Epoch 8933: train_loss=868.71631, val_loss=883.67230\n",
      "Epoch 8934: train_loss=868.39886, val_loss=883.26178\n",
      "Epoch 8935: train_loss=868.08398, val_loss=883.01221\n",
      "Epoch 8936: train_loss=867.77185, val_loss=882.65601\n",
      "Epoch 8937: train_loss=867.46570, val_loss=882.36646\n",
      "Epoch 8938: train_loss=867.16425, val_loss=882.06189\n",
      "Epoch 8939: train_loss=866.86694, val_loss=881.73999\n",
      "Epoch 8940: train_loss=866.57324, val_loss=881.48138\n",
      "Epoch 8941: train_loss=866.28192, val_loss=881.13257\n",
      "Epoch 8942: train_loss=865.99341, val_loss=880.91852\n",
      "Epoch 8943: train_loss=865.70825, val_loss=880.54132\n",
      "Epoch 8944: train_loss=865.42395, val_loss=880.35736\n",
      "Epoch 8945: train_loss=865.13971, val_loss=879.95209\n",
      "Epoch 8946: train_loss=864.85339, val_loss=879.78131\n",
      "Epoch 8947: train_loss=864.56561, val_loss=879.35657\n",
      "Epoch 8948: train_loss=864.27356, val_loss=879.18219\n",
      "Epoch 8949: train_loss=863.98047, val_loss=878.75757\n",
      "Epoch 8950: train_loss=863.68433, val_loss=878.57715\n",
      "Epoch 8951: train_loss=863.38867, val_loss=878.16272\n",
      "Epoch 8952: train_loss=863.09045, val_loss=877.96661\n",
      "Epoch 8953: train_loss=862.79205, val_loss=877.57025\n",
      "Epoch 8954: train_loss=862.49414, val_loss=877.35498\n",
      "Epoch 8955: train_loss=862.19745, val_loss=876.98157\n",
      "Epoch 8956: train_loss=861.90100, val_loss=876.74133\n",
      "Epoch 8957: train_loss=861.60626, val_loss=876.39624\n",
      "Epoch 8958: train_loss=861.31342, val_loss=876.13177\n",
      "Epoch 8959: train_loss=861.02264, val_loss=875.81427\n",
      "Epoch 8960: train_loss=860.73364, val_loss=875.53192\n",
      "Epoch 8961: train_loss=860.44611, val_loss=875.23877\n",
      "Epoch 8962: train_loss=860.15985, val_loss=874.94037\n",
      "Epoch 8963: train_loss=859.87512, val_loss=874.66956\n",
      "Epoch 8964: train_loss=859.59222, val_loss=874.35516\n",
      "Epoch 8965: train_loss=859.31085, val_loss=874.11029\n",
      "Epoch 8966: train_loss=859.03168, val_loss=873.77429\n",
      "Epoch 8967: train_loss=858.75439, val_loss=873.56879\n",
      "Epoch 8968: train_loss=858.48315, val_loss=873.20618\n",
      "Epoch 8969: train_loss=858.21741, val_loss=873.05975\n",
      "Epoch 8970: train_loss=857.95978, val_loss=872.66504\n",
      "Epoch 8971: train_loss=857.70935, val_loss=872.58856\n",
      "Epoch 8972: train_loss=857.46527, val_loss=872.15436\n",
      "Epoch 8973: train_loss=857.22498, val_loss=872.12909\n",
      "Epoch 8974: train_loss=856.97992, val_loss=871.64313\n",
      "Epoch 8975: train_loss=856.72693, val_loss=871.61438\n",
      "Epoch 8976: train_loss=856.45319, val_loss=871.07947\n",
      "Epoch 8977: train_loss=856.16071, val_loss=870.98956\n",
      "Epoch 8978: train_loss=855.84454, val_loss=870.44861\n",
      "Epoch 8979: train_loss=855.50836, val_loss=870.26300\n",
      "Epoch 8980: train_loss=855.16968, val_loss=869.82507\n",
      "Epoch 8981: train_loss=854.84497, val_loss=869.57349\n",
      "Epoch 8982: train_loss=854.54486, val_loss=869.29065\n",
      "Epoch 8983: train_loss=854.26831, val_loss=868.98431\n",
      "Epoch 8984: train_loss=854.00946, val_loss=868.82281\n",
      "Epoch 8985: train_loss=853.76270, val_loss=868.45917\n",
      "Epoch 8986: train_loss=853.52069, val_loss=868.35986\n",
      "Epoch 8987: train_loss=853.27075, val_loss=867.93927\n",
      "Epoch 8988: train_loss=853.01031, val_loss=867.83154\n",
      "Epoch 8989: train_loss=852.73547, val_loss=867.38727\n",
      "Epoch 8990: train_loss=852.45093, val_loss=867.23438\n",
      "Epoch 8991: train_loss=852.15643, val_loss=866.81256\n",
      "Epoch 8992: train_loss=851.86298, val_loss=866.61035\n",
      "Epoch 8993: train_loss=851.56750, val_loss=866.24847\n",
      "Epoch 8994: train_loss=851.27832, val_loss=865.99872\n",
      "Epoch 8995: train_loss=850.99762, val_loss=865.71857\n",
      "Epoch 8996: train_loss=850.72522, val_loss=865.42700\n",
      "Epoch 8997: train_loss=850.45972, val_loss=865.21582\n",
      "Epoch 8998: train_loss=850.20074, val_loss=864.88452\n",
      "Epoch 8999: train_loss=849.94617, val_loss=864.72894\n",
      "Epoch 9000: train_loss=849.69269, val_loss=864.36108\n",
      "Epoch 9001: train_loss=849.43811, val_loss=864.23730\n",
      "Epoch 9002: train_loss=849.18066, val_loss=863.84094\n",
      "Epoch 9003: train_loss=848.91699, val_loss=863.72308\n",
      "Epoch 9004: train_loss=848.64862, val_loss=863.31317\n",
      "Epoch 9005: train_loss=848.37128, val_loss=863.17535\n",
      "Epoch 9006: train_loss=848.09045, val_loss=862.77618\n",
      "Epoch 9007: train_loss=847.80273, val_loss=862.59882\n",
      "Epoch 9008: train_loss=847.51331, val_loss=862.24225\n",
      "Epoch 9009: train_loss=847.22583, val_loss=862.02393\n",
      "Epoch 9010: train_loss=846.94299, val_loss=861.72705\n",
      "Epoch 9011: train_loss=846.66650, val_loss=861.46802\n",
      "Epoch 9012: train_loss=846.39551, val_loss=861.22791\n",
      "Epoch 9013: train_loss=846.12878, val_loss=860.93707\n",
      "Epoch 9014: train_loss=845.86816, val_loss=860.74347\n",
      "Epoch 9015: train_loss=845.61084, val_loss=860.41888\n",
      "Epoch 9016: train_loss=845.35376, val_loss=860.25421\n",
      "Epoch 9017: train_loss=845.09894, val_loss=859.90289\n",
      "Epoch 9018: train_loss=844.84448, val_loss=859.76282\n",
      "Epoch 9019: train_loss=844.59167, val_loss=859.38763\n",
      "Epoch 9020: train_loss=844.33893, val_loss=859.26685\n",
      "Epoch 9021: train_loss=844.08630, val_loss=858.87061\n",
      "Epoch 9022: train_loss=843.83038, val_loss=858.75739\n",
      "Epoch 9023: train_loss=843.57196, val_loss=858.34998\n",
      "Epoch 9024: train_loss=843.31024, val_loss=858.22949\n",
      "Epoch 9025: train_loss=843.04224, val_loss=857.82056\n",
      "Epoch 9026: train_loss=842.77100, val_loss=857.67987\n",
      "Epoch 9027: train_loss=842.49646, val_loss=857.28290\n",
      "Epoch 9028: train_loss=842.21851, val_loss=857.10809\n",
      "Epoch 9029: train_loss=841.94037, val_loss=856.74353\n",
      "Epoch 9030: train_loss=841.66248, val_loss=856.53162\n",
      "Epoch 9031: train_loss=841.38892, val_loss=856.21686\n",
      "Epoch 9032: train_loss=841.11938, val_loss=855.97052\n",
      "Epoch 9033: train_loss=840.85461, val_loss=855.70807\n",
      "Epoch 9034: train_loss=840.59436, val_loss=855.43121\n",
      "Epoch 9035: train_loss=840.33740, val_loss=855.20880\n",
      "Epoch 9036: train_loss=840.08240, val_loss=854.90552\n",
      "Epoch 9037: train_loss=839.82922, val_loss=854.72131\n",
      "Epoch 9038: train_loss=839.58093, val_loss=854.39038\n",
      "Epoch 9039: train_loss=839.33508, val_loss=854.24658\n",
      "Epoch 9040: train_loss=839.09363, val_loss=853.88831\n",
      "Epoch 9041: train_loss=838.85553, val_loss=853.78668\n",
      "Epoch 9042: train_loss=838.62079, val_loss=853.39801\n",
      "Epoch 9043: train_loss=838.38611, val_loss=853.32330\n",
      "Epoch 9044: train_loss=838.14722, val_loss=852.90283\n",
      "Epoch 9045: train_loss=837.90558, val_loss=852.83020\n",
      "Epoch 9046: train_loss=837.65332, val_loss=852.38275\n",
      "Epoch 9047: train_loss=837.39270, val_loss=852.27747\n",
      "Epoch 9048: train_loss=837.11591, val_loss=851.82837\n",
      "Epoch 9049: train_loss=836.83319, val_loss=851.67285\n",
      "Epoch 9050: train_loss=836.54291, val_loss=851.26685\n",
      "Epoch 9051: train_loss=836.25543, val_loss=851.06024\n",
      "Epoch 9052: train_loss=835.97528, val_loss=850.73938\n",
      "Epoch 9053: train_loss=835.70660, val_loss=850.48834\n",
      "Epoch 9054: train_loss=835.44849, val_loss=850.25293\n",
      "Epoch 9055: train_loss=835.19983, val_loss=849.95795\n",
      "Epoch 9056: train_loss=834.95728, val_loss=849.78455\n",
      "Epoch 9057: train_loss=834.71814, val_loss=849.45190\n",
      "Epoch 9058: train_loss=834.48077, val_loss=849.32062\n",
      "Epoch 9059: train_loss=834.24457, val_loss=848.95465\n",
      "Epoch 9060: train_loss=834.00623, val_loss=848.84583\n",
      "Epoch 9061: train_loss=833.76666, val_loss=848.45398\n",
      "Epoch 9062: train_loss=833.52271, val_loss=848.34875\n",
      "Epoch 9063: train_loss=833.27563, val_loss=847.94086\n",
      "Epoch 9064: train_loss=833.02179, val_loss=847.82495\n",
      "Epoch 9065: train_loss=832.76538, val_loss=847.41803\n",
      "Epoch 9066: train_loss=832.50208, val_loss=847.28125\n",
      "Epoch 9067: train_loss=832.23950, val_loss=846.89490\n",
      "Epoch 9068: train_loss=831.97394, val_loss=846.72736\n",
      "Epoch 9069: train_loss=831.70746, val_loss=846.37201\n",
      "Epoch 9070: train_loss=831.44226, val_loss=846.17017\n",
      "Epoch 9071: train_loss=831.17993, val_loss=845.85693\n",
      "Epoch 9072: train_loss=830.92133, val_loss=845.62384\n",
      "Epoch 9073: train_loss=830.66687, val_loss=845.35260\n",
      "Epoch 9074: train_loss=830.41486, val_loss=845.09174\n",
      "Epoch 9075: train_loss=830.16559, val_loss=844.85712\n",
      "Epoch 9076: train_loss=829.91840, val_loss=844.57288\n",
      "Epoch 9077: train_loss=829.67334, val_loss=844.37488\n",
      "Epoch 9078: train_loss=829.43164, val_loss=844.06989\n",
      "Epoch 9079: train_loss=829.19397, val_loss=843.91577\n",
      "Epoch 9080: train_loss=828.96088, val_loss=843.58167\n",
      "Epoch 9081: train_loss=828.73090, val_loss=843.47467\n",
      "Epoch 9082: train_loss=828.50696, val_loss=843.10822\n",
      "Epoch 9083: train_loss=828.28210, val_loss=843.03595\n",
      "Epoch 9084: train_loss=828.05798, val_loss=842.63873\n",
      "Epoch 9085: train_loss=827.82819, val_loss=842.57294\n",
      "Epoch 9086: train_loss=827.58856, val_loss=842.15027\n",
      "Epoch 9087: train_loss=827.33893, val_loss=842.06024\n",
      "Epoch 9088: train_loss=827.07837, val_loss=841.63513\n",
      "Epoch 9089: train_loss=826.80920, val_loss=841.50165\n",
      "Epoch 9090: train_loss=826.53241, val_loss=841.10791\n",
      "Epoch 9091: train_loss=826.25604, val_loss=840.92865\n",
      "Epoch 9092: train_loss=825.98193, val_loss=840.60107\n",
      "Epoch 9093: train_loss=825.71472, val_loss=840.37787\n",
      "Epoch 9094: train_loss=825.45862, val_loss=840.12897\n",
      "Epoch 9095: train_loss=825.21179, val_loss=839.86847\n",
      "Epoch 9096: train_loss=824.97229, val_loss=839.67999\n",
      "Epoch 9097: train_loss=824.73853, val_loss=839.38379\n",
      "Epoch 9098: train_loss=824.50659, val_loss=839.23151\n",
      "Epoch 9099: train_loss=824.27570, val_loss=838.90790\n",
      "Epoch 9100: train_loss=824.04358, val_loss=838.77112\n",
      "Epoch 9101: train_loss=823.80865, val_loss=838.42755\n",
      "Epoch 9102: train_loss=823.57013, val_loss=838.28870\n",
      "Epoch 9103: train_loss=823.32739, val_loss=837.94000\n",
      "Epoch 9104: train_loss=823.08221, val_loss=837.78986\n",
      "Epoch 9105: train_loss=822.83374, val_loss=837.44830\n",
      "Epoch 9106: train_loss=822.58423, val_loss=837.28693\n",
      "Epoch 9107: train_loss=822.33594, val_loss=836.96155\n",
      "Epoch 9108: train_loss=822.08679, val_loss=836.78619\n",
      "Epoch 9109: train_loss=821.84021, val_loss=836.47845\n",
      "Epoch 9110: train_loss=821.59436, val_loss=836.29242\n",
      "Epoch 9111: train_loss=821.35016, val_loss=835.99921\n",
      "Epoch 9112: train_loss=821.10693, val_loss=835.80731\n",
      "Epoch 9113: train_loss=820.86591, val_loss=835.52203\n",
      "Epoch 9114: train_loss=820.62476, val_loss=835.32605\n",
      "Epoch 9115: train_loss=820.38550, val_loss=835.04462\n",
      "Epoch 9116: train_loss=820.14691, val_loss=834.84595\n",
      "Epoch 9117: train_loss=819.90912, val_loss=834.56415\n",
      "Epoch 9118: train_loss=819.67249, val_loss=834.36987\n",
      "Epoch 9119: train_loss=819.43756, val_loss=834.08282\n",
      "Epoch 9120: train_loss=819.20343, val_loss=833.90167\n",
      "Epoch 9121: train_loss=818.97144, val_loss=833.60504\n",
      "Epoch 9122: train_loss=818.74023, val_loss=833.44281\n",
      "Epoch 9123: train_loss=818.51288, val_loss=833.13409\n",
      "Epoch 9124: train_loss=818.28625, val_loss=832.99884\n",
      "Epoch 9125: train_loss=818.06519, val_loss=832.67529\n",
      "Epoch 9126: train_loss=817.84692, val_loss=832.57623\n",
      "Epoch 9127: train_loss=817.63422, val_loss=832.23389\n",
      "Epoch 9128: train_loss=817.42542, val_loss=832.16913\n",
      "Epoch 9129: train_loss=817.21863, val_loss=831.79962\n",
      "Epoch 9130: train_loss=817.00879, val_loss=831.74274\n",
      "Epoch 9131: train_loss=816.78766, val_loss=831.33435\n",
      "Epoch 9132: train_loss=816.55029, val_loss=831.23907\n",
      "Epoch 9133: train_loss=816.29608, val_loss=830.81830\n",
      "Epoch 9134: train_loss=816.02826, val_loss=830.67059\n",
      "Epoch 9135: train_loss=815.75635, val_loss=830.29095\n",
      "Epoch 9136: train_loss=815.48352, val_loss=830.09430\n",
      "Epoch 9137: train_loss=815.21918, val_loss=829.80157\n",
      "Epoch 9138: train_loss=814.96967, val_loss=829.57050\n",
      "Epoch 9139: train_loss=814.73425, val_loss=829.36597\n",
      "Epoch 9140: train_loss=814.51080, val_loss=829.09790\n",
      "Epoch 9141: train_loss=814.29431, val_loss=828.94855\n",
      "Epoch 9142: train_loss=814.07983, val_loss=828.64484\n",
      "Epoch 9143: train_loss=813.86395, val_loss=828.51483\n",
      "Epoch 9144: train_loss=813.64331, val_loss=828.18604\n",
      "Epoch 9145: train_loss=813.41663, val_loss=828.05035\n",
      "Epoch 9146: train_loss=813.18524, val_loss=827.71637\n",
      "Epoch 9147: train_loss=812.94904, val_loss=827.56128\n",
      "Epoch 9148: train_loss=812.70990, val_loss=827.24158\n",
      "Epoch 9149: train_loss=812.46936, val_loss=827.06366\n",
      "Epoch 9150: train_loss=812.22864, val_loss=826.77319\n",
      "Epoch 9151: train_loss=811.99066, val_loss=826.57507\n",
      "Epoch 9152: train_loss=811.75629, val_loss=826.31750\n",
      "Epoch 9153: train_loss=811.52545, val_loss=826.10236\n",
      "Epoch 9154: train_loss=811.29773, val_loss=825.86993\n",
      "Epoch 9155: train_loss=811.07245, val_loss=825.63824\n",
      "Epoch 9156: train_loss=810.84863, val_loss=825.42371\n",
      "Epoch 9157: train_loss=810.62604, val_loss=825.17609\n",
      "Epoch 9158: train_loss=810.40540, val_loss=824.98230\n",
      "Epoch 9159: train_loss=810.18665, val_loss=824.71606\n",
      "Epoch 9160: train_loss=809.97058, val_loss=824.55164\n",
      "Epoch 9161: train_loss=809.75836, val_loss=824.26697\n",
      "Epoch 9162: train_loss=809.55243, val_loss=824.14447\n",
      "Epoch 9163: train_loss=809.35034, val_loss=823.83990\n",
      "Epoch 9164: train_loss=809.15692, val_loss=823.77087\n",
      "Epoch 9165: train_loss=808.97040, val_loss=823.44489\n",
      "Epoch 9166: train_loss=808.79266, val_loss=823.42932\n",
      "Epoch 9167: train_loss=808.61554, val_loss=823.06512\n",
      "Epoch 9168: train_loss=808.43573, val_loss=823.05359\n",
      "Epoch 9169: train_loss=808.23413, val_loss=822.63104\n",
      "Epoch 9170: train_loss=808.01343, val_loss=822.56158\n",
      "Epoch 9171: train_loss=807.75934, val_loss=822.10846\n",
      "Epoch 9172: train_loss=807.48694, val_loss=821.96509\n",
      "Epoch 9173: train_loss=807.20160, val_loss=821.56519\n",
      "Epoch 9174: train_loss=806.91870, val_loss=821.37115\n",
      "Epoch 9175: train_loss=806.65540, val_loss=821.10126\n",
      "Epoch 9176: train_loss=806.41748, val_loss=820.87445\n",
      "Epoch 9177: train_loss=806.20441, val_loss=820.72778\n",
      "Epoch 9178: train_loss=806.00793, val_loss=820.45795\n",
      "Epoch 9179: train_loss=805.81647, val_loss=820.36591\n",
      "Epoch 9180: train_loss=805.62152, val_loss=820.04382\n",
      "Epoch 9181: train_loss=805.41455, val_loss=819.94366\n",
      "Epoch 9182: train_loss=805.19598, val_loss=819.59265\n",
      "Epoch 9183: train_loss=804.96393, val_loss=819.45947\n",
      "Epoch 9184: train_loss=804.72552, val_loss=819.12225\n",
      "Epoch 9185: train_loss=804.48401, val_loss=818.95270\n",
      "Epoch 9186: train_loss=804.24335, val_loss=818.66370\n",
      "Epoch 9187: train_loss=804.00818, val_loss=818.46198\n",
      "Epoch 9188: train_loss=803.77985, val_loss=818.23370\n",
      "Epoch 9189: train_loss=803.55865, val_loss=818.00220\n",
      "Epoch 9190: train_loss=803.34271, val_loss=817.81958\n",
      "Epoch 9191: train_loss=803.13019, val_loss=817.56146\n",
      "Epoch 9192: train_loss=802.92023, val_loss=817.41333\n",
      "Epoch 9193: train_loss=802.71204, val_loss=817.12970\n",
      "Epoch 9194: train_loss=802.50433, val_loss=817.00830\n",
      "Epoch 9195: train_loss=802.29987, val_loss=816.69867\n",
      "Epoch 9196: train_loss=802.09479, val_loss=816.59906\n",
      "Epoch 9197: train_loss=801.89166, val_loss=816.27002\n",
      "Epoch 9198: train_loss=801.68909, val_loss=816.19421\n",
      "Epoch 9199: train_loss=801.48785, val_loss=815.84473\n",
      "Epoch 9200: train_loss=801.28491, val_loss=815.77985\n",
      "Epoch 9201: train_loss=801.07843, val_loss=815.40698\n",
      "Epoch 9202: train_loss=800.86383, val_loss=815.32819\n",
      "Epoch 9203: train_loss=800.64020, val_loss=814.94226\n",
      "Epoch 9204: train_loss=800.40436, val_loss=814.82574\n",
      "Epoch 9205: train_loss=800.16125, val_loss=814.45868\n",
      "Epoch 9206: train_loss=799.91272, val_loss=814.29242\n",
      "Epoch 9207: train_loss=799.66693, val_loss=813.98981\n",
      "Epoch 9208: train_loss=799.42926, val_loss=813.78198\n",
      "Epoch 9209: train_loss=799.20367, val_loss=813.56335\n",
      "Epoch 9210: train_loss=798.98969, val_loss=813.31897\n",
      "Epoch 9211: train_loss=798.78375, val_loss=813.16504\n",
      "Epoch 9212: train_loss=798.58295, val_loss=812.88727\n",
      "Epoch 9213: train_loss=798.38330, val_loss=812.76715\n",
      "Epoch 9214: train_loss=798.18066, val_loss=812.46039\n",
      "Epoch 9215: train_loss=797.97412, val_loss=812.34375\n",
      "Epoch 9216: train_loss=797.76196, val_loss=812.02228\n",
      "Epoch 9217: train_loss=797.54480, val_loss=811.89050\n",
      "Epoch 9218: train_loss=797.32410, val_loss=811.57520\n",
      "Epoch 9219: train_loss=797.10162, val_loss=811.42535\n",
      "Epoch 9220: train_loss=796.87903, val_loss=811.13226\n",
      "Epoch 9221: train_loss=796.65704, val_loss=810.96277\n",
      "Epoch 9222: train_loss=796.43695, val_loss=810.70038\n",
      "Epoch 9223: train_loss=796.21954, val_loss=810.51453\n",
      "Epoch 9224: train_loss=796.00403, val_loss=810.27991\n",
      "Epoch 9225: train_loss=795.79077, val_loss=810.07867\n",
      "Epoch 9226: train_loss=795.57922, val_loss=809.86157\n",
      "Epoch 9227: train_loss=795.36877, val_loss=809.64813\n",
      "Epoch 9228: train_loss=795.15924, val_loss=809.43890\n",
      "Epoch 9229: train_loss=794.95007, val_loss=809.21686\n",
      "Epoch 9230: train_loss=794.74158, val_loss=809.01947\n",
      "Epoch 9231: train_loss=794.53400, val_loss=808.78839\n",
      "Epoch 9232: train_loss=794.32812, val_loss=808.61206\n",
      "Epoch 9233: train_loss=794.12384, val_loss=808.36609\n",
      "Epoch 9234: train_loss=793.92316, val_loss=808.22479\n",
      "Epoch 9235: train_loss=793.72729, val_loss=807.95703\n",
      "Epoch 9236: train_loss=793.53778, val_loss=807.87122\n",
      "Epoch 9237: train_loss=793.35742, val_loss=807.57812\n",
      "Epoch 9238: train_loss=793.18451, val_loss=807.55402\n",
      "Epoch 9239: train_loss=793.01917, val_loss=807.22479\n",
      "Epoch 9240: train_loss=792.85413, val_loss=807.23279\n",
      "Epoch 9241: train_loss=792.68231, val_loss=806.85315\n",
      "Epoch 9242: train_loss=792.49927, val_loss=806.84442\n",
      "Epoch 9243: train_loss=792.29376, val_loss=806.41913\n",
      "Epoch 9244: train_loss=792.06604, val_loss=806.34949\n",
      "Epoch 9245: train_loss=791.82056, val_loss=805.93097\n",
      "Epoch 9246: train_loss=791.56116, val_loss=805.79999\n",
      "Epoch 9247: train_loss=791.30847, val_loss=805.46368\n",
      "Epoch 9248: train_loss=791.06403, val_loss=805.28363\n",
      "Epoch 9249: train_loss=790.83734, val_loss=805.06305\n",
      "Epoch 9250: train_loss=790.62982, val_loss=804.84174\n",
      "Epoch 9251: train_loss=790.43781, val_loss=804.71216\n",
      "Epoch 9252: train_loss=790.25452, val_loss=804.44629\n",
      "Epoch 9253: train_loss=790.07202, val_loss=804.36249\n",
      "Epoch 9254: train_loss=789.88916, val_loss=804.06104\n",
      "Epoch 9255: train_loss=789.69879, val_loss=803.98352\n",
      "Epoch 9256: train_loss=789.50275, val_loss=803.66046\n",
      "Epoch 9257: train_loss=789.29755, val_loss=803.56293\n",
      "Epoch 9258: train_loss=789.08771, val_loss=803.24097\n",
      "Epoch 9259: train_loss=788.87195, val_loss=803.11261\n",
      "Epoch 9260: train_loss=788.65747, val_loss=802.81836\n",
      "Epoch 9261: train_loss=788.44238, val_loss=802.66150\n",
      "Epoch 9262: train_loss=788.23035, val_loss=802.41064\n",
      "Epoch 9263: train_loss=788.02124, val_loss=802.22736\n",
      "Epoch 9264: train_loss=787.81622, val_loss=802.01849\n",
      "Epoch 9265: train_loss=787.61456, val_loss=801.81006\n",
      "Epoch 9266: train_loss=787.41577, val_loss=801.63214\n",
      "Epoch 9267: train_loss=787.21838, val_loss=801.39960\n",
      "Epoch 9268: train_loss=787.02332, val_loss=801.25269\n",
      "Epoch 9269: train_loss=786.83087, val_loss=800.99799\n",
      "Epoch 9270: train_loss=786.64087, val_loss=800.88379\n",
      "Epoch 9271: train_loss=786.45349, val_loss=800.60687\n",
      "Epoch 9272: train_loss=786.26813, val_loss=800.52887\n",
      "Epoch 9273: train_loss=786.08582, val_loss=800.22681\n",
      "Epoch 9274: train_loss=785.90118, val_loss=800.16736\n",
      "Epoch 9275: train_loss=785.71503, val_loss=799.84033\n",
      "Epoch 9276: train_loss=785.52338, val_loss=799.77881\n",
      "Epoch 9277: train_loss=785.32605, val_loss=799.43158\n",
      "Epoch 9278: train_loss=785.12018, val_loss=799.35175\n",
      "Epoch 9279: train_loss=784.90894, val_loss=799.00598\n",
      "Epoch 9280: train_loss=784.69098, val_loss=798.89429\n",
      "Epoch 9281: train_loss=784.46979, val_loss=798.56543\n",
      "Epoch 9282: train_loss=784.24310, val_loss=798.41083\n",
      "Epoch 9283: train_loss=784.01648, val_loss=798.13300\n",
      "Epoch 9284: train_loss=783.79346, val_loss=797.94006\n",
      "Epoch 9285: train_loss=783.57635, val_loss=797.71576\n",
      "Epoch 9286: train_loss=783.36267, val_loss=797.48029\n",
      "Epoch 9287: train_loss=783.15222, val_loss=797.30591\n",
      "Epoch 9288: train_loss=782.94470, val_loss=797.04260\n",
      "Epoch 9289: train_loss=782.73944, val_loss=796.90533\n",
      "Epoch 9290: train_loss=782.53418, val_loss=796.61670\n",
      "Epoch 9291: train_loss=782.32867, val_loss=796.50433\n",
      "Epoch 9292: train_loss=782.12384, val_loss=796.19702\n",
      "Epoch 9293: train_loss=781.92078, val_loss=796.09741\n",
      "Epoch 9294: train_loss=781.71570, val_loss=795.77960\n",
      "Epoch 9295: train_loss=781.51196, val_loss=795.68127\n",
      "Epoch 9296: train_loss=781.30518, val_loss=795.36603\n",
      "Epoch 9297: train_loss=781.09937, val_loss=795.26123\n",
      "Epoch 9298: train_loss=780.89154, val_loss=794.96057\n",
      "Epoch 9299: train_loss=780.68420, val_loss=794.84113\n",
      "Epoch 9300: train_loss=780.47784, val_loss=794.56519\n",
      "Epoch 9301: train_loss=780.27319, val_loss=794.43341\n",
      "Epoch 9302: train_loss=780.07129, val_loss=794.18134\n",
      "Epoch 9303: train_loss=779.87225, val_loss=794.03461\n",
      "Epoch 9304: train_loss=779.67523, val_loss=793.80170\n",
      "Epoch 9305: train_loss=779.47760, val_loss=793.63684\n",
      "Epoch 9306: train_loss=779.28210, val_loss=793.42316\n",
      "Epoch 9307: train_loss=779.08820, val_loss=793.24878\n",
      "Epoch 9308: train_loss=778.89514, val_loss=793.04681\n",
      "Epoch 9309: train_loss=778.70312, val_loss=792.86792\n",
      "Epoch 9310: train_loss=778.51215, val_loss=792.67291\n",
      "Epoch 9311: train_loss=778.32184, val_loss=792.49072\n",
      "Epoch 9312: train_loss=778.13190, val_loss=792.30072\n",
      "Epoch 9313: train_loss=777.94196, val_loss=792.11548\n",
      "Epoch 9314: train_loss=777.75256, val_loss=791.92670\n",
      "Epoch 9315: train_loss=777.56372, val_loss=791.73993\n",
      "Epoch 9316: train_loss=777.37537, val_loss=791.55060\n",
      "Epoch 9317: train_loss=777.18726, val_loss=791.36194\n",
      "Epoch 9318: train_loss=776.99915, val_loss=791.17554\n",
      "Epoch 9319: train_loss=776.81140, val_loss=790.98840\n",
      "Epoch 9320: train_loss=776.62402, val_loss=790.80499\n",
      "Epoch 9321: train_loss=776.43646, val_loss=790.61554\n",
      "Epoch 9322: train_loss=776.24921, val_loss=790.43420\n",
      "Epoch 9323: train_loss=776.06201, val_loss=790.23883\n",
      "Epoch 9324: train_loss=775.87531, val_loss=790.06329\n",
      "Epoch 9325: train_loss=775.68915, val_loss=789.86047\n",
      "Epoch 9326: train_loss=775.50421, val_loss=789.70477\n",
      "Epoch 9327: train_loss=775.32153, val_loss=789.48596\n",
      "Epoch 9328: train_loss=775.14282, val_loss=789.37048\n",
      "Epoch 9329: train_loss=774.97034, val_loss=789.12689\n",
      "Epoch 9330: train_loss=774.80481, val_loss=789.07819\n",
      "Epoch 9331: train_loss=774.65149, val_loss=788.80688\n",
      "Epoch 9332: train_loss=774.50659, val_loss=788.83966\n",
      "Epoch 9333: train_loss=774.37793, val_loss=788.53351\n",
      "Epoch 9334: train_loss=774.25549, val_loss=788.63483\n",
      "Epoch 9335: train_loss=774.13843, val_loss=788.27167\n",
      "Epoch 9336: train_loss=774.01355, val_loss=788.38763\n",
      "Epoch 9337: train_loss=773.86768, val_loss=787.94562\n",
      "Epoch 9338: train_loss=773.68854, val_loss=787.98413\n",
      "Epoch 9339: train_loss=773.46417, val_loss=787.48413\n",
      "Epoch 9340: train_loss=773.19971, val_loss=787.40234\n",
      "Epoch 9341: train_loss=772.91779, val_loss=786.97711\n",
      "Epoch 9342: train_loss=772.64075, val_loss=786.82544\n",
      "Epoch 9343: train_loss=772.39746, val_loss=786.60266\n",
      "Epoch 9344: train_loss=772.19800, val_loss=786.41534\n",
      "Epoch 9345: train_loss=772.03839, val_loss=786.36481\n",
      "Epoch 9346: train_loss=771.90173, val_loss=786.11011\n",
      "Epoch 9347: train_loss=771.76599, val_loss=786.11835\n",
      "Epoch 9348: train_loss=771.62122, val_loss=785.79327\n",
      "Epoch 9349: train_loss=771.45081, val_loss=785.77429\n",
      "Epoch 9350: train_loss=771.26300, val_loss=785.42249\n",
      "Epoch 9351: train_loss=771.05316, val_loss=785.34131\n",
      "Epoch 9352: train_loss=770.83893, val_loss=785.03320\n",
      "Epoch 9353: train_loss=770.62469, val_loss=784.90179\n",
      "Epoch 9354: train_loss=770.42194, val_loss=784.68134\n",
      "Epoch 9355: train_loss=770.23138, val_loss=784.51111\n",
      "Epoch 9356: train_loss=770.05292, val_loss=784.37506\n",
      "Epoch 9357: train_loss=769.88422, val_loss=784.16510\n",
      "Epoch 9358: train_loss=769.72235, val_loss=784.08923\n",
      "Epoch 9359: train_loss=769.56549, val_loss=783.84009\n",
      "Epoch 9360: train_loss=769.40887, val_loss=783.79340\n",
      "Epoch 9361: train_loss=769.24738, val_loss=783.50934\n",
      "Epoch 9362: train_loss=769.07904, val_loss=783.45428\n",
      "Epoch 9363: train_loss=768.89929, val_loss=783.15668\n",
      "Epoch 9364: train_loss=768.71442, val_loss=783.07367\n",
      "Epoch 9365: train_loss=768.52258, val_loss=782.79370\n",
      "Epoch 9366: train_loss=768.32843, val_loss=782.67529\n",
      "Epoch 9367: train_loss=768.13483, val_loss=782.44409\n",
      "Epoch 9368: train_loss=767.94495, val_loss=782.29150\n",
      "Epoch 9369: train_loss=767.76050, val_loss=782.11829\n",
      "Epoch 9370: train_loss=767.58179, val_loss=781.93256\n",
      "Epoch 9371: train_loss=767.40686, val_loss=781.80237\n",
      "Epoch 9372: train_loss=767.23450, val_loss=781.58838\n",
      "Epoch 9373: train_loss=767.06287, val_loss=781.48468\n",
      "Epoch 9374: train_loss=766.89050, val_loss=781.25073\n",
      "Epoch 9375: train_loss=766.71576, val_loss=781.15527\n",
      "Epoch 9376: train_loss=766.53912, val_loss=780.91010\n",
      "Epoch 9377: train_loss=766.35938, val_loss=780.80737\n",
      "Epoch 9378: train_loss=766.17822, val_loss=780.56299\n",
      "Epoch 9379: train_loss=765.99500, val_loss=780.44720\n",
      "Epoch 9380: train_loss=765.81232, val_loss=780.21515\n",
      "Epoch 9381: train_loss=765.62897, val_loss=780.08398\n",
      "Epoch 9382: train_loss=765.44666, val_loss=779.86902\n",
      "Epoch 9383: train_loss=765.26501, val_loss=779.72394\n",
      "Epoch 9384: train_loss=765.08514, val_loss=779.52563\n",
      "Epoch 9385: train_loss=764.90631, val_loss=779.37347\n",
      "Epoch 9386: train_loss=764.72894, val_loss=779.18292\n",
      "Epoch 9387: train_loss=764.55127, val_loss=779.02917\n",
      "Epoch 9388: train_loss=764.37402, val_loss=778.83826\n",
      "Epoch 9389: train_loss=764.19513, val_loss=778.68152\n",
      "Epoch 9390: train_loss=764.01459, val_loss=778.48712\n",
      "Epoch 9391: train_loss=763.83435, val_loss=778.34131\n",
      "Epoch 9392: train_loss=763.65527, val_loss=778.14014\n",
      "Epoch 9393: train_loss=763.47626, val_loss=778.00879\n",
      "Epoch 9394: train_loss=763.29761, val_loss=777.79169\n",
      "Epoch 9395: train_loss=763.11975, val_loss=777.68408\n",
      "Epoch 9396: train_loss=762.94525, val_loss=777.44562\n",
      "Epoch 9397: train_loss=762.77484, val_loss=777.37195\n",
      "Epoch 9398: train_loss=762.60876, val_loss=777.10779\n",
      "Epoch 9399: train_loss=762.44592, val_loss=777.07605\n",
      "Epoch 9400: train_loss=762.28467, val_loss=776.78485\n",
      "Epoch 9401: train_loss=762.12537, val_loss=776.78369\n",
      "Epoch 9402: train_loss=761.96277, val_loss=776.46649\n",
      "Epoch 9403: train_loss=761.79938, val_loss=776.46527\n",
      "Epoch 9404: train_loss=761.62231, val_loss=776.11230\n",
      "Epoch 9405: train_loss=761.43463, val_loss=776.06653\n",
      "Epoch 9406: train_loss=761.22925, val_loss=775.70441\n",
      "Epoch 9407: train_loss=761.01538, val_loss=775.60907\n",
      "Epoch 9408: train_loss=760.79553, val_loss=775.28839\n",
      "Epoch 9409: train_loss=760.57782, val_loss=775.14935\n",
      "Epoch 9410: train_loss=760.36731, val_loss=774.89868\n",
      "Epoch 9411: train_loss=760.16724, val_loss=774.72437\n",
      "Epoch 9412: train_loss=759.97803, val_loss=774.55438\n",
      "Epoch 9413: train_loss=759.79968, val_loss=774.35504\n",
      "Epoch 9414: train_loss=759.62701, val_loss=774.23969\n",
      "Epoch 9415: train_loss=759.45776, val_loss=774.00928\n",
      "Epoch 9416: train_loss=759.28729, val_loss=773.92047\n",
      "Epoch 9417: train_loss=759.11530, val_loss=773.66022\n",
      "Epoch 9418: train_loss=758.94159, val_loss=773.58289\n",
      "Epoch 9419: train_loss=758.76605, val_loss=773.30304\n",
      "Epoch 9420: train_loss=758.58862, val_loss=773.23444\n",
      "Epoch 9421: train_loss=758.41309, val_loss=772.95233\n",
      "Epoch 9422: train_loss=758.23676, val_loss=772.89069\n",
      "Epoch 9423: train_loss=758.06012, val_loss=772.60345\n",
      "Epoch 9424: train_loss=757.88116, val_loss=772.54010\n",
      "Epoch 9425: train_loss=757.70319, val_loss=772.25323\n",
      "Epoch 9426: train_loss=757.52411, val_loss=772.17773\n",
      "Epoch 9427: train_loss=757.34326, val_loss=771.89410\n",
      "Epoch 9428: train_loss=757.16144, val_loss=771.80597\n",
      "Epoch 9429: train_loss=756.97925, val_loss=771.54102\n",
      "Epoch 9430: train_loss=756.79742, val_loss=771.43292\n",
      "Epoch 9431: train_loss=756.61652, val_loss=771.19281\n",
      "Epoch 9432: train_loss=756.43591, val_loss=771.06549\n",
      "Epoch 9433: train_loss=756.25897, val_loss=770.85492\n",
      "Epoch 9434: train_loss=756.08337, val_loss=770.70776\n",
      "Epoch 9435: train_loss=755.90973, val_loss=770.51654\n",
      "Epoch 9436: train_loss=755.73810, val_loss=770.35107\n",
      "Epoch 9437: train_loss=755.56714, val_loss=770.17474\n",
      "Epoch 9438: train_loss=755.39703, val_loss=769.99982\n",
      "Epoch 9439: train_loss=755.22681, val_loss=769.83948\n",
      "Epoch 9440: train_loss=755.05670, val_loss=769.65692\n",
      "Epoch 9441: train_loss=754.88672, val_loss=769.51050\n",
      "Epoch 9442: train_loss=754.71759, val_loss=769.31281\n",
      "Epoch 9443: train_loss=754.54944, val_loss=769.18372\n",
      "Epoch 9444: train_loss=754.38263, val_loss=768.96552\n",
      "Epoch 9445: train_loss=754.21753, val_loss=768.86108\n",
      "Epoch 9446: train_loss=754.05499, val_loss=768.62305\n",
      "Epoch 9447: train_loss=753.89465, val_loss=768.55652\n",
      "Epoch 9448: train_loss=753.73883, val_loss=768.29889\n",
      "Epoch 9449: train_loss=753.58612, val_loss=768.28064\n",
      "Epoch 9450: train_loss=753.44098, val_loss=767.99542\n",
      "Epoch 9451: train_loss=753.29718, val_loss=768.02417\n",
      "Epoch 9452: train_loss=753.15765, val_loss=767.70941\n",
      "Epoch 9453: train_loss=753.01953, val_loss=767.77051\n",
      "Epoch 9454: train_loss=752.87708, val_loss=767.41931\n",
      "Epoch 9455: train_loss=752.73047, val_loss=767.48450\n",
      "Epoch 9456: train_loss=752.57227, val_loss=767.09308\n",
      "Epoch 9457: train_loss=752.39905, val_loss=767.11920\n",
      "Epoch 9458: train_loss=752.20929, val_loss=766.71307\n",
      "Epoch 9459: train_loss=752.00330, val_loss=766.67670\n",
      "Epoch 9460: train_loss=751.78656, val_loss=766.30939\n",
      "Epoch 9461: train_loss=751.56976, val_loss=766.21582\n",
      "Epoch 9462: train_loss=751.35944, val_loss=765.93774\n",
      "Epoch 9463: train_loss=751.16040, val_loss=765.79626\n",
      "Epoch 9464: train_loss=750.97595, val_loss=765.62274\n",
      "Epoch 9465: train_loss=750.80670, val_loss=765.43042\n",
      "Epoch 9466: train_loss=750.64941, val_loss=765.33960\n",
      "Epoch 9467: train_loss=750.49884, val_loss=765.10077\n",
      "Epoch 9468: train_loss=750.35278, val_loss=765.06732\n",
      "Epoch 9469: train_loss=750.20636, val_loss=764.79529\n",
      "Epoch 9470: train_loss=750.06012, val_loss=764.78967\n",
      "Epoch 9471: train_loss=749.90808, val_loss=764.48907\n",
      "Epoch 9472: train_loss=749.75208, val_loss=764.48297\n",
      "Epoch 9473: train_loss=749.58478, val_loss=764.16217\n",
      "Epoch 9474: train_loss=749.40918, val_loss=764.12909\n",
      "Epoch 9475: train_loss=749.22443, val_loss=763.81445\n",
      "Epoch 9476: train_loss=749.03662, val_loss=763.74719\n",
      "Epoch 9477: train_loss=748.84619, val_loss=763.46460\n",
      "Epoch 9478: train_loss=748.65686, val_loss=763.36182\n",
      "Epoch 9479: train_loss=748.46875, val_loss=763.12878\n",
      "Epoch 9480: train_loss=748.28546, val_loss=762.99731\n",
      "Epoch 9481: train_loss=748.10596, val_loss=762.81146\n",
      "Epoch 9482: train_loss=747.93085, val_loss=762.65289\n",
      "Epoch 9483: train_loss=747.75885, val_loss=762.49805\n",
      "Epoch 9484: train_loss=747.58899, val_loss=762.31708\n",
      "Epoch 9485: train_loss=747.42029, val_loss=762.19104\n",
      "Epoch 9486: train_loss=747.25299, val_loss=761.99139\n",
      "Epoch 9487: train_loss=747.08728, val_loss=761.89630\n",
      "Epoch 9488: train_loss=746.92383, val_loss=761.68048\n",
      "Epoch 9489: train_loss=746.76434, val_loss=761.61975\n",
      "Epoch 9490: train_loss=746.60736, val_loss=761.38049\n",
      "Epoch 9491: train_loss=746.45520, val_loss=761.35822\n",
      "Epoch 9492: train_loss=746.30505, val_loss=761.09222\n",
      "Epoch 9493: train_loss=746.15698, val_loss=761.09943\n",
      "Epoch 9494: train_loss=746.00934, val_loss=760.79810\n",
      "Epoch 9495: train_loss=745.85992, val_loss=760.81573\n",
      "Epoch 9496: train_loss=745.70355, val_loss=760.48560\n",
      "Epoch 9497: train_loss=745.53943, val_loss=760.48926\n",
      "Epoch 9498: train_loss=745.36383, val_loss=760.14594\n",
      "Epoch 9499: train_loss=745.17981, val_loss=760.11371\n",
      "Epoch 9500: train_loss=744.98651, val_loss=759.77679\n",
      "Epoch 9501: train_loss=744.78595, val_loss=759.69299\n",
      "Epoch 9502: train_loss=744.58246, val_loss=759.39648\n",
      "Epoch 9503: train_loss=744.38013, val_loss=759.26794\n",
      "Epoch 9504: train_loss=744.18561, val_loss=759.04407\n",
      "Epoch 9505: train_loss=743.99982, val_loss=758.87982\n",
      "Epoch 9506: train_loss=743.82245, val_loss=758.72656\n",
      "Epoch 9507: train_loss=743.65247, val_loss=758.52777\n",
      "Epoch 9508: train_loss=743.48737, val_loss=758.42651\n",
      "Epoch 9509: train_loss=743.32654, val_loss=758.19843\n",
      "Epoch 9510: train_loss=743.16803, val_loss=758.14148\n",
      "Epoch 9511: train_loss=743.01166, val_loss=757.88672\n",
      "Epoch 9512: train_loss=742.85596, val_loss=757.85901\n",
      "Epoch 9513: train_loss=742.70178, val_loss=757.57477\n",
      "Epoch 9514: train_loss=742.54565, val_loss=757.56519\n",
      "Epoch 9515: train_loss=742.38837, val_loss=757.25616\n",
      "Epoch 9516: train_loss=742.22394, val_loss=757.24664\n",
      "Epoch 9517: train_loss=742.05133, val_loss=756.91370\n",
      "Epoch 9518: train_loss=741.86505, val_loss=756.87256\n",
      "Epoch 9519: train_loss=741.66864, val_loss=756.53528\n",
      "Epoch 9520: train_loss=741.46118, val_loss=756.44659\n",
      "Epoch 9521: train_loss=741.25006, val_loss=756.14935\n",
      "Epoch 9522: train_loss=741.04016, val_loss=756.01837\n",
      "Epoch 9523: train_loss=740.83636, val_loss=755.80072\n",
      "Epoch 9524: train_loss=740.64368, val_loss=755.63312\n",
      "Epoch 9525: train_loss=740.46069, val_loss=755.49176\n",
      "Epoch 9526: train_loss=740.28601, val_loss=755.28931\n",
      "Epoch 9527: train_loss=740.11652, val_loss=755.19733\n",
      "Epoch 9528: train_loss=739.94861, val_loss=754.96405\n",
      "Epoch 9529: train_loss=739.77979, val_loss=754.90057\n",
      "Epoch 9530: train_loss=739.60754, val_loss=754.63812\n",
      "Epoch 9531: train_loss=739.43079, val_loss=754.57898\n",
      "Epoch 9532: train_loss=739.25208, val_loss=754.29883\n",
      "Epoch 9533: train_loss=739.06781, val_loss=754.23535\n",
      "Epoch 9534: train_loss=738.88110, val_loss=753.94928\n",
      "Epoch 9535: train_loss=738.68878, val_loss=753.87231\n",
      "Epoch 9536: train_loss=738.49573, val_loss=753.59363\n",
      "Epoch 9537: train_loss=738.29828, val_loss=753.49701\n",
      "Epoch 9538: train_loss=738.10181, val_loss=753.23584\n",
      "Epoch 9539: train_loss=737.90308, val_loss=753.11646\n",
      "Epoch 9540: train_loss=737.70514, val_loss=752.88422\n",
      "Epoch 9541: train_loss=737.50781, val_loss=752.73993\n",
      "Epoch 9542: train_loss=737.31403, val_loss=752.54559\n",
      "Epoch 9543: train_loss=737.12463, val_loss=752.37970\n",
      "Epoch 9544: train_loss=736.93927, val_loss=752.22229\n",
      "Epoch 9545: train_loss=736.75714, val_loss=752.03815\n",
      "Epoch 9546: train_loss=736.57727, val_loss=751.91162\n",
      "Epoch 9547: train_loss=736.40045, val_loss=751.70978\n",
      "Epoch 9548: train_loss=736.22809, val_loss=751.61932\n",
      "Epoch 9549: train_loss=736.06171, val_loss=751.39233\n",
      "Epoch 9550: train_loss=735.90009, val_loss=751.33820\n",
      "Epoch 9551: train_loss=735.74371, val_loss=751.09088\n",
      "Epoch 9552: train_loss=735.59271, val_loss=751.07239\n",
      "Epoch 9553: train_loss=735.44220, val_loss=750.79559\n",
      "Epoch 9554: train_loss=735.28973, val_loss=750.78784\n",
      "Epoch 9555: train_loss=735.12579, val_loss=750.47308\n",
      "Epoch 9556: train_loss=734.94684, val_loss=750.43103\n",
      "Epoch 9557: train_loss=734.74579, val_loss=750.09711\n",
      "Epoch 9558: train_loss=734.53143, val_loss=750.00720\n",
      "Epoch 9559: train_loss=734.31158, val_loss=749.71637\n",
      "Epoch 9560: train_loss=734.09515, val_loss=749.59442\n",
      "Epoch 9561: train_loss=733.88818, val_loss=749.37775\n",
      "Epoch 9562: train_loss=733.69275, val_loss=749.22729\n",
      "Epoch 9563: train_loss=733.50873, val_loss=749.08478\n",
      "Epoch 9564: train_loss=733.33838, val_loss=748.90869\n",
      "Epoch 9565: train_loss=733.17853, val_loss=748.81464\n",
      "Epoch 9566: train_loss=733.02496, val_loss=748.60651\n",
      "Epoch 9567: train_loss=732.87665, val_loss=748.54523\n",
      "Epoch 9568: train_loss=732.73047, val_loss=748.31287\n",
      "Epoch 9569: train_loss=732.58240, val_loss=748.26825\n",
      "Epoch 9570: train_loss=732.43274, val_loss=748.01221\n",
      "Epoch 9571: train_loss=732.27948, val_loss=747.96008\n",
      "Epoch 9572: train_loss=732.11957, val_loss=747.69446\n",
      "Epoch 9573: train_loss=731.95300, val_loss=747.62543\n",
      "Epoch 9574: train_loss=731.78333, val_loss=747.36285\n",
      "Epoch 9575: train_loss=731.61096, val_loss=747.27734\n",
      "Epoch 9576: train_loss=731.43915, val_loss=747.03046\n",
      "Epoch 9577: train_loss=731.26678, val_loss=746.92828\n",
      "Epoch 9578: train_loss=731.09668, val_loss=746.70618\n",
      "Epoch 9579: train_loss=730.92828, val_loss=746.58740\n",
      "Epoch 9580: train_loss=730.76306, val_loss=746.38959\n",
      "Epoch 9581: train_loss=730.60016, val_loss=746.25903\n",
      "Epoch 9582: train_loss=730.43945, val_loss=746.08063\n",
      "Epoch 9583: train_loss=730.28033, val_loss=745.94562\n",
      "Epoch 9584: train_loss=730.12219, val_loss=745.77679\n",
      "Epoch 9585: train_loss=729.96503, val_loss=745.63751\n",
      "Epoch 9586: train_loss=729.80841, val_loss=745.46838\n",
      "Epoch 9587: train_loss=729.65283, val_loss=745.33728\n",
      "Epoch 9588: train_loss=729.49829, val_loss=745.16364\n",
      "Epoch 9589: train_loss=729.34625, val_loss=745.05603\n",
      "Epoch 9590: train_loss=729.19769, val_loss=744.87122\n",
      "Epoch 9591: train_loss=729.05542, val_loss=744.80115\n",
      "Epoch 9592: train_loss=728.91754, val_loss=744.60016\n",
      "Epoch 9593: train_loss=728.78668, val_loss=744.57178\n",
      "Epoch 9594: train_loss=728.65845, val_loss=744.34821\n",
      "Epoch 9595: train_loss=728.53546, val_loss=744.34869\n",
      "Epoch 9596: train_loss=728.40613, val_loss=744.09491\n",
      "Epoch 9597: train_loss=728.27350, val_loss=744.08862\n",
      "Epoch 9598: train_loss=728.12286, val_loss=743.80115\n",
      "Epoch 9599: train_loss=727.96332, val_loss=743.75568\n",
      "Epoch 9600: train_loss=727.78345, val_loss=743.45209\n",
      "Epoch 9601: train_loss=727.59521, val_loss=743.35803\n",
      "Epoch 9602: train_loss=727.40063, val_loss=743.09583\n",
      "Epoch 9603: train_loss=727.21320, val_loss=742.97430\n",
      "Epoch 9604: train_loss=727.03479, val_loss=742.77966\n",
      "Epoch 9605: train_loss=726.86810, val_loss=742.63092\n",
      "Epoch 9606: train_loss=726.71167, val_loss=742.49762\n",
      "Epoch 9607: train_loss=726.56445, val_loss=742.32086\n",
      "Epoch 9608: train_loss=726.42163, val_loss=742.22711\n",
      "Epoch 9609: train_loss=726.28149, val_loss=742.02747\n",
      "Epoch 9610: train_loss=726.14294, val_loss=741.95490\n",
      "Epoch 9611: train_loss=726.00165, val_loss=741.73743\n",
      "Epoch 9612: train_loss=725.86200, val_loss=741.67670\n",
      "Epoch 9613: train_loss=725.71814, val_loss=741.44781\n",
      "Epoch 9614: train_loss=725.57605, val_loss=741.38940\n",
      "Epoch 9615: train_loss=725.42798, val_loss=741.15265\n",
      "Epoch 9616: train_loss=725.27966, val_loss=741.08722\n",
      "Epoch 9617: train_loss=725.12634, val_loss=740.84845\n",
      "Epoch 9618: train_loss=724.97369, val_loss=740.77124\n",
      "Epoch 9619: train_loss=724.81549, val_loss=740.53802\n",
      "Epoch 9620: train_loss=724.65863, val_loss=740.44855\n",
      "Epoch 9621: train_loss=724.49988, val_loss=740.22839\n",
      "Epoch 9622: train_loss=724.34027, val_loss=740.12280\n",
      "Epoch 9623: train_loss=724.18225, val_loss=739.92926\n",
      "Epoch 9624: train_loss=724.02594, val_loss=739.80756\n",
      "Epoch 9625: train_loss=723.87207, val_loss=739.64093\n",
      "Epoch 9626: train_loss=723.72162, val_loss=739.50476\n",
      "Epoch 9627: train_loss=723.57379, val_loss=739.36548\n",
      "Epoch 9628: train_loss=723.42828, val_loss=739.21655\n",
      "Epoch 9629: train_loss=723.28455, val_loss=739.09900\n",
      "Epoch 9630: train_loss=723.14282, val_loss=738.93561\n",
      "Epoch 9631: train_loss=723.00305, val_loss=738.83905\n",
      "Epoch 9632: train_loss=722.86615, val_loss=738.66071\n",
      "Epoch 9633: train_loss=722.73248, val_loss=738.58881\n",
      "Epoch 9634: train_loss=722.60040, val_loss=738.39685\n",
      "Epoch 9635: train_loss=722.47235, val_loss=738.34894\n",
      "Epoch 9636: train_loss=722.34418, val_loss=738.13904\n",
      "Epoch 9637: train_loss=722.21906, val_loss=738.10632\n",
      "Epoch 9638: train_loss=722.08905, val_loss=737.87555\n",
      "Epoch 9639: train_loss=721.95752, val_loss=737.84076\n",
      "Epoch 9640: train_loss=721.81519, val_loss=737.59283\n",
      "Epoch 9641: train_loss=721.66901, val_loss=737.53802\n",
      "Epoch 9642: train_loss=721.51172, val_loss=737.28613\n",
      "Epoch 9643: train_loss=721.35083, val_loss=737.20660\n",
      "Epoch 9644: train_loss=721.18707, val_loss=736.97626\n",
      "Epoch 9645: train_loss=721.02374, val_loss=736.87433\n",
      "Epoch 9646: train_loss=720.86316, val_loss=736.68494\n",
      "Epoch 9647: train_loss=720.70862, val_loss=736.56488\n",
      "Epoch 9648: train_loss=720.55914, val_loss=736.41412\n",
      "Epoch 9649: train_loss=720.41504, val_loss=736.27295\n",
      "Epoch 9650: train_loss=720.27472, val_loss=736.15503\n",
      "Epoch 9651: train_loss=720.13751, val_loss=735.99866\n",
      "Epoch 9652: train_loss=720.00262, val_loss=735.90784\n",
      "Epoch 9653: train_loss=719.86853, val_loss=735.73700\n",
      "Epoch 9654: train_loss=719.73755, val_loss=735.66846\n",
      "Epoch 9655: train_loss=719.60718, val_loss=735.48248\n",
      "Epoch 9656: train_loss=719.47864, val_loss=735.43445\n",
      "Epoch 9657: train_loss=719.35089, val_loss=735.23511\n",
      "Epoch 9658: train_loss=719.22601, val_loss=735.20880\n",
      "Epoch 9659: train_loss=719.09998, val_loss=734.99213\n",
      "Epoch 9660: train_loss=718.97400, val_loss=734.97131\n",
      "Epoch 9661: train_loss=718.84119, val_loss=734.73303\n",
      "Epoch 9662: train_loss=718.70483, val_loss=734.70001\n",
      "Epoch 9663: train_loss=718.55652, val_loss=734.45178\n",
      "Epoch 9664: train_loss=718.40540, val_loss=734.39740\n",
      "Epoch 9665: train_loss=718.24469, val_loss=734.15436\n",
      "Epoch 9666: train_loss=718.08069, val_loss=734.07092\n",
      "Epoch 9667: train_loss=717.91437, val_loss=733.85645\n",
      "Epoch 9668: train_loss=717.75183, val_loss=733.74841\n",
      "Epoch 9669: train_loss=717.59259, val_loss=733.57709\n",
      "Epoch 9670: train_loss=717.44000, val_loss=733.44531\n",
      "Epoch 9671: train_loss=717.29382, val_loss=733.31732\n",
      "Epoch 9672: train_loss=717.15314, val_loss=733.16180\n",
      "Epoch 9673: train_loss=717.01587, val_loss=733.06580\n",
      "Epoch 9674: train_loss=716.88141, val_loss=732.89081\n",
      "Epoch 9675: train_loss=716.74799, val_loss=732.81757\n",
      "Epoch 9676: train_loss=716.61505, val_loss=732.62762\n",
      "Epoch 9677: train_loss=716.48517, val_loss=732.57294\n",
      "Epoch 9678: train_loss=716.35498, val_loss=732.36517\n",
      "Epoch 9679: train_loss=716.22681, val_loss=732.32214\n",
      "Epoch 9680: train_loss=716.09351, val_loss=732.09656\n",
      "Epoch 9681: train_loss=715.95911, val_loss=732.05017\n",
      "Epoch 9682: train_loss=715.81757, val_loss=731.81488\n",
      "Epoch 9683: train_loss=715.67590, val_loss=731.75732\n",
      "Epoch 9684: train_loss=715.52655, val_loss=731.52344\n",
      "Epoch 9685: train_loss=715.37750, val_loss=731.45221\n",
      "Epoch 9686: train_loss=715.22290, val_loss=731.23199\n",
      "Epoch 9687: train_loss=715.07043, val_loss=731.14465\n",
      "Epoch 9688: train_loss=714.91699, val_loss=730.94739\n",
      "Epoch 9689: train_loss=714.76642, val_loss=730.83978\n",
      "Epoch 9690: train_loss=714.61798, val_loss=730.67383\n",
      "Epoch 9691: train_loss=714.47351, val_loss=730.54816\n",
      "Epoch 9692: train_loss=714.33289, val_loss=730.41284\n",
      "Epoch 9693: train_loss=714.19495, val_loss=730.27075\n",
      "Epoch 9694: train_loss=714.05994, val_loss=730.16077\n",
      "Epoch 9695: train_loss=713.92749, val_loss=730.00299\n",
      "Epoch 9696: train_loss=713.79712, val_loss=729.91699\n",
      "Epoch 9697: train_loss=713.66846, val_loss=729.74512\n",
      "Epoch 9698: train_loss=713.54108, val_loss=729.67877\n",
      "Epoch 9699: train_loss=713.41296, val_loss=729.49060\n",
      "Epoch 9700: train_loss=713.28412, val_loss=729.42816\n",
      "Epoch 9701: train_loss=713.15173, val_loss=729.22540\n",
      "Epoch 9702: train_loss=713.01855, val_loss=729.16272\n",
      "Epoch 9703: train_loss=712.88208, val_loss=728.95764\n",
      "Epoch 9704: train_loss=712.74713, val_loss=728.89490\n",
      "Epoch 9705: train_loss=712.60858, val_loss=728.69043\n",
      "Epoch 9706: train_loss=712.47253, val_loss=728.62823\n",
      "Epoch 9707: train_loss=712.33374, val_loss=728.42450\n",
      "Epoch 9708: train_loss=712.19666, val_loss=728.36157\n",
      "Epoch 9709: train_loss=712.05737, val_loss=728.16187\n",
      "Epoch 9710: train_loss=711.92047, val_loss=728.09662\n",
      "Epoch 9711: train_loss=711.78015, val_loss=727.90100\n",
      "Epoch 9712: train_loss=711.64215, val_loss=727.83197\n",
      "Epoch 9713: train_loss=711.50269, val_loss=727.64014\n",
      "Epoch 9714: train_loss=711.36401, val_loss=727.56409\n",
      "Epoch 9715: train_loss=711.22333, val_loss=727.37842\n",
      "Epoch 9716: train_loss=711.08264, val_loss=727.29333\n",
      "Epoch 9717: train_loss=710.94250, val_loss=727.11621\n",
      "Epoch 9718: train_loss=710.80365, val_loss=727.02289\n",
      "Epoch 9719: train_loss=710.66583, val_loss=726.85632\n",
      "Epoch 9720: train_loss=710.52979, val_loss=726.76257\n",
      "Epoch 9721: train_loss=710.39514, val_loss=726.60297\n",
      "Epoch 9722: train_loss=710.26233, val_loss=726.51440\n",
      "Epoch 9723: train_loss=710.13098, val_loss=726.35602\n",
      "Epoch 9724: train_loss=710.00165, val_loss=726.27954\n",
      "Epoch 9725: train_loss=709.87439, val_loss=726.11810\n",
      "Epoch 9726: train_loss=709.75043, val_loss=726.06085\n",
      "Epoch 9727: train_loss=709.62787, val_loss=725.89191\n",
      "Epoch 9728: train_loss=709.50922, val_loss=725.85364\n",
      "Epoch 9729: train_loss=709.39062, val_loss=725.67279\n",
      "Epoch 9730: train_loss=709.27747, val_loss=725.65625\n",
      "Epoch 9731: train_loss=709.16254, val_loss=725.46277\n",
      "Epoch 9732: train_loss=709.05127, val_loss=725.46130\n",
      "Epoch 9733: train_loss=708.93274, val_loss=725.25146\n",
      "Epoch 9734: train_loss=708.81549, val_loss=725.24658\n",
      "Epoch 9735: train_loss=708.68555, val_loss=725.01263\n",
      "Epoch 9736: train_loss=708.54999, val_loss=724.97931\n",
      "Epoch 9737: train_loss=708.39911, val_loss=724.73676\n",
      "Epoch 9738: train_loss=708.24292, val_loss=724.66901\n",
      "Epoch 9739: train_loss=708.07971, val_loss=724.44849\n",
      "Epoch 9740: train_loss=707.91907, val_loss=724.35358\n",
      "Epoch 9741: train_loss=707.76434, val_loss=724.18109\n",
      "Epoch 9742: train_loss=707.61792, val_loss=724.06555\n",
      "Epoch 9743: train_loss=707.47894, val_loss=723.94086\n",
      "Epoch 9744: train_loss=707.34692, val_loss=723.80627\n",
      "Epoch 9745: train_loss=707.22034, val_loss=723.71844\n",
      "Epoch 9746: train_loss=707.09790, val_loss=723.56250\n",
      "Epoch 9747: train_loss=706.97821, val_loss=723.49963\n",
      "Epoch 9748: train_loss=706.85938, val_loss=723.32452\n",
      "Epoch 9749: train_loss=706.74078, val_loss=723.27966\n",
      "Epoch 9750: train_loss=706.62189, val_loss=723.08783\n",
      "Epoch 9751: train_loss=706.50079, val_loss=723.05115\n",
      "Epoch 9752: train_loss=706.37787, val_loss=722.84332\n",
      "Epoch 9753: train_loss=706.25055, val_loss=722.80188\n",
      "Epoch 9754: train_loss=706.11993, val_loss=722.58716\n",
      "Epoch 9755: train_loss=705.98480, val_loss=722.53430\n",
      "Epoch 9756: train_loss=705.84723, val_loss=722.32281\n",
      "Epoch 9757: train_loss=705.70642, val_loss=722.25397\n",
      "Epoch 9758: train_loss=705.56506, val_loss=722.05554\n",
      "Epoch 9759: train_loss=705.42456, val_loss=721.96936\n",
      "Epoch 9760: train_loss=705.28503, val_loss=721.78979\n",
      "Epoch 9761: train_loss=705.14734, val_loss=721.68988\n",
      "Epoch 9762: train_loss=705.01135, val_loss=721.53253\n",
      "Epoch 9763: train_loss=704.87744, val_loss=721.41638\n",
      "Epoch 9764: train_loss=704.74603, val_loss=721.27307\n",
      "Epoch 9765: train_loss=704.61627, val_loss=721.14288\n",
      "Epoch 9766: train_loss=704.48737, val_loss=721.01099\n",
      "Epoch 9767: train_loss=704.35919, val_loss=720.87317\n",
      "Epoch 9768: train_loss=704.23163, val_loss=720.75372\n",
      "Epoch 9769: train_loss=704.10449, val_loss=720.61005\n",
      "Epoch 9770: train_loss=703.97864, val_loss=720.50739\n",
      "Epoch 9771: train_loss=703.85437, val_loss=720.35327\n",
      "Epoch 9772: train_loss=703.73224, val_loss=720.27240\n",
      "Epoch 9773: train_loss=703.61279, val_loss=720.10504\n",
      "Epoch 9774: train_loss=703.49725, val_loss=720.05359\n",
      "Epoch 9775: train_loss=703.38580, val_loss=719.87231\n",
      "Epoch 9776: train_loss=703.27814, val_loss=719.85352\n",
      "Epoch 9777: train_loss=703.17493, val_loss=719.65503\n",
      "Epoch 9778: train_loss=703.07434, val_loss=719.66479\n",
      "Epoch 9779: train_loss=702.97522, val_loss=719.44397\n",
      "Epoch 9780: train_loss=702.87250, val_loss=719.45959\n",
      "Epoch 9781: train_loss=702.76196, val_loss=719.20605\n",
      "Epoch 9782: train_loss=702.63818, val_loss=719.19476\n",
      "Epoch 9783: train_loss=702.50067, val_loss=718.92017\n",
      "Epoch 9784: train_loss=702.34900, val_loss=718.86792\n",
      "Epoch 9785: train_loss=702.18933, val_loss=718.60779\n",
      "Epoch 9786: train_loss=702.02472, val_loss=718.52112\n",
      "Epoch 9787: train_loss=701.86414, val_loss=718.31305\n",
      "Epoch 9788: train_loss=701.71143, val_loss=718.20319\n",
      "Epoch 9789: train_loss=701.57074, val_loss=718.05725\n",
      "Epoch 9790: train_loss=701.44019, val_loss=717.92767\n",
      "Epoch 9791: train_loss=701.31726, val_loss=717.82965\n",
      "Epoch 9792: train_loss=701.20013, val_loss=717.68060\n",
      "Epoch 9793: train_loss=701.08765, val_loss=717.62128\n",
      "Epoch 9794: train_loss=700.97882, val_loss=717.45276\n",
      "Epoch 9795: train_loss=700.87122, val_loss=717.41742\n",
      "Epoch 9796: train_loss=700.76337, val_loss=717.22681\n",
      "Epoch 9797: train_loss=700.65387, val_loss=717.20172\n",
      "Epoch 9798: train_loss=700.54114, val_loss=716.99182\n",
      "Epoch 9799: train_loss=700.42365, val_loss=716.96527\n",
      "Epoch 9800: train_loss=700.30255, val_loss=716.74414\n",
      "Epoch 9801: train_loss=700.17700, val_loss=716.70526\n",
      "Epoch 9802: train_loss=700.04578, val_loss=716.48041\n",
      "Epoch 9803: train_loss=699.91150, val_loss=716.42303\n",
      "Epoch 9804: train_loss=699.77509, val_loss=716.20776\n",
      "Epoch 9805: train_loss=699.63623, val_loss=716.13269\n",
      "Epoch 9806: train_loss=699.49786, val_loss=715.94055\n",
      "Epoch 9807: train_loss=699.36047, val_loss=715.84833\n",
      "Epoch 9808: train_loss=699.22638, val_loss=715.68799\n",
      "Epoch 9809: train_loss=699.09515, val_loss=715.57715\n",
      "Epoch 9810: train_loss=698.96808, val_loss=715.44604\n",
      "Epoch 9811: train_loss=698.84473, val_loss=715.32220\n",
      "Epoch 9812: train_loss=698.72406, val_loss=715.21649\n",
      "Epoch 9813: train_loss=698.60577, val_loss=715.08063\n",
      "Epoch 9814: train_loss=698.48969, val_loss=714.99860\n",
      "Epoch 9815: train_loss=698.37573, val_loss=714.85187\n",
      "Epoch 9816: train_loss=698.26434, val_loss=714.79938\n",
      "Epoch 9817: train_loss=698.15643, val_loss=714.63983\n",
      "Epoch 9818: train_loss=698.05115, val_loss=714.61566\n",
      "Epoch 9819: train_loss=697.94946, val_loss=714.44250\n",
      "Epoch 9820: train_loss=697.85065, val_loss=714.44147\n",
      "Epoch 9821: train_loss=697.75189, val_loss=714.24939\n",
      "Epoch 9822: train_loss=697.65314, val_loss=714.26355\n",
      "Epoch 9823: train_loss=697.55304, val_loss=714.05066\n",
      "Epoch 9824: train_loss=697.44598, val_loss=714.05963\n",
      "Epoch 9825: train_loss=697.33093, val_loss=713.83002\n",
      "Epoch 9826: train_loss=697.20441, val_loss=713.81378\n",
      "Epoch 9827: train_loss=697.06940, val_loss=713.58386\n",
      "Epoch 9828: train_loss=696.92615, val_loss=713.53210\n",
      "Epoch 9829: train_loss=696.78046, val_loss=713.33508\n",
      "Epoch 9830: train_loss=696.63684, val_loss=713.25598\n",
      "Epoch 9831: train_loss=696.50153, val_loss=713.11877\n",
      "Epoch 9832: train_loss=696.37549, val_loss=713.02032\n",
      "Epoch 9833: train_loss=696.25879, val_loss=712.93951\n",
      "Epoch 9834: train_loss=696.14929, val_loss=712.81628\n",
      "Epoch 9835: train_loss=696.04413, val_loss=712.76776\n",
      "Epoch 9836: train_loss=695.94049, val_loss=712.62329\n",
      "Epoch 9837: train_loss=695.83655, val_loss=712.59119\n",
      "Epoch 9838: train_loss=695.73157, val_loss=712.43018\n",
      "Epoch 9839: train_loss=695.62341, val_loss=712.40131\n",
      "Epoch 9840: train_loss=695.51355, val_loss=712.23145\n",
      "Epoch 9841: train_loss=695.40149, val_loss=712.20032\n",
      "Epoch 9842: train_loss=695.28790, val_loss=712.02698\n",
      "Epoch 9843: train_loss=695.17310, val_loss=711.99030\n",
      "Epoch 9844: train_loss=695.05695, val_loss=711.81842\n",
      "Epoch 9845: train_loss=694.93945, val_loss=711.77386\n",
      "Epoch 9846: train_loss=694.82263, val_loss=711.60492\n",
      "Epoch 9847: train_loss=694.70544, val_loss=711.55109\n",
      "Epoch 9848: train_loss=694.58746, val_loss=711.38837\n",
      "Epoch 9849: train_loss=694.46857, val_loss=711.32391\n",
      "Epoch 9850: train_loss=694.35016, val_loss=711.17395\n",
      "Epoch 9851: train_loss=694.23157, val_loss=711.09802\n",
      "Epoch 9852: train_loss=694.11377, val_loss=710.96143\n",
      "Epoch 9853: train_loss=693.99707, val_loss=710.87421\n",
      "Epoch 9854: train_loss=693.88116, val_loss=710.75238\n",
      "Epoch 9855: train_loss=693.76654, val_loss=710.65765\n",
      "Epoch 9856: train_loss=693.65338, val_loss=710.54779\n",
      "Epoch 9857: train_loss=693.54083, val_loss=710.44751\n",
      "Epoch 9858: train_loss=693.42877, val_loss=710.34540\n",
      "Epoch 9859: train_loss=693.31683, val_loss=710.23853\n",
      "Epoch 9860: train_loss=693.20526, val_loss=710.14227\n",
      "Epoch 9861: train_loss=693.09418, val_loss=710.02789\n",
      "Epoch 9862: train_loss=692.98328, val_loss=709.93854\n",
      "Epoch 9863: train_loss=692.87378, val_loss=709.81586\n",
      "Epoch 9864: train_loss=692.76556, val_loss=709.74084\n",
      "Epoch 9865: train_loss=692.65900, val_loss=709.60907\n",
      "Epoch 9866: train_loss=692.55573, val_loss=709.55908\n",
      "Epoch 9867: train_loss=692.45709, val_loss=709.41669\n",
      "Epoch 9868: train_loss=692.36310, val_loss=709.40015\n",
      "Epoch 9869: train_loss=692.27686, val_loss=709.24799\n",
      "Epoch 9870: train_loss=692.19696, val_loss=709.26825\n",
      "Epoch 9871: train_loss=692.12225, val_loss=709.09717\n",
      "Epoch 9872: train_loss=692.05066, val_loss=709.14447\n",
      "Epoch 9873: train_loss=691.97772, val_loss=708.94745\n",
      "Epoch 9874: train_loss=691.90009, val_loss=708.99780\n",
      "Epoch 9875: train_loss=691.81390, val_loss=708.76422\n",
      "Epoch 9876: train_loss=691.70929, val_loss=708.77631\n",
      "Epoch 9877: train_loss=691.58252, val_loss=708.50928\n",
      "Epoch 9878: train_loss=691.43469, val_loss=708.45758\n",
      "Epoch 9879: train_loss=691.26440, val_loss=708.19861\n",
      "Epoch 9880: train_loss=691.09344, val_loss=708.10889\n",
      "Epoch 9881: train_loss=690.92621, val_loss=707.92188\n",
      "Epoch 9882: train_loss=690.77661, val_loss=707.82068\n",
      "Epoch 9883: train_loss=690.64911, val_loss=707.73041\n",
      "Epoch 9884: train_loss=690.54205, val_loss=707.61835\n",
      "Epoch 9885: train_loss=690.44855, val_loss=707.58636\n",
      "Epoch 9886: train_loss=690.36121, val_loss=707.44312\n",
      "Epoch 9887: train_loss=690.27155, val_loss=707.41693\n",
      "Epoch 9888: train_loss=690.17108, val_loss=707.23938\n",
      "Epoch 9889: train_loss=690.06049, val_loss=707.19647\n",
      "Epoch 9890: train_loss=689.94006, val_loss=707.01129\n",
      "Epoch 9891: train_loss=689.81219, val_loss=706.94128\n",
      "Epoch 9892: train_loss=689.68042, val_loss=706.77814\n",
      "Epoch 9893: train_loss=689.55164, val_loss=706.69153\n",
      "Epoch 9894: train_loss=689.42841, val_loss=706.57007\n",
      "Epoch 9895: train_loss=689.31256, val_loss=706.46680\n",
      "Epoch 9896: train_loss=689.20325, val_loss=706.38306\n",
      "Epoch 9897: train_loss=689.09747, val_loss=706.26227\n",
      "Epoch 9898: train_loss=688.99493, val_loss=706.20300\n",
      "Epoch 9899: train_loss=688.89362, val_loss=706.06445\n",
      "Epoch 9900: train_loss=688.79199, val_loss=706.01770\n",
      "Epoch 9901: train_loss=688.68817, val_loss=705.86523\n",
      "Epoch 9902: train_loss=688.58282, val_loss=705.82257\n",
      "Epoch 9903: train_loss=688.47424, val_loss=705.65820\n",
      "Epoch 9904: train_loss=688.36261, val_loss=705.60785\n",
      "Epoch 9905: train_loss=688.24658, val_loss=705.43451\n",
      "Epoch 9906: train_loss=688.12817, val_loss=705.37555\n",
      "Epoch 9907: train_loss=688.00787, val_loss=705.20673\n",
      "Epoch 9908: train_loss=687.88666, val_loss=705.13727\n",
      "Epoch 9909: train_loss=687.76526, val_loss=704.98102\n",
      "Epoch 9910: train_loss=687.64471, val_loss=704.89813\n",
      "Epoch 9911: train_loss=687.52515, val_loss=704.75836\n",
      "Epoch 9912: train_loss=687.40735, val_loss=704.66144\n",
      "Epoch 9913: train_loss=687.29077, val_loss=704.54321\n",
      "Epoch 9914: train_loss=687.17633, val_loss=704.43512\n",
      "Epoch 9915: train_loss=687.06409, val_loss=704.33331\n",
      "Epoch 9916: train_loss=686.95331, val_loss=704.21570\n",
      "Epoch 9917: train_loss=686.84515, val_loss=704.12762\n",
      "Epoch 9918: train_loss=686.73853, val_loss=704.00128\n",
      "Epoch 9919: train_loss=686.63251, val_loss=703.92645\n",
      "Epoch 9920: train_loss=686.52783, val_loss=703.79175\n",
      "Epoch 9921: train_loss=686.42474, val_loss=703.72974\n",
      "Epoch 9922: train_loss=686.32318, val_loss=703.58582\n",
      "Epoch 9923: train_loss=686.22369, val_loss=703.53253\n",
      "Epoch 9924: train_loss=686.12354, val_loss=703.37836\n",
      "Epoch 9925: train_loss=686.02502, val_loss=703.33344\n",
      "Epoch 9926: train_loss=685.92493, val_loss=703.17413\n",
      "Epoch 9927: train_loss=685.82458, val_loss=703.13287\n",
      "Epoch 9928: train_loss=685.72314, val_loss=702.96893\n",
      "Epoch 9929: train_loss=685.61987, val_loss=702.92688\n",
      "Epoch 9930: train_loss=685.51611, val_loss=702.76141\n",
      "Epoch 9931: train_loss=685.41046, val_loss=702.71564\n",
      "Epoch 9932: train_loss=685.30341, val_loss=702.55450\n",
      "Epoch 9933: train_loss=685.19574, val_loss=702.50134\n",
      "Epoch 9934: train_loss=685.08740, val_loss=702.34637\n",
      "Epoch 9935: train_loss=684.97858, val_loss=702.28455\n",
      "Epoch 9936: train_loss=684.86926, val_loss=702.14447\n",
      "Epoch 9937: train_loss=684.76080, val_loss=702.07483\n",
      "Epoch 9938: train_loss=684.65417, val_loss=701.94995\n",
      "Epoch 9939: train_loss=684.54901, val_loss=701.86884\n",
      "Epoch 9940: train_loss=684.44531, val_loss=701.76270\n",
      "Epoch 9941: train_loss=684.34332, val_loss=701.67261\n",
      "Epoch 9942: train_loss=684.24280, val_loss=701.57990\n",
      "Epoch 9943: train_loss=684.14307, val_loss=701.48138\n",
      "Epoch 9944: train_loss=684.04401, val_loss=701.39838\n",
      "Epoch 9945: train_loss=683.94586, val_loss=701.29083\n",
      "Epoch 9946: train_loss=683.84894, val_loss=701.22369\n",
      "Epoch 9947: train_loss=683.75354, val_loss=701.10822\n",
      "Epoch 9948: train_loss=683.66083, val_loss=701.06354\n",
      "Epoch 9949: train_loss=683.57233, val_loss=700.94006\n",
      "Epoch 9950: train_loss=683.49078, val_loss=700.93359\n",
      "Epoch 9951: train_loss=683.41852, val_loss=700.80188\n",
      "Epoch 9952: train_loss=683.35754, val_loss=700.84875\n",
      "Epoch 9953: train_loss=683.30817, val_loss=700.71185\n",
      "Epoch 9954: train_loss=683.27313, val_loss=700.81598\n",
      "Epoch 9955: train_loss=683.24518, val_loss=700.66949\n",
      "Epoch 9956: train_loss=683.23444, val_loss=700.80847\n",
      "Epoch 9957: train_loss=683.20654, val_loss=700.60626\n",
      "Epoch 9958: train_loss=683.17053, val_loss=700.69025\n",
      "Epoch 9959: train_loss=683.07129, val_loss=700.38031\n",
      "Epoch 9960: train_loss=682.93158, val_loss=700.33002\n",
      "Epoch 9961: train_loss=682.72034, val_loss=699.97131\n",
      "Epoch 9962: train_loss=682.49457, val_loss=699.84540\n",
      "Epoch 9963: train_loss=682.26849, val_loss=699.59796\n",
      "Epoch 9964: train_loss=682.08325, val_loss=699.49341\n",
      "Epoch 9965: train_loss=681.95642, val_loss=699.44281\n",
      "Epoch 9966: train_loss=681.88287, val_loss=699.35028\n",
      "Epoch 9967: train_loss=681.83740, val_loss=699.38330\n",
      "Epoch 9968: train_loss=681.78973, val_loss=699.22980\n",
      "Epoch 9969: train_loss=681.72235, val_loss=699.22034\n",
      "Epoch 9970: train_loss=681.61884, val_loss=699.00848\n",
      "Epoch 9971: train_loss=681.49200, val_loss=698.93787\n",
      "Epoch 9972: train_loss=681.34814, val_loss=698.74493\n",
      "Epoch 9973: train_loss=681.20660, val_loss=698.64990\n",
      "Epoch 9974: train_loss=681.08215, val_loss=698.54602\n",
      "Epoch 9975: train_loss=680.98047, val_loss=698.44775\n",
      "Epoch 9976: train_loss=680.89703, val_loss=698.41132\n",
      "Epoch 9977: train_loss=680.82013, val_loss=698.28973\n",
      "Epoch 9978: train_loss=680.74011, val_loss=698.25897\n",
      "Epoch 9979: train_loss=680.64948, val_loss=698.10840\n",
      "Epoch 9980: train_loss=680.54895, val_loss=698.05273\n",
      "Epoch 9981: train_loss=680.43927, val_loss=697.90125\n",
      "Epoch 9982: train_loss=680.32672, val_loss=697.82605\n",
      "Epoch 9983: train_loss=680.21503, val_loss=697.70288\n",
      "Epoch 9984: train_loss=680.10852, val_loss=697.61523\n",
      "Epoch 9985: train_loss=680.00885, val_loss=697.52966\n",
      "Epoch 9986: train_loss=679.91559, val_loss=697.43011\n",
      "Epoch 9987: train_loss=679.82672, val_loss=697.37048\n",
      "Epoch 9988: train_loss=679.73999, val_loss=697.25873\n",
      "Epoch 9989: train_loss=679.65466, val_loss=697.21387\n",
      "Epoch 9990: train_loss=679.56873, val_loss=697.08771\n",
      "Epoch 9991: train_loss=679.48145, val_loss=697.04449\n",
      "Epoch 9992: train_loss=679.39069, val_loss=696.90826\n",
      "Epoch 9993: train_loss=679.29810, val_loss=696.86023\n",
      "Epoch 9994: train_loss=679.20154, val_loss=696.72150\n",
      "Epoch 9995: train_loss=679.10388, val_loss=696.66449\n",
      "Epoch 9996: train_loss=679.00348, val_loss=696.52881\n",
      "Epoch 9997: train_loss=678.90216, val_loss=696.46033\n",
      "Epoch 9998: train_loss=678.80060, val_loss=696.33649\n",
      "Epoch 9999: train_loss=678.70007, val_loss=696.25653\n",
      "Epoch 10000: train_loss=678.60114, val_loss=696.14923\n",
      "Epoch 10001: train_loss=678.50415, val_loss=696.05914\n",
      "Epoch 10002: train_loss=678.40967, val_loss=695.97083\n",
      "Epoch 10003: train_loss=678.31708, val_loss=695.87341\n",
      "Epoch 10004: train_loss=678.22601, val_loss=695.79755\n",
      "Epoch 10005: train_loss=678.13568, val_loss=695.69177\n",
      "Epoch 10006: train_loss=678.04633, val_loss=695.62653\n",
      "Epoch 10007: train_loss=677.95758, val_loss=695.51733\n",
      "Epoch 10008: train_loss=677.86951, val_loss=695.46320\n",
      "Epoch 10009: train_loss=677.78198, val_loss=695.34766\n",
      "Epoch 10010: train_loss=677.69427, val_loss=695.30048\n",
      "Epoch 10011: train_loss=677.60730, val_loss=695.17944\n",
      "Epoch 10012: train_loss=677.52069, val_loss=695.13812\n",
      "Epoch 10013: train_loss=677.43414, val_loss=695.01257\n",
      "Epoch 10014: train_loss=677.34790, val_loss=694.97711\n",
      "Epoch 10015: train_loss=677.26099, val_loss=694.84473\n",
      "Epoch 10016: train_loss=677.17352, val_loss=694.80707\n",
      "Epoch 10017: train_loss=677.08350, val_loss=694.66748\n",
      "Epoch 10018: train_loss=676.99200, val_loss=694.62469\n",
      "Epoch 10019: train_loss=676.89624, val_loss=694.48431\n",
      "Epoch 10020: train_loss=676.79822, val_loss=694.43182\n",
      "Epoch 10021: train_loss=676.69653, val_loss=694.29724\n",
      "Epoch 10022: train_loss=676.59381, val_loss=694.22943\n",
      "Epoch 10023: train_loss=676.49146, val_loss=694.10980\n",
      "Epoch 10024: train_loss=676.39099, val_loss=694.03156\n",
      "Epoch 10025: train_loss=676.29321, val_loss=693.93286\n",
      "Epoch 10026: train_loss=676.19794, val_loss=693.84674\n",
      "Epoch 10027: train_loss=676.10486, val_loss=693.76312\n",
      "Epoch 10028: train_loss=676.01367, val_loss=693.66846\n",
      "Epoch 10029: train_loss=675.92401, val_loss=693.59998\n",
      "Epoch 10030: train_loss=675.83691, val_loss=693.49805\n",
      "Epoch 10031: train_loss=675.75330, val_loss=693.44873\n",
      "Epoch 10032: train_loss=675.67242, val_loss=693.33759\n",
      "Epoch 10033: train_loss=675.59576, val_loss=693.30774\n",
      "Epoch 10034: train_loss=675.52063, val_loss=693.18433\n",
      "Epoch 10035: train_loss=675.44769, val_loss=693.16583\n",
      "Epoch 10036: train_loss=675.37189, val_loss=693.02759\n",
      "Epoch 10037: train_loss=675.29639, val_loss=693.00964\n",
      "Epoch 10038: train_loss=675.21301, val_loss=692.85669\n",
      "Epoch 10039: train_loss=675.12872, val_loss=692.82990\n",
      "Epoch 10040: train_loss=675.03595, val_loss=692.66858\n",
      "Epoch 10041: train_loss=674.94159, val_loss=692.62543\n",
      "Epoch 10042: train_loss=674.83698, val_loss=692.46149\n",
      "Epoch 10043: train_loss=674.72900, val_loss=692.39648\n",
      "Epoch 10044: train_loss=674.61646, val_loss=692.24664\n",
      "Epoch 10045: train_loss=674.50641, val_loss=692.16675\n",
      "Epoch 10046: train_loss=674.40100, val_loss=692.05151\n",
      "Epoch 10047: train_loss=674.30255, val_loss=691.96564\n",
      "Epoch 10048: train_loss=674.21179, val_loss=691.88928\n",
      "Epoch 10049: train_loss=674.12726, val_loss=691.79492\n",
      "Epoch 10050: train_loss=674.04700, val_loss=691.74127\n",
      "Epoch 10051: train_loss=673.96881, val_loss=691.63562\n",
      "Epoch 10052: train_loss=673.89044, val_loss=691.59198\n",
      "Epoch 10053: train_loss=673.81134, val_loss=691.47626\n",
      "Epoch 10054: train_loss=673.73065, val_loss=691.43561\n",
      "Epoch 10055: train_loss=673.64844, val_loss=691.31073\n",
      "Epoch 10056: train_loss=673.56421, val_loss=691.26556\n",
      "Epoch 10057: train_loss=673.47772, val_loss=691.13519\n",
      "Epoch 10058: train_loss=673.38812, val_loss=691.08441\n",
      "Epoch 10059: train_loss=673.29669, val_loss=690.95703\n",
      "Epoch 10060: train_loss=673.20410, val_loss=690.89935\n",
      "Epoch 10061: train_loss=673.11029, val_loss=690.77570\n",
      "Epoch 10062: train_loss=673.01678, val_loss=690.71155\n",
      "Epoch 10063: train_loss=672.92340, val_loss=690.59546\n",
      "Epoch 10064: train_loss=672.83099, val_loss=690.52704\n",
      "Epoch 10065: train_loss=672.73938, val_loss=690.41888\n",
      "Epoch 10066: train_loss=672.64880, val_loss=690.34900\n",
      "Epoch 10067: train_loss=672.55994, val_loss=690.24518\n",
      "Epoch 10068: train_loss=672.47205, val_loss=690.17523\n",
      "Epoch 10069: train_loss=672.38483, val_loss=690.07452\n",
      "Epoch 10070: train_loss=672.29883, val_loss=690.00848\n",
      "Epoch 10071: train_loss=672.21368, val_loss=689.90747\n",
      "Epoch 10072: train_loss=672.13031, val_loss=689.84766\n",
      "Epoch 10073: train_loss=672.04852, val_loss=689.74371\n",
      "Epoch 10074: train_loss=671.96893, val_loss=689.69348\n",
      "Epoch 10075: train_loss=671.89178, val_loss=689.58777\n",
      "Epoch 10076: train_loss=671.81824, val_loss=689.55310\n",
      "Epoch 10077: train_loss=671.74792, val_loss=689.44641\n",
      "Epoch 10078: train_loss=671.68280, val_loss=689.42963\n",
      "Epoch 10079: train_loss=671.62006, val_loss=689.32172\n",
      "Epoch 10080: train_loss=671.56238, val_loss=689.31921\n",
      "Epoch 10081: train_loss=671.50470, val_loss=689.20520\n",
      "Epoch 10082: train_loss=671.44904, val_loss=689.20587\n",
      "Epoch 10083: train_loss=671.38660, val_loss=689.07465\n",
      "Epoch 10084: train_loss=671.31946, val_loss=689.05280\n",
      "Epoch 10085: train_loss=671.23285, val_loss=688.89240\n",
      "Epoch 10086: train_loss=671.13458, val_loss=688.83124\n",
      "Epoch 10087: train_loss=671.01569, val_loss=688.64978\n",
      "Epoch 10088: train_loss=670.88837, val_loss=688.55872\n",
      "Epoch 10089: train_loss=670.75415, val_loss=688.39606\n",
      "Epoch 10090: train_loss=670.62738, val_loss=688.30334\n",
      "Epoch 10091: train_loss=670.50983, val_loss=688.18579\n",
      "Epoch 10092: train_loss=670.40601, val_loss=688.10107\n",
      "Epoch 10093: train_loss=670.31567, val_loss=688.02582\n",
      "Epoch 10094: train_loss=670.23578, val_loss=687.94226\n",
      "Epoch 10095: train_loss=670.16357, val_loss=687.89398\n",
      "Epoch 10096: train_loss=670.09631, val_loss=687.80267\n",
      "Epoch 10097: train_loss=670.03064, val_loss=687.76776\n",
      "Epoch 10098: train_loss=669.96411, val_loss=687.66699\n",
      "Epoch 10099: train_loss=669.89618, val_loss=687.63123\n",
      "Epoch 10100: train_loss=669.82361, val_loss=687.51624\n",
      "Epoch 10101: train_loss=669.74707, val_loss=687.47327\n",
      "Epoch 10102: train_loss=669.66498, val_loss=687.34979\n",
      "Epoch 10103: train_loss=669.57959, val_loss=687.29944\n",
      "Epoch 10104: train_loss=669.48993, val_loss=687.17303\n",
      "Epoch 10105: train_loss=669.39777, val_loss=687.11389\n",
      "Epoch 10106: train_loss=669.30304, val_loss=686.98676\n",
      "Epoch 10107: train_loss=669.20679, val_loss=686.91901\n",
      "Epoch 10108: train_loss=669.11023, val_loss=686.79974\n",
      "Epoch 10109: train_loss=669.01440, val_loss=686.72723\n",
      "Epoch 10110: train_loss=668.92004, val_loss=686.62170\n",
      "Epoch 10111: train_loss=668.82843, val_loss=686.54633\n",
      "Epoch 10112: train_loss=668.73920, val_loss=686.45209\n",
      "Epoch 10113: train_loss=668.65308, val_loss=686.37506\n",
      "Epoch 10114: train_loss=668.56848, val_loss=686.28784\n",
      "Epoch 10115: train_loss=668.48541, val_loss=686.20972\n",
      "Epoch 10116: train_loss=668.40289, val_loss=686.12598\n",
      "Epoch 10117: train_loss=668.32056, val_loss=686.04565\n",
      "Epoch 10118: train_loss=668.23859, val_loss=685.96143\n",
      "Epoch 10119: train_loss=668.15662, val_loss=685.87891\n",
      "Epoch 10120: train_loss=668.07477, val_loss=685.79358\n",
      "Epoch 10121: train_loss=667.99280, val_loss=685.71198\n",
      "Epoch 10122: train_loss=667.91144, val_loss=685.62653\n",
      "Epoch 10123: train_loss=667.83057, val_loss=685.54907\n",
      "Epoch 10124: train_loss=667.75049, val_loss=685.46198\n",
      "Epoch 10125: train_loss=667.67200, val_loss=685.39221\n",
      "Epoch 10126: train_loss=667.59619, val_loss=685.30829\n",
      "Epoch 10127: train_loss=667.52649, val_loss=685.26306\n",
      "Epoch 10128: train_loss=667.46515, val_loss=685.18903\n",
      "Epoch 10129: train_loss=667.41626, val_loss=685.18188\n",
      "Epoch 10130: train_loss=667.37958, val_loss=685.12201\n",
      "Epoch 10131: train_loss=667.35999, val_loss=685.15265\n",
      "Epoch 10132: train_loss=667.34619, val_loss=685.09680\n",
      "Epoch 10133: train_loss=667.34442, val_loss=685.12939\n",
      "Epoch 10134: train_loss=667.31915, val_loss=685.03772\n",
      "Epoch 10135: train_loss=667.29028, val_loss=685.01160\n",
      "Epoch 10136: train_loss=667.20325, val_loss=684.83850\n",
      "Epoch 10137: train_loss=667.09277, val_loss=684.71985\n",
      "Epoch 10138: train_loss=666.92188, val_loss=684.48737\n",
      "Epoch 10139: train_loss=666.74023, val_loss=684.33575\n",
      "Epoch 10140: train_loss=666.55597, val_loss=684.16095\n",
      "Epoch 10141: train_loss=666.40442, val_loss=684.06036\n",
      "Epoch 10142: train_loss=666.29675, val_loss=683.99829\n",
      "Epoch 10143: train_loss=666.22961, val_loss=683.94354\n",
      "Epoch 10144: train_loss=666.18805, val_loss=683.93304\n",
      "Epoch 10145: train_loss=666.15228, val_loss=683.85962\n",
      "Epoch 10146: train_loss=666.10742, val_loss=683.82104\n",
      "Epoch 10147: train_loss=666.03687, val_loss=683.69629\n",
      "Epoch 10148: train_loss=665.94464, val_loss=683.61273\n",
      "Epoch 10149: train_loss=665.83209, val_loss=683.47119\n",
      "Epoch 10150: train_loss=665.71533, val_loss=683.37665\n",
      "Epoch 10151: train_loss=665.60278, val_loss=683.27014\n",
      "Epoch 10152: train_loss=665.50555, val_loss=683.19208\n",
      "Epoch 10153: train_loss=665.42389, val_loss=683.13068\n",
      "Epoch 10154: train_loss=665.35510, val_loss=683.05731\n",
      "Epoch 10155: train_loss=665.29327, val_loss=683.01373\n",
      "Epoch 10156: train_loss=665.23303, val_loss=682.93195\n",
      "Epoch 10157: train_loss=665.16937, val_loss=682.88141\n",
      "Epoch 10158: train_loss=665.09625, val_loss=682.78406\n",
      "Epoch 10159: train_loss=665.01807, val_loss=682.71747\n",
      "Epoch 10160: train_loss=664.92883, val_loss=682.60876\n",
      "Epoch 10161: train_loss=664.83551, val_loss=682.53021\n",
      "Epoch 10162: train_loss=664.73920, val_loss=682.43140\n",
      "Epoch 10163: train_loss=664.64545, val_loss=682.35382\n",
      "Epoch 10164: train_loss=664.55530, val_loss=682.27264\n",
      "Epoch 10165: train_loss=664.47131, val_loss=682.19586\n",
      "Epoch 10166: train_loss=664.39270, val_loss=682.12878\n",
      "Epoch 10167: train_loss=664.31683, val_loss=682.05096\n",
      "Epoch 10168: train_loss=664.24225, val_loss=681.99176\n",
      "Epoch 10169: train_loss=664.16681, val_loss=681.91113\n",
      "Epoch 10170: train_loss=664.09064, val_loss=681.85175\n",
      "Epoch 10171: train_loss=664.01373, val_loss=681.76672\n",
      "Epoch 10172: train_loss=663.93536, val_loss=681.70557\n",
      "Epoch 10173: train_loss=663.85535, val_loss=681.61932\n",
      "Epoch 10174: train_loss=663.77448, val_loss=681.55585\n",
      "Epoch 10175: train_loss=663.69110, val_loss=681.46527\n",
      "Epoch 10176: train_loss=663.60748, val_loss=681.39795\n",
      "Epoch 10177: train_loss=663.52155, val_loss=681.30579\n",
      "Epoch 10178: train_loss=663.43488, val_loss=681.23560\n",
      "Epoch 10179: train_loss=663.34668, val_loss=681.14618\n",
      "Epoch 10180: train_loss=663.25854, val_loss=681.07257\n",
      "Epoch 10181: train_loss=663.17096, val_loss=680.98853\n",
      "Epoch 10182: train_loss=663.08521, val_loss=680.91370\n",
      "Epoch 10183: train_loss=663.00110, val_loss=680.83844\n",
      "Epoch 10184: train_loss=662.91895, val_loss=680.76331\n",
      "Epoch 10185: train_loss=662.83789, val_loss=680.69476\n",
      "Epoch 10186: train_loss=662.75745, val_loss=680.61768\n",
      "Epoch 10187: train_loss=662.67853, val_loss=680.55670\n",
      "Epoch 10188: train_loss=662.60156, val_loss=680.48187\n",
      "Epoch 10189: train_loss=662.52692, val_loss=680.43018\n",
      "Epoch 10190: train_loss=662.45343, val_loss=680.35687\n",
      "Epoch 10191: train_loss=662.38342, val_loss=680.31372\n",
      "Epoch 10192: train_loss=662.31329, val_loss=680.23883\n",
      "Epoch 10193: train_loss=662.24799, val_loss=680.20343\n",
      "Epoch 10194: train_loss=662.17969, val_loss=680.12170\n",
      "Epoch 10195: train_loss=662.11371, val_loss=680.08344\n",
      "Epoch 10196: train_loss=662.03772, val_loss=679.98572\n",
      "Epoch 10197: train_loss=661.95941, val_loss=679.93475\n",
      "Epoch 10198: train_loss=661.87018, val_loss=679.82336\n",
      "Epoch 10199: train_loss=661.77899, val_loss=679.75970\n",
      "Epoch 10200: train_loss=661.68231, val_loss=679.64752\n",
      "Epoch 10201: train_loss=661.58618, val_loss=679.57739\n",
      "Epoch 10202: train_loss=661.49164, val_loss=679.47717\n",
      "Epoch 10203: train_loss=661.39990, val_loss=679.40442\n",
      "Epoch 10204: train_loss=661.31299, val_loss=679.32489\n",
      "Epoch 10205: train_loss=661.23187, val_loss=679.25116\n",
      "Epoch 10206: train_loss=661.15552, val_loss=679.19012\n",
      "Epoch 10207: train_loss=661.08301, val_loss=679.11066\n",
      "Epoch 10208: train_loss=661.01178, val_loss=679.05865\n",
      "Epoch 10209: train_loss=660.94128, val_loss=678.97223\n",
      "Epoch 10210: train_loss=660.87006, val_loss=678.92297\n",
      "Epoch 10211: train_loss=660.79810, val_loss=678.83264\n",
      "Epoch 10212: train_loss=660.72491, val_loss=678.78296\n",
      "Epoch 10213: train_loss=660.65033, val_loss=678.69202\n",
      "Epoch 10214: train_loss=660.57538, val_loss=678.64343\n",
      "Epoch 10215: train_loss=660.50055, val_loss=678.55249\n",
      "Epoch 10216: train_loss=660.42615, val_loss=678.50446\n",
      "Epoch 10217: train_loss=660.35101, val_loss=678.41254\n",
      "Epoch 10218: train_loss=660.27490, val_loss=678.36377\n",
      "Epoch 10219: train_loss=660.19830, val_loss=678.27075\n",
      "Epoch 10220: train_loss=660.12018, val_loss=678.21912\n",
      "Epoch 10221: train_loss=660.04095, val_loss=678.12610\n",
      "Epoch 10222: train_loss=659.96063, val_loss=678.07257\n",
      "Epoch 10223: train_loss=659.87988, val_loss=677.98108\n",
      "Epoch 10224: train_loss=659.79883, val_loss=677.92407\n",
      "Epoch 10225: train_loss=659.71704, val_loss=677.83289\n",
      "Epoch 10226: train_loss=659.63489, val_loss=677.77161\n",
      "Epoch 10227: train_loss=659.55249, val_loss=677.68494\n",
      "Epoch 10228: train_loss=659.47089, val_loss=677.62311\n",
      "Epoch 10229: train_loss=659.39020, val_loss=677.54407\n",
      "Epoch 10230: train_loss=659.31079, val_loss=677.47974\n",
      "Epoch 10231: train_loss=659.23224, val_loss=677.40662\n",
      "Epoch 10232: train_loss=659.15564, val_loss=677.34009\n",
      "Epoch 10233: train_loss=659.07971, val_loss=677.27295\n",
      "Epoch 10234: train_loss=659.00488, val_loss=677.20453\n",
      "Epoch 10235: train_loss=658.93085, val_loss=677.14209\n",
      "Epoch 10236: train_loss=658.85760, val_loss=677.07312\n",
      "Epoch 10237: train_loss=658.78552, val_loss=677.02069\n",
      "Epoch 10238: train_loss=658.71576, val_loss=676.95465\n",
      "Epoch 10239: train_loss=658.65137, val_loss=676.91937\n",
      "Epoch 10240: train_loss=658.59186, val_loss=676.85822\n",
      "Epoch 10241: train_loss=658.54218, val_loss=676.85303\n",
      "Epoch 10242: train_loss=658.50409, val_loss=676.80823\n",
      "Epoch 10243: train_loss=658.48236, val_loss=676.84399\n",
      "Epoch 10244: train_loss=658.46973, val_loss=676.81738\n",
      "Epoch 10245: train_loss=658.47961, val_loss=676.87903\n",
      "Epoch 10246: train_loss=658.48059, val_loss=676.83636\n",
      "Epoch 10247: train_loss=658.48932, val_loss=676.86578\n",
      "Epoch 10248: train_loss=658.45117, val_loss=676.74963\n",
      "Epoch 10249: train_loss=658.39105, val_loss=676.67798\n",
      "Epoch 10250: train_loss=658.25293, val_loss=676.45648\n",
      "Epoch 10251: train_loss=658.08276, val_loss=676.30371\n",
      "Epoch 10252: train_loss=657.88116, val_loss=676.08722\n",
      "Epoch 10253: train_loss=657.69818, val_loss=675.96979\n",
      "Epoch 10254: train_loss=657.55719, val_loss=675.88452\n",
      "Epoch 10255: train_loss=657.47028, val_loss=675.84167\n",
      "Epoch 10256: train_loss=657.42902, val_loss=675.85504\n",
      "Epoch 10257: train_loss=657.41107, val_loss=675.80872\n",
      "Epoch 10258: train_loss=657.38983, val_loss=675.80377\n",
      "Epoch 10259: train_loss=657.34332, val_loss=675.69556\n",
      "Epoch 10260: train_loss=657.26935, val_loss=675.63171\n",
      "Epoch 10261: train_loss=657.16376, val_loss=675.48816\n",
      "Epoch 10262: train_loss=657.04541, val_loss=675.40143\n",
      "Epoch 10263: train_loss=656.92938, val_loss=675.29614\n",
      "Epoch 10264: train_loss=656.83075, val_loss=675.22833\n",
      "Epoch 10265: train_loss=656.75568, val_loss=675.18573\n",
      "Epoch 10266: train_loss=656.69977, val_loss=675.12677\n",
      "Epoch 10267: train_loss=656.65167, val_loss=675.10181\n",
      "Epoch 10268: train_loss=656.60144, val_loss=675.02484\n",
      "Epoch 10269: train_loss=656.54272, val_loss=674.98273\n",
      "Epoch 10270: train_loss=656.47174, val_loss=674.88501\n",
      "Epoch 10271: train_loss=656.39209, val_loss=674.82288\n",
      "Epoch 10272: train_loss=656.30573, val_loss=674.72101\n",
      "Epoch 10273: train_loss=656.21674, val_loss=674.65143\n",
      "Epoch 10274: train_loss=656.13080, val_loss=674.56738\n",
      "Epoch 10275: train_loss=656.04993, val_loss=674.50146\n",
      "Epoch 10276: train_loss=655.97662, val_loss=674.44281\n",
      "Epoch 10277: train_loss=655.91003, val_loss=674.37775\n",
      "Epoch 10278: train_loss=655.84711, val_loss=674.33081\n",
      "Epoch 10279: train_loss=655.78577, val_loss=674.25903\n",
      "Epoch 10280: train_loss=655.72327, val_loss=674.21362\n",
      "Epoch 10281: train_loss=655.65845, val_loss=674.13477\n",
      "Epoch 10282: train_loss=655.58978, val_loss=674.08429\n",
      "Epoch 10283: train_loss=655.51819, val_loss=674.00140\n",
      "Epoch 10284: train_loss=655.44397, val_loss=673.94293\n",
      "Epoch 10285: train_loss=655.36890, val_loss=673.86182\n",
      "Epoch 10286: train_loss=655.29382, val_loss=673.80029\n",
      "Epoch 10287: train_loss=655.21948, val_loss=673.72711\n",
      "Epoch 10288: train_loss=655.14624, val_loss=673.66504\n",
      "Epoch 10289: train_loss=655.07507, val_loss=673.60211\n",
      "Epoch 10290: train_loss=655.00592, val_loss=673.53766\n",
      "Epoch 10291: train_loss=654.93811, val_loss=673.48041\n",
      "Epoch 10292: train_loss=654.87164, val_loss=673.41302\n",
      "Epoch 10293: train_loss=654.80591, val_loss=673.36066\n",
      "Epoch 10294: train_loss=654.74097, val_loss=673.29303\n",
      "Epoch 10295: train_loss=654.67749, val_loss=673.24652\n",
      "Epoch 10296: train_loss=654.61523, val_loss=673.17676\n",
      "Epoch 10297: train_loss=654.55414, val_loss=673.13446\n",
      "Epoch 10298: train_loss=654.49506, val_loss=673.06403\n",
      "Epoch 10299: train_loss=654.43817, val_loss=673.02948\n",
      "Epoch 10300: train_loss=654.38239, val_loss=672.96045\n",
      "Epoch 10301: train_loss=654.33002, val_loss=672.93018\n",
      "Epoch 10302: train_loss=654.27637, val_loss=672.85303\n",
      "Epoch 10303: train_loss=654.22198, val_loss=672.81561\n",
      "Epoch 10304: train_loss=654.16180, val_loss=672.72595\n",
      "Epoch 10305: train_loss=654.09778, val_loss=672.67822\n",
      "Epoch 10306: train_loss=654.02423, val_loss=672.57819\n",
      "Epoch 10307: train_loss=653.94745, val_loss=672.51404\n",
      "Epoch 10308: train_loss=653.86194, val_loss=672.40259\n",
      "Epoch 10309: train_loss=653.77319, val_loss=672.32611\n",
      "Epoch 10310: train_loss=653.68231, val_loss=672.22296\n",
      "Epoch 10311: train_loss=653.59485, val_loss=672.14978\n",
      "Epoch 10312: train_loss=653.51190, val_loss=672.06927\n",
      "Epoch 10313: train_loss=653.43622, val_loss=672.00061\n",
      "Epoch 10314: train_loss=653.36719, val_loss=671.93927\n",
      "Epoch 10315: train_loss=653.30365, val_loss=671.87213\n",
      "Epoch 10316: train_loss=653.24341, val_loss=671.82306\n",
      "Epoch 10317: train_loss=653.18445, val_loss=671.75720\n",
      "Epoch 10318: train_loss=653.12720, val_loss=671.71436\n",
      "Epoch 10319: train_loss=653.06897, val_loss=671.64453\n",
      "Epoch 10320: train_loss=653.01154, val_loss=671.60297\n",
      "Epoch 10321: train_loss=652.95123, val_loss=671.52997\n",
      "Epoch 10322: train_loss=652.89081, val_loss=671.48822\n",
      "Epoch 10323: train_loss=652.82697, val_loss=671.41223\n",
      "Epoch 10324: train_loss=652.76331, val_loss=671.36707\n",
      "Epoch 10325: train_loss=652.69659, val_loss=671.28644\n",
      "Epoch 10326: train_loss=652.63007, val_loss=671.23779\n",
      "Epoch 10327: train_loss=652.56104, val_loss=671.15497\n",
      "Epoch 10328: train_loss=652.49078, val_loss=671.10370\n",
      "Epoch 10329: train_loss=652.41736, val_loss=671.01917\n",
      "Epoch 10330: train_loss=652.34216, val_loss=670.96307\n",
      "Epoch 10331: train_loss=652.26599, val_loss=670.88049\n",
      "Epoch 10332: train_loss=652.18982, val_loss=670.82013\n",
      "Epoch 10333: train_loss=652.11346, val_loss=670.74194\n",
      "Epoch 10334: train_loss=652.03851, val_loss=670.68170\n",
      "Epoch 10335: train_loss=651.96521, val_loss=670.61316\n",
      "Epoch 10336: train_loss=651.89398, val_loss=670.55341\n",
      "Epoch 10337: train_loss=651.82513, val_loss=670.49457\n",
      "Epoch 10338: train_loss=651.75818, val_loss=670.43402\n",
      "Epoch 10339: train_loss=651.69244, val_loss=670.38037\n",
      "Epoch 10340: train_loss=651.62836, val_loss=670.31836\n",
      "Epoch 10341: train_loss=651.56537, val_loss=670.27045\n",
      "Epoch 10342: train_loss=651.50403, val_loss=670.20941\n",
      "Epoch 10343: train_loss=651.44482, val_loss=670.16925\n",
      "Epoch 10344: train_loss=651.38831, val_loss=670.11194\n",
      "Epoch 10345: train_loss=651.33643, val_loss=670.08203\n",
      "Epoch 10346: train_loss=651.28741, val_loss=670.02777\n",
      "Epoch 10347: train_loss=651.24390, val_loss=670.00958\n",
      "Epoch 10348: train_loss=651.20197, val_loss=669.95770\n",
      "Epoch 10349: train_loss=651.16382, val_loss=669.94635\n",
      "Epoch 10350: train_loss=651.12372, val_loss=669.88763\n",
      "Epoch 10351: train_loss=651.08234, val_loss=669.86823\n",
      "Epoch 10352: train_loss=651.03345, val_loss=669.79053\n",
      "Epoch 10353: train_loss=650.97583, val_loss=669.74713\n",
      "Epoch 10354: train_loss=650.90283, val_loss=669.64502\n",
      "Epoch 10355: train_loss=650.81836, val_loss=669.57300\n",
      "Epoch 10356: train_loss=650.71875, val_loss=669.45270\n",
      "Epoch 10357: train_loss=650.61340, val_loss=669.36407\n",
      "Epoch 10358: train_loss=650.50562, val_loss=669.25775\n",
      "Epoch 10359: train_loss=650.40662, val_loss=669.18384\n",
      "Epoch 10360: train_loss=650.31964, val_loss=669.11444\n",
      "Epoch 10361: train_loss=650.24738, val_loss=669.05664\n",
      "Epoch 10362: train_loss=650.18726, val_loss=669.01379\n",
      "Epoch 10363: train_loss=650.13513, val_loss=668.96167\n",
      "Epoch 10364: train_loss=650.08643, val_loss=668.92615\n",
      "Epoch 10365: train_loss=650.03638, val_loss=668.86884\n",
      "Epoch 10366: train_loss=649.98535, val_loss=668.82697\n",
      "Epoch 10367: train_loss=649.92841, val_loss=668.76123\n",
      "Epoch 10368: train_loss=649.87256, val_loss=668.71497\n",
      "Epoch 10369: train_loss=649.80981, val_loss=668.64343\n",
      "Epoch 10370: train_loss=649.74762, val_loss=668.59467\n",
      "Epoch 10371: train_loss=649.67938, val_loss=668.52045\n",
      "Epoch 10372: train_loss=649.61194, val_loss=668.46613\n",
      "Epoch 10373: train_loss=649.53973, val_loss=668.38885\n",
      "Epoch 10374: train_loss=649.46875, val_loss=668.33038\n",
      "Epoch 10375: train_loss=649.39496, val_loss=668.25366\n",
      "Epoch 10376: train_loss=649.32263, val_loss=668.19427\n",
      "Epoch 10377: train_loss=649.24951, val_loss=668.12244\n",
      "Epoch 10378: train_loss=649.17865, val_loss=668.06281\n",
      "Epoch 10379: train_loss=649.10931, val_loss=667.99640\n",
      "Epoch 10380: train_loss=649.04205, val_loss=667.93677\n",
      "Epoch 10381: train_loss=648.97668, val_loss=667.87720\n",
      "Epoch 10382: train_loss=648.91321, val_loss=667.82117\n",
      "Epoch 10383: train_loss=648.85114, val_loss=667.76752\n",
      "Epoch 10384: train_loss=648.78973, val_loss=667.71045\n",
      "Epoch 10385: train_loss=648.72949, val_loss=667.65765\n",
      "Epoch 10386: train_loss=648.67004, val_loss=667.59875\n",
      "Epoch 10387: train_loss=648.61212, val_loss=667.55383\n",
      "Epoch 10388: train_loss=648.55627, val_loss=667.50385\n",
      "Epoch 10389: train_loss=648.50446, val_loss=667.47107\n",
      "Epoch 10390: train_loss=648.45624, val_loss=667.42761\n",
      "Epoch 10391: train_loss=648.41400, val_loss=667.40253\n",
      "Epoch 10392: train_loss=648.37665, val_loss=667.36627\n",
      "Epoch 10393: train_loss=648.34686, val_loss=667.35315\n",
      "Epoch 10394: train_loss=648.31732, val_loss=667.31940\n",
      "Epoch 10395: train_loss=648.28925, val_loss=667.30151\n",
      "Epoch 10396: train_loss=648.25250, val_loss=667.24951\n",
      "Epoch 10397: train_loss=648.20886, val_loss=667.20367\n",
      "Epoch 10398: train_loss=648.14685, val_loss=667.11890\n",
      "Epoch 10399: train_loss=648.07208, val_loss=667.04016\n",
      "Epoch 10400: train_loss=647.97656, val_loss=666.93158\n",
      "Epoch 10401: train_loss=647.87396, val_loss=666.83582\n",
      "Epoch 10402: train_loss=647.76416, val_loss=666.72601\n",
      "Epoch 10403: train_loss=647.65955, val_loss=666.63922\n",
      "Epoch 10404: train_loss=647.56451, val_loss=666.56201\n",
      "Epoch 10405: train_loss=647.48730, val_loss=666.50604\n",
      "Epoch 10406: train_loss=647.42725, val_loss=666.46643\n",
      "Epoch 10407: train_loss=647.37909, val_loss=666.42480\n",
      "Epoch 10408: train_loss=647.33679, val_loss=666.39343\n",
      "Epoch 10409: train_loss=647.29486, val_loss=666.34668\n",
      "Epoch 10410: train_loss=647.25153, val_loss=666.31061\n",
      "Epoch 10411: train_loss=647.20361, val_loss=666.25732\n",
      "Epoch 10412: train_loss=647.15326, val_loss=666.21582\n",
      "Epoch 10413: train_loss=647.09717, val_loss=666.15057\n",
      "Epoch 10414: train_loss=647.03595, val_loss=666.09613\n",
      "Epoch 10415: train_loss=646.96808, val_loss=666.02100\n",
      "Epoch 10416: train_loss=646.89661, val_loss=665.95978\n",
      "Epoch 10417: train_loss=646.82239, val_loss=665.88300\n",
      "Epoch 10418: train_loss=646.74731, val_loss=665.81775\n",
      "Epoch 10419: train_loss=646.67151, val_loss=665.73993\n",
      "Epoch 10420: train_loss=646.59619, val_loss=665.67371\n",
      "Epoch 10421: train_loss=646.52252, val_loss=665.60681\n",
      "Epoch 10422: train_loss=646.45343, val_loss=665.54907\n",
      "Epoch 10423: train_loss=646.38934, val_loss=665.49487\n",
      "Epoch 10424: train_loss=646.33020, val_loss=665.44171\n",
      "Epoch 10425: train_loss=646.27472, val_loss=665.39325\n",
      "Epoch 10426: train_loss=646.22070, val_loss=665.34094\n",
      "Epoch 10427: train_loss=646.16797, val_loss=665.29803\n",
      "Epoch 10428: train_loss=646.11505, val_loss=665.24646\n",
      "Epoch 10429: train_loss=646.06097, val_loss=665.20221\n",
      "Epoch 10430: train_loss=646.00574, val_loss=665.14886\n",
      "Epoch 10431: train_loss=645.95020, val_loss=665.10254\n",
      "Epoch 10432: train_loss=645.89435, val_loss=665.04791\n",
      "Epoch 10433: train_loss=645.83923, val_loss=665.00299\n",
      "Epoch 10434: train_loss=645.78455, val_loss=664.95258\n",
      "Epoch 10435: train_loss=645.73169, val_loss=664.90942\n",
      "Epoch 10436: train_loss=645.67969, val_loss=664.85791\n",
      "Epoch 10437: train_loss=645.62732, val_loss=664.81311\n",
      "Epoch 10438: train_loss=645.57623, val_loss=664.76038\n",
      "Epoch 10439: train_loss=645.52307, val_loss=664.71454\n",
      "Epoch 10440: train_loss=645.46991, val_loss=664.65845\n",
      "Epoch 10441: train_loss=645.41156, val_loss=664.60510\n",
      "Epoch 10442: train_loss=645.35168, val_loss=664.53998\n",
      "Epoch 10443: train_loss=645.28650, val_loss=664.47809\n",
      "Epoch 10444: train_loss=645.21930, val_loss=664.40881\n",
      "Epoch 10445: train_loss=645.14844, val_loss=664.34418\n",
      "Epoch 10446: train_loss=645.07733, val_loss=664.27661\n",
      "Epoch 10447: train_loss=645.00647, val_loss=664.21216\n",
      "Epoch 10448: train_loss=644.93610, val_loss=664.14429\n",
      "Epoch 10449: train_loss=644.86694, val_loss=664.08228\n",
      "Epoch 10450: train_loss=644.80060, val_loss=664.02319\n",
      "Epoch 10451: train_loss=644.73767, val_loss=663.96973\n",
      "Epoch 10452: train_loss=644.67847, val_loss=663.91766\n",
      "Epoch 10453: train_loss=644.62219, val_loss=663.86597\n",
      "Epoch 10454: train_loss=644.56818, val_loss=663.81616\n",
      "Epoch 10455: train_loss=644.51599, val_loss=663.76660\n",
      "Epoch 10456: train_loss=644.46466, val_loss=663.72156\n",
      "Epoch 10457: train_loss=644.41486, val_loss=663.68018\n",
      "Epoch 10458: train_loss=644.36780, val_loss=663.63953\n",
      "Epoch 10459: train_loss=644.32465, val_loss=663.60370\n",
      "Epoch 10460: train_loss=644.28528, val_loss=663.56927\n",
      "Epoch 10461: train_loss=644.25208, val_loss=663.54437\n",
      "Epoch 10462: train_loss=644.22223, val_loss=663.51764\n",
      "Epoch 10463: train_loss=644.19543, val_loss=663.49524\n",
      "Epoch 10464: train_loss=644.16669, val_loss=663.45654\n",
      "Epoch 10465: train_loss=644.13025, val_loss=663.41632\n",
      "Epoch 10466: train_loss=644.08392, val_loss=663.35010\n",
      "Epoch 10467: train_loss=644.02148, val_loss=663.28076\n",
      "Epoch 10468: train_loss=643.94452, val_loss=663.18817\n",
      "Epoch 10469: train_loss=643.85370, val_loss=663.09552\n",
      "Epoch 10470: train_loss=643.75415, val_loss=662.99677\n",
      "Epoch 10471: train_loss=643.65601, val_loss=662.91107\n",
      "Epoch 10472: train_loss=643.56451, val_loss=662.82996\n",
      "Epoch 10473: train_loss=643.48364, val_loss=662.76520\n",
      "Epoch 10474: train_loss=643.41449, val_loss=662.70917\n",
      "Epoch 10475: train_loss=643.35498, val_loss=662.66046\n",
      "Epoch 10476: train_loss=643.30261, val_loss=662.61865\n",
      "Epoch 10477: train_loss=643.25513, val_loss=662.57458\n",
      "Epoch 10478: train_loss=643.20978, val_loss=662.53735\n",
      "Epoch 10479: train_loss=643.16632, val_loss=662.49237\n",
      "Epoch 10480: train_loss=643.12183, val_loss=662.45349\n",
      "Epoch 10481: train_loss=643.07605, val_loss=662.40234\n",
      "Epoch 10482: train_loss=643.02710, val_loss=662.35809\n",
      "Epoch 10483: train_loss=642.97485, val_loss=662.29797\n",
      "Epoch 10484: train_loss=642.91937, val_loss=662.24573\n",
      "Epoch 10485: train_loss=642.85999, val_loss=662.18085\n",
      "Epoch 10486: train_loss=642.79962, val_loss=662.12622\n",
      "Epoch 10487: train_loss=642.73621, val_loss=662.06061\n",
      "Epoch 10488: train_loss=642.67291, val_loss=662.00470\n",
      "Epoch 10489: train_loss=642.60876, val_loss=661.93835\n",
      "Epoch 10490: train_loss=642.54456, val_loss=661.88141\n",
      "Epoch 10491: train_loss=642.48096, val_loss=661.81641\n",
      "Epoch 10492: train_loss=642.41754, val_loss=661.76172\n",
      "Epoch 10493: train_loss=642.35559, val_loss=661.70062\n",
      "Epoch 10494: train_loss=642.29431, val_loss=661.64673\n",
      "Epoch 10495: train_loss=642.23401, val_loss=661.58618\n",
      "Epoch 10496: train_loss=642.17438, val_loss=661.53339\n",
      "Epoch 10497: train_loss=642.11603, val_loss=661.47528\n",
      "Epoch 10498: train_loss=642.05811, val_loss=661.42267\n",
      "Epoch 10499: train_loss=642.00024, val_loss=661.36603\n",
      "Epoch 10500: train_loss=641.94287, val_loss=661.31360\n",
      "Epoch 10501: train_loss=641.88556, val_loss=661.25726\n",
      "Epoch 10502: train_loss=641.82910, val_loss=661.20581\n",
      "Epoch 10503: train_loss=641.77319, val_loss=661.15216\n",
      "Epoch 10504: train_loss=641.71881, val_loss=661.10779\n",
      "Epoch 10505: train_loss=641.66595, val_loss=661.05841\n",
      "Epoch 10506: train_loss=641.61615, val_loss=661.02124\n",
      "Epoch 10507: train_loss=641.56909, val_loss=660.97644\n",
      "Epoch 10508: train_loss=641.52814, val_loss=660.95276\n",
      "Epoch 10509: train_loss=641.49207, val_loss=660.91669\n",
      "Epoch 10510: train_loss=641.46368, val_loss=660.90747\n",
      "Epoch 10511: train_loss=641.43756, val_loss=660.87207\n",
      "Epoch 10512: train_loss=641.41266, val_loss=660.86212\n",
      "Epoch 10513: train_loss=641.38251, val_loss=660.80902\n",
      "Epoch 10514: train_loss=641.34497, val_loss=660.78070\n",
      "Epoch 10515: train_loss=641.29553, val_loss=660.70135\n",
      "Epoch 10516: train_loss=641.23187, val_loss=660.64587\n",
      "Epoch 10517: train_loss=641.15533, val_loss=660.54462\n",
      "Epoch 10518: train_loss=641.06836, val_loss=660.46667\n",
      "Epoch 10519: train_loss=640.97552, val_loss=660.36072\n",
      "Epoch 10520: train_loss=640.88287, val_loss=660.28253\n",
      "Epoch 10521: train_loss=640.79694, val_loss=660.20007\n",
      "Epoch 10522: train_loss=640.72137, val_loss=660.13867\n",
      "Epoch 10523: train_loss=640.65631, val_loss=660.08148\n",
      "Epoch 10524: train_loss=640.59961, val_loss=660.02863\n",
      "Epoch 10525: train_loss=640.54901, val_loss=659.98627\n",
      "Epoch 10526: train_loss=640.50305, val_loss=659.93646\n",
      "Epoch 10527: train_loss=640.45929, val_loss=659.90228\n",
      "Epoch 10528: train_loss=640.41681, val_loss=659.84985\n",
      "Epoch 10529: train_loss=640.37524, val_loss=659.81500\n",
      "Epoch 10530: train_loss=640.33118, val_loss=659.75433\n",
      "Epoch 10531: train_loss=640.28503, val_loss=659.71576\n",
      "Epoch 10532: train_loss=640.23480, val_loss=659.64722\n",
      "Epoch 10533: train_loss=640.18231, val_loss=659.60406\n",
      "Epoch 10534: train_loss=640.12524, val_loss=659.53131\n",
      "Epoch 10535: train_loss=640.06720, val_loss=659.48523\n",
      "Epoch 10536: train_loss=640.00537, val_loss=659.41168\n",
      "Epoch 10537: train_loss=639.94507, val_loss=659.36377\n",
      "Epoch 10538: train_loss=639.88275, val_loss=659.29114\n",
      "Epoch 10539: train_loss=639.82233, val_loss=659.24188\n",
      "Epoch 10540: train_loss=639.76086, val_loss=659.17163\n",
      "Epoch 10541: train_loss=639.70117, val_loss=659.12201\n",
      "Epoch 10542: train_loss=639.64130, val_loss=659.05585\n",
      "Epoch 10543: train_loss=639.58313, val_loss=659.00836\n",
      "Epoch 10544: train_loss=639.52502, val_loss=658.94672\n",
      "Epoch 10545: train_loss=639.46844, val_loss=658.90009\n",
      "Epoch 10546: train_loss=639.41205, val_loss=658.83820\n",
      "Epoch 10547: train_loss=639.35693, val_loss=658.78967\n",
      "Epoch 10548: train_loss=639.30225, val_loss=658.72821\n",
      "Epoch 10549: train_loss=639.24884, val_loss=658.68188\n",
      "Epoch 10550: train_loss=639.19525, val_loss=658.62292\n",
      "Epoch 10551: train_loss=639.14355, val_loss=658.58032\n",
      "Epoch 10552: train_loss=639.09271, val_loss=658.52338\n",
      "Epoch 10553: train_loss=639.04504, val_loss=658.48834\n",
      "Epoch 10554: train_loss=638.99915, val_loss=658.43561\n",
      "Epoch 10555: train_loss=638.95898, val_loss=658.41193\n",
      "Epoch 10556: train_loss=638.92145, val_loss=658.36353\n",
      "Epoch 10557: train_loss=638.88940, val_loss=658.35449\n",
      "Epoch 10558: train_loss=638.86047, val_loss=658.30579\n",
      "Epoch 10559: train_loss=638.83319, val_loss=658.29755\n",
      "Epoch 10560: train_loss=638.80145, val_loss=658.23590\n",
      "Epoch 10561: train_loss=638.76593, val_loss=658.21320\n",
      "Epoch 10562: train_loss=638.71576, val_loss=658.12897\n",
      "Epoch 10563: train_loss=638.65833, val_loss=658.08221\n",
      "Epoch 10564: train_loss=638.58423, val_loss=657.97772\n",
      "Epoch 10565: train_loss=638.50427, val_loss=657.91486\n",
      "Epoch 10566: train_loss=638.41901, val_loss=657.81171\n",
      "Epoch 10567: train_loss=638.33429, val_loss=657.74921\n",
      "Epoch 10568: train_loss=638.25586, val_loss=657.67096\n",
      "Epoch 10569: train_loss=638.18463, val_loss=657.61884\n",
      "Epoch 10570: train_loss=638.12280, val_loss=657.56830\n",
      "Epoch 10571: train_loss=638.06934, val_loss=657.51929\n",
      "Epoch 10572: train_loss=638.02167, val_loss=657.48315\n",
      "Epoch 10573: train_loss=637.97748, val_loss=657.43036\n",
      "Epoch 10574: train_loss=637.93463, val_loss=657.40070\n",
      "Epoch 10575: train_loss=637.89215, val_loss=657.34241\n",
      "Epoch 10576: train_loss=637.84802, val_loss=657.31250\n",
      "Epoch 10577: train_loss=637.80133, val_loss=657.24829\n",
      "Epoch 10578: train_loss=637.75348, val_loss=657.21625\n",
      "Epoch 10579: train_loss=637.70221, val_loss=657.14972\n",
      "Epoch 10580: train_loss=637.65088, val_loss=657.11688\n",
      "Epoch 10581: train_loss=637.59662, val_loss=657.04706\n",
      "Epoch 10582: train_loss=637.54150, val_loss=657.00836\n",
      "Epoch 10583: train_loss=637.48492, val_loss=656.93579\n",
      "Epoch 10584: train_loss=637.42847, val_loss=656.89246\n",
      "Epoch 10585: train_loss=637.37085, val_loss=656.82202\n",
      "Epoch 10586: train_loss=637.31342, val_loss=656.77838\n",
      "Epoch 10587: train_loss=637.25586, val_loss=656.71344\n",
      "Epoch 10588: train_loss=637.19904, val_loss=656.66705\n",
      "Epoch 10589: train_loss=637.14270, val_loss=656.60577\n",
      "Epoch 10590: train_loss=637.08789, val_loss=656.55847\n",
      "Epoch 10591: train_loss=637.03394, val_loss=656.50336\n",
      "Epoch 10592: train_loss=636.98077, val_loss=656.45465\n",
      "Epoch 10593: train_loss=636.92834, val_loss=656.40173\n",
      "Epoch 10594: train_loss=636.87640, val_loss=656.34985\n",
      "Epoch 10595: train_loss=636.82489, val_loss=656.29962\n",
      "Epoch 10596: train_loss=636.77362, val_loss=656.24731\n",
      "Epoch 10597: train_loss=636.72290, val_loss=656.20209\n",
      "Epoch 10598: train_loss=636.67297, val_loss=656.14996\n",
      "Epoch 10599: train_loss=636.62384, val_loss=656.10986\n",
      "Epoch 10600: train_loss=636.57611, val_loss=656.05640\n",
      "Epoch 10601: train_loss=636.53064, val_loss=656.02661\n",
      "Epoch 10602: train_loss=636.48755, val_loss=655.97327\n",
      "Epoch 10603: train_loss=636.44934, val_loss=655.96008\n",
      "Epoch 10604: train_loss=636.41534, val_loss=655.90997\n",
      "Epoch 10605: train_loss=636.38873, val_loss=655.91876\n",
      "Epoch 10606: train_loss=636.36664, val_loss=655.86987\n",
      "Epoch 10607: train_loss=636.35059, val_loss=655.89520\n",
      "Epoch 10608: train_loss=636.33453, val_loss=655.83264\n",
      "Epoch 10609: train_loss=636.31561, val_loss=655.84821\n",
      "Epoch 10610: train_loss=636.28345, val_loss=655.75342\n",
      "Epoch 10611: train_loss=636.23700, val_loss=655.73853\n",
      "Epoch 10612: train_loss=636.17212, val_loss=655.61340\n",
      "Epoch 10613: train_loss=636.09235, val_loss=655.56366\n",
      "Epoch 10614: train_loss=635.99976, val_loss=655.42963\n",
      "Epoch 10615: train_loss=635.90344, val_loss=655.36407\n",
      "Epoch 10616: train_loss=635.80933, val_loss=655.25964\n",
      "Epoch 10617: train_loss=635.72638, val_loss=655.20343\n",
      "Epoch 10618: train_loss=635.65631, val_loss=655.14233\n",
      "Epoch 10619: train_loss=635.59894, val_loss=655.09369\n",
      "Epoch 10620: train_loss=635.55182, val_loss=655.06268\n",
      "Epoch 10621: train_loss=635.51117, val_loss=655.01044\n",
      "Epoch 10622: train_loss=635.47491, val_loss=654.99725\n",
      "Epoch 10623: train_loss=635.44055, val_loss=654.93884\n",
      "Epoch 10624: train_loss=635.40533, val_loss=654.92877\n",
      "Epoch 10625: train_loss=635.36487, val_loss=654.85687\n",
      "Epoch 10626: train_loss=635.32227, val_loss=654.84033\n",
      "Epoch 10627: train_loss=635.27307, val_loss=654.75568\n",
      "Epoch 10628: train_loss=635.22070, val_loss=654.73083\n",
      "Epoch 10629: train_loss=635.16339, val_loss=654.64423\n",
      "Epoch 10630: train_loss=635.10455, val_loss=654.61176\n",
      "Epoch 10631: train_loss=635.04285, val_loss=654.52820\n",
      "Epoch 10632: train_loss=634.98279, val_loss=654.48889\n",
      "Epoch 10633: train_loss=634.92206, val_loss=654.41449\n",
      "Epoch 10634: train_loss=634.86359, val_loss=654.37238\n",
      "Epoch 10635: train_loss=634.80652, val_loss=654.30884\n",
      "Epoch 10636: train_loss=634.75189, val_loss=654.26276\n",
      "Epoch 10637: train_loss=634.69940, val_loss=654.20923\n",
      "Epoch 10638: train_loss=634.64880, val_loss=654.15955\n",
      "Epoch 10639: train_loss=634.59937, val_loss=654.11609\n",
      "Epoch 10640: train_loss=634.55084, val_loss=654.06549\n",
      "Epoch 10641: train_loss=634.50305, val_loss=654.02917\n",
      "Epoch 10642: train_loss=634.45599, val_loss=653.97418\n",
      "Epoch 10643: train_loss=634.40997, val_loss=653.94452\n",
      "Epoch 10644: train_loss=634.36530, val_loss=653.88464\n",
      "Epoch 10645: train_loss=634.32233, val_loss=653.86548\n",
      "Epoch 10646: train_loss=634.28143, val_loss=653.80383\n",
      "Epoch 10647: train_loss=634.24377, val_loss=653.79944\n",
      "Epoch 10648: train_loss=634.20685, val_loss=653.73315\n",
      "Epoch 10649: train_loss=634.17249, val_loss=653.74097\n",
      "Epoch 10650: train_loss=634.13824, val_loss=653.66760\n",
      "Epoch 10651: train_loss=634.10535, val_loss=653.68329\n",
      "Epoch 10652: train_loss=634.07178, val_loss=653.59979\n",
      "Epoch 10653: train_loss=634.03729, val_loss=653.61414\n",
      "Epoch 10654: train_loss=633.99744, val_loss=653.51636\n",
      "Epoch 10655: train_loss=633.95312, val_loss=653.52026\n",
      "Epoch 10656: train_loss=633.90094, val_loss=653.41089\n",
      "Epoch 10657: train_loss=633.84436, val_loss=653.40137\n",
      "Epoch 10658: train_loss=633.78094, val_loss=653.28735\n",
      "Epoch 10659: train_loss=633.71326, val_loss=653.26245\n",
      "Epoch 10660: train_loss=633.64282, val_loss=653.15570\n",
      "Epoch 10661: train_loss=633.57214, val_loss=653.11871\n",
      "Epoch 10662: train_loss=633.50281, val_loss=653.03058\n",
      "Epoch 10663: train_loss=633.43872, val_loss=652.98779\n",
      "Epoch 10664: train_loss=633.37854, val_loss=652.92438\n",
      "Epoch 10665: train_loss=633.32355, val_loss=652.87750\n",
      "Epoch 10666: train_loss=633.27325, val_loss=652.83600\n",
      "Epoch 10667: train_loss=633.22650, val_loss=652.78326\n",
      "Epoch 10668: train_loss=633.18231, val_loss=652.75555\n",
      "Epoch 10669: train_loss=633.13940, val_loss=652.69550\n",
      "Epoch 10670: train_loss=633.09845, val_loss=652.67828\n",
      "Epoch 10671: train_loss=633.05701, val_loss=652.61194\n",
      "Epoch 10672: train_loss=633.01801, val_loss=652.60785\n",
      "Epoch 10673: train_loss=632.97949, val_loss=652.53827\n",
      "Epoch 10674: train_loss=632.94464, val_loss=652.54779\n",
      "Epoch 10675: train_loss=632.90973, val_loss=652.47144\n",
      "Epoch 10676: train_loss=632.87805, val_loss=652.49127\n",
      "Epoch 10677: train_loss=632.84369, val_loss=652.40698\n",
      "Epoch 10678: train_loss=632.81079, val_loss=652.43182\n",
      "Epoch 10679: train_loss=632.77161, val_loss=652.33191\n",
      "Epoch 10680: train_loss=632.72992, val_loss=652.34613\n",
      "Epoch 10681: train_loss=632.67871, val_loss=652.23096\n",
      "Epoch 10682: train_loss=632.62469, val_loss=652.22601\n",
      "Epoch 10683: train_loss=632.56012, val_loss=652.10779\n",
      "Epoch 10684: train_loss=632.49554, val_loss=652.08850\n",
      "Epoch 10685: train_loss=632.42468, val_loss=651.97913\n",
      "Epoch 10686: train_loss=632.35626, val_loss=651.94751\n",
      "Epoch 10687: train_loss=632.28833, val_loss=651.85883\n",
      "Epoch 10688: train_loss=632.22516, val_loss=651.81848\n",
      "Epoch 10689: train_loss=632.16656, val_loss=651.75665\n",
      "Epoch 10690: train_loss=632.11310, val_loss=651.70825\n",
      "Epoch 10691: train_loss=632.06427, val_loss=651.66968\n",
      "Epoch 10692: train_loss=632.01953, val_loss=651.61359\n",
      "Epoch 10693: train_loss=631.97760, val_loss=651.59393\n",
      "Epoch 10694: train_loss=631.93793, val_loss=651.53040\n",
      "Epoch 10695: train_loss=631.89838, val_loss=651.52472\n",
      "Epoch 10696: train_loss=631.85962, val_loss=651.45264\n",
      "Epoch 10697: train_loss=631.82111, val_loss=651.45319\n",
      "Epoch 10698: train_loss=631.78247, val_loss=651.37140\n",
      "Epoch 10699: train_loss=631.74341, val_loss=651.37811\n",
      "Epoch 10700: train_loss=631.70282, val_loss=651.29108\n",
      "Epoch 10701: train_loss=631.66107, val_loss=651.29889\n",
      "Epoch 10702: train_loss=631.61584, val_loss=651.20410\n",
      "Epoch 10703: train_loss=631.56964, val_loss=651.20575\n",
      "Epoch 10704: train_loss=631.51935, val_loss=651.10614\n",
      "Epoch 10705: train_loss=631.46790, val_loss=651.09875\n",
      "Epoch 10706: train_loss=631.41217, val_loss=651.00085\n",
      "Epoch 10707: train_loss=631.35675, val_loss=650.98480\n",
      "Epoch 10708: train_loss=631.29926, val_loss=650.89185\n",
      "Epoch 10709: train_loss=631.24188, val_loss=650.86475\n",
      "Epoch 10710: train_loss=631.18420, val_loss=650.78375\n",
      "Epoch 10711: train_loss=631.12878, val_loss=650.75043\n",
      "Epoch 10712: train_loss=631.07465, val_loss=650.68665\n",
      "Epoch 10713: train_loss=631.02264, val_loss=650.64758\n",
      "Epoch 10714: train_loss=630.97253, val_loss=650.59662\n",
      "Epoch 10715: train_loss=630.92407, val_loss=650.54852\n",
      "Epoch 10716: train_loss=630.87677, val_loss=650.50598\n",
      "Epoch 10717: train_loss=630.83057, val_loss=650.45331\n",
      "Epoch 10718: train_loss=630.78546, val_loss=650.42426\n",
      "Epoch 10719: train_loss=630.74127, val_loss=650.36676\n",
      "Epoch 10720: train_loss=630.69843, val_loss=650.34882\n",
      "Epoch 10721: train_loss=630.65753, val_loss=650.28320\n",
      "Epoch 10722: train_loss=630.62067, val_loss=650.28625\n",
      "Epoch 10723: train_loss=630.58765, val_loss=650.21735\n",
      "Epoch 10724: train_loss=630.56140, val_loss=650.25403\n",
      "Epoch 10725: train_loss=630.54138, val_loss=650.17926\n",
      "Epoch 10726: train_loss=630.52826, val_loss=650.25055\n",
      "Epoch 10727: train_loss=630.52216, val_loss=650.16010\n",
      "Epoch 10728: train_loss=630.51471, val_loss=650.24908\n",
      "Epoch 10729: train_loss=630.50604, val_loss=650.12628\n",
      "Epoch 10730: train_loss=630.48199, val_loss=650.19727\n",
      "Epoch 10731: train_loss=630.44489, val_loss=650.03162\n",
      "Epoch 10732: train_loss=630.38177, val_loss=650.05139\n",
      "Epoch 10733: train_loss=630.30090, val_loss=649.86169\n",
      "Epoch 10734: train_loss=630.20117, val_loss=649.83398\n",
      "Epoch 10735: train_loss=630.09839, val_loss=649.67743\n",
      "Epoch 10736: train_loss=630.00140, val_loss=649.63531\n",
      "Epoch 10737: train_loss=629.91809, val_loss=649.54980\n",
      "Epoch 10738: train_loss=629.85211, val_loss=649.50574\n",
      "Epoch 10739: train_loss=629.80316, val_loss=649.48462\n",
      "Epoch 10740: train_loss=629.76678, val_loss=649.42816\n",
      "Epoch 10741: train_loss=629.73694, val_loss=649.43793\n",
      "Epoch 10742: train_loss=629.70819, val_loss=649.36108\n",
      "Epoch 10743: train_loss=629.67792, val_loss=649.37585\n",
      "Epoch 10744: train_loss=629.64111, val_loss=649.27875\n",
      "Epoch 10745: train_loss=629.59906, val_loss=649.28400\n",
      "Epoch 10746: train_loss=629.54889, val_loss=649.17688\n",
      "Epoch 10747: train_loss=629.49390, val_loss=649.16595\n",
      "Epoch 10748: train_loss=629.43433, val_loss=649.06635\n",
      "Epoch 10749: train_loss=629.37488, val_loss=649.04285\n",
      "Epoch 10750: train_loss=629.31586, val_loss=648.96259\n",
      "Epoch 10751: train_loss=629.26007, val_loss=648.92694\n",
      "Epoch 10752: train_loss=629.20740, val_loss=648.86951\n",
      "Epoch 10753: train_loss=629.15808, val_loss=648.82379\n",
      "Epoch 10754: train_loss=629.11218, val_loss=648.78613\n",
      "Epoch 10755: train_loss=629.06830, val_loss=648.73151\n",
      "Epoch 10756: train_loss=629.02612, val_loss=648.71057\n",
      "Epoch 10757: train_loss=628.98517, val_loss=648.64697\n",
      "Epoch 10758: train_loss=628.94464, val_loss=648.63715\n",
      "Epoch 10759: train_loss=628.90503, val_loss=648.56415\n",
      "Epoch 10760: train_loss=628.86609, val_loss=648.56525\n",
      "Epoch 10761: train_loss=628.82849, val_loss=648.48425\n",
      "Epoch 10762: train_loss=628.79138, val_loss=648.49829\n",
      "Epoch 10763: train_loss=628.75580, val_loss=648.40936\n",
      "Epoch 10764: train_loss=628.72003, val_loss=648.43219\n",
      "Epoch 10765: train_loss=628.68323, val_loss=648.33374\n",
      "Epoch 10766: train_loss=628.64478, val_loss=648.35718\n",
      "Epoch 10767: train_loss=628.60266, val_loss=648.25146\n",
      "Epoch 10768: train_loss=628.55933, val_loss=648.26935\n",
      "Epoch 10769: train_loss=628.51068, val_loss=648.15912\n",
      "Epoch 10770: train_loss=628.46173, val_loss=648.16833\n",
      "Epoch 10771: train_loss=628.40918, val_loss=648.05780\n",
      "Epoch 10772: train_loss=628.35657, val_loss=648.05896\n",
      "Epoch 10773: train_loss=628.30219, val_loss=647.95276\n",
      "Epoch 10774: train_loss=628.24664, val_loss=647.94409\n",
      "Epoch 10775: train_loss=628.19128, val_loss=647.84851\n",
      "Epoch 10776: train_loss=628.13574, val_loss=647.83136\n",
      "Epoch 10777: train_loss=628.08167, val_loss=647.74988\n",
      "Epoch 10778: train_loss=628.02753, val_loss=647.72394\n",
      "Epoch 10779: train_loss=627.97528, val_loss=647.65924\n",
      "Epoch 10780: train_loss=627.92468, val_loss=647.62415\n",
      "Epoch 10781: train_loss=627.87604, val_loss=647.57324\n",
      "Epoch 10782: train_loss=627.82904, val_loss=647.52869\n",
      "Epoch 10783: train_loss=627.78308, val_loss=647.48755\n",
      "Epoch 10784: train_loss=627.73773, val_loss=647.43707\n",
      "Epoch 10785: train_loss=627.69312, val_loss=647.40717\n",
      "Epoch 10786: train_loss=627.64862, val_loss=647.35187\n",
      "Epoch 10787: train_loss=627.60504, val_loss=647.33356\n",
      "Epoch 10788: train_loss=627.56287, val_loss=647.27087\n",
      "Epoch 10789: train_loss=627.52325, val_loss=647.27136\n",
      "Epoch 10790: train_loss=627.48700, val_loss=647.20111\n",
      "Epoch 10791: train_loss=627.45471, val_loss=647.22729\n",
      "Epoch 10792: train_loss=627.42719, val_loss=647.14618\n",
      "Epoch 10793: train_loss=627.40582, val_loss=647.20166\n",
      "Epoch 10794: train_loss=627.38733, val_loss=647.10809\n",
      "Epoch 10795: train_loss=627.37335, val_loss=647.18939\n",
      "Epoch 10796: train_loss=627.35809, val_loss=647.07532\n",
      "Epoch 10797: train_loss=627.34125, val_loss=647.15979\n",
      "Epoch 10798: train_loss=627.31555, val_loss=647.01257\n",
      "Epoch 10799: train_loss=627.27777, val_loss=647.07275\n",
      "Epoch 10800: train_loss=627.22388, val_loss=646.89874\n",
      "Epoch 10801: train_loss=627.15466, val_loss=646.91687\n",
      "Epoch 10802: train_loss=627.07147, val_loss=646.74408\n",
      "Epoch 10803: train_loss=626.98486, val_loss=646.73010\n",
      "Epoch 10804: train_loss=626.89752, val_loss=646.59497\n",
      "Epoch 10805: train_loss=626.81787, val_loss=646.56659\n",
      "Epoch 10806: train_loss=626.74841, val_loss=646.48889\n",
      "Epoch 10807: train_loss=626.69000, val_loss=646.44843\n",
      "Epoch 10808: train_loss=626.64221, val_loss=646.41888\n",
      "Epoch 10809: train_loss=626.60223, val_loss=646.36206\n",
      "Epoch 10810: train_loss=626.56732, val_loss=646.36462\n",
      "Epoch 10811: train_loss=626.53479, val_loss=646.29083\n",
      "Epoch 10812: train_loss=626.50208, val_loss=646.31018\n",
      "Epoch 10813: train_loss=626.46802, val_loss=646.21985\n",
      "Epoch 10814: train_loss=626.43237, val_loss=646.24109\n",
      "Epoch 10815: train_loss=626.39227, val_loss=646.13879\n",
      "Epoch 10816: train_loss=626.35034, val_loss=646.15747\n",
      "Epoch 10817: train_loss=626.30286, val_loss=646.05145\n",
      "Epoch 10818: train_loss=626.25458, val_loss=646.06104\n",
      "Epoch 10819: train_loss=626.20251, val_loss=645.95459\n",
      "Epoch 10820: train_loss=626.14990, val_loss=645.95135\n",
      "Epoch 10821: train_loss=626.09558, val_loss=645.85492\n",
      "Epoch 10822: train_loss=626.04169, val_loss=645.83984\n",
      "Epoch 10823: train_loss=625.98828, val_loss=645.76080\n",
      "Epoch 10824: train_loss=625.93646, val_loss=645.73364\n",
      "Epoch 10825: train_loss=625.88654, val_loss=645.67194\n",
      "Epoch 10826: train_loss=625.83862, val_loss=645.63428\n",
      "Epoch 10827: train_loss=625.79224, val_loss=645.58752\n",
      "Epoch 10828: train_loss=625.74719, val_loss=645.54163\n",
      "Epoch 10829: train_loss=625.70294, val_loss=645.50720\n",
      "Epoch 10830: train_loss=625.65967, val_loss=645.45270\n",
      "Epoch 10831: train_loss=625.61682, val_loss=645.42920\n",
      "Epoch 10832: train_loss=625.57452, val_loss=645.36792\n",
      "Epoch 10833: train_loss=625.53296, val_loss=645.35632\n",
      "Epoch 10834: train_loss=625.49219, val_loss=645.28870\n",
      "Epoch 10835: train_loss=625.45282, val_loss=645.29120\n",
      "Epoch 10836: train_loss=625.41479, val_loss=645.21381\n",
      "Epoch 10837: train_loss=625.37988, val_loss=645.23389\n",
      "Epoch 10838: train_loss=625.34662, val_loss=645.14661\n",
      "Epoch 10839: train_loss=625.31726, val_loss=645.18915\n",
      "Epoch 10840: train_loss=625.28912, val_loss=645.09021\n",
      "Epoch 10841: train_loss=625.26489, val_loss=645.15326\n",
      "Epoch 10842: train_loss=625.23987, val_loss=645.03931\n",
      "Epoch 10843: train_loss=625.21704, val_loss=645.11444\n",
      "Epoch 10844: train_loss=625.18811, val_loss=644.98096\n",
      "Epoch 10845: train_loss=625.15698, val_loss=645.05225\n",
      "Epoch 10846: train_loss=625.11591, val_loss=644.89795\n",
      "Epoch 10847: train_loss=625.06805, val_loss=644.94556\n",
      "Epoch 10848: train_loss=625.00861, val_loss=644.78204\n",
      "Epoch 10849: train_loss=624.94409, val_loss=644.80182\n",
      "Epoch 10850: train_loss=624.87146, val_loss=644.64990\n",
      "Epoch 10851: train_loss=624.79761, val_loss=644.64386\n",
      "Epoch 10852: train_loss=624.72443, val_loss=644.52618\n",
      "Epoch 10853: train_loss=624.65686, val_loss=644.50018\n",
      "Epoch 10854: train_loss=624.59564, val_loss=644.43060\n",
      "Epoch 10855: train_loss=624.54193, val_loss=644.38892\n",
      "Epoch 10856: train_loss=624.49542, val_loss=644.36072\n",
      "Epoch 10857: train_loss=624.45398, val_loss=644.29993\n",
      "Epoch 10858: train_loss=624.41589, val_loss=644.29681\n",
      "Epoch 10859: train_loss=624.37909, val_loss=644.21729\n",
      "Epoch 10860: train_loss=624.34302, val_loss=644.23206\n",
      "Epoch 10861: train_loss=624.30603, val_loss=644.14081\n",
      "Epoch 10862: train_loss=624.26978, val_loss=644.16821\n",
      "Epoch 10863: train_loss=624.23151, val_loss=644.06305\n",
      "Epoch 10864: train_loss=624.19312, val_loss=644.09613\n",
      "Epoch 10865: train_loss=624.15192, val_loss=643.97888\n",
      "Epoch 10866: train_loss=624.10986, val_loss=644.01331\n",
      "Epoch 10867: train_loss=624.06464, val_loss=643.88733\n",
      "Epoch 10868: train_loss=624.01794, val_loss=643.91589\n",
      "Epoch 10869: train_loss=623.96649, val_loss=643.78497\n",
      "Epoch 10870: train_loss=623.91351, val_loss=643.80389\n",
      "Epoch 10871: train_loss=623.85632, val_loss=643.67566\n",
      "Epoch 10872: train_loss=623.79889, val_loss=643.68353\n",
      "Epoch 10873: train_loss=623.73865, val_loss=643.56390\n",
      "Epoch 10874: train_loss=623.67944, val_loss=643.55884\n",
      "Epoch 10875: train_loss=623.61932, val_loss=643.45276\n",
      "Epoch 10876: train_loss=623.55981, val_loss=643.43414\n",
      "Epoch 10877: train_loss=623.50177, val_loss=643.34882\n",
      "Epoch 10878: train_loss=623.44568, val_loss=643.31677\n",
      "Epoch 10879: train_loss=623.39233, val_loss=643.25281\n",
      "Epoch 10880: train_loss=623.34143, val_loss=643.20941\n",
      "Epoch 10881: train_loss=623.29211, val_loss=643.16217\n",
      "Epoch 10882: train_loss=623.24390, val_loss=643.10901\n",
      "Epoch 10883: train_loss=623.19696, val_loss=643.07635\n",
      "Epoch 10884: train_loss=623.15106, val_loss=643.01453\n",
      "Epoch 10885: train_loss=623.10614, val_loss=642.99707\n",
      "Epoch 10886: train_loss=623.06244, val_loss=642.92566\n",
      "Epoch 10887: train_loss=623.02075, val_loss=642.92548\n",
      "Epoch 10888: train_loss=622.98059, val_loss=642.84241\n",
      "Epoch 10889: train_loss=622.94452, val_loss=642.86700\n",
      "Epoch 10890: train_loss=622.91046, val_loss=642.77350\n",
      "Epoch 10891: train_loss=622.88385, val_loss=642.83331\n",
      "Epoch 10892: train_loss=622.86090, val_loss=642.72693\n",
      "Epoch 10893: train_loss=622.84613, val_loss=642.82178\n",
      "Epoch 10894: train_loss=622.83099, val_loss=642.69257\n",
      "Epoch 10895: train_loss=622.81732, val_loss=642.80548\n",
      "Epoch 10896: train_loss=622.79773, val_loss=642.64453\n",
      "Epoch 10897: train_loss=622.77130, val_loss=642.74628\n",
      "Epoch 10898: train_loss=622.72961, val_loss=642.55109\n",
      "Epoch 10899: train_loss=622.67340, val_loss=642.61414\n",
      "Epoch 10900: train_loss=622.60071, val_loss=642.40723\n",
      "Epoch 10901: train_loss=622.51587, val_loss=642.42291\n",
      "Epoch 10902: train_loss=622.42365, val_loss=642.24567\n",
      "Epoch 10903: train_loss=622.33435, val_loss=642.22821\n",
      "Epoch 10904: train_loss=622.25177, val_loss=642.11401\n",
      "Epoch 10905: train_loss=622.18195, val_loss=642.07526\n",
      "Epoch 10906: train_loss=622.12549, val_loss=642.03253\n",
      "Epoch 10907: train_loss=622.08136, val_loss=641.97284\n",
      "Epoch 10908: train_loss=622.04596, val_loss=641.98053\n",
      "Epoch 10909: train_loss=622.01495, val_loss=641.89612\n",
      "Epoch 10910: train_loss=621.98419, val_loss=641.92548\n",
      "Epoch 10911: train_loss=621.95032, val_loss=641.81842\n",
      "Epoch 10912: train_loss=621.91418, val_loss=641.85052\n",
      "Epoch 10913: train_loss=621.87183, val_loss=641.72937\n",
      "Epoch 10914: train_loss=621.82654, val_loss=641.75195\n",
      "Epoch 10915: train_loss=621.77515, val_loss=641.62860\n",
      "Epoch 10916: train_loss=621.72241, val_loss=641.63623\n",
      "Epoch 10917: train_loss=621.66620, val_loss=641.52258\n",
      "Epoch 10918: train_loss=621.61078, val_loss=641.51508\n",
      "Epoch 10919: train_loss=621.55511, val_loss=641.42426\n",
      "Epoch 10920: train_loss=621.50073, val_loss=641.39941\n",
      "Epoch 10921: train_loss=621.44910, val_loss=641.33533\n",
      "Epoch 10922: train_loss=621.40076, val_loss=641.29309\n",
      "Epoch 10923: train_loss=621.35468, val_loss=641.25281\n",
      "Epoch 10924: train_loss=621.31067, val_loss=641.19751\n",
      "Epoch 10925: train_loss=621.26801, val_loss=641.17615\n",
      "Epoch 10926: train_loss=621.22662, val_loss=641.10760\n",
      "Epoch 10927: train_loss=621.18640, val_loss=641.10260\n",
      "Epoch 10928: train_loss=621.14728, val_loss=641.02155\n",
      "Epoch 10929: train_loss=621.11029, val_loss=641.03595\n",
      "Epoch 10930: train_loss=621.07397, val_loss=640.94385\n",
      "Epoch 10931: train_loss=621.04175, val_loss=640.98273\n",
      "Epoch 10932: train_loss=621.01019, val_loss=640.87579\n",
      "Epoch 10933: train_loss=620.98248, val_loss=640.93622\n",
      "Epoch 10934: train_loss=620.95361, val_loss=640.81085\n",
      "Epoch 10935: train_loss=620.92725, val_loss=640.88586\n",
      "Epoch 10936: train_loss=620.89740, val_loss=640.74115\n",
      "Epoch 10937: train_loss=620.86676, val_loss=640.81927\n",
      "Epoch 10938: train_loss=620.82806, val_loss=640.65802\n",
      "Epoch 10939: train_loss=620.78723, val_loss=640.72559\n",
      "Epoch 10940: train_loss=620.73639, val_loss=640.55579\n",
      "Epoch 10941: train_loss=620.68329, val_loss=640.60284\n",
      "Epoch 10942: train_loss=620.62048, val_loss=640.43726\n",
      "Epoch 10943: train_loss=620.55707, val_loss=640.45892\n",
      "Epoch 10944: train_loss=620.48792, val_loss=640.31226\n",
      "Epoch 10945: train_loss=620.42029, val_loss=640.30493\n",
      "Epoch 10946: train_loss=620.35413, val_loss=640.19922\n",
      "Epoch 10947: train_loss=620.29333, val_loss=640.16711\n",
      "Epoch 10948: train_loss=620.23926, val_loss=640.11481\n",
      "Epoch 10949: train_loss=620.19269, val_loss=640.05920\n",
      "Epoch 10950: train_loss=620.15173, val_loss=640.04736\n",
      "Epoch 10951: train_loss=620.11420, val_loss=639.96991\n",
      "Epoch 10952: train_loss=620.07812, val_loss=639.98401\n",
      "Epoch 10953: train_loss=620.04205, val_loss=639.88904\n",
      "Epoch 10954: train_loss=620.00531, val_loss=639.91516\n",
      "Epoch 10955: train_loss=619.96600, val_loss=639.80603\n",
      "Epoch 10956: train_loss=619.92657, val_loss=639.83667\n",
      "Epoch 10957: train_loss=619.88422, val_loss=639.72034\n",
      "Epoch 10958: train_loss=619.84155, val_loss=639.75165\n",
      "Epoch 10959: train_loss=619.79639, val_loss=639.63177\n",
      "Epoch 10960: train_loss=619.75116, val_loss=639.65955\n",
      "Epoch 10961: train_loss=619.70392, val_loss=639.53912\n",
      "Epoch 10962: train_loss=619.65631, val_loss=639.56140\n",
      "Epoch 10963: train_loss=619.60687, val_loss=639.44458\n",
      "Epoch 10964: train_loss=619.55658, val_loss=639.45605\n",
      "Epoch 10965: train_loss=619.50494, val_loss=639.34662\n",
      "Epoch 10966: train_loss=619.45282, val_loss=639.34204\n",
      "Epoch 10967: train_loss=619.40063, val_loss=639.24658\n",
      "Epoch 10968: train_loss=619.34943, val_loss=639.22931\n",
      "Epoch 10969: train_loss=619.29871, val_loss=639.15393\n",
      "Epoch 10970: train_loss=619.24921, val_loss=639.12341\n",
      "Epoch 10971: train_loss=619.20062, val_loss=639.06549\n",
      "Epoch 10972: train_loss=619.15350, val_loss=639.02179\n",
      "Epoch 10973: train_loss=619.10724, val_loss=638.97858\n",
      "Epoch 10974: train_loss=619.06195, val_loss=638.92719\n",
      "Epoch 10975: train_loss=619.01740, val_loss=638.89783\n",
      "Epoch 10976: train_loss=618.97357, val_loss=638.83301\n",
      "Epoch 10977: train_loss=618.93066, val_loss=638.82147\n",
      "Epoch 10978: train_loss=618.88977, val_loss=638.74268\n",
      "Epoch 10979: train_loss=618.85138, val_loss=638.76123\n",
      "Epoch 10980: train_loss=618.81677, val_loss=638.66791\n",
      "Epoch 10981: train_loss=618.78748, val_loss=638.72601\n",
      "Epoch 10982: train_loss=618.76434, val_loss=638.61304\n",
      "Epoch 10983: train_loss=618.74768, val_loss=638.71472\n",
      "Epoch 10984: train_loss=618.73535, val_loss=638.57617\n",
      "Epoch 10985: train_loss=618.72675, val_loss=638.71606\n",
      "Epoch 10986: train_loss=618.71881, val_loss=638.54492\n",
      "Epoch 10987: train_loss=618.70514, val_loss=638.69238\n",
      "Epoch 10988: train_loss=618.68207, val_loss=638.47656\n",
      "Epoch 10989: train_loss=618.64154, val_loss=638.58783\n",
      "Epoch 10990: train_loss=618.58252, val_loss=638.34265\n",
      "Epoch 10991: train_loss=618.50415, val_loss=638.39752\n",
      "Epoch 10992: train_loss=618.41248, val_loss=638.17297\n",
      "Epoch 10993: train_loss=618.31824, val_loss=638.18359\n",
      "Epoch 10994: train_loss=618.22711, val_loss=638.02429\n",
      "Epoch 10995: train_loss=618.14752, val_loss=638.00104\n",
      "Epoch 10996: train_loss=618.08069, val_loss=637.92389\n",
      "Epoch 10997: train_loss=618.02704, val_loss=637.87372\n",
      "Epoch 10998: train_loss=617.98438, val_loss=637.86603\n",
      "Epoch 10999: train_loss=617.94940, val_loss=637.78503\n",
      "Epoch 11000: train_loss=617.91895, val_loss=637.81610\n",
      "Epoch 11001: train_loss=617.88928, val_loss=637.70514\n",
      "Epoch 11002: train_loss=617.86023, val_loss=637.75897\n",
      "Epoch 11003: train_loss=617.82751, val_loss=637.62445\n",
      "Epoch 11004: train_loss=617.79150, val_loss=637.67987\n",
      "Epoch 11005: train_loss=617.74976, val_loss=637.52692\n",
      "Epoch 11006: train_loss=617.70319, val_loss=637.56793\n",
      "Epoch 11007: train_loss=617.65155, val_loss=637.41821\n",
      "Epoch 11008: train_loss=617.59760, val_loss=637.44476\n",
      "Epoch 11009: train_loss=617.54138, val_loss=637.31201\n",
      "Epoch 11010: train_loss=617.48572, val_loss=637.31866\n",
      "Epoch 11011: train_loss=617.42963, val_loss=637.20990\n",
      "Epoch 11012: train_loss=617.37567, val_loss=637.19696\n",
      "Epoch 11013: train_loss=617.32349, val_loss=637.11749\n",
      "Epoch 11014: train_loss=617.27399, val_loss=637.08759\n",
      "Epoch 11015: train_loss=617.22656, val_loss=637.03314\n",
      "Epoch 11016: train_loss=617.18103, val_loss=636.98700\n",
      "Epoch 11017: train_loss=617.13684, val_loss=636.95233\n",
      "Epoch 11018: train_loss=617.09381, val_loss=636.89001\n",
      "Epoch 11019: train_loss=617.05176, val_loss=636.87372\n",
      "Epoch 11020: train_loss=617.01141, val_loss=636.79559\n",
      "Epoch 11021: train_loss=616.97290, val_loss=636.80524\n",
      "Epoch 11022: train_loss=616.93683, val_loss=636.70978\n",
      "Epoch 11023: train_loss=616.90350, val_loss=636.74933\n",
      "Epoch 11024: train_loss=616.87250, val_loss=636.63348\n",
      "Epoch 11025: train_loss=616.84583, val_loss=636.70508\n",
      "Epoch 11026: train_loss=616.81952, val_loss=636.56653\n",
      "Epoch 11027: train_loss=616.79486, val_loss=636.66187\n",
      "Epoch 11028: train_loss=616.76776, val_loss=636.49731\n",
      "Epoch 11029: train_loss=616.73718, val_loss=636.59796\n",
      "Epoch 11030: train_loss=616.70111, val_loss=636.40991\n",
      "Epoch 11031: train_loss=616.65631, val_loss=636.49304\n",
      "Epoch 11032: train_loss=616.60327, val_loss=636.29889\n",
      "Epoch 11033: train_loss=616.54297, val_loss=636.35370\n",
      "Epoch 11034: train_loss=616.47821, val_loss=636.17902\n",
      "Epoch 11035: train_loss=616.41302, val_loss=636.20532\n",
      "Epoch 11036: train_loss=616.34894, val_loss=636.06635\n",
      "Epoch 11037: train_loss=616.28815, val_loss=636.06775\n",
      "Epoch 11038: train_loss=616.23169, val_loss=635.96881\n",
      "Epoch 11039: train_loss=616.17932, val_loss=635.94855\n",
      "Epoch 11040: train_loss=616.12994, val_loss=635.88391\n",
      "Epoch 11041: train_loss=616.08325, val_loss=635.84131\n",
      "Epoch 11042: train_loss=616.03864, val_loss=635.80139\n",
      "Epoch 11043: train_loss=615.99573, val_loss=635.73962\n",
      "Epoch 11044: train_loss=615.95410, val_loss=635.72186\n",
      "Epoch 11045: train_loss=615.91388, val_loss=635.64313\n",
      "Epoch 11046: train_loss=615.87512, val_loss=635.64801\n",
      "Epoch 11047: train_loss=615.83734, val_loss=635.55341\n",
      "Epoch 11048: train_loss=615.80219, val_loss=635.58398\n",
      "Epoch 11049: train_loss=615.76764, val_loss=635.47028\n",
      "Epoch 11050: train_loss=615.73621, val_loss=635.52612\n",
      "Epoch 11051: train_loss=615.70422, val_loss=635.39386\n",
      "Epoch 11052: train_loss=615.67615, val_loss=635.47577\n",
      "Epoch 11053: train_loss=615.64746, val_loss=635.32355\n",
      "Epoch 11054: train_loss=615.62207, val_loss=635.42749\n",
      "Epoch 11055: train_loss=615.59314, val_loss=635.25354\n",
      "Epoch 11056: train_loss=615.56360, val_loss=635.36511\n",
      "Epoch 11057: train_loss=615.52655, val_loss=635.17096\n",
      "Epoch 11058: train_loss=615.48480, val_loss=635.27087\n",
      "Epoch 11059: train_loss=615.43463, val_loss=635.06879\n",
      "Epoch 11060: train_loss=615.38037, val_loss=635.14117\n",
      "Epoch 11061: train_loss=615.31592, val_loss=634.94910\n",
      "Epoch 11062: train_loss=615.25037, val_loss=634.98804\n",
      "Epoch 11063: train_loss=615.18115, val_loss=634.83032\n",
      "Epoch 11064: train_loss=615.11646, val_loss=634.83765\n",
      "Epoch 11065: train_loss=615.05432, val_loss=634.72803\n",
      "Epoch 11066: train_loss=614.99701, val_loss=634.70673\n",
      "Epoch 11067: train_loss=614.94543, val_loss=634.64893\n",
      "Epoch 11068: train_loss=614.89874, val_loss=634.59814\n",
      "Epoch 11069: train_loss=614.85583, val_loss=634.57971\n",
      "Epoch 11070: train_loss=614.81604, val_loss=634.50159\n",
      "Epoch 11071: train_loss=614.77936, val_loss=634.51935\n",
      "Epoch 11072: train_loss=614.74463, val_loss=634.41656\n",
      "Epoch 11073: train_loss=614.71173, val_loss=634.46466\n",
      "Epoch 11074: train_loss=614.67883, val_loss=634.33783\n",
      "Epoch 11075: train_loss=614.64722, val_loss=634.40570\n",
      "Epoch 11076: train_loss=614.61340, val_loss=634.25739\n",
      "Epoch 11077: train_loss=614.57892, val_loss=634.33582\n",
      "Epoch 11078: train_loss=614.54022, val_loss=634.17444\n",
      "Epoch 11079: train_loss=614.50067, val_loss=634.25323\n",
      "Epoch 11080: train_loss=614.45630, val_loss=634.08319\n",
      "Epoch 11081: train_loss=614.41095, val_loss=634.15222\n",
      "Epoch 11082: train_loss=614.36035, val_loss=633.98242\n",
      "Epoch 11083: train_loss=614.30975, val_loss=634.03961\n",
      "Epoch 11084: train_loss=614.25507, val_loss=633.88159\n",
      "Epoch 11085: train_loss=614.20099, val_loss=633.92004\n",
      "Epoch 11086: train_loss=614.14447, val_loss=633.77802\n",
      "Epoch 11087: train_loss=614.08960, val_loss=633.79309\n",
      "Epoch 11088: train_loss=614.03436, val_loss=633.67566\n",
      "Epoch 11089: train_loss=613.98169, val_loss=633.67218\n",
      "Epoch 11090: train_loss=613.93011, val_loss=633.58081\n",
      "Epoch 11091: train_loss=613.88031, val_loss=633.55670\n",
      "Epoch 11092: train_loss=613.83203, val_loss=633.48920\n",
      "Epoch 11093: train_loss=613.78497, val_loss=633.44720\n",
      "Epoch 11094: train_loss=613.73926, val_loss=633.40179\n",
      "Epoch 11095: train_loss=613.69434, val_loss=633.34515\n",
      "Epoch 11096: train_loss=613.65045, val_loss=633.31763\n",
      "Epoch 11097: train_loss=613.60706, val_loss=633.24542\n",
      "Epoch 11098: train_loss=613.56439, val_loss=633.23633\n",
      "Epoch 11099: train_loss=613.52252, val_loss=633.15063\n",
      "Epoch 11100: train_loss=613.48224, val_loss=633.16370\n",
      "Epoch 11101: train_loss=613.44275, val_loss=633.05908\n",
      "Epoch 11102: train_loss=613.40662, val_loss=633.09991\n",
      "Epoch 11103: train_loss=613.37109, val_loss=632.97400\n",
      "Epoch 11104: train_loss=613.33990, val_loss=633.05017\n",
      "Epoch 11105: train_loss=613.30872, val_loss=632.89948\n",
      "Epoch 11106: train_loss=613.28192, val_loss=633.00885\n",
      "Epoch 11107: train_loss=613.25439, val_loss=632.83026\n",
      "Epoch 11108: train_loss=613.22852, val_loss=632.96313\n",
      "Epoch 11109: train_loss=613.19836, val_loss=632.75562\n",
      "Epoch 11110: train_loss=613.16284, val_loss=632.88995\n",
      "Epoch 11111: train_loss=613.11975, val_loss=632.65833\n",
      "Epoch 11112: train_loss=613.06696, val_loss=632.76740\n",
      "Epoch 11113: train_loss=613.00494, val_loss=632.53394\n",
      "Epoch 11114: train_loss=612.93591, val_loss=632.60559\n",
      "Epoch 11115: train_loss=612.86206, val_loss=632.40057\n",
      "Epoch 11116: train_loss=612.78674, val_loss=632.43164\n",
      "Epoch 11117: train_loss=612.71509, val_loss=632.28223\n",
      "Epoch 11118: train_loss=612.64874, val_loss=632.27472\n",
      "Epoch 11119: train_loss=612.58862, val_loss=632.18677\n",
      "Epoch 11120: train_loss=612.53534, val_loss=632.14563\n",
      "Epoch 11121: train_loss=612.48724, val_loss=632.11292\n",
      "Epoch 11122: train_loss=612.44318, val_loss=632.04218\n",
      "Epoch 11123: train_loss=612.40186, val_loss=632.04749\n",
      "Epoch 11124: train_loss=612.36255, val_loss=631.94550\n",
      "Epoch 11125: train_loss=612.32446, val_loss=631.98138\n",
      "Epoch 11126: train_loss=612.28735, val_loss=631.85767\n",
      "Epoch 11127: train_loss=612.25043, val_loss=631.92017\n",
      "Epoch 11128: train_loss=612.21307, val_loss=631.77814\n",
      "Epoch 11129: train_loss=612.17578, val_loss=631.85907\n",
      "Epoch 11130: train_loss=612.13910, val_loss=631.69720\n",
      "Epoch 11131: train_loss=612.10229, val_loss=631.79181\n",
      "Epoch 11132: train_loss=612.06494, val_loss=631.61530\n",
      "Epoch 11133: train_loss=612.02521, val_loss=631.71826\n",
      "Epoch 11134: train_loss=611.98322, val_loss=631.53186\n",
      "Epoch 11135: train_loss=611.93860, val_loss=631.62921\n",
      "Epoch 11136: train_loss=611.89130, val_loss=631.43622\n",
      "Epoch 11137: train_loss=611.84167, val_loss=631.52179\n",
      "Epoch 11138: train_loss=611.78906, val_loss=631.33588\n",
      "Epoch 11139: train_loss=611.73578, val_loss=631.40778\n",
      "Epoch 11140: train_loss=611.67975, val_loss=631.23529\n",
      "Epoch 11141: train_loss=611.62335, val_loss=631.28204\n",
      "Epoch 11142: train_loss=611.56482, val_loss=631.12982\n",
      "Epoch 11143: train_loss=611.50745, val_loss=631.15021\n",
      "Epoch 11144: train_loss=611.45081, val_loss=631.02997\n",
      "Epoch 11145: train_loss=611.39600, val_loss=631.02747\n",
      "Epoch 11146: train_loss=611.34351, val_loss=630.94110\n",
      "Epoch 11147: train_loss=611.29315, val_loss=630.91681\n",
      "Epoch 11148: train_loss=611.24469, val_loss=630.85535\n",
      "Epoch 11149: train_loss=611.19739, val_loss=630.81348\n",
      "Epoch 11150: train_loss=611.15100, val_loss=630.77191\n",
      "Epoch 11151: train_loss=611.10547, val_loss=630.71362\n",
      "Epoch 11152: train_loss=611.06061, val_loss=630.69006\n",
      "Epoch 11153: train_loss=611.01648, val_loss=630.61475\n",
      "Epoch 11154: train_loss=610.97388, val_loss=630.61670\n",
      "Epoch 11155: train_loss=610.93286, val_loss=630.52191\n",
      "Epoch 11156: train_loss=610.89441, val_loss=630.55927\n",
      "Epoch 11157: train_loss=610.85925, val_loss=630.43890\n",
      "Epoch 11158: train_loss=610.82843, val_loss=630.52094\n",
      "Epoch 11159: train_loss=610.80164, val_loss=630.36993\n",
      "Epoch 11160: train_loss=610.77917, val_loss=630.50092\n",
      "Epoch 11161: train_loss=610.76050, val_loss=630.31488\n",
      "Epoch 11162: train_loss=610.74365, val_loss=630.48810\n",
      "Epoch 11163: train_loss=610.72778, val_loss=630.26337\n",
      "Epoch 11164: train_loss=610.70685, val_loss=630.45520\n",
      "Epoch 11165: train_loss=610.68036, val_loss=630.19189\n",
      "Epoch 11166: train_loss=610.64032, val_loss=630.36517\n",
      "Epoch 11167: train_loss=610.58911, val_loss=630.08289\n",
      "Epoch 11168: train_loss=610.52301, val_loss=630.21033\n",
      "Epoch 11169: train_loss=610.44757, val_loss=629.94629\n",
      "Epoch 11170: train_loss=610.36639, val_loss=630.02087\n",
      "Epoch 11171: train_loss=610.28339, val_loss=629.81195\n",
      "Epoch 11172: train_loss=610.20612, val_loss=629.84021\n",
      "Epoch 11173: train_loss=610.13458, val_loss=629.70630\n",
      "Epoch 11174: train_loss=610.07153, val_loss=629.69336\n",
      "Epoch 11175: train_loss=610.01599, val_loss=629.62982\n",
      "Epoch 11176: train_loss=609.96729, val_loss=629.57477\n",
      "Epoch 11177: train_loss=609.92432, val_loss=629.56775\n",
      "Epoch 11178: train_loss=609.88470, val_loss=629.47766\n",
      "Epoch 11179: train_loss=609.84692, val_loss=629.50964\n",
      "Epoch 11180: train_loss=609.81067, val_loss=629.38910\n",
      "Epoch 11181: train_loss=609.77576, val_loss=629.45105\n",
      "Epoch 11182: train_loss=609.74091, val_loss=629.30481\n",
      "Epoch 11183: train_loss=609.70673, val_loss=629.39417\n",
      "Epoch 11184: train_loss=609.67163, val_loss=629.22693\n",
      "Epoch 11185: train_loss=609.63568, val_loss=629.33014\n",
      "Epoch 11186: train_loss=609.59772, val_loss=629.14313\n",
      "Epoch 11187: train_loss=609.55743, val_loss=629.24921\n",
      "Epoch 11188: train_loss=609.51465, val_loss=629.05328\n",
      "Epoch 11189: train_loss=609.46912, val_loss=629.15747\n",
      "Epoch 11190: train_loss=609.42126, val_loss=628.96094\n",
      "Epoch 11191: train_loss=609.36957, val_loss=629.04822\n",
      "Epoch 11192: train_loss=609.31567, val_loss=628.85968\n",
      "Epoch 11193: train_loss=609.26025, val_loss=628.92548\n",
      "Epoch 11194: train_loss=609.20392, val_loss=628.75720\n",
      "Epoch 11195: train_loss=609.14844, val_loss=628.80206\n",
      "Epoch 11196: train_loss=609.09296, val_loss=628.65796\n",
      "Epoch 11197: train_loss=609.03864, val_loss=628.68048\n",
      "Epoch 11198: train_loss=608.98572, val_loss=628.56165\n",
      "Epoch 11199: train_loss=608.93390, val_loss=628.56183\n",
      "Epoch 11200: train_loss=608.88312, val_loss=628.46814\n",
      "Epoch 11201: train_loss=608.83362, val_loss=628.44934\n",
      "Epoch 11202: train_loss=608.78485, val_loss=628.37866\n",
      "Epoch 11203: train_loss=608.73700, val_loss=628.34058\n",
      "Epoch 11204: train_loss=608.68988, val_loss=628.28864\n",
      "Epoch 11205: train_loss=608.64343, val_loss=628.23730\n",
      "Epoch 11206: train_loss=608.59747, val_loss=628.20123\n",
      "Epoch 11207: train_loss=608.55170, val_loss=628.13739\n",
      "Epoch 11208: train_loss=608.50647, val_loss=628.11456\n",
      "Epoch 11209: train_loss=608.46173, val_loss=628.03369\n",
      "Epoch 11210: train_loss=608.41772, val_loss=628.02905\n",
      "Epoch 11211: train_loss=608.37506, val_loss=627.93195\n",
      "Epoch 11212: train_loss=608.33380, val_loss=627.95929\n",
      "Epoch 11213: train_loss=608.29529, val_loss=627.84021\n",
      "Epoch 11214: train_loss=608.25916, val_loss=627.90527\n",
      "Epoch 11215: train_loss=608.22687, val_loss=627.75446\n",
      "Epoch 11216: train_loss=608.19855, val_loss=627.86884\n",
      "Epoch 11217: train_loss=608.17499, val_loss=627.68573\n",
      "Epoch 11218: train_loss=608.15570, val_loss=627.85614\n",
      "Epoch 11219: train_loss=608.13977, val_loss=627.63135\n",
      "Epoch 11220: train_loss=608.12347, val_loss=627.83759\n",
      "Epoch 11221: train_loss=608.10468, val_loss=627.56818\n",
      "Epoch 11222: train_loss=608.07666, val_loss=627.77570\n",
      "Epoch 11223: train_loss=608.03772, val_loss=627.47247\n",
      "Epoch 11224: train_loss=607.98285, val_loss=627.63873\n",
      "Epoch 11225: train_loss=607.91339, val_loss=627.33441\n",
      "Epoch 11226: train_loss=607.83289, val_loss=627.43787\n",
      "Epoch 11227: train_loss=607.74634, val_loss=627.18604\n",
      "Epoch 11228: train_loss=607.65948, val_loss=627.22900\n",
      "Epoch 11229: train_loss=607.57941, val_loss=627.07239\n",
      "Epoch 11230: train_loss=607.50873, val_loss=627.05835\n",
      "Epoch 11231: train_loss=607.45020, val_loss=627.00128\n",
      "Epoch 11232: train_loss=607.40247, val_loss=626.93225\n",
      "Epoch 11233: train_loss=607.36261, val_loss=626.95160\n",
      "Epoch 11234: train_loss=607.32751, val_loss=626.83667\n",
      "Epoch 11235: train_loss=607.29376, val_loss=626.90405\n",
      "Epoch 11236: train_loss=607.26001, val_loss=626.75250\n",
      "Epoch 11237: train_loss=607.22455, val_loss=626.84045\n",
      "Epoch 11238: train_loss=607.18671, val_loss=626.66284\n",
      "Epoch 11239: train_loss=607.14600, val_loss=626.75507\n",
      "Epoch 11240: train_loss=607.10168, val_loss=626.56909\n",
      "Epoch 11241: train_loss=607.05518, val_loss=626.65460\n",
      "Epoch 11242: train_loss=607.00568, val_loss=626.47021\n",
      "Epoch 11243: train_loss=606.95483, val_loss=626.53748\n",
      "Epoch 11244: train_loss=606.90253, val_loss=626.36578\n",
      "Epoch 11245: train_loss=606.85028, val_loss=626.41742\n",
      "Epoch 11246: train_loss=606.79822, val_loss=626.26587\n",
      "Epoch 11247: train_loss=606.74597, val_loss=626.29944\n",
      "Epoch 11248: train_loss=606.69489, val_loss=626.16803\n",
      "Epoch 11249: train_loss=606.64508, val_loss=626.18445\n",
      "Epoch 11250: train_loss=606.59558, val_loss=626.07007\n",
      "Epoch 11251: train_loss=606.54724, val_loss=626.07385\n",
      "Epoch 11252: train_loss=606.49896, val_loss=625.97614\n",
      "Epoch 11253: train_loss=606.45142, val_loss=625.96759\n",
      "Epoch 11254: train_loss=606.40417, val_loss=625.88190\n",
      "Epoch 11255: train_loss=606.35767, val_loss=625.86292\n",
      "Epoch 11256: train_loss=606.31152, val_loss=625.78448\n",
      "Epoch 11257: train_loss=606.26611, val_loss=625.76477\n",
      "Epoch 11258: train_loss=606.22089, val_loss=625.68823\n",
      "Epoch 11259: train_loss=606.17603, val_loss=625.67291\n",
      "Epoch 11260: train_loss=606.13165, val_loss=625.58911\n",
      "Epoch 11261: train_loss=606.08807, val_loss=625.58759\n",
      "Epoch 11262: train_loss=606.04541, val_loss=625.49060\n",
      "Epoch 11263: train_loss=606.00360, val_loss=625.51257\n",
      "Epoch 11264: train_loss=605.96381, val_loss=625.39520\n",
      "Epoch 11265: train_loss=605.92615, val_loss=625.45178\n",
      "Epoch 11266: train_loss=605.89301, val_loss=625.30536\n",
      "Epoch 11267: train_loss=605.86316, val_loss=625.41248\n",
      "Epoch 11268: train_loss=605.83899, val_loss=625.23401\n",
      "Epoch 11269: train_loss=605.81982, val_loss=625.40027\n",
      "Epoch 11270: train_loss=605.80573, val_loss=625.18188\n",
      "Epoch 11271: train_loss=605.79541, val_loss=625.39886\n",
      "Epoch 11272: train_loss=605.78510, val_loss=625.13281\n",
      "Epoch 11273: train_loss=605.76892, val_loss=625.36841\n",
      "Epoch 11274: train_loss=605.74359, val_loss=625.05719\n",
      "Epoch 11275: train_loss=605.70135, val_loss=625.25903\n",
      "Epoch 11276: train_loss=605.64258, val_loss=624.92828\n",
      "Epoch 11277: train_loss=605.56799, val_loss=625.06641\n",
      "Epoch 11278: train_loss=605.48175, val_loss=624.77240\n",
      "Epoch 11279: train_loss=605.39124, val_loss=624.84460\n",
      "Epoch 11280: train_loss=605.30255, val_loss=624.63794\n",
      "Epoch 11281: train_loss=605.22095, val_loss=624.64520\n",
      "Epoch 11282: train_loss=605.15289, val_loss=624.54932\n",
      "Epoch 11283: train_loss=605.09790, val_loss=624.49811\n",
      "Epoch 11284: train_loss=605.05432, val_loss=624.49799\n",
      "Epoch 11285: train_loss=605.01874, val_loss=624.39435\n",
      "Epoch 11286: train_loss=604.98798, val_loss=624.45947\n",
      "Epoch 11287: train_loss=604.95966, val_loss=624.30811\n",
      "Epoch 11288: train_loss=604.93011, val_loss=624.40997\n",
      "Epoch 11289: train_loss=604.89960, val_loss=624.22412\n",
      "Epoch 11290: train_loss=604.86438, val_loss=624.33868\n",
      "Epoch 11291: train_loss=604.82623, val_loss=624.13269\n",
      "Epoch 11292: train_loss=604.78259, val_loss=624.24164\n",
      "Epoch 11293: train_loss=604.73590, val_loss=624.03168\n",
      "Epoch 11294: train_loss=604.68488, val_loss=624.12134\n",
      "Epoch 11295: train_loss=604.63263, val_loss=623.92389\n",
      "Epoch 11296: train_loss=604.57574, val_loss=623.98438\n",
      "Epoch 11297: train_loss=604.51917, val_loss=623.81940\n",
      "Epoch 11298: train_loss=604.46198, val_loss=623.84741\n",
      "Epoch 11299: train_loss=604.40710, val_loss=623.72327\n",
      "Epoch 11300: train_loss=604.35437, val_loss=623.71887\n",
      "Epoch 11301: train_loss=604.30396, val_loss=623.63501\n",
      "Epoch 11302: train_loss=604.25562, val_loss=623.60107\n",
      "Epoch 11303: train_loss=604.20941, val_loss=623.55365\n",
      "Epoch 11304: train_loss=604.16486, val_loss=623.49500\n",
      "Epoch 11305: train_loss=604.12170, val_loss=623.47760\n",
      "Epoch 11306: train_loss=604.07953, val_loss=623.39691\n",
      "Epoch 11307: train_loss=604.03821, val_loss=623.40845\n",
      "Epoch 11308: train_loss=603.99829, val_loss=623.30432\n",
      "Epoch 11309: train_loss=603.95892, val_loss=623.34143\n",
      "Epoch 11310: train_loss=603.92096, val_loss=623.21112\n",
      "Epoch 11311: train_loss=603.88312, val_loss=623.27179\n",
      "Epoch 11312: train_loss=603.84692, val_loss=623.11951\n",
      "Epoch 11313: train_loss=603.81140, val_loss=623.21014\n",
      "Epoch 11314: train_loss=603.77808, val_loss=623.03656\n",
      "Epoch 11315: train_loss=603.74554, val_loss=623.15582\n",
      "Epoch 11316: train_loss=603.71436, val_loss=622.95807\n",
      "Epoch 11317: train_loss=603.68152, val_loss=623.09662\n",
      "Epoch 11318: train_loss=603.64838, val_loss=622.87555\n",
      "Epoch 11319: train_loss=603.61133, val_loss=623.02167\n",
      "Epoch 11320: train_loss=603.57233, val_loss=622.78577\n",
      "Epoch 11321: train_loss=603.52850, val_loss=622.92560\n",
      "Epoch 11322: train_loss=603.48126, val_loss=622.68579\n",
      "Epoch 11323: train_loss=603.42841, val_loss=622.80566\n",
      "Epoch 11324: train_loss=603.37286, val_loss=622.57678\n",
      "Epoch 11325: train_loss=603.31189, val_loss=622.66144\n",
      "Epoch 11326: train_loss=603.25012, val_loss=622.46680\n",
      "Epoch 11327: train_loss=603.18646, val_loss=622.51019\n",
      "Epoch 11328: train_loss=603.12604, val_loss=622.36871\n",
      "Epoch 11329: train_loss=603.06812, val_loss=622.36847\n",
      "Epoch 11330: train_loss=603.01410, val_loss=622.28564\n",
      "Epoch 11331: train_loss=602.96460, val_loss=622.24524\n",
      "Epoch 11332: train_loss=602.91888, val_loss=622.21344\n",
      "Epoch 11333: train_loss=602.87604, val_loss=622.13812\n",
      "Epoch 11334: train_loss=602.83539, val_loss=622.14807\n",
      "Epoch 11335: train_loss=602.79620, val_loss=622.04156\n",
      "Epoch 11336: train_loss=602.75861, val_loss=622.08746\n",
      "Epoch 11337: train_loss=602.72302, val_loss=621.95056\n",
      "Epoch 11338: train_loss=602.68848, val_loss=622.03339\n",
      "Epoch 11339: train_loss=602.65643, val_loss=621.86786\n",
      "Epoch 11340: train_loss=602.62506, val_loss=621.98560\n",
      "Epoch 11341: train_loss=602.59521, val_loss=621.78979\n",
      "Epoch 11342: train_loss=602.56433, val_loss=621.93262\n",
      "Epoch 11343: train_loss=602.53339, val_loss=621.70996\n",
      "Epoch 11344: train_loss=602.50104, val_loss=621.87036\n",
      "Epoch 11345: train_loss=602.46674, val_loss=621.62573\n",
      "Epoch 11346: train_loss=602.42749, val_loss=621.78809\n",
      "Epoch 11347: train_loss=602.38434, val_loss=621.53198\n",
      "Epoch 11348: train_loss=602.33545, val_loss=621.67810\n",
      "Epoch 11349: train_loss=602.28192, val_loss=621.42517\n",
      "Epoch 11350: train_loss=602.22119, val_loss=621.53870\n",
      "Epoch 11351: train_loss=602.15881, val_loss=621.31396\n",
      "Epoch 11352: train_loss=602.09271, val_loss=621.38397\n",
      "Epoch 11353: train_loss=602.02881, val_loss=621.20947\n",
      "Epoch 11354: train_loss=601.96649, val_loss=621.23669\n",
      "Epoch 11355: train_loss=601.90948, val_loss=621.12042\n",
      "Epoch 11356: train_loss=601.85583, val_loss=621.10645\n",
      "Epoch 11357: train_loss=601.80609, val_loss=621.04486\n",
      "Epoch 11358: train_loss=601.75977, val_loss=620.99469\n",
      "Epoch 11359: train_loss=601.71600, val_loss=620.97772\n",
      "Epoch 11360: train_loss=601.67395, val_loss=620.89539\n",
      "Epoch 11361: train_loss=601.63306, val_loss=620.91180\n",
      "Epoch 11362: train_loss=601.59375, val_loss=620.80115\n",
      "Epoch 11363: train_loss=601.55463, val_loss=620.84662\n",
      "Epoch 11364: train_loss=601.51715, val_loss=620.71210\n",
      "Epoch 11365: train_loss=601.47894, val_loss=620.78168\n",
      "Epoch 11366: train_loss=601.44177, val_loss=620.62518\n",
      "Epoch 11367: train_loss=601.40295, val_loss=620.71002\n",
      "Epoch 11368: train_loss=601.36383, val_loss=620.53735\n",
      "Epoch 11369: train_loss=601.32355, val_loss=620.63348\n",
      "Epoch 11370: train_loss=601.28290, val_loss=620.44934\n",
      "Epoch 11371: train_loss=601.23987, val_loss=620.54797\n",
      "Epoch 11372: train_loss=601.19635, val_loss=620.35718\n",
      "Epoch 11373: train_loss=601.15045, val_loss=620.45111\n",
      "Epoch 11374: train_loss=601.10382, val_loss=620.26086\n",
      "Epoch 11375: train_loss=601.05530, val_loss=620.34344\n",
      "Epoch 11376: train_loss=601.00531, val_loss=620.16309\n",
      "Epoch 11377: train_loss=600.95319, val_loss=620.22369\n",
      "Epoch 11378: train_loss=600.89978, val_loss=620.06555\n",
      "Epoch 11379: train_loss=600.84607, val_loss=620.09869\n",
      "Epoch 11380: train_loss=600.79303, val_loss=619.97284\n",
      "Epoch 11381: train_loss=600.74121, val_loss=619.97839\n",
      "Epoch 11382: train_loss=600.69086, val_loss=619.88342\n",
      "Epoch 11383: train_loss=600.64203, val_loss=619.86560\n",
      "Epoch 11384: train_loss=600.59467, val_loss=619.79535\n",
      "Epoch 11385: train_loss=600.54791, val_loss=619.76105\n",
      "Epoch 11386: train_loss=600.50159, val_loss=619.71021\n",
      "Epoch 11387: train_loss=600.45569, val_loss=619.66034\n",
      "Epoch 11388: train_loss=600.41010, val_loss=619.62390\n",
      "Epoch 11389: train_loss=600.36475, val_loss=619.55981\n",
      "Epoch 11390: train_loss=600.31970, val_loss=619.53760\n",
      "Epoch 11391: train_loss=600.27502, val_loss=619.46033\n",
      "Epoch 11392: train_loss=600.23083, val_loss=619.45819\n",
      "Epoch 11393: train_loss=600.18768, val_loss=619.36151\n",
      "Epoch 11394: train_loss=600.14612, val_loss=619.39124\n",
      "Epoch 11395: train_loss=600.10712, val_loss=619.26642\n",
      "Epoch 11396: train_loss=600.07190, val_loss=619.34857\n",
      "Epoch 11397: train_loss=600.04279, val_loss=619.18439\n",
      "Epoch 11398: train_loss=600.01886, val_loss=619.34009\n",
      "Epoch 11399: train_loss=600.00421, val_loss=619.12762\n",
      "Epoch 11400: train_loss=599.99420, val_loss=619.36243\n",
      "Epoch 11401: train_loss=599.99402, val_loss=619.09241\n",
      "Epoch 11402: train_loss=599.99420, val_loss=619.39294\n",
      "Epoch 11403: train_loss=599.99841, val_loss=619.05591\n",
      "Epoch 11404: train_loss=599.98596, val_loss=619.36908\n",
      "Epoch 11405: train_loss=599.96429, val_loss=618.96783\n",
      "Epoch 11406: train_loss=599.90948, val_loss=619.22052\n",
      "Epoch 11407: train_loss=599.83533, val_loss=618.80219\n",
      "Epoch 11408: train_loss=599.73120, val_loss=618.95386\n",
      "Epoch 11409: train_loss=599.61859, val_loss=618.61145\n",
      "Epoch 11410: train_loss=599.50262, val_loss=618.66199\n",
      "Epoch 11411: train_loss=599.39923, val_loss=618.48029\n",
      "Epoch 11412: train_loss=599.31732, val_loss=618.44385\n",
      "Epoch 11413: train_loss=599.26221, val_loss=618.44562\n",
      "Epoch 11414: train_loss=599.22919, val_loss=618.32794\n",
      "Epoch 11415: train_loss=599.20886, val_loss=618.44916\n",
      "Epoch 11416: train_loss=599.19293, val_loss=618.25446\n",
      "Epoch 11417: train_loss=599.16931, val_loss=618.40460\n",
      "Epoch 11418: train_loss=599.13574, val_loss=618.15717\n",
      "Epoch 11419: train_loss=599.08551, val_loss=618.27454\n",
      "Epoch 11420: train_loss=599.02600, val_loss=618.03693\n",
      "Epoch 11421: train_loss=598.95685, val_loss=618.10052\n",
      "Epoch 11422: train_loss=598.88831, val_loss=617.92725\n",
      "Epoch 11423: train_loss=598.82172, val_loss=617.93030\n",
      "Epoch 11424: train_loss=598.76233, val_loss=617.84442\n",
      "Epoch 11425: train_loss=598.71057, val_loss=617.78638\n",
      "Epoch 11426: train_loss=598.66608, val_loss=617.78235\n",
      "Epoch 11427: train_loss=598.62616, val_loss=617.67688\n",
      "Epoch 11428: train_loss=598.58759, val_loss=617.72076\n",
      "Epoch 11429: train_loss=598.54980, val_loss=617.57916\n",
      "Epoch 11430: train_loss=598.50946, val_loss=617.64014\n",
      "Epoch 11431: train_loss=598.46753, val_loss=617.48083\n",
      "Epoch 11432: train_loss=598.42310, val_loss=617.54358\n",
      "Epoch 11433: train_loss=598.37634, val_loss=617.38391\n",
      "Epoch 11434: train_loss=598.32764, val_loss=617.43555\n",
      "Epoch 11435: train_loss=598.27759, val_loss=617.28625\n",
      "Epoch 11436: train_loss=598.22589, val_loss=617.31604\n",
      "Epoch 11437: train_loss=598.17432, val_loss=617.19049\n",
      "Epoch 11438: train_loss=598.12286, val_loss=617.19971\n",
      "Epoch 11439: train_loss=598.07257, val_loss=617.10052\n",
      "Epoch 11440: train_loss=598.02307, val_loss=617.09186\n",
      "Epoch 11441: train_loss=597.97430, val_loss=617.01166\n",
      "Epoch 11442: train_loss=597.92596, val_loss=616.98810\n",
      "Epoch 11443: train_loss=597.87823, val_loss=616.92377\n",
      "Epoch 11444: train_loss=597.83087, val_loss=616.88806\n",
      "Epoch 11445: train_loss=597.78351, val_loss=616.83344\n",
      "Epoch 11446: train_loss=597.73657, val_loss=616.78955\n",
      "Epoch 11447: train_loss=597.69025, val_loss=616.74408\n",
      "Epoch 11448: train_loss=597.64447, val_loss=616.69299\n",
      "Epoch 11449: train_loss=597.59851, val_loss=616.65454\n",
      "Epoch 11450: train_loss=597.55280, val_loss=616.59497\n",
      "Epoch 11451: train_loss=597.50745, val_loss=616.56592\n",
      "Epoch 11452: train_loss=597.46252, val_loss=616.49585\n",
      "Epoch 11453: train_loss=597.41779, val_loss=616.47968\n",
      "Epoch 11454: train_loss=597.37341, val_loss=616.39203\n",
      "Epoch 11455: train_loss=597.33020, val_loss=616.40198\n",
      "Epoch 11456: train_loss=597.28888, val_loss=616.28986\n",
      "Epoch 11457: train_loss=597.24963, val_loss=616.34253\n",
      "Epoch 11458: train_loss=597.21484, val_loss=616.19501\n",
      "Epoch 11459: train_loss=597.18518, val_loss=616.31360\n",
      "Epoch 11460: train_loss=597.16437, val_loss=616.11945\n",
      "Epoch 11461: train_loss=597.15112, val_loss=616.32440\n",
      "Epoch 11462: train_loss=597.14801, val_loss=616.07642\n",
      "Epoch 11463: train_loss=597.15289, val_loss=616.37018\n",
      "Epoch 11464: train_loss=597.16327, val_loss=616.05334\n",
      "Epoch 11465: train_loss=597.16785, val_loss=616.38788\n",
      "Epoch 11466: train_loss=597.16180, val_loss=615.99310\n",
      "Epoch 11467: train_loss=597.12817, val_loss=616.28760\n",
      "Epoch 11468: train_loss=597.06982, val_loss=615.84723\n",
      "Epoch 11469: train_loss=596.97516, val_loss=616.03632\n",
      "Epoch 11470: train_loss=596.86273, val_loss=615.64740\n",
      "Epoch 11471: train_loss=596.73834, val_loss=615.72491\n",
      "Epoch 11472: train_loss=596.62518, val_loss=615.49579\n",
      "Epoch 11473: train_loss=596.53125, val_loss=615.48309\n",
      "Epoch 11474: train_loss=596.46454, val_loss=615.44775\n",
      "Epoch 11475: train_loss=596.42236, val_loss=615.35242\n",
      "Epoch 11476: train_loss=596.39752, val_loss=615.45270\n",
      "Epoch 11477: train_loss=596.38043, val_loss=615.27252\n",
      "Epoch 11478: train_loss=596.36102, val_loss=615.42883\n",
      "Epoch 11479: train_loss=596.33655, val_loss=615.18860\n",
      "Epoch 11480: train_loss=596.29742, val_loss=615.33691\n",
      "Epoch 11481: train_loss=596.24866, val_loss=615.08282\n",
      "Epoch 11482: train_loss=596.18787, val_loss=615.18555\n",
      "Epoch 11483: train_loss=596.12286, val_loss=614.96790\n",
      "Epoch 11484: train_loss=596.05481, val_loss=615.01135\n",
      "Epoch 11485: train_loss=595.98969, val_loss=614.86981\n",
      "Epoch 11486: train_loss=595.93018, val_loss=614.85437\n",
      "Epoch 11487: train_loss=595.87726, val_loss=614.79761\n",
      "Epoch 11488: train_loss=595.83093, val_loss=614.72668\n",
      "Epoch 11489: train_loss=595.78961, val_loss=614.73712\n",
      "Epoch 11490: train_loss=595.75116, val_loss=614.62006\n",
      "Epoch 11491: train_loss=595.71387, val_loss=614.67493\n",
      "Epoch 11492: train_loss=595.67725, val_loss=614.52338\n",
      "Epoch 11493: train_loss=595.63989, val_loss=614.60364\n",
      "Epoch 11494: train_loss=595.60150, val_loss=614.42786\n",
      "Epoch 11495: train_loss=595.56091, val_loss=614.52094\n",
      "Epoch 11496: train_loss=595.51892, val_loss=614.33429\n",
      "Epoch 11497: train_loss=595.47437, val_loss=614.42737\n",
      "Epoch 11498: train_loss=595.42896, val_loss=614.23822\n",
      "Epoch 11499: train_loss=595.38098, val_loss=614.32117\n",
      "Epoch 11500: train_loss=595.33252, val_loss=614.14081\n",
      "Epoch 11501: train_loss=595.28247, val_loss=614.20825\n",
      "Epoch 11502: train_loss=595.23212, val_loss=614.04535\n",
      "Epoch 11503: train_loss=595.18054, val_loss=614.09100\n",
      "Epoch 11504: train_loss=595.12970, val_loss=613.94989\n",
      "Epoch 11505: train_loss=595.07928, val_loss=613.97443\n",
      "Epoch 11506: train_loss=595.03003, val_loss=613.85657\n",
      "Epoch 11507: train_loss=594.98145, val_loss=613.86432\n",
      "Epoch 11508: train_loss=594.93372, val_loss=613.76501\n",
      "Epoch 11509: train_loss=594.88647, val_loss=613.75928\n",
      "Epoch 11510: train_loss=594.83984, val_loss=613.67194\n",
      "Epoch 11511: train_loss=594.79358, val_loss=613.65662\n",
      "Epoch 11512: train_loss=594.74780, val_loss=613.57507\n",
      "Epoch 11513: train_loss=594.70227, val_loss=613.56036\n",
      "Epoch 11514: train_loss=594.65704, val_loss=613.47833\n",
      "Epoch 11515: train_loss=594.61218, val_loss=613.47076\n",
      "Epoch 11516: train_loss=594.56757, val_loss=613.37970\n",
      "Epoch 11517: train_loss=594.52399, val_loss=613.38757\n",
      "Epoch 11518: train_loss=594.48120, val_loss=613.28003\n",
      "Epoch 11519: train_loss=594.44019, val_loss=613.31989\n",
      "Epoch 11520: train_loss=594.40143, val_loss=613.18524\n",
      "Epoch 11521: train_loss=594.36627, val_loss=613.27374\n",
      "Epoch 11522: train_loss=594.33539, val_loss=613.09924\n",
      "Epoch 11523: train_loss=594.30902, val_loss=613.25092\n",
      "Epoch 11524: train_loss=594.28876, val_loss=613.03027\n",
      "Epoch 11525: train_loss=594.27216, val_loss=613.24744\n",
      "Epoch 11526: train_loss=594.25916, val_loss=612.97247\n",
      "Epoch 11527: train_loss=594.24316, val_loss=613.22778\n",
      "Epoch 11528: train_loss=594.22284, val_loss=612.89899\n",
      "Epoch 11529: train_loss=594.18860, val_loss=613.14691\n",
      "Epoch 11530: train_loss=594.14410, val_loss=612.78998\n",
      "Epoch 11531: train_loss=594.08173, val_loss=612.98779\n",
      "Epoch 11532: train_loss=594.00800, val_loss=612.65186\n",
      "Epoch 11533: train_loss=593.92426, val_loss=612.77655\n",
      "Epoch 11534: train_loss=593.83795, val_loss=612.51538\n",
      "Epoch 11535: train_loss=593.75281, val_loss=612.55939\n",
      "Epoch 11536: train_loss=593.67725, val_loss=612.42017\n",
      "Epoch 11537: train_loss=593.61346, val_loss=612.38904\n",
      "Epoch 11538: train_loss=593.56232, val_loss=612.37006\n",
      "Epoch 11539: train_loss=593.52155, val_loss=612.26935\n",
      "Epoch 11540: train_loss=593.48749, val_loss=612.33496\n",
      "Epoch 11541: train_loss=593.45648, val_loss=612.17548\n",
      "Epoch 11542: train_loss=593.42438, val_loss=612.28436\n",
      "Epoch 11543: train_loss=593.39056, val_loss=612.08527\n",
      "Epoch 11544: train_loss=593.35071, val_loss=612.20032\n",
      "Epoch 11545: train_loss=593.30664, val_loss=611.98730\n",
      "Epoch 11546: train_loss=593.25690, val_loss=612.08551\n",
      "Epoch 11547: train_loss=593.20435, val_loss=611.88531\n",
      "Epoch 11548: train_loss=593.14746, val_loss=611.94995\n",
      "Epoch 11549: train_loss=593.09052, val_loss=611.78510\n",
      "Epoch 11550: train_loss=593.03345, val_loss=611.80988\n",
      "Epoch 11551: train_loss=592.97839, val_loss=611.69464\n",
      "Epoch 11552: train_loss=592.92560, val_loss=611.68073\n",
      "Epoch 11553: train_loss=592.87549, val_loss=611.61578\n",
      "Epoch 11554: train_loss=592.82806, val_loss=611.56439\n",
      "Epoch 11555: train_loss=592.78241, val_loss=611.53827\n",
      "Epoch 11556: train_loss=592.73840, val_loss=611.45514\n",
      "Epoch 11557: train_loss=592.69531, val_loss=611.46362\n",
      "Epoch 11558: train_loss=592.65302, val_loss=611.35535\n",
      "Epoch 11559: train_loss=592.61151, val_loss=611.39368\n",
      "Epoch 11560: train_loss=592.57098, val_loss=611.25861\n",
      "Epoch 11561: train_loss=592.53137, val_loss=611.32343\n",
      "Epoch 11562: train_loss=592.49152, val_loss=611.16449\n",
      "Epoch 11563: train_loss=592.45123, val_loss=611.24982\n",
      "Epoch 11564: train_loss=592.41052, val_loss=611.07129\n",
      "Epoch 11565: train_loss=592.36865, val_loss=611.16614\n",
      "Epoch 11566: train_loss=592.32599, val_loss=610.97473\n",
      "Epoch 11567: train_loss=592.28143, val_loss=611.07324\n",
      "Epoch 11568: train_loss=592.23639, val_loss=610.87891\n",
      "Epoch 11569: train_loss=592.18982, val_loss=610.97583\n",
      "Epoch 11570: train_loss=592.14276, val_loss=610.78308\n",
      "Epoch 11571: train_loss=592.09473, val_loss=610.87152\n",
      "Epoch 11572: train_loss=592.04614, val_loss=610.68561\n",
      "Epoch 11573: train_loss=591.99695, val_loss=610.76276\n",
      "Epoch 11574: train_loss=591.94714, val_loss=610.58923\n",
      "Epoch 11575: train_loss=591.89636, val_loss=610.64960\n",
      "Epoch 11576: train_loss=591.84552, val_loss=610.49249\n",
      "Epoch 11577: train_loss=591.79468, val_loss=610.53326\n",
      "Epoch 11578: train_loss=591.74438, val_loss=610.39795\n",
      "Epoch 11579: train_loss=591.69440, val_loss=610.41956\n",
      "Epoch 11580: train_loss=591.64502, val_loss=610.30469\n",
      "Epoch 11581: train_loss=591.59637, val_loss=610.30841\n",
      "Epoch 11582: train_loss=591.54822, val_loss=610.21051\n",
      "Epoch 11583: train_loss=591.50079, val_loss=610.20221\n",
      "Epoch 11584: train_loss=591.45361, val_loss=610.11615\n",
      "Epoch 11585: train_loss=591.40686, val_loss=610.10187\n",
      "Epoch 11586: train_loss=591.36029, val_loss=610.02063\n",
      "Epoch 11587: train_loss=591.31421, val_loss=610.00787\n",
      "Epoch 11588: train_loss=591.26843, val_loss=609.92267\n",
      "Epoch 11589: train_loss=591.22327, val_loss=609.92139\n",
      "Epoch 11590: train_loss=591.17853, val_loss=609.82288\n",
      "Epoch 11591: train_loss=591.13513, val_loss=609.84448\n",
      "Epoch 11592: train_loss=591.09296, val_loss=609.72186\n",
      "Epoch 11593: train_loss=591.05322, val_loss=609.78271\n",
      "Epoch 11594: train_loss=591.01642, val_loss=609.62500\n",
      "Epoch 11595: train_loss=590.98407, val_loss=609.74377\n",
      "Epoch 11596: train_loss=590.95654, val_loss=609.54199\n",
      "Epoch 11597: train_loss=590.93542, val_loss=609.73480\n",
      "Epoch 11598: train_loss=590.92029, val_loss=609.48041\n",
      "Epoch 11599: train_loss=590.91010, val_loss=609.74823\n",
      "Epoch 11600: train_loss=590.90411, val_loss=609.43256\n",
      "Epoch 11601: train_loss=590.89526, val_loss=609.75134\n",
      "Epoch 11602: train_loss=590.88556, val_loss=609.37323\n",
      "Epoch 11603: train_loss=590.86011, val_loss=609.69495\n",
      "Epoch 11604: train_loss=590.82489, val_loss=609.27185\n",
      "Epoch 11605: train_loss=590.76367, val_loss=609.53577\n",
      "Epoch 11606: train_loss=590.68640, val_loss=609.11786\n",
      "Epoch 11607: train_loss=590.58862, val_loss=609.28625\n",
      "Epoch 11608: train_loss=590.48450, val_loss=608.95416\n",
      "Epoch 11609: train_loss=590.38013, val_loss=609.02356\n",
      "Epoch 11610: train_loss=590.28870, val_loss=608.84460\n",
      "Epoch 11611: train_loss=590.21411, val_loss=608.82605\n",
      "Epoch 11612: train_loss=590.15741, val_loss=608.79987\n",
      "Epoch 11613: train_loss=590.11530, val_loss=608.69806\n",
      "Epoch 11614: train_loss=590.08350, val_loss=608.78290\n",
      "Epoch 11615: train_loss=590.05743, val_loss=608.60791\n",
      "Epoch 11616: train_loss=590.03296, val_loss=608.75684\n",
      "Epoch 11617: train_loss=590.00653, val_loss=608.52448\n",
      "Epoch 11618: train_loss=589.97394, val_loss=608.68878\n",
      "Epoch 11619: train_loss=589.93311, val_loss=608.42767\n",
      "Epoch 11620: train_loss=589.88269, val_loss=608.56793\n",
      "Epoch 11621: train_loss=589.82532, val_loss=608.31885\n",
      "Epoch 11622: train_loss=589.76294, val_loss=608.41504\n",
      "Epoch 11623: train_loss=589.69952, val_loss=608.21179\n",
      "Epoch 11624: train_loss=589.63690, val_loss=608.26105\n",
      "Epoch 11625: train_loss=589.57770, val_loss=608.11536\n",
      "Epoch 11626: train_loss=589.52203, val_loss=608.12354\n",
      "Epoch 11627: train_loss=589.46924, val_loss=608.02899\n",
      "Epoch 11628: train_loss=589.41864, val_loss=607.99951\n",
      "Epoch 11629: train_loss=589.37024, val_loss=607.94916\n",
      "Epoch 11630: train_loss=589.32355, val_loss=607.88507\n",
      "Epoch 11631: train_loss=589.27814, val_loss=607.87097\n",
      "Epoch 11632: train_loss=589.23401, val_loss=607.77838\n",
      "Epoch 11633: train_loss=589.19086, val_loss=607.79999\n",
      "Epoch 11634: train_loss=589.14886, val_loss=607.67755\n",
      "Epoch 11635: train_loss=589.10742, val_loss=607.72980\n",
      "Epoch 11636: train_loss=589.06647, val_loss=607.57928\n",
      "Epoch 11637: train_loss=589.02649, val_loss=607.65961\n",
      "Epoch 11638: train_loss=588.98657, val_loss=607.48438\n",
      "Epoch 11639: train_loss=588.94781, val_loss=607.59155\n",
      "Epoch 11640: train_loss=588.90906, val_loss=607.39136\n",
      "Epoch 11641: train_loss=588.87134, val_loss=607.52252\n",
      "Epoch 11642: train_loss=588.83319, val_loss=607.29785\n",
      "Epoch 11643: train_loss=588.79443, val_loss=607.44543\n",
      "Epoch 11644: train_loss=588.75305, val_loss=607.20300\n",
      "Epoch 11645: train_loss=588.71039, val_loss=607.35364\n",
      "Epoch 11646: train_loss=588.66382, val_loss=607.10376\n",
      "Epoch 11647: train_loss=588.61536, val_loss=607.24316\n",
      "Epoch 11648: train_loss=588.56281, val_loss=606.99945\n",
      "Epoch 11649: train_loss=588.50879, val_loss=607.11725\n",
      "Epoch 11650: train_loss=588.45233, val_loss=606.89514\n",
      "Epoch 11651: train_loss=588.39557, val_loss=606.98444\n",
      "Epoch 11652: train_loss=588.33832, val_loss=606.79340\n",
      "Epoch 11653: train_loss=588.28143, val_loss=606.84900\n",
      "Epoch 11654: train_loss=588.22516, val_loss=606.69672\n",
      "Epoch 11655: train_loss=588.17029, val_loss=606.71906\n",
      "Epoch 11656: train_loss=588.11725, val_loss=606.60706\n",
      "Epoch 11657: train_loss=588.06592, val_loss=606.59766\n",
      "Epoch 11658: train_loss=588.01587, val_loss=606.51794\n",
      "Epoch 11659: train_loss=587.96716, val_loss=606.48132\n",
      "Epoch 11660: train_loss=587.91931, val_loss=606.42950\n",
      "Epoch 11661: train_loss=587.87207, val_loss=606.37305\n",
      "Epoch 11662: train_loss=587.82532, val_loss=606.34363\n",
      "Epoch 11663: train_loss=587.77893, val_loss=606.26648\n",
      "Epoch 11664: train_loss=587.73297, val_loss=606.25586\n",
      "Epoch 11665: train_loss=587.68750, val_loss=606.15790\n",
      "Epoch 11666: train_loss=587.64301, val_loss=606.17615\n",
      "Epoch 11667: train_loss=587.59967, val_loss=606.05402\n",
      "Epoch 11668: train_loss=587.55811, val_loss=606.10822\n",
      "Epoch 11669: train_loss=587.51801, val_loss=605.95319\n",
      "Epoch 11670: train_loss=587.48029, val_loss=606.04730\n",
      "Epoch 11671: train_loss=587.44446, val_loss=605.85645\n",
      "Epoch 11672: train_loss=587.41138, val_loss=605.99805\n",
      "Epoch 11673: train_loss=587.38019, val_loss=605.76978\n",
      "Epoch 11674: train_loss=587.35266, val_loss=605.96094\n",
      "Epoch 11675: train_loss=587.32556, val_loss=605.68970\n",
      "Epoch 11676: train_loss=587.29950, val_loss=605.92163\n",
      "Epoch 11677: train_loss=587.27240, val_loss=605.60968\n",
      "Epoch 11678: train_loss=587.24091, val_loss=605.86169\n",
      "Epoch 11679: train_loss=587.20544, val_loss=605.51752\n",
      "Epoch 11680: train_loss=587.16028, val_loss=605.75775\n",
      "Epoch 11681: train_loss=587.10864, val_loss=605.40363\n",
      "Epoch 11682: train_loss=587.04535, val_loss=605.59760\n",
      "Epoch 11683: train_loss=586.97260, val_loss=605.27252\n",
      "Epoch 11684: train_loss=586.89337, val_loss=605.39935\n",
      "Epoch 11685: train_loss=586.81244, val_loss=605.14722\n",
      "Epoch 11686: train_loss=586.73273, val_loss=605.19409\n",
      "Epoch 11687: train_loss=586.66040, val_loss=605.04846\n",
      "Epoch 11688: train_loss=586.59686, val_loss=605.02344\n",
      "Epoch 11689: train_loss=586.54272, val_loss=604.98303\n",
      "Epoch 11690: train_loss=586.49609, val_loss=604.89343\n",
      "Epoch 11691: train_loss=586.45483, val_loss=604.93158\n",
      "Epoch 11692: train_loss=586.41724, val_loss=604.78644\n",
      "Epoch 11693: train_loss=586.38092, val_loss=604.87689\n",
      "Epoch 11694: train_loss=586.34564, val_loss=604.68634\n",
      "Epoch 11695: train_loss=586.30786, val_loss=604.80463\n",
      "Epoch 11696: train_loss=586.26849, val_loss=604.58643\n",
      "Epoch 11697: train_loss=586.22473, val_loss=604.71075\n",
      "Epoch 11698: train_loss=586.17834, val_loss=604.48114\n",
      "Epoch 11699: train_loss=586.12726, val_loss=604.59351\n",
      "Epoch 11700: train_loss=586.07507, val_loss=604.37225\n",
      "Epoch 11701: train_loss=586.02020, val_loss=604.46429\n",
      "Epoch 11702: train_loss=585.96533, val_loss=604.26434\n",
      "Epoch 11703: train_loss=585.90955, val_loss=604.33246\n",
      "Epoch 11704: train_loss=585.85474, val_loss=604.15942\n",
      "Epoch 11705: train_loss=585.79980, val_loss=604.20160\n",
      "Epoch 11706: train_loss=585.74640, val_loss=604.05786\n",
      "Epoch 11707: train_loss=585.69360, val_loss=604.07684\n",
      "Epoch 11708: train_loss=585.64203, val_loss=603.95935\n",
      "Epoch 11709: train_loss=585.59113, val_loss=603.95734\n",
      "Epoch 11710: train_loss=585.54120, val_loss=603.86017\n",
      "Epoch 11711: train_loss=585.49176, val_loss=603.84344\n",
      "Epoch 11712: train_loss=585.44293, val_loss=603.76178\n",
      "Epoch 11713: train_loss=585.39447, val_loss=603.73785\n",
      "Epoch 11714: train_loss=585.34625, val_loss=603.66272\n",
      "Epoch 11715: train_loss=585.29828, val_loss=603.63599\n",
      "Epoch 11716: train_loss=585.25031, val_loss=603.55939\n",
      "Epoch 11717: train_loss=585.20276, val_loss=603.53717\n",
      "Epoch 11718: train_loss=585.15533, val_loss=603.45264\n",
      "Epoch 11719: train_loss=585.10846, val_loss=603.44604\n",
      "Epoch 11720: train_loss=585.06232, val_loss=603.34375\n",
      "Epoch 11721: train_loss=585.01746, val_loss=603.36749\n",
      "Epoch 11722: train_loss=584.97467, val_loss=603.23645\n",
      "Epoch 11723: train_loss=584.93524, val_loss=603.31311\n",
      "Epoch 11724: train_loss=584.90015, val_loss=603.13782\n",
      "Epoch 11725: train_loss=584.87000, val_loss=603.28473\n",
      "Epoch 11726: train_loss=584.84625, val_loss=603.05493\n",
      "Epoch 11727: train_loss=584.82751, val_loss=603.28229\n",
      "Epoch 11728: train_loss=584.81512, val_loss=602.99420\n",
      "Epoch 11729: train_loss=584.80450, val_loss=603.29034\n",
      "Epoch 11730: train_loss=584.79486, val_loss=602.93445\n",
      "Epoch 11731: train_loss=584.77393, val_loss=603.25067\n",
      "Epoch 11732: train_loss=584.74414, val_loss=602.84210\n",
      "Epoch 11733: train_loss=584.69135, val_loss=603.11633\n",
      "Epoch 11734: train_loss=584.62311, val_loss=602.70300\n",
      "Epoch 11735: train_loss=584.53467, val_loss=602.88959\n",
      "Epoch 11736: train_loss=584.43799, val_loss=602.54559\n",
      "Epoch 11737: train_loss=584.33728, val_loss=602.63513\n",
      "Epoch 11738: train_loss=584.24451, val_loss=602.42725\n",
      "Epoch 11739: train_loss=584.16449, val_loss=602.42407\n",
      "Epoch 11740: train_loss=584.09967, val_loss=602.36700\n",
      "Epoch 11741: train_loss=584.04999, val_loss=602.27637\n",
      "Epoch 11742: train_loss=584.01117, val_loss=602.33490\n",
      "Epoch 11743: train_loss=583.97784, val_loss=602.16998\n",
      "Epoch 11744: train_loss=583.94672, val_loss=602.29333\n",
      "Epoch 11745: train_loss=583.91315, val_loss=602.07288\n",
      "Epoch 11746: train_loss=583.87372, val_loss=602.20990\n",
      "Epoch 11747: train_loss=583.82751, val_loss=601.96698\n",
      "Epoch 11748: train_loss=583.77411, val_loss=602.08472\n",
      "Epoch 11749: train_loss=583.71619, val_loss=601.85748\n",
      "Epoch 11750: train_loss=583.65454, val_loss=601.93268\n",
      "Epoch 11751: train_loss=583.59192, val_loss=601.75037\n",
      "Epoch 11752: train_loss=583.52997, val_loss=601.77844\n",
      "Epoch 11753: train_loss=583.47125, val_loss=601.65375\n",
      "Epoch 11754: train_loss=583.41571, val_loss=601.63983\n",
      "Epoch 11755: train_loss=583.36279, val_loss=601.56256\n",
      "Epoch 11756: train_loss=583.31177, val_loss=601.51135\n",
      "Epoch 11757: train_loss=583.26263, val_loss=601.47107\n",
      "Epoch 11758: train_loss=583.21429, val_loss=601.39044\n",
      "Epoch 11759: train_loss=583.16681, val_loss=601.38232\n",
      "Epoch 11760: train_loss=583.12042, val_loss=601.27264\n",
      "Epoch 11761: train_loss=583.07507, val_loss=601.29773\n",
      "Epoch 11762: train_loss=583.03076, val_loss=601.15887\n",
      "Epoch 11763: train_loss=582.98737, val_loss=601.22064\n",
      "Epoch 11764: train_loss=582.94550, val_loss=601.05115\n",
      "Epoch 11765: train_loss=582.90503, val_loss=601.14911\n",
      "Epoch 11766: train_loss=582.86523, val_loss=600.94812\n",
      "Epoch 11767: train_loss=582.82587, val_loss=601.07324\n",
      "Epoch 11768: train_loss=582.78479, val_loss=600.84613\n",
      "Epoch 11769: train_loss=582.74219, val_loss=600.98279\n",
      "Epoch 11770: train_loss=582.69623, val_loss=600.74060\n",
      "Epoch 11771: train_loss=582.64758, val_loss=600.87268\n",
      "Epoch 11772: train_loss=582.59558, val_loss=600.63257\n",
      "Epoch 11773: train_loss=582.54163, val_loss=600.74469\n",
      "Epoch 11774: train_loss=582.48438, val_loss=600.52356\n",
      "Epoch 11775: train_loss=582.42639, val_loss=600.60376\n",
      "Epoch 11776: train_loss=582.36731, val_loss=600.41473\n",
      "Epoch 11777: train_loss=582.30841, val_loss=600.45648\n",
      "Epoch 11778: train_loss=582.25043, val_loss=600.31213\n",
      "Epoch 11779: train_loss=582.19409, val_loss=600.31580\n",
      "Epoch 11780: train_loss=582.13959, val_loss=600.21594\n",
      "Epoch 11781: train_loss=582.08728, val_loss=600.18567\n",
      "Epoch 11782: train_loss=582.03607, val_loss=600.12335\n",
      "Epoch 11783: train_loss=581.98627, val_loss=600.06384\n",
      "Epoch 11784: train_loss=581.93719, val_loss=600.03113\n",
      "Epoch 11785: train_loss=581.88873, val_loss=599.94550\n",
      "Epoch 11786: train_loss=581.84076, val_loss=599.93860\n",
      "Epoch 11787: train_loss=581.79346, val_loss=599.82910\n",
      "Epoch 11788: train_loss=581.74670, val_loss=599.84979\n",
      "Epoch 11789: train_loss=581.70068, val_loss=599.71320\n",
      "Epoch 11790: train_loss=581.65576, val_loss=599.76599\n",
      "Epoch 11791: train_loss=581.61200, val_loss=599.60242\n",
      "Epoch 11792: train_loss=581.56970, val_loss=599.69299\n",
      "Epoch 11793: train_loss=581.52863, val_loss=599.49664\n",
      "Epoch 11794: train_loss=581.48969, val_loss=599.62494\n",
      "Epoch 11795: train_loss=581.45117, val_loss=599.39380\n",
      "Epoch 11796: train_loss=581.41400, val_loss=599.55640\n",
      "Epoch 11797: train_loss=581.37537, val_loss=599.29211\n",
      "Epoch 11798: train_loss=581.33423, val_loss=599.47113\n",
      "Epoch 11799: train_loss=581.29004, val_loss=599.18182\n",
      "Epoch 11800: train_loss=581.24152, val_loss=599.36066\n",
      "Epoch 11801: train_loss=581.19037, val_loss=599.06403\n",
      "Epoch 11802: train_loss=581.13324, val_loss=599.22345\n",
      "Epoch 11803: train_loss=581.07178, val_loss=598.93927\n",
      "Epoch 11804: train_loss=581.00507, val_loss=599.06049\n",
      "Epoch 11805: train_loss=580.93597, val_loss=598.81262\n",
      "Epoch 11806: train_loss=580.86731, val_loss=598.88702\n",
      "Epoch 11807: train_loss=580.79913, val_loss=598.69092\n",
      "Epoch 11808: train_loss=580.73334, val_loss=598.72009\n",
      "Epoch 11809: train_loss=580.67047, val_loss=598.58087\n",
      "Epoch 11810: train_loss=580.61072, val_loss=598.56775\n",
      "Epoch 11811: train_loss=580.55371, val_loss=598.48010\n",
      "Epoch 11812: train_loss=580.49921, val_loss=598.43469\n",
      "Epoch 11813: train_loss=580.44672, val_loss=598.38757\n",
      "Epoch 11814: train_loss=580.39563, val_loss=598.30963\n",
      "Epoch 11815: train_loss=580.34552, val_loss=598.29498\n",
      "Epoch 11816: train_loss=580.29608, val_loss=598.18970\n",
      "Epoch 11817: train_loss=580.24713, val_loss=598.20227\n",
      "Epoch 11818: train_loss=580.19891, val_loss=598.07111\n",
      "Epoch 11819: train_loss=580.15137, val_loss=598.11230\n",
      "Epoch 11820: train_loss=580.10480, val_loss=597.95618\n",
      "Epoch 11821: train_loss=580.05963, val_loss=598.03058\n",
      "Epoch 11822: train_loss=580.01587, val_loss=597.84528\n",
      "Epoch 11823: train_loss=579.97461, val_loss=597.96362\n",
      "Epoch 11824: train_loss=579.93652, val_loss=597.74390\n",
      "Epoch 11825: train_loss=579.90155, val_loss=597.91138\n",
      "Epoch 11826: train_loss=579.86871, val_loss=597.65106\n",
      "Epoch 11827: train_loss=579.83759, val_loss=597.86304\n",
      "Epoch 11828: train_loss=579.80737, val_loss=597.56378\n",
      "Epoch 11829: train_loss=579.77509, val_loss=597.80328\n",
      "Epoch 11830: train_loss=579.74182, val_loss=597.47156\n",
      "Epoch 11831: train_loss=579.70166, val_loss=597.70660\n",
      "Epoch 11832: train_loss=579.65277, val_loss=597.35779\n",
      "Epoch 11833: train_loss=579.59369, val_loss=597.55731\n",
      "Epoch 11834: train_loss=579.52570, val_loss=597.22675\n",
      "Epoch 11835: train_loss=579.44965, val_loss=597.36395\n",
      "Epoch 11836: train_loss=579.36871, val_loss=597.09473\n",
      "Epoch 11837: train_loss=579.28888, val_loss=597.16064\n",
      "Epoch 11838: train_loss=579.21252, val_loss=596.98676\n",
      "Epoch 11839: train_loss=579.14264, val_loss=596.97772\n",
      "Epoch 11840: train_loss=579.08197, val_loss=596.91132\n",
      "Epoch 11841: train_loss=579.02966, val_loss=596.83276\n",
      "Epoch 11842: train_loss=578.98413, val_loss=596.85175\n",
      "Epoch 11843: train_loss=578.94263, val_loss=596.71698\n",
      "Epoch 11844: train_loss=578.90283, val_loss=596.79077\n",
      "Epoch 11845: train_loss=578.86359, val_loss=596.61206\n",
      "Epoch 11846: train_loss=578.82208, val_loss=596.71082\n",
      "Epoch 11847: train_loss=578.77869, val_loss=596.50647\n",
      "Epoch 11848: train_loss=578.73206, val_loss=596.61017\n",
      "Epoch 11849: train_loss=578.68274, val_loss=596.39838\n",
      "Epoch 11850: train_loss=578.63037, val_loss=596.49139\n",
      "Epoch 11851: train_loss=578.57678, val_loss=596.28754\n",
      "Epoch 11852: train_loss=578.52081, val_loss=596.36066\n",
      "Epoch 11853: train_loss=578.46527, val_loss=596.17566\n",
      "Epoch 11854: train_loss=578.40863, val_loss=596.22705\n",
      "Epoch 11855: train_loss=578.35333, val_loss=596.06567\n",
      "Epoch 11856: train_loss=578.29797, val_loss=596.09729\n",
      "Epoch 11857: train_loss=578.24390, val_loss=595.95587\n",
      "Epoch 11858: train_loss=578.19019, val_loss=595.97089\n",
      "Epoch 11859: train_loss=578.13708, val_loss=595.84503\n",
      "Epoch 11860: train_loss=578.08527, val_loss=595.85223\n",
      "Epoch 11861: train_loss=578.03412, val_loss=595.73370\n",
      "Epoch 11862: train_loss=577.98309, val_loss=595.74158\n",
      "Epoch 11863: train_loss=577.93329, val_loss=595.62238\n",
      "Epoch 11864: train_loss=577.88361, val_loss=595.63837\n",
      "Epoch 11865: train_loss=577.83508, val_loss=595.50879\n",
      "Epoch 11866: train_loss=577.78754, val_loss=595.54626\n",
      "Epoch 11867: train_loss=577.74194, val_loss=595.39661\n",
      "Epoch 11868: train_loss=577.69897, val_loss=595.47455\n",
      "Epoch 11869: train_loss=577.65991, val_loss=595.29230\n",
      "Epoch 11870: train_loss=577.62531, val_loss=595.42853\n",
      "Epoch 11871: train_loss=577.59625, val_loss=595.20282\n",
      "Epoch 11872: train_loss=577.57336, val_loss=595.41486\n",
      "Epoch 11873: train_loss=577.55762, val_loss=595.13745\n",
      "Epoch 11874: train_loss=577.54828, val_loss=595.42987\n",
      "Epoch 11875: train_loss=577.54315, val_loss=595.08960\n",
      "Epoch 11876: train_loss=577.53674, val_loss=595.43195\n",
      "Epoch 11877: train_loss=577.52307, val_loss=595.02155\n",
      "Epoch 11878: train_loss=577.48993, val_loss=595.34290\n",
      "Epoch 11879: train_loss=577.43591, val_loss=594.88898\n",
      "Epoch 11880: train_loss=577.35254, val_loss=595.11963\n",
      "Epoch 11881: train_loss=577.24762, val_loss=594.70343\n",
      "Epoch 11882: train_loss=577.13074, val_loss=594.82330\n",
      "Epoch 11883: train_loss=577.01501, val_loss=594.54236\n",
      "Epoch 11884: train_loss=576.91144, val_loss=594.56171\n",
      "Epoch 11885: train_loss=576.82849, val_loss=594.46112\n",
      "Epoch 11886: train_loss=576.76740, val_loss=594.38910\n",
      "Epoch 11887: train_loss=576.72437, val_loss=594.43787\n",
      "Epoch 11888: train_loss=576.69373, val_loss=594.27924\n",
      "Epoch 11889: train_loss=576.66840, val_loss=594.41339\n",
      "Epoch 11890: train_loss=576.63983, val_loss=594.18634\n",
      "Epoch 11891: train_loss=576.60449, val_loss=594.33820\n",
      "Epoch 11892: train_loss=576.55933, val_loss=594.07758\n",
      "Epoch 11893: train_loss=576.50439, val_loss=594.20056\n",
      "Epoch 11894: train_loss=576.44202, val_loss=593.95563\n",
      "Epoch 11895: train_loss=576.37543, val_loss=594.03418\n",
      "Epoch 11896: train_loss=576.30817, val_loss=593.84167\n",
      "Epoch 11897: train_loss=576.24255, val_loss=593.87140\n",
      "Epoch 11898: train_loss=576.18011, val_loss=593.74194\n",
      "Epoch 11899: train_loss=576.12164, val_loss=593.72308\n",
      "Epoch 11900: train_loss=576.06653, val_loss=593.65210\n",
      "Epoch 11901: train_loss=576.01471, val_loss=593.59253\n",
      "Epoch 11902: train_loss=575.96509, val_loss=593.56958\n",
      "Epoch 11903: train_loss=575.91754, val_loss=593.47217\n",
      "Epoch 11904: train_loss=575.87170, val_loss=593.49072\n",
      "Epoch 11905: train_loss=575.82733, val_loss=593.35754\n",
      "Epoch 11906: train_loss=575.78485, val_loss=593.41986\n",
      "Epoch 11907: train_loss=575.74438, val_loss=593.25256\n",
      "Epoch 11908: train_loss=575.70587, val_loss=593.35919\n",
      "Epoch 11909: train_loss=575.66895, val_loss=593.15503\n",
      "Epoch 11910: train_loss=575.63293, val_loss=593.29828\n",
      "Epoch 11911: train_loss=575.59680, val_loss=593.05920\n",
      "Epoch 11912: train_loss=575.55774, val_loss=593.22131\n",
      "Epoch 11913: train_loss=575.51562, val_loss=592.95880\n",
      "Epoch 11914: train_loss=575.46826, val_loss=593.11633\n",
      "Epoch 11915: train_loss=575.41608, val_loss=592.84766\n",
      "Epoch 11916: train_loss=575.35809, val_loss=592.98004\n",
      "Epoch 11917: train_loss=575.29669, val_loss=592.72937\n",
      "Epoch 11918: train_loss=575.23102, val_loss=592.82251\n",
      "Epoch 11919: train_loss=575.16541, val_loss=592.61505\n",
      "Epoch 11920: train_loss=575.10059, val_loss=592.66553\n",
      "Epoch 11921: train_loss=575.03784, val_loss=592.50806\n",
      "Epoch 11922: train_loss=574.97839, val_loss=592.51910\n",
      "Epoch 11923: train_loss=574.92139, val_loss=592.40961\n",
      "Epoch 11924: train_loss=574.86676, val_loss=592.38544\n",
      "Epoch 11925: train_loss=574.81390, val_loss=592.31696\n",
      "Epoch 11926: train_loss=574.76276, val_loss=592.26233\n",
      "Epoch 11927: train_loss=574.71283, val_loss=592.22693\n",
      "Epoch 11928: train_loss=574.66364, val_loss=592.14685\n",
      "Epoch 11929: train_loss=574.61523, val_loss=592.13684\n",
      "Epoch 11930: train_loss=574.56720, val_loss=592.03320\n",
      "Epoch 11931: train_loss=574.51984, val_loss=592.04614\n",
      "Epoch 11932: train_loss=574.47290, val_loss=591.92041\n",
      "Epoch 11933: train_loss=574.42719, val_loss=591.96234\n",
      "Epoch 11934: train_loss=574.38312, val_loss=591.81073\n",
      "Epoch 11935: train_loss=574.34131, val_loss=591.89178\n",
      "Epoch 11936: train_loss=574.30194, val_loss=591.70886\n",
      "Epoch 11937: train_loss=574.26526, val_loss=591.83636\n",
      "Epoch 11938: train_loss=574.23169, val_loss=591.61621\n",
      "Epoch 11939: train_loss=574.19995, val_loss=591.79150\n",
      "Epoch 11940: train_loss=574.17102, val_loss=591.53009\n",
      "Epoch 11941: train_loss=574.14081, val_loss=591.74164\n",
      "Epoch 11942: train_loss=574.10992, val_loss=591.44135\n",
      "Epoch 11943: train_loss=574.07288, val_loss=591.66254\n",
      "Epoch 11944: train_loss=574.02991, val_loss=591.33783\n",
      "Epoch 11945: train_loss=573.97717, val_loss=591.53888\n",
      "Epoch 11946: train_loss=573.91711, val_loss=591.21454\n",
      "Epoch 11947: train_loss=573.84564, val_loss=591.36285\n",
      "Epoch 11948: train_loss=573.76984, val_loss=591.07843\n",
      "Epoch 11949: train_loss=573.68884, val_loss=591.15887\n",
      "Epoch 11950: train_loss=573.61060, val_loss=590.95587\n",
      "Epoch 11951: train_loss=573.53748, val_loss=590.97314\n",
      "Epoch 11952: train_loss=573.47198, val_loss=590.86273\n",
      "Epoch 11953: train_loss=573.41357, val_loss=590.82062\n",
      "Epoch 11954: train_loss=573.36139, val_loss=590.78888\n",
      "Epoch 11955: train_loss=573.31427, val_loss=590.69421\n",
      "Epoch 11956: train_loss=573.27057, val_loss=590.72266\n",
      "Epoch 11957: train_loss=573.22925, val_loss=590.58362\n",
      "Epoch 11958: train_loss=573.18872, val_loss=590.65601\n",
      "Epoch 11959: train_loss=573.14929, val_loss=590.48016\n",
      "Epoch 11960: train_loss=573.10858, val_loss=590.58228\n",
      "Epoch 11961: train_loss=573.06836, val_loss=590.37897\n",
      "Epoch 11962: train_loss=573.02563, val_loss=590.50171\n",
      "Epoch 11963: train_loss=572.98438, val_loss=590.27734\n",
      "Epoch 11964: train_loss=572.93958, val_loss=590.41003\n",
      "Epoch 11965: train_loss=572.89532, val_loss=590.17236\n",
      "Epoch 11966: train_loss=572.84692, val_loss=590.30701\n",
      "Epoch 11967: train_loss=572.79871, val_loss=590.06476\n",
      "Epoch 11968: train_loss=572.74603, val_loss=590.19135\n",
      "Epoch 11969: train_loss=572.69397, val_loss=589.95453\n",
      "Epoch 11970: train_loss=572.63770, val_loss=590.06622\n",
      "Epoch 11971: train_loss=572.58258, val_loss=589.84344\n",
      "Epoch 11972: train_loss=572.52429, val_loss=589.93146\n",
      "Epoch 11973: train_loss=572.46661, val_loss=589.73126\n",
      "Epoch 11974: train_loss=572.40674, val_loss=589.78882\n",
      "Epoch 11975: train_loss=572.34778, val_loss=589.62195\n",
      "Epoch 11976: train_loss=572.28900, val_loss=589.64722\n",
      "Epoch 11977: train_loss=572.23206, val_loss=589.51904\n",
      "Epoch 11978: train_loss=572.17615, val_loss=589.51233\n",
      "Epoch 11979: train_loss=572.12225, val_loss=589.42194\n",
      "Epoch 11980: train_loss=572.06976, val_loss=589.38397\n",
      "Epoch 11981: train_loss=572.01862, val_loss=589.32831\n",
      "Epoch 11982: train_loss=571.96869, val_loss=589.26331\n",
      "Epoch 11983: train_loss=571.91980, val_loss=589.23566\n",
      "Epoch 11984: train_loss=571.87146, val_loss=589.14801\n",
      "Epoch 11985: train_loss=571.82404, val_loss=589.14771\n",
      "Epoch 11986: train_loss=571.77777, val_loss=589.03326\n",
      "Epoch 11987: train_loss=571.73309, val_loss=589.07013\n",
      "Epoch 11988: train_loss=571.69141, val_loss=588.92480\n",
      "Epoch 11989: train_loss=571.65210, val_loss=589.01440\n",
      "Epoch 11990: train_loss=571.61786, val_loss=588.82947\n",
      "Epoch 11991: train_loss=571.58691, val_loss=588.97968\n",
      "Epoch 11992: train_loss=571.56165, val_loss=588.74799\n",
      "Epoch 11993: train_loss=571.53882, val_loss=588.95850\n",
      "Epoch 11994: train_loss=571.51984, val_loss=588.67859\n",
      "Epoch 11995: train_loss=571.49927, val_loss=588.93036\n",
      "Epoch 11996: train_loss=571.47577, val_loss=588.59973\n",
      "Epoch 11997: train_loss=571.43958, val_loss=588.84711\n",
      "Epoch 11998: train_loss=571.39392, val_loss=588.48645\n",
      "Epoch 11999: train_loss=571.33002, val_loss=588.68555\n",
      "Epoch 12000: train_loss=571.25488, val_loss=588.34076\n",
      "Epoch 12001: train_loss=571.16711, val_loss=588.46606\n",
      "Epoch 12002: train_loss=571.07629, val_loss=588.19434\n",
      "Epoch 12003: train_loss=570.98633, val_loss=588.24017\n",
      "Epoch 12004: train_loss=570.90588, val_loss=588.08075\n",
      "Epoch 12005: train_loss=570.83588, val_loss=588.05371\n",
      "Epoch 12006: train_loss=570.77777, val_loss=588.00891\n",
      "Epoch 12007: train_loss=570.72974, val_loss=587.91711\n",
      "Epoch 12008: train_loss=570.68890, val_loss=587.95740\n",
      "Epoch 12009: train_loss=570.65222, val_loss=587.80695\n",
      "Epoch 12010: train_loss=570.61603, val_loss=587.90002\n",
      "Epoch 12011: train_loss=570.58105, val_loss=587.70483\n",
      "Epoch 12012: train_loss=570.54211, val_loss=587.82452\n",
      "Epoch 12013: train_loss=570.50244, val_loss=587.60089\n",
      "Epoch 12014: train_loss=570.45667, val_loss=587.72449\n",
      "Epoch 12015: train_loss=570.40894, val_loss=587.49005\n",
      "Epoch 12016: train_loss=570.35516, val_loss=587.60046\n",
      "Epoch 12017: train_loss=570.29987, val_loss=587.37476\n",
      "Epoch 12018: train_loss=570.24042, val_loss=587.45892\n",
      "Epoch 12019: train_loss=570.18109, val_loss=587.25879\n",
      "Epoch 12020: train_loss=570.11963, val_loss=587.30981\n",
      "Epoch 12021: train_loss=570.06000, val_loss=587.14832\n",
      "Epoch 12022: train_loss=570.00031, val_loss=587.16217\n",
      "Epoch 12023: train_loss=569.94305, val_loss=587.04535\n",
      "Epoch 12024: train_loss=569.88727, val_loss=587.02252\n",
      "Epoch 12025: train_loss=569.83405, val_loss=586.94989\n",
      "Epoch 12026: train_loss=569.78284, val_loss=586.89557\n",
      "Epoch 12027: train_loss=569.73303, val_loss=586.85632\n",
      "Epoch 12028: train_loss=569.68445, val_loss=586.77637\n",
      "Epoch 12029: train_loss=569.63660, val_loss=586.76599\n",
      "Epoch 12030: train_loss=569.58954, val_loss=586.66461\n",
      "Epoch 12031: train_loss=569.54303, val_loss=586.68262\n",
      "Epoch 12032: train_loss=569.49835, val_loss=586.55579\n",
      "Epoch 12033: train_loss=569.45459, val_loss=586.60699\n",
      "Epoch 12034: train_loss=569.41412, val_loss=586.44971\n",
      "Epoch 12035: train_loss=569.37494, val_loss=586.54510\n",
      "Epoch 12036: train_loss=569.33990, val_loss=586.35461\n",
      "Epoch 12037: train_loss=569.30554, val_loss=586.49634\n",
      "Epoch 12038: train_loss=569.27545, val_loss=586.26794\n",
      "Epoch 12039: train_loss=569.24396, val_loss=586.44934\n",
      "Epoch 12040: train_loss=569.21509, val_loss=586.18347\n",
      "Epoch 12041: train_loss=569.17944, val_loss=586.38281\n",
      "Epoch 12042: train_loss=569.14221, val_loss=586.08826\n",
      "Epoch 12043: train_loss=569.09210, val_loss=586.27301\n",
      "Epoch 12044: train_loss=569.03778, val_loss=585.97150\n",
      "Epoch 12045: train_loss=568.96985, val_loss=586.11249\n",
      "Epoch 12046: train_loss=568.90009, val_loss=585.84308\n",
      "Epoch 12047: train_loss=568.82391, val_loss=585.92889\n",
      "Epoch 12048: train_loss=568.75018, val_loss=585.72510\n",
      "Epoch 12049: train_loss=568.67804, val_loss=585.75403\n",
      "Epoch 12050: train_loss=568.61188, val_loss=585.62994\n",
      "Epoch 12051: train_loss=568.55170, val_loss=585.60254\n",
      "Epoch 12052: train_loss=568.49731, val_loss=585.55255\n",
      "Epoch 12053: train_loss=568.44806, val_loss=585.47632\n",
      "Epoch 12054: train_loss=568.40283, val_loss=585.48560\n",
      "Epoch 12055: train_loss=568.35968, val_loss=585.36768\n",
      "Epoch 12056: train_loss=568.31757, val_loss=585.41461\n",
      "Epoch 12057: train_loss=568.27521, val_loss=585.26465\n",
      "Epoch 12058: train_loss=568.23218, val_loss=585.33728\n",
      "Epoch 12059: train_loss=568.18970, val_loss=585.16626\n",
      "Epoch 12060: train_loss=568.14594, val_loss=585.25775\n",
      "Epoch 12061: train_loss=568.10333, val_loss=585.06830\n",
      "Epoch 12062: train_loss=568.05988, val_loss=585.17468\n",
      "Epoch 12063: train_loss=568.01715, val_loss=584.96912\n",
      "Epoch 12064: train_loss=567.97345, val_loss=585.09192\n",
      "Epoch 12065: train_loss=567.93115, val_loss=584.87231\n",
      "Epoch 12066: train_loss=567.88623, val_loss=585.00531\n",
      "Epoch 12067: train_loss=567.84271, val_loss=584.77246\n",
      "Epoch 12068: train_loss=567.79541, val_loss=584.90778\n",
      "Epoch 12069: train_loss=567.74860, val_loss=584.66870\n",
      "Epoch 12070: train_loss=567.69617, val_loss=584.79504\n",
      "Epoch 12071: train_loss=567.64349, val_loss=584.56036\n",
      "Epoch 12072: train_loss=567.58588, val_loss=584.66449\n",
      "Epoch 12073: train_loss=567.52844, val_loss=584.44812\n",
      "Epoch 12074: train_loss=567.46771, val_loss=584.52069\n",
      "Epoch 12075: train_loss=567.40662, val_loss=584.33850\n",
      "Epoch 12076: train_loss=567.34467, val_loss=584.37097\n",
      "Epoch 12077: train_loss=567.28412, val_loss=584.23755\n",
      "Epoch 12078: train_loss=567.22552, val_loss=584.22479\n",
      "Epoch 12079: train_loss=567.17017, val_loss=584.14673\n",
      "Epoch 12080: train_loss=567.11823, val_loss=584.09265\n",
      "Epoch 12081: train_loss=567.06915, val_loss=584.06580\n",
      "Epoch 12082: train_loss=567.02228, val_loss=583.97687\n",
      "Epoch 12083: train_loss=566.97681, val_loss=583.98669\n",
      "Epoch 12084: train_loss=566.93201, val_loss=583.86816\n",
      "Epoch 12085: train_loss=566.88763, val_loss=583.90564\n",
      "Epoch 12086: train_loss=566.84418, val_loss=583.76196\n",
      "Epoch 12087: train_loss=566.80054, val_loss=583.82520\n",
      "Epoch 12088: train_loss=566.75861, val_loss=583.65961\n",
      "Epoch 12089: train_loss=566.71631, val_loss=583.75031\n",
      "Epoch 12090: train_loss=566.67694, val_loss=583.56110\n",
      "Epoch 12091: train_loss=566.63684, val_loss=583.68286\n",
      "Epoch 12092: train_loss=566.60095, val_loss=583.46747\n",
      "Epoch 12093: train_loss=566.56311, val_loss=583.62097\n",
      "Epoch 12094: train_loss=566.52972, val_loss=583.37659\n",
      "Epoch 12095: train_loss=566.49182, val_loss=583.55548\n",
      "Epoch 12096: train_loss=566.45770, val_loss=583.28406\n",
      "Epoch 12097: train_loss=566.41522, val_loss=583.47107\n",
      "Epoch 12098: train_loss=566.37360, val_loss=583.18213\n",
      "Epoch 12099: train_loss=566.32123, val_loss=583.35822\n",
      "Epoch 12100: train_loss=566.26868, val_loss=583.06836\n",
      "Epoch 12101: train_loss=566.20514, val_loss=583.21124\n",
      "Epoch 12102: train_loss=566.14087, val_loss=582.94360\n",
      "Epoch 12103: train_loss=566.06909, val_loss=583.03625\n",
      "Epoch 12104: train_loss=565.99774, val_loss=582.82178\n",
      "Epoch 12105: train_loss=565.92548, val_loss=582.85559\n",
      "Epoch 12106: train_loss=565.85773, val_loss=582.71887\n",
      "Epoch 12107: train_loss=565.79486, val_loss=582.69312\n",
      "Epoch 12108: train_loss=565.73895, val_loss=582.63947\n",
      "Epoch 12109: train_loss=565.68933, val_loss=582.56018\n",
      "Epoch 12110: train_loss=565.64417, val_loss=582.57098\n",
      "Epoch 12111: train_loss=565.60156, val_loss=582.44806\n",
      "Epoch 12112: train_loss=565.55969, val_loss=582.50079\n",
      "Epoch 12113: train_loss=565.51746, val_loss=582.34534\n",
      "Epoch 12114: train_loss=565.47266, val_loss=582.42017\n",
      "Epoch 12115: train_loss=565.42810, val_loss=582.24438\n",
      "Epoch 12116: train_loss=565.37988, val_loss=582.32758\n",
      "Epoch 12117: train_loss=565.33154, val_loss=582.14294\n",
      "Epoch 12118: train_loss=565.27985, val_loss=582.22229\n",
      "Epoch 12119: train_loss=565.22882, val_loss=582.03790\n",
      "Epoch 12120: train_loss=565.17542, val_loss=582.10474\n",
      "Epoch 12121: train_loss=565.12244, val_loss=581.92908\n",
      "Epoch 12122: train_loss=565.06781, val_loss=581.98151\n",
      "Epoch 12123: train_loss=565.01434, val_loss=581.82086\n",
      "Epoch 12124: train_loss=564.95984, val_loss=581.85583\n",
      "Epoch 12125: train_loss=564.90607, val_loss=581.71252\n",
      "Epoch 12126: train_loss=564.85156, val_loss=581.72845\n",
      "Epoch 12127: train_loss=564.79858, val_loss=581.60614\n",
      "Epoch 12128: train_loss=564.74548, val_loss=581.60449\n",
      "Epoch 12129: train_loss=564.69318, val_loss=581.50446\n",
      "Epoch 12130: train_loss=564.64105, val_loss=581.48560\n",
      "Epoch 12131: train_loss=564.58966, val_loss=581.40387\n",
      "Epoch 12132: train_loss=564.53882, val_loss=581.36981\n",
      "Epoch 12133: train_loss=564.48840, val_loss=581.30267\n",
      "Epoch 12134: train_loss=564.43848, val_loss=581.25775\n",
      "Epoch 12135: train_loss=564.38849, val_loss=581.20105\n",
      "Epoch 12136: train_loss=564.33875, val_loss=581.14752\n",
      "Epoch 12137: train_loss=564.28912, val_loss=581.09766\n",
      "Epoch 12138: train_loss=564.23950, val_loss=581.03778\n",
      "Epoch 12139: train_loss=564.18982, val_loss=580.99506\n",
      "Epoch 12140: train_loss=564.14044, val_loss=580.92938\n",
      "Epoch 12141: train_loss=564.09082, val_loss=580.89301\n",
      "Epoch 12142: train_loss=564.04156, val_loss=580.81866\n",
      "Epoch 12143: train_loss=563.99255, val_loss=580.79327\n",
      "Epoch 12144: train_loss=563.94379, val_loss=580.70770\n",
      "Epoch 12145: train_loss=563.89551, val_loss=580.69891\n",
      "Epoch 12146: train_loss=563.84796, val_loss=580.59723\n",
      "Epoch 12147: train_loss=563.80109, val_loss=580.61438\n",
      "Epoch 12148: train_loss=563.75604, val_loss=580.48920\n",
      "Epoch 12149: train_loss=563.71271, val_loss=580.54578\n",
      "Epoch 12150: train_loss=563.67346, val_loss=580.38708\n",
      "Epoch 12151: train_loss=563.63763, val_loss=580.50372\n",
      "Epoch 12152: train_loss=563.61011, val_loss=580.30194\n",
      "Epoch 12153: train_loss=563.58832, val_loss=580.50317\n",
      "Epoch 12154: train_loss=563.57904, val_loss=580.24817\n",
      "Epoch 12155: train_loss=563.57611, val_loss=580.54407\n",
      "Epoch 12156: train_loss=563.58514, val_loss=580.22192\n",
      "Epoch 12157: train_loss=563.59161, val_loss=580.59332\n",
      "Epoch 12158: train_loss=563.60431, val_loss=580.19238\n",
      "Epoch 12159: train_loss=563.59155, val_loss=580.56842\n",
      "Epoch 12160: train_loss=563.56726, val_loss=580.08728\n",
      "Epoch 12161: train_loss=563.49139, val_loss=580.36511\n",
      "Epoch 12162: train_loss=563.39148, val_loss=579.87665\n",
      "Epoch 12163: train_loss=563.24982, val_loss=580.00745\n",
      "Epoch 12164: train_loss=563.10559, val_loss=579.66272\n",
      "Epoch 12165: train_loss=562.97198, val_loss=579.67792\n",
      "Epoch 12166: train_loss=562.87030, val_loss=579.57153\n",
      "Epoch 12167: train_loss=562.80573, val_loss=579.49176\n",
      "Epoch 12168: train_loss=562.77332, val_loss=579.58716\n",
      "Epoch 12169: train_loss=562.75977, val_loss=579.40613\n",
      "Epoch 12170: train_loss=562.74713, val_loss=579.58234\n",
      "Epoch 12171: train_loss=562.72546, val_loss=579.31830\n",
      "Epoch 12172: train_loss=562.68219, val_loss=579.46985\n",
      "Epoch 12173: train_loss=562.62268, val_loss=579.19153\n",
      "Epoch 12174: train_loss=562.54553, val_loss=579.27191\n",
      "Epoch 12175: train_loss=562.46649, val_loss=579.06708\n",
      "Epoch 12176: train_loss=562.38892, val_loss=579.06903\n",
      "Epoch 12177: train_loss=562.32153, val_loss=578.98364\n",
      "Epoch 12178: train_loss=562.26624, val_loss=578.91528\n",
      "Epoch 12179: train_loss=562.22192, val_loss=578.93488\n",
      "Epoch 12180: train_loss=562.18396, val_loss=578.80298\n",
      "Epoch 12181: train_loss=562.14758, val_loss=578.87909\n",
      "Epoch 12182: train_loss=562.11023, val_loss=578.70117\n",
      "Epoch 12183: train_loss=562.06781, val_loss=578.79169\n",
      "Epoch 12184: train_loss=562.02179, val_loss=578.59827\n",
      "Epoch 12185: train_loss=561.96985, val_loss=578.67413\n",
      "Epoch 12186: train_loss=561.91541, val_loss=578.49207\n",
      "Epoch 12187: train_loss=561.85785, val_loss=578.53857\n",
      "Epoch 12188: train_loss=561.80072, val_loss=578.39050\n",
      "Epoch 12189: train_loss=561.74323, val_loss=578.40234\n",
      "Epoch 12190: train_loss=561.68793, val_loss=578.29822\n",
      "Epoch 12191: train_loss=561.63428, val_loss=578.27264\n",
      "Epoch 12192: train_loss=561.58295, val_loss=578.21484\n",
      "Epoch 12193: train_loss=561.53381, val_loss=578.15344\n",
      "Epoch 12194: train_loss=561.48651, val_loss=578.13458\n",
      "Epoch 12195: train_loss=561.44049, val_loss=578.04504\n",
      "Epoch 12196: train_loss=561.39496, val_loss=578.05212\n",
      "Epoch 12197: train_loss=561.34985, val_loss=577.93976\n",
      "Epoch 12198: train_loss=561.30463, val_loss=577.96375\n",
      "Epoch 12199: train_loss=561.25922, val_loss=577.83563\n",
      "Epoch 12200: train_loss=561.21326, val_loss=577.87231\n",
      "Epoch 12201: train_loss=561.16736, val_loss=577.73511\n",
      "Epoch 12202: train_loss=561.12109, val_loss=577.77875\n",
      "Epoch 12203: train_loss=561.07489, val_loss=577.63312\n",
      "Epoch 12204: train_loss=561.02795, val_loss=577.67938\n",
      "Epoch 12205: train_loss=560.98096, val_loss=577.53033\n",
      "Epoch 12206: train_loss=560.93304, val_loss=577.57660\n",
      "Epoch 12207: train_loss=560.88501, val_loss=577.43018\n",
      "Epoch 12208: train_loss=560.83636, val_loss=577.47113\n",
      "Epoch 12209: train_loss=560.78741, val_loss=577.32947\n",
      "Epoch 12210: train_loss=560.73804, val_loss=577.36072\n",
      "Epoch 12211: train_loss=560.68829, val_loss=577.22906\n",
      "Epoch 12212: train_loss=560.63885, val_loss=577.25098\n",
      "Epoch 12213: train_loss=560.58923, val_loss=577.13025\n",
      "Epoch 12214: train_loss=560.54010, val_loss=577.14166\n",
      "Epoch 12215: train_loss=560.49127, val_loss=577.02899\n",
      "Epoch 12216: train_loss=560.44281, val_loss=577.03387\n",
      "Epoch 12217: train_loss=560.39465, val_loss=576.92822\n",
      "Epoch 12218: train_loss=560.34692, val_loss=576.93408\n",
      "Epoch 12219: train_loss=560.29980, val_loss=576.82806\n",
      "Epoch 12220: train_loss=560.25275, val_loss=576.83569\n",
      "Epoch 12221: train_loss=560.20624, val_loss=576.72406\n",
      "Epoch 12222: train_loss=560.15985, val_loss=576.73950\n",
      "Epoch 12223: train_loss=560.11414, val_loss=576.62054\n",
      "Epoch 12224: train_loss=560.06891, val_loss=576.65137\n",
      "Epoch 12225: train_loss=560.02490, val_loss=576.51825\n",
      "Epoch 12226: train_loss=559.98151, val_loss=576.57068\n",
      "Epoch 12227: train_loss=559.94043, val_loss=576.41681\n",
      "Epoch 12228: train_loss=559.89996, val_loss=576.50226\n",
      "Epoch 12229: train_loss=559.86346, val_loss=576.32208\n",
      "Epoch 12230: train_loss=559.82800, val_loss=576.44781\n",
      "Epoch 12231: train_loss=559.79639, val_loss=576.23456\n",
      "Epoch 12232: train_loss=559.76599, val_loss=576.40393\n",
      "Epoch 12233: train_loss=559.73999, val_loss=576.15405\n",
      "Epoch 12234: train_loss=559.71063, val_loss=576.35901\n",
      "Epoch 12235: train_loss=559.68378, val_loss=576.07385\n",
      "Epoch 12236: train_loss=559.64728, val_loss=576.28595\n",
      "Epoch 12237: train_loss=559.60852, val_loss=575.97583\n",
      "Epoch 12238: train_loss=559.55621, val_loss=576.16162\n",
      "Epoch 12239: train_loss=559.49762, val_loss=575.85413\n",
      "Epoch 12240: train_loss=559.42670, val_loss=575.98840\n",
      "Epoch 12241: train_loss=559.35327, val_loss=575.72473\n",
      "Epoch 12242: train_loss=559.27576, val_loss=575.79608\n",
      "Epoch 12243: train_loss=559.20276, val_loss=575.61108\n",
      "Epoch 12244: train_loss=559.13385, val_loss=575.61884\n",
      "Epoch 12245: train_loss=559.07269, val_loss=575.52393\n",
      "Epoch 12246: train_loss=559.01886, val_loss=575.47516\n",
      "Epoch 12247: train_loss=558.97125, val_loss=575.45697\n",
      "Epoch 12248: train_loss=558.92841, val_loss=575.35840\n",
      "Epoch 12249: train_loss=558.88843, val_loss=575.39655\n",
      "Epoch 12250: train_loss=558.85071, val_loss=575.25482\n",
      "Epoch 12251: train_loss=558.81299, val_loss=575.33374\n",
      "Epoch 12252: train_loss=558.77643, val_loss=575.15900\n",
      "Epoch 12253: train_loss=558.73755, val_loss=575.26294\n",
      "Epoch 12254: train_loss=558.69879, val_loss=575.06464\n",
      "Epoch 12255: train_loss=558.65778, val_loss=575.18347\n",
      "Epoch 12256: train_loss=558.61725, val_loss=574.96912\n",
      "Epoch 12257: train_loss=558.57428, val_loss=575.09894\n",
      "Epoch 12258: train_loss=558.53241, val_loss=574.87469\n",
      "Epoch 12259: train_loss=558.48822, val_loss=575.00806\n",
      "Epoch 12260: train_loss=558.44366, val_loss=574.77600\n",
      "Epoch 12261: train_loss=558.39581, val_loss=574.90448\n",
      "Epoch 12262: train_loss=558.34772, val_loss=574.67291\n",
      "Epoch 12263: train_loss=558.29578, val_loss=574.78754\n",
      "Epoch 12264: train_loss=558.24316, val_loss=574.56683\n",
      "Epoch 12265: train_loss=558.18701, val_loss=574.65686\n",
      "Epoch 12266: train_loss=558.13080, val_loss=574.45984\n",
      "Epoch 12267: train_loss=558.07312, val_loss=574.52026\n",
      "Epoch 12268: train_loss=558.01715, val_loss=574.35516\n",
      "Epoch 12269: train_loss=557.96075, val_loss=574.38367\n",
      "Epoch 12270: train_loss=557.90594, val_loss=574.25781\n",
      "Epoch 12271: train_loss=557.85254, val_loss=574.25323\n",
      "Epoch 12272: train_loss=557.80096, val_loss=574.16693\n",
      "Epoch 12273: train_loss=557.75098, val_loss=574.13092\n",
      "Epoch 12274: train_loss=557.70288, val_loss=574.08081\n",
      "Epoch 12275: train_loss=557.65601, val_loss=574.01648\n",
      "Epoch 12276: train_loss=557.61017, val_loss=573.99512\n",
      "Epoch 12277: train_loss=557.56506, val_loss=573.90918\n",
      "Epoch 12278: train_loss=557.52051, val_loss=573.91095\n",
      "Epoch 12279: train_loss=557.47632, val_loss=573.80536\n",
      "Epoch 12280: train_loss=557.43280, val_loss=573.83185\n",
      "Epoch 12281: train_loss=557.39117, val_loss=573.70441\n",
      "Epoch 12282: train_loss=557.35059, val_loss=573.76587\n",
      "Epoch 12283: train_loss=557.31360, val_loss=573.60956\n",
      "Epoch 12284: train_loss=557.27826, val_loss=573.71564\n",
      "Epoch 12285: train_loss=557.24792, val_loss=573.52441\n",
      "Epoch 12286: train_loss=557.22046, val_loss=573.68555\n",
      "Epoch 12287: train_loss=557.19879, val_loss=573.45349\n",
      "Epoch 12288: train_loss=557.17810, val_loss=573.66675\n",
      "Epoch 12289: train_loss=557.16052, val_loss=573.38824\n",
      "Epoch 12290: train_loss=557.13757, val_loss=573.63306\n",
      "Epoch 12291: train_loss=557.11426, val_loss=573.31293\n",
      "Epoch 12292: train_loss=557.07788, val_loss=573.55389\n",
      "Epoch 12293: train_loss=557.03534, val_loss=573.20715\n",
      "Epoch 12294: train_loss=556.97333, val_loss=573.40033\n",
      "Epoch 12295: train_loss=556.90222, val_loss=573.06842\n",
      "Epoch 12296: train_loss=556.81726, val_loss=573.18970\n",
      "Epoch 12297: train_loss=556.73053, val_loss=572.93091\n",
      "Epoch 12298: train_loss=556.64410, val_loss=572.97504\n",
      "Epoch 12299: train_loss=556.56677, val_loss=572.82990\n",
      "Epoch 12300: train_loss=556.50092, val_loss=572.80151\n",
      "Epoch 12301: train_loss=556.44757, val_loss=572.77441\n",
      "Epoch 12302: train_loss=556.40533, val_loss=572.67993\n",
      "Epoch 12303: train_loss=556.37067, val_loss=572.73804\n",
      "Epoch 12304: train_loss=556.33936, val_loss=572.58527\n",
      "Epoch 12305: train_loss=556.30701, val_loss=572.68512\n",
      "Epoch 12306: train_loss=556.27264, val_loss=572.49371\n",
      "Epoch 12307: train_loss=556.23267, val_loss=572.60516\n",
      "Epoch 12308: train_loss=556.18994, val_loss=572.39813\n",
      "Epoch 12309: train_loss=556.14087, val_loss=572.49615\n",
      "Epoch 12310: train_loss=556.08978, val_loss=572.29498\n",
      "Epoch 12311: train_loss=556.03406, val_loss=572.36621\n",
      "Epoch 12312: train_loss=555.97913, val_loss=572.19214\n",
      "Epoch 12313: train_loss=555.92236, val_loss=572.22980\n",
      "Epoch 12314: train_loss=555.86707, val_loss=572.09546\n",
      "Epoch 12315: train_loss=555.81287, val_loss=572.09668\n",
      "Epoch 12316: train_loss=555.76093, val_loss=572.00549\n",
      "Epoch 12317: train_loss=555.71112, val_loss=571.97351\n",
      "Epoch 12318: train_loss=555.66321, val_loss=571.92047\n",
      "Epoch 12319: train_loss=555.61700, val_loss=571.85999\n",
      "Epoch 12320: train_loss=555.57184, val_loss=571.83649\n",
      "Epoch 12321: train_loss=555.52753, val_loss=571.75323\n",
      "Epoch 12322: train_loss=555.48346, val_loss=571.75201\n",
      "Epoch 12323: train_loss=555.43976, val_loss=571.65308\n",
      "Epoch 12324: train_loss=555.39618, val_loss=571.67041\n",
      "Epoch 12325: train_loss=555.35333, val_loss=571.55585\n",
      "Epoch 12326: train_loss=555.31067, val_loss=571.59210\n",
      "Epoch 12327: train_loss=555.26947, val_loss=571.45935\n",
      "Epoch 12328: train_loss=555.22858, val_loss=571.52002\n",
      "Epoch 12329: train_loss=555.18970, val_loss=571.36694\n",
      "Epoch 12330: train_loss=555.15112, val_loss=571.45361\n",
      "Epoch 12331: train_loss=555.11426, val_loss=571.27576\n",
      "Epoch 12332: train_loss=555.07690, val_loss=571.38751\n",
      "Epoch 12333: train_loss=555.04138, val_loss=571.18719\n",
      "Epoch 12334: train_loss=555.00421, val_loss=571.32080\n",
      "Epoch 12335: train_loss=554.96808, val_loss=571.10065\n",
      "Epoch 12336: train_loss=554.92883, val_loss=571.24811\n",
      "Epoch 12337: train_loss=554.89111, val_loss=571.01056\n",
      "Epoch 12338: train_loss=554.84851, val_loss=571.16046\n",
      "Epoch 12339: train_loss=554.80621, val_loss=570.91473\n",
      "Epoch 12340: train_loss=554.75830, val_loss=571.05701\n",
      "Epoch 12341: train_loss=554.70996, val_loss=570.81519\n",
      "Epoch 12342: train_loss=554.65643, val_loss=570.93811\n",
      "Epoch 12343: train_loss=554.60291, val_loss=570.71295\n",
      "Epoch 12344: train_loss=554.54547, val_loss=570.80469\n",
      "Epoch 12345: train_loss=554.48877, val_loss=570.60986\n",
      "Epoch 12346: train_loss=554.43048, val_loss=570.66449\n",
      "Epoch 12347: train_loss=554.37354, val_loss=570.51428\n",
      "Epoch 12348: train_loss=554.31775, val_loss=570.52826\n",
      "Epoch 12349: train_loss=554.26489, val_loss=570.42773\n",
      "Epoch 12350: train_loss=554.21448, val_loss=570.40381\n",
      "Epoch 12351: train_loss=554.16699, val_loss=570.35028\n",
      "Epoch 12352: train_loss=554.12152, val_loss=570.29370\n",
      "Epoch 12353: train_loss=554.07770, val_loss=570.27582\n",
      "Epoch 12354: train_loss=554.03546, val_loss=570.18927\n",
      "Epoch 12355: train_loss=553.99432, val_loss=570.20483\n",
      "Epoch 12356: train_loss=553.95459, val_loss=570.08966\n",
      "Epoch 12357: train_loss=553.91638, val_loss=570.14264\n",
      "Epoch 12358: train_loss=553.88068, val_loss=569.99707\n",
      "Epoch 12359: train_loss=553.84680, val_loss=570.09186\n",
      "Epoch 12360: train_loss=553.81604, val_loss=569.91315\n",
      "Epoch 12361: train_loss=553.78680, val_loss=570.05438\n",
      "Epoch 12362: train_loss=553.76190, val_loss=569.84113\n",
      "Epoch 12363: train_loss=553.73822, val_loss=570.03088\n",
      "Epoch 12364: train_loss=553.71973, val_loss=569.77704\n",
      "Epoch 12365: train_loss=553.69751, val_loss=570.00183\n",
      "Epoch 12366: train_loss=553.67719, val_loss=569.70587\n",
      "Epoch 12367: train_loss=553.64526, val_loss=569.93555\n",
      "Epoch 12368: train_loss=553.60962, val_loss=569.61169\n",
      "Epoch 12369: train_loss=553.55621, val_loss=569.80865\n",
      "Epoch 12370: train_loss=553.49658, val_loss=569.49017\n",
      "Epoch 12371: train_loss=553.42145, val_loss=569.62360\n",
      "Epoch 12372: train_loss=553.34399, val_loss=569.35822\n",
      "Epoch 12373: train_loss=553.26361, val_loss=569.42236\n",
      "Epoch 12374: train_loss=553.18988, val_loss=569.25024\n",
      "Epoch 12375: train_loss=553.12299, val_loss=569.24890\n",
      "Epoch 12376: train_loss=553.06604, val_loss=569.18127\n",
      "Epoch 12377: train_loss=553.01855, val_loss=569.11877\n",
      "Epoch 12378: train_loss=552.97894, val_loss=569.13715\n",
      "Epoch 12379: train_loss=552.94458, val_loss=569.02100\n",
      "Epoch 12380: train_loss=552.91278, val_loss=569.09515\n",
      "Epoch 12381: train_loss=552.88123, val_loss=568.93536\n",
      "Epoch 12382: train_loss=552.84766, val_loss=569.03827\n",
      "Epoch 12383: train_loss=552.81335, val_loss=568.85077\n",
      "Epoch 12384: train_loss=552.77545, val_loss=568.96313\n",
      "Epoch 12385: train_loss=552.73602, val_loss=568.76147\n",
      "Epoch 12386: train_loss=552.69293, val_loss=568.87073\n",
      "Epoch 12387: train_loss=552.64844, val_loss=568.66943\n",
      "Epoch 12388: train_loss=552.60071, val_loss=568.76416\n",
      "Epoch 12389: train_loss=552.55176, val_loss=568.57379\n",
      "Epoch 12390: train_loss=552.50049, val_loss=568.64337\n",
      "Epoch 12391: train_loss=552.44879, val_loss=568.47717\n",
      "Epoch 12392: train_loss=552.39636, val_loss=568.51575\n",
      "Epoch 12393: train_loss=552.34460, val_loss=568.38599\n",
      "Epoch 12394: train_loss=552.29401, val_loss=568.39270\n",
      "Epoch 12395: train_loss=552.24548, val_loss=568.30365\n",
      "Epoch 12396: train_loss=552.19879, val_loss=568.27930\n",
      "Epoch 12397: train_loss=552.15381, val_loss=568.22552\n",
      "Epoch 12398: train_loss=552.11017, val_loss=568.17480\n",
      "Epoch 12399: train_loss=552.06763, val_loss=568.14948\n",
      "Epoch 12400: train_loss=552.02588, val_loss=568.07629\n",
      "Epoch 12401: train_loss=551.98474, val_loss=568.07495\n",
      "Epoch 12402: train_loss=551.94421, val_loss=567.98163\n",
      "Epoch 12403: train_loss=551.90399, val_loss=568.00214\n",
      "Epoch 12404: train_loss=551.86481, val_loss=567.88953\n",
      "Epoch 12405: train_loss=551.82611, val_loss=567.93567\n",
      "Epoch 12406: train_loss=551.78967, val_loss=567.80029\n",
      "Epoch 12407: train_loss=551.75482, val_loss=567.88232\n",
      "Epoch 12408: train_loss=551.72327, val_loss=567.71832\n",
      "Epoch 12409: train_loss=551.69415, val_loss=567.84338\n",
      "Epoch 12410: train_loss=551.66797, val_loss=567.64459\n",
      "Epoch 12411: train_loss=551.64294, val_loss=567.81287\n",
      "Epoch 12412: train_loss=551.62091, val_loss=567.57550\n",
      "Epoch 12413: train_loss=551.59576, val_loss=567.77264\n",
      "Epoch 12414: train_loss=551.57031, val_loss=567.50201\n",
      "Epoch 12415: train_loss=551.53784, val_loss=567.70715\n",
      "Epoch 12416: train_loss=551.50244, val_loss=567.41522\n",
      "Epoch 12417: train_loss=551.45715, val_loss=567.60242\n",
      "Epoch 12418: train_loss=551.40637, val_loss=567.30945\n",
      "Epoch 12419: train_loss=551.34515, val_loss=567.45435\n",
      "Epoch 12420: train_loss=551.28070, val_loss=567.19293\n",
      "Epoch 12421: train_loss=551.21100, val_loss=567.28339\n",
      "Epoch 12422: train_loss=551.14362, val_loss=567.08704\n",
      "Epoch 12423: train_loss=551.07849, val_loss=567.12048\n",
      "Epoch 12424: train_loss=551.01965, val_loss=567.00275\n",
      "Epoch 12425: train_loss=550.96680, val_loss=566.98474\n",
      "Epoch 12426: train_loss=550.91974, val_loss=566.93774\n",
      "Epoch 12427: train_loss=550.87708, val_loss=566.87396\n",
      "Epoch 12428: train_loss=550.83801, val_loss=566.88306\n",
      "Epoch 12429: train_loss=550.80170, val_loss=566.77783\n",
      "Epoch 12430: train_loss=550.76654, val_loss=566.83032\n",
      "Epoch 12431: train_loss=550.73291, val_loss=566.69159\n",
      "Epoch 12432: train_loss=550.69989, val_loss=566.77905\n",
      "Epoch 12433: train_loss=550.66803, val_loss=566.61011\n",
      "Epoch 12434: train_loss=550.63593, val_loss=566.72699\n",
      "Epoch 12435: train_loss=550.60510, val_loss=566.53064\n",
      "Epoch 12436: train_loss=550.57257, val_loss=566.66956\n",
      "Epoch 12437: train_loss=550.54028, val_loss=566.45117\n",
      "Epoch 12438: train_loss=550.50427, val_loss=566.59882\n",
      "Epoch 12439: train_loss=550.46686, val_loss=566.36609\n",
      "Epoch 12440: train_loss=550.42548, val_loss=566.50787\n",
      "Epoch 12441: train_loss=550.38190, val_loss=566.27356\n",
      "Epoch 12442: train_loss=550.33435, val_loss=566.40045\n",
      "Epoch 12443: train_loss=550.28564, val_loss=566.17908\n",
      "Epoch 12444: train_loss=550.23389, val_loss=566.28168\n",
      "Epoch 12445: train_loss=550.18219, val_loss=566.08386\n",
      "Epoch 12446: train_loss=550.12915, val_loss=566.15540\n",
      "Epoch 12447: train_loss=550.07678, val_loss=565.99170\n",
      "Epoch 12448: train_loss=550.02490, val_loss=566.03168\n",
      "Epoch 12449: train_loss=549.97479, val_loss=565.90900\n",
      "Epoch 12450: train_loss=549.92633, val_loss=565.91473\n",
      "Epoch 12451: train_loss=549.87946, val_loss=565.83167\n",
      "Epoch 12452: train_loss=549.83466, val_loss=565.80426\n",
      "Epoch 12453: train_loss=549.79163, val_loss=565.75830\n",
      "Epoch 12454: train_loss=549.74994, val_loss=565.70447\n",
      "Epoch 12455: train_loss=549.70917, val_loss=565.68750\n",
      "Epoch 12456: train_loss=549.66913, val_loss=565.61066\n",
      "Epoch 12457: train_loss=549.63019, val_loss=565.61847\n",
      "Epoch 12458: train_loss=549.59174, val_loss=565.51849\n",
      "Epoch 12459: train_loss=549.55426, val_loss=565.55487\n",
      "Epoch 12460: train_loss=549.51813, val_loss=565.43158\n",
      "Epoch 12461: train_loss=549.48376, val_loss=565.50525\n",
      "Epoch 12462: train_loss=549.45264, val_loss=565.34985\n",
      "Epoch 12463: train_loss=549.42438, val_loss=565.47131\n",
      "Epoch 12464: train_loss=549.40082, val_loss=565.27826\n",
      "Epoch 12465: train_loss=549.38019, val_loss=565.45392\n",
      "Epoch 12466: train_loss=549.36279, val_loss=565.21875\n",
      "Epoch 12467: train_loss=549.34576, val_loss=565.44104\n",
      "Epoch 12468: train_loss=549.33032, val_loss=565.16095\n",
      "Epoch 12469: train_loss=549.30951, val_loss=565.40625\n",
      "Epoch 12470: train_loss=549.28625, val_loss=565.08838\n",
      "Epoch 12471: train_loss=549.25049, val_loss=565.31995\n",
      "Epoch 12472: train_loss=549.20544, val_loss=564.98541\n",
      "Epoch 12473: train_loss=549.14441, val_loss=565.16541\n",
      "Epoch 12474: train_loss=549.07471, val_loss=564.85858\n",
      "Epoch 12475: train_loss=548.99762, val_loss=564.97089\n",
      "Epoch 12476: train_loss=548.92126, val_loss=564.74030\n",
      "Epoch 12477: train_loss=548.84833, val_loss=564.78546\n",
      "Epoch 12478: train_loss=548.78412, val_loss=564.65387\n",
      "Epoch 12479: train_loss=548.72803, val_loss=564.63373\n",
      "Epoch 12480: train_loss=548.68103, val_loss=564.59961\n",
      "Epoch 12481: train_loss=548.64178, val_loss=564.52112\n",
      "Epoch 12482: train_loss=548.60803, val_loss=564.56543\n",
      "Epoch 12483: train_loss=548.57849, val_loss=564.43671\n",
      "Epoch 12484: train_loss=548.54944, val_loss=564.53003\n",
      "Epoch 12485: train_loss=548.52161, val_loss=564.35889\n",
      "Epoch 12486: train_loss=548.49060, val_loss=564.47766\n",
      "Epoch 12487: train_loss=548.45923, val_loss=564.28009\n",
      "Epoch 12488: train_loss=548.42334, val_loss=564.40735\n",
      "Epoch 12489: train_loss=548.38605, val_loss=564.19794\n",
      "Epoch 12490: train_loss=548.34424, val_loss=564.31573\n",
      "Epoch 12491: train_loss=548.30054, val_loss=564.10931\n",
      "Epoch 12492: train_loss=548.25244, val_loss=564.20563\n",
      "Epoch 12493: train_loss=548.20392, val_loss=564.02106\n",
      "Epoch 12494: train_loss=548.15338, val_loss=564.08716\n",
      "Epoch 12495: train_loss=548.10358, val_loss=563.93506\n",
      "Epoch 12496: train_loss=548.05371, val_loss=563.96625\n",
      "Epoch 12497: train_loss=548.00580, val_loss=563.85449\n",
      "Epoch 12498: train_loss=547.95941, val_loss=563.85242\n",
      "Epoch 12499: train_loss=547.91510, val_loss=563.78033\n",
      "Epoch 12500: train_loss=547.87256, val_loss=563.74811\n",
      "Epoch 12501: train_loss=547.83154, val_loss=563.70953\n",
      "Epoch 12502: train_loss=547.79175, val_loss=563.65143\n",
      "Epoch 12503: train_loss=547.75293, val_loss=563.64240\n",
      "Epoch 12504: train_loss=547.71497, val_loss=563.56171\n",
      "Epoch 12505: train_loss=547.67792, val_loss=563.58289\n",
      "Epoch 12506: train_loss=547.64227, val_loss=563.47723\n",
      "Epoch 12507: train_loss=547.60730, val_loss=563.52850\n",
      "Epoch 12508: train_loss=547.57416, val_loss=563.39563\n",
      "Epoch 12509: train_loss=547.54248, val_loss=563.48029\n",
      "Epoch 12510: train_loss=547.51276, val_loss=563.31860\n",
      "Epoch 12511: train_loss=547.48395, val_loss=563.43744\n",
      "Epoch 12512: train_loss=547.45654, val_loss=563.24591\n",
      "Epoch 12513: train_loss=547.43018, val_loss=563.39368\n",
      "Epoch 12514: train_loss=547.40314, val_loss=563.17383\n",
      "Epoch 12515: train_loss=547.37567, val_loss=563.34113\n",
      "Epoch 12516: train_loss=547.34540, val_loss=563.09955\n",
      "Epoch 12517: train_loss=547.31293, val_loss=563.27362\n",
      "Epoch 12518: train_loss=547.27679, val_loss=563.01819\n",
      "Epoch 12519: train_loss=547.23645, val_loss=563.18195\n",
      "Epoch 12520: train_loss=547.19232, val_loss=562.92657\n",
      "Epoch 12521: train_loss=547.14240, val_loss=563.06250\n",
      "Epoch 12522: train_loss=547.08936, val_loss=562.82861\n",
      "Epoch 12523: train_loss=547.03400, val_loss=562.92841\n",
      "Epoch 12524: train_loss=546.97852, val_loss=562.73242\n",
      "Epoch 12525: train_loss=546.92340, val_loss=562.79248\n",
      "Epoch 12526: train_loss=546.87079, val_loss=562.64551\n",
      "Epoch 12527: train_loss=546.82043, val_loss=562.66626\n",
      "Epoch 12528: train_loss=546.77301, val_loss=562.57037\n",
      "Epoch 12529: train_loss=546.72845, val_loss=562.55438\n",
      "Epoch 12530: train_loss=546.68665, val_loss=562.50183\n",
      "Epoch 12531: train_loss=546.64661, val_loss=562.45380\n",
      "Epoch 12532: train_loss=546.60815, val_loss=562.43640\n",
      "Epoch 12533: train_loss=546.57086, val_loss=562.36444\n",
      "Epoch 12534: train_loss=546.53412, val_loss=562.37390\n",
      "Epoch 12535: train_loss=546.49835, val_loss=562.27893\n",
      "Epoch 12536: train_loss=546.46289, val_loss=562.31177\n",
      "Epoch 12537: train_loss=546.42853, val_loss=562.19543\n",
      "Epoch 12538: train_loss=546.39508, val_loss=562.25586\n",
      "Epoch 12539: train_loss=546.36310, val_loss=562.11639\n",
      "Epoch 12540: train_loss=546.33276, val_loss=562.20782\n",
      "Epoch 12541: train_loss=546.30408, val_loss=562.04120\n",
      "Epoch 12542: train_loss=546.27740, val_loss=562.16595\n",
      "Epoch 12543: train_loss=546.25134, val_loss=561.97162\n",
      "Epoch 12544: train_loss=546.22693, val_loss=562.12952\n",
      "Epoch 12545: train_loss=546.20367, val_loss=561.90717\n",
      "Epoch 12546: train_loss=546.18121, val_loss=562.09485\n",
      "Epoch 12547: train_loss=546.15924, val_loss=561.84344\n",
      "Epoch 12548: train_loss=546.13568, val_loss=562.05176\n",
      "Epoch 12549: train_loss=546.11011, val_loss=561.77496\n",
      "Epoch 12550: train_loss=546.07904, val_loss=561.98395\n",
      "Epoch 12551: train_loss=546.04260, val_loss=561.69153\n",
      "Epoch 12552: train_loss=545.99768, val_loss=561.87268\n",
      "Epoch 12553: train_loss=545.94482, val_loss=561.58606\n",
      "Epoch 12554: train_loss=545.88342, val_loss=561.71906\n",
      "Epoch 12555: train_loss=545.81934, val_loss=561.47601\n",
      "Epoch 12556: train_loss=545.75287, val_loss=561.55237\n",
      "Epoch 12557: train_loss=545.69000, val_loss=561.38190\n",
      "Epoch 12558: train_loss=545.63135, val_loss=561.40204\n",
      "Epoch 12559: train_loss=545.57965, val_loss=561.31464\n",
      "Epoch 12560: train_loss=545.53442, val_loss=561.28198\n",
      "Epoch 12561: train_loss=545.49506, val_loss=561.26630\n",
      "Epoch 12562: train_loss=545.46033, val_loss=561.18622\n",
      "Epoch 12563: train_loss=545.42859, val_loss=561.22430\n",
      "Epoch 12564: train_loss=545.39923, val_loss=561.10474\n",
      "Epoch 12565: train_loss=545.37122, val_loss=561.18475\n",
      "Epoch 12566: train_loss=545.34375, val_loss=561.03223\n",
      "Epoch 12567: train_loss=545.31653, val_loss=561.14172\n",
      "Epoch 12568: train_loss=545.28833, val_loss=560.96277\n",
      "Epoch 12569: train_loss=545.25824, val_loss=561.08734\n",
      "Epoch 12570: train_loss=545.22662, val_loss=560.89081\n",
      "Epoch 12571: train_loss=545.19177, val_loss=561.01593\n",
      "Epoch 12572: train_loss=545.15515, val_loss=560.81244\n",
      "Epoch 12573: train_loss=545.11511, val_loss=560.92712\n",
      "Epoch 12574: train_loss=545.07355, val_loss=560.72894\n",
      "Epoch 12575: train_loss=545.02905, val_loss=560.82428\n",
      "Epoch 12576: train_loss=544.98383, val_loss=560.64398\n",
      "Epoch 12577: train_loss=544.93756, val_loss=560.71570\n",
      "Epoch 12578: train_loss=544.89124, val_loss=560.56250\n",
      "Epoch 12579: train_loss=544.84546, val_loss=560.61041\n",
      "Epoch 12580: train_loss=544.80078, val_loss=560.48492\n",
      "Epoch 12581: train_loss=544.75714, val_loss=560.51086\n",
      "Epoch 12582: train_loss=544.71490, val_loss=560.40814\n",
      "Epoch 12583: train_loss=544.67261, val_loss=560.41309\n",
      "Epoch 12584: train_loss=544.63086, val_loss=560.33362\n",
      "Epoch 12585: train_loss=544.58978, val_loss=560.32117\n",
      "Epoch 12586: train_loss=544.54938, val_loss=560.26202\n",
      "Epoch 12587: train_loss=544.50958, val_loss=560.23053\n",
      "Epoch 12588: train_loss=544.47034, val_loss=560.18585\n",
      "Epoch 12589: train_loss=544.43158, val_loss=560.14001\n",
      "Epoch 12590: train_loss=544.39313, val_loss=560.10931\n",
      "Epoch 12591: train_loss=544.35480, val_loss=560.05225\n",
      "Epoch 12592: train_loss=544.31671, val_loss=560.03168\n",
      "Epoch 12593: train_loss=544.27905, val_loss=559.96088\n",
      "Epoch 12594: train_loss=544.24170, val_loss=559.95343\n",
      "Epoch 12595: train_loss=544.20471, val_loss=559.86798\n",
      "Epoch 12596: train_loss=544.16870, val_loss=559.88055\n",
      "Epoch 12597: train_loss=544.13348, val_loss=559.77679\n",
      "Epoch 12598: train_loss=544.09961, val_loss=559.81506\n",
      "Epoch 12599: train_loss=544.06775, val_loss=559.68805\n",
      "Epoch 12600: train_loss=544.03784, val_loss=559.76245\n",
      "Epoch 12601: train_loss=544.01111, val_loss=559.60980\n",
      "Epoch 12602: train_loss=543.98834, val_loss=559.73199\n",
      "Epoch 12603: train_loss=543.96881, val_loss=559.54626\n",
      "Epoch 12604: train_loss=543.95355, val_loss=559.72180\n",
      "Epoch 12605: train_loss=543.94293, val_loss=559.49786\n",
      "Epoch 12606: train_loss=543.93463, val_loss=559.72351\n",
      "Epoch 12607: train_loss=543.92810, val_loss=559.45502\n",
      "Epoch 12608: train_loss=543.91608, val_loss=559.70483\n",
      "Epoch 12609: train_loss=543.89984, val_loss=559.39319\n",
      "Epoch 12610: train_loss=543.86920, val_loss=559.62805\n",
      "Epoch 12611: train_loss=543.82941, val_loss=559.29297\n",
      "Epoch 12612: train_loss=543.77008, val_loss=559.47333\n",
      "Epoch 12613: train_loss=543.69989, val_loss=559.15717\n",
      "Epoch 12614: train_loss=543.61755, val_loss=559.26385\n",
      "Epoch 12615: train_loss=543.53442, val_loss=559.02393\n",
      "Epoch 12616: train_loss=543.45514, val_loss=559.06085\n",
      "Epoch 12617: train_loss=543.38635, val_loss=558.93365\n",
      "Epoch 12618: train_loss=543.33026, val_loss=558.91022\n",
      "Epoch 12619: train_loss=543.28632, val_loss=558.88855\n",
      "Epoch 12620: train_loss=543.25250, val_loss=558.80731\n",
      "Epoch 12621: train_loss=543.22571, val_loss=558.86163\n",
      "Epoch 12622: train_loss=543.20227, val_loss=558.73090\n",
      "Epoch 12623: train_loss=543.17932, val_loss=558.82990\n",
      "Epoch 12624: train_loss=543.15643, val_loss=558.66254\n",
      "Epoch 12625: train_loss=543.13025, val_loss=558.78180\n",
      "Epoch 12626: train_loss=543.10089, val_loss=558.58972\n",
      "Epoch 12627: train_loss=543.06677, val_loss=558.70831\n",
      "Epoch 12628: train_loss=543.02985, val_loss=558.50934\n",
      "Epoch 12629: train_loss=542.98828, val_loss=558.61462\n",
      "Epoch 12630: train_loss=542.94495, val_loss=558.42456\n",
      "Epoch 12631: train_loss=542.89813, val_loss=558.50458\n",
      "Epoch 12632: train_loss=542.85107, val_loss=558.33679\n",
      "Epoch 12633: train_loss=542.80267, val_loss=558.38599\n",
      "Epoch 12634: train_loss=542.75580, val_loss=558.25183\n",
      "Epoch 12635: train_loss=542.70990, val_loss=558.27100\n",
      "Epoch 12636: train_loss=542.66602, val_loss=558.17340\n",
      "Epoch 12637: train_loss=542.62421, val_loss=558.16711\n",
      "Epoch 12638: train_loss=542.58423, val_loss=558.09955\n",
      "Epoch 12639: train_loss=542.54547, val_loss=558.07172\n",
      "Epoch 12640: train_loss=542.50800, val_loss=558.02692\n",
      "Epoch 12641: train_loss=542.47119, val_loss=557.98236\n",
      "Epoch 12642: train_loss=542.43475, val_loss=557.95587\n",
      "Epoch 12643: train_loss=542.39874, val_loss=557.89545\n",
      "Epoch 12644: train_loss=542.36322, val_loss=557.88892\n",
      "Epoch 12645: train_loss=542.32849, val_loss=557.81061\n",
      "Epoch 12646: train_loss=542.29443, val_loss=557.82635\n",
      "Epoch 12647: train_loss=542.26160, val_loss=557.72736\n",
      "Epoch 12648: train_loss=542.23004, val_loss=557.77161\n",
      "Epoch 12649: train_loss=542.20020, val_loss=557.64862\n",
      "Epoch 12650: train_loss=542.17310, val_loss=557.72888\n",
      "Epoch 12651: train_loss=542.14758, val_loss=557.57739\n",
      "Epoch 12652: train_loss=542.12457, val_loss=557.69952\n",
      "Epoch 12653: train_loss=542.10388, val_loss=557.51721\n",
      "Epoch 12654: train_loss=542.08441, val_loss=557.68048\n",
      "Epoch 12655: train_loss=542.06622, val_loss=557.46564\n",
      "Epoch 12656: train_loss=542.04559, val_loss=557.65295\n",
      "Epoch 12657: train_loss=542.02252, val_loss=557.40686\n",
      "Epoch 12658: train_loss=541.99268, val_loss=557.59668\n",
      "Epoch 12659: train_loss=541.95776, val_loss=557.33264\n",
      "Epoch 12660: train_loss=541.91248, val_loss=557.49707\n",
      "Epoch 12661: train_loss=541.86035, val_loss=557.23602\n",
      "Epoch 12662: train_loss=541.79883, val_loss=557.35126\n",
      "Epoch 12663: train_loss=541.73511, val_loss=557.12921\n",
      "Epoch 12664: train_loss=541.66907, val_loss=557.19019\n",
      "Epoch 12665: train_loss=541.60742, val_loss=557.03540\n",
      "Epoch 12666: train_loss=541.55029, val_loss=557.04578\n",
      "Epoch 12667: train_loss=541.50067, val_loss=556.96240\n",
      "Epoch 12668: train_loss=541.45660, val_loss=556.92645\n",
      "Epoch 12669: train_loss=541.41797, val_loss=556.90527\n",
      "Epoch 12670: train_loss=541.38324, val_loss=556.82898\n",
      "Epoch 12671: train_loss=541.35132, val_loss=556.85645\n",
      "Epoch 12672: train_loss=541.32147, val_loss=556.74579\n",
      "Epoch 12673: train_loss=541.29248, val_loss=556.80774\n",
      "Epoch 12674: train_loss=541.26434, val_loss=556.66815\n",
      "Epoch 12675: train_loss=541.23700, val_loss=556.75739\n",
      "Epoch 12676: train_loss=541.20917, val_loss=556.59338\n",
      "Epoch 12677: train_loss=541.18103, val_loss=556.70258\n",
      "Epoch 12678: train_loss=541.15198, val_loss=556.52142\n",
      "Epoch 12679: train_loss=541.12213, val_loss=556.64465\n",
      "Epoch 12680: train_loss=541.09125, val_loss=556.45056\n",
      "Epoch 12681: train_loss=541.05951, val_loss=556.58185\n",
      "Epoch 12682: train_loss=541.02679, val_loss=556.37830\n",
      "Epoch 12683: train_loss=540.99115, val_loss=556.50793\n",
      "Epoch 12684: train_loss=540.95404, val_loss=556.29968\n",
      "Epoch 12685: train_loss=540.91284, val_loss=556.41864\n",
      "Epoch 12686: train_loss=540.87054, val_loss=556.21802\n",
      "Epoch 12687: train_loss=540.82593, val_loss=556.32343\n",
      "Epoch 12688: train_loss=540.78119, val_loss=556.13745\n",
      "Epoch 12689: train_loss=540.73566, val_loss=556.22351\n",
      "Epoch 12690: train_loss=540.68951, val_loss=556.05695\n",
      "Epoch 12691: train_loss=540.64307, val_loss=556.11688\n",
      "Epoch 12692: train_loss=540.59637, val_loss=555.97644\n",
      "Epoch 12693: train_loss=540.55054, val_loss=556.00848\n",
      "Epoch 12694: train_loss=540.50610, val_loss=555.90063\n",
      "Epoch 12695: train_loss=540.46344, val_loss=555.90619\n",
      "Epoch 12696: train_loss=540.42242, val_loss=555.82837\n",
      "Epoch 12697: train_loss=540.38300, val_loss=555.81049\n",
      "Epoch 12698: train_loss=540.34479, val_loss=555.75830\n",
      "Epoch 12699: train_loss=540.30762, val_loss=555.72314\n",
      "Epoch 12700: train_loss=540.27112, val_loss=555.68939\n",
      "Epoch 12701: train_loss=540.23523, val_loss=555.63873\n",
      "Epoch 12702: train_loss=540.19977, val_loss=555.62042\n",
      "Epoch 12703: train_loss=540.16455, val_loss=555.55402\n",
      "Epoch 12704: train_loss=540.13031, val_loss=555.55670\n",
      "Epoch 12705: train_loss=540.09723, val_loss=555.47083\n",
      "Epoch 12706: train_loss=540.06586, val_loss=555.50385\n",
      "Epoch 12707: train_loss=540.03699, val_loss=555.39069\n",
      "Epoch 12708: train_loss=540.01086, val_loss=555.46594\n",
      "Epoch 12709: train_loss=539.98846, val_loss=555.32080\n",
      "Epoch 12710: train_loss=539.96899, val_loss=555.44617\n",
      "Epoch 12711: train_loss=539.95435, val_loss=555.26520\n",
      "Epoch 12712: train_loss=539.94196, val_loss=555.44006\n",
      "Epoch 12713: train_loss=539.93280, val_loss=555.21912\n",
      "Epoch 12714: train_loss=539.92139, val_loss=555.42798\n",
      "Epoch 12715: train_loss=539.90967, val_loss=555.16895\n",
      "Epoch 12716: train_loss=539.89008, val_loss=555.38513\n",
      "Epoch 12717: train_loss=539.86462, val_loss=555.09583\n",
      "Epoch 12718: train_loss=539.82404, val_loss=555.27966\n",
      "Epoch 12719: train_loss=539.77289, val_loss=554.99072\n",
      "Epoch 12720: train_loss=539.70978, val_loss=555.11841\n",
      "Epoch 12721: train_loss=539.64111, val_loss=554.87469\n",
      "Epoch 12722: train_loss=539.57153, val_loss=554.94434\n",
      "Epoch 12723: train_loss=539.50610, val_loss=554.77960\n",
      "Epoch 12724: train_loss=539.44751, val_loss=554.79413\n",
      "Epoch 12725: train_loss=539.39746, val_loss=554.71771\n",
      "Epoch 12726: train_loss=539.35571, val_loss=554.67920\n",
      "Epoch 12727: train_loss=539.32147, val_loss=554.67950\n",
      "Epoch 12728: train_loss=539.29285, val_loss=554.59479\n",
      "Epoch 12729: train_loss=539.26801, val_loss=554.65253\n",
      "Epoch 12730: train_loss=539.24518, val_loss=554.52667\n",
      "Epoch 12731: train_loss=539.22290, val_loss=554.61975\n",
      "Epoch 12732: train_loss=539.20062, val_loss=554.46143\n",
      "Epoch 12733: train_loss=539.17743, val_loss=554.57751\n",
      "Epoch 12734: train_loss=539.15314, val_loss=554.39655\n",
      "Epoch 12735: train_loss=539.12732, val_loss=554.52429\n",
      "Epoch 12736: train_loss=539.09906, val_loss=554.32678\n",
      "Epoch 12737: train_loss=539.06793, val_loss=554.45251\n",
      "Epoch 12738: train_loss=539.03375, val_loss=554.24957\n",
      "Epoch 12739: train_loss=538.99750, val_loss=554.36609\n",
      "Epoch 12740: train_loss=538.95868, val_loss=554.16907\n",
      "Epoch 12741: train_loss=538.91772, val_loss=554.26746\n",
      "Epoch 12742: train_loss=538.87482, val_loss=554.08527\n",
      "Epoch 12743: train_loss=538.83075, val_loss=554.15802\n",
      "Epoch 12744: train_loss=538.78650, val_loss=554.00281\n",
      "Epoch 12745: train_loss=538.74292, val_loss=554.04956\n",
      "Epoch 12746: train_loss=538.70044, val_loss=553.92578\n",
      "Epoch 12747: train_loss=538.65936, val_loss=553.94855\n",
      "Epoch 12748: train_loss=538.62030, val_loss=553.85413\n",
      "Epoch 12749: train_loss=538.58240, val_loss=553.85406\n",
      "Epoch 12750: train_loss=538.54602, val_loss=553.78528\n",
      "Epoch 12751: train_loss=538.51074, val_loss=553.76758\n",
      "Epoch 12752: train_loss=538.47626, val_loss=553.71851\n",
      "Epoch 12753: train_loss=538.44238, val_loss=553.68817\n",
      "Epoch 12754: train_loss=538.40906, val_loss=553.65350\n",
      "Epoch 12755: train_loss=538.37585, val_loss=553.61395\n",
      "Epoch 12756: train_loss=538.34271, val_loss=553.59088\n",
      "Epoch 12757: train_loss=538.31006, val_loss=553.54230\n",
      "Epoch 12758: train_loss=538.27759, val_loss=553.53192\n",
      "Epoch 12759: train_loss=538.24554, val_loss=553.47137\n",
      "Epoch 12760: train_loss=538.21411, val_loss=553.47717\n",
      "Epoch 12761: train_loss=538.18329, val_loss=553.40002\n",
      "Epoch 12762: train_loss=538.15375, val_loss=553.42828\n",
      "Epoch 12763: train_loss=538.12567, val_loss=553.33020\n",
      "Epoch 12764: train_loss=538.10022, val_loss=553.39294\n",
      "Epoch 12765: train_loss=538.07739, val_loss=553.26794\n",
      "Epoch 12766: train_loss=538.05878, val_loss=553.37634\n",
      "Epoch 12767: train_loss=538.04382, val_loss=553.21869\n",
      "Epoch 12768: train_loss=538.03284, val_loss=553.37665\n",
      "Epoch 12769: train_loss=538.02472, val_loss=553.18164\n",
      "Epoch 12770: train_loss=538.01917, val_loss=553.38367\n",
      "Epoch 12771: train_loss=538.01392, val_loss=553.14771\n",
      "Epoch 12772: train_loss=538.00470, val_loss=553.37073\n",
      "Epoch 12773: train_loss=537.98962, val_loss=553.09802\n",
      "Epoch 12774: train_loss=537.96338, val_loss=553.30536\n",
      "Epoch 12775: train_loss=537.92505, val_loss=553.01276\n",
      "Epoch 12776: train_loss=537.87354, val_loss=553.17346\n",
      "Epoch 12777: train_loss=537.81189, val_loss=552.90021\n",
      "Epoch 12778: train_loss=537.74353, val_loss=553.00110\n",
      "Epoch 12779: train_loss=537.67352, val_loss=552.79260\n",
      "Epoch 12780: train_loss=537.60748, val_loss=552.83630\n",
      "Epoch 12781: train_loss=537.54907, val_loss=552.71771\n",
      "Epoch 12782: train_loss=537.50012, val_loss=552.70764\n",
      "Epoch 12783: train_loss=537.46057, val_loss=552.67560\n",
      "Epoch 12784: train_loss=537.42877, val_loss=552.61615\n",
      "Epoch 12785: train_loss=537.40253, val_loss=552.65021\n",
      "Epoch 12786: train_loss=537.37988, val_loss=552.54755\n",
      "Epoch 12787: train_loss=537.35822, val_loss=552.62207\n",
      "Epoch 12788: train_loss=537.33624, val_loss=552.48688\n",
      "Epoch 12789: train_loss=537.31427, val_loss=552.58429\n",
      "Epoch 12790: train_loss=537.28955, val_loss=552.42645\n",
      "Epoch 12791: train_loss=537.26385, val_loss=552.53186\n",
      "Epoch 12792: train_loss=537.23486, val_loss=552.36176\n",
      "Epoch 12793: train_loss=537.20422, val_loss=552.46527\n",
      "Epoch 12794: train_loss=537.17053, val_loss=552.29443\n",
      "Epoch 12795: train_loss=537.13580, val_loss=552.38666\n",
      "Epoch 12796: train_loss=537.09869, val_loss=552.22437\n",
      "Epoch 12797: train_loss=537.06171, val_loss=552.30084\n",
      "Epoch 12798: train_loss=537.02362, val_loss=552.15350\n",
      "Epoch 12799: train_loss=536.98547, val_loss=552.20953\n",
      "Epoch 12800: train_loss=536.94647, val_loss=552.08398\n",
      "Epoch 12801: train_loss=536.90808, val_loss=552.11700\n",
      "Epoch 12802: train_loss=536.87048, val_loss=552.01935\n",
      "Epoch 12803: train_loss=536.83398, val_loss=552.03003\n",
      "Epoch 12804: train_loss=536.79877, val_loss=551.95929\n",
      "Epoch 12805: train_loss=536.76453, val_loss=551.94891\n",
      "Epoch 12806: train_loss=536.73138, val_loss=551.90076\n",
      "Epoch 12807: train_loss=536.69910, val_loss=551.87311\n",
      "Epoch 12808: train_loss=536.66736, val_loss=551.84454\n",
      "Epoch 12809: train_loss=536.63617, val_loss=551.80243\n",
      "Epoch 12810: train_loss=536.60547, val_loss=551.78979\n",
      "Epoch 12811: train_loss=536.57520, val_loss=551.73199\n",
      "Epoch 12812: train_loss=536.54559, val_loss=551.73895\n",
      "Epoch 12813: train_loss=536.51697, val_loss=551.66418\n",
      "Epoch 12814: train_loss=536.48950, val_loss=551.69751\n",
      "Epoch 12815: train_loss=536.46344, val_loss=551.59998\n",
      "Epoch 12816: train_loss=536.43909, val_loss=551.66364\n",
      "Epoch 12817: train_loss=536.41656, val_loss=551.54077\n",
      "Epoch 12818: train_loss=536.39655, val_loss=551.64276\n",
      "Epoch 12819: train_loss=536.37952, val_loss=551.49170\n",
      "Epoch 12820: train_loss=536.36633, val_loss=551.63953\n",
      "Epoch 12821: train_loss=536.35651, val_loss=551.45441\n",
      "Epoch 12822: train_loss=536.34930, val_loss=551.64600\n",
      "Epoch 12823: train_loss=536.34369, val_loss=551.42438\n",
      "Epoch 12824: train_loss=536.33807, val_loss=551.64941\n",
      "Epoch 12825: train_loss=536.33002, val_loss=551.38971\n",
      "Epoch 12826: train_loss=536.31482, val_loss=551.62372\n",
      "Epoch 12827: train_loss=536.29523, val_loss=551.33356\n",
      "Epoch 12828: train_loss=536.26086, val_loss=551.54211\n",
      "Epoch 12829: train_loss=536.21869, val_loss=551.24377\n",
      "Epoch 12830: train_loss=536.16150, val_loss=551.40076\n",
      "Epoch 12831: train_loss=536.09924, val_loss=551.13672\n",
      "Epoch 12832: train_loss=536.03149, val_loss=551.23346\n",
      "Epoch 12833: train_loss=535.96576, val_loss=551.04126\n",
      "Epoch 12834: train_loss=535.90497, val_loss=551.07928\n",
      "Epoch 12835: train_loss=535.85199, val_loss=550.97968\n",
      "Epoch 12836: train_loss=535.80853, val_loss=550.96405\n",
      "Epoch 12837: train_loss=535.77393, val_loss=550.95068\n",
      "Epoch 12838: train_loss=535.74658, val_loss=550.88403\n",
      "Epoch 12839: train_loss=535.72400, val_loss=550.93103\n",
      "Epoch 12840: train_loss=535.70380, val_loss=550.82141\n",
      "Epoch 12841: train_loss=535.68347, val_loss=550.90112\n",
      "Epoch 12842: train_loss=535.66180, val_loss=550.76410\n",
      "Epoch 12843: train_loss=535.63879, val_loss=550.85876\n",
      "Epoch 12844: train_loss=535.61334, val_loss=550.70538\n",
      "Epoch 12845: train_loss=535.58618, val_loss=550.80328\n",
      "Epoch 12846: train_loss=535.55682, val_loss=550.64453\n",
      "Epoch 12847: train_loss=535.52582, val_loss=550.73755\n",
      "Epoch 12848: train_loss=535.49310, val_loss=550.57990\n",
      "Epoch 12849: train_loss=535.45917, val_loss=550.66260\n",
      "Epoch 12850: train_loss=535.42450, val_loss=550.51154\n",
      "Epoch 12851: train_loss=535.38928, val_loss=550.58209\n",
      "Epoch 12852: train_loss=535.35382, val_loss=550.44226\n",
      "Epoch 12853: train_loss=535.31812, val_loss=550.49933\n",
      "Epoch 12854: train_loss=535.28229, val_loss=550.37445\n",
      "Epoch 12855: train_loss=535.24591, val_loss=550.41406\n",
      "Epoch 12856: train_loss=535.21039, val_loss=550.30731\n",
      "Epoch 12857: train_loss=535.17511, val_loss=550.32886\n",
      "Epoch 12858: train_loss=535.14032, val_loss=550.24292\n",
      "Epoch 12859: train_loss=535.10577, val_loss=550.24756\n",
      "Epoch 12860: train_loss=535.07184, val_loss=550.18170\n",
      "Epoch 12861: train_loss=535.03851, val_loss=550.16864\n",
      "Epoch 12862: train_loss=535.00568, val_loss=550.11823\n",
      "Epoch 12863: train_loss=534.97388, val_loss=550.09351\n",
      "Epoch 12864: train_loss=534.94312, val_loss=550.05463\n",
      "Epoch 12865: train_loss=534.91406, val_loss=550.02509\n",
      "Epoch 12866: train_loss=534.88525, val_loss=549.99457\n",
      "Epoch 12867: train_loss=534.85663, val_loss=549.96198\n",
      "Epoch 12868: train_loss=534.82770, val_loss=549.93677\n",
      "Epoch 12869: train_loss=534.79877, val_loss=549.90167\n",
      "Epoch 12870: train_loss=534.76959, val_loss=549.88049\n",
      "Epoch 12871: train_loss=534.74060, val_loss=549.84076\n",
      "Epoch 12872: train_loss=534.71155, val_loss=549.82532\n",
      "Epoch 12873: train_loss=534.68256, val_loss=549.77771\n",
      "Epoch 12874: train_loss=534.65387, val_loss=549.77509\n",
      "Epoch 12875: train_loss=534.62579, val_loss=549.71387\n",
      "Epoch 12876: train_loss=534.59863, val_loss=549.73438\n",
      "Epoch 12877: train_loss=534.57343, val_loss=549.64990\n",
      "Epoch 12878: train_loss=534.55090, val_loss=549.71210\n",
      "Epoch 12879: train_loss=534.53308, val_loss=549.59601\n",
      "Epoch 12880: train_loss=534.52173, val_loss=549.72607\n",
      "Epoch 12881: train_loss=534.51923, val_loss=549.56903\n",
      "Epoch 12882: train_loss=534.52734, val_loss=549.79120\n",
      "Epoch 12883: train_loss=534.54816, val_loss=549.58331\n",
      "Epoch 12884: train_loss=534.58002, val_loss=549.91235\n",
      "Epoch 12885: train_loss=534.62744, val_loss=549.64124\n",
      "Epoch 12886: train_loss=534.67499, val_loss=550.04700\n",
      "Epoch 12887: train_loss=534.72388, val_loss=549.68225\n",
      "Epoch 12888: train_loss=534.74023, val_loss=550.06152\n",
      "Epoch 12889: train_loss=534.72607, val_loss=549.59241\n",
      "Epoch 12890: train_loss=534.64508, val_loss=549.82471\n",
      "Epoch 12891: train_loss=534.52362, val_loss=549.36157\n",
      "Epoch 12892: train_loss=534.36694, val_loss=549.44281\n",
      "Epoch 12893: train_loss=534.22028, val_loss=549.17908\n",
      "Epoch 12894: train_loss=534.10760, val_loss=549.17633\n",
      "Epoch 12895: train_loss=534.04462, val_loss=549.18060\n",
      "Epoch 12896: train_loss=534.02728, val_loss=549.10040\n",
      "Epoch 12897: train_loss=534.04010, val_loss=549.27856\n",
      "Epoch 12898: train_loss=534.06268, val_loss=549.09576\n",
      "Epoch 12899: train_loss=534.07312, val_loss=549.29633\n",
      "Epoch 12900: train_loss=534.05865, val_loss=549.03613\n",
      "Epoch 12901: train_loss=534.01355, val_loss=549.16339\n",
      "Epoch 12902: train_loss=533.94879, val_loss=548.93304\n",
      "Epoch 12903: train_loss=533.87720, val_loss=548.97858\n",
      "Epoch 12904: train_loss=533.81323, val_loss=548.86981\n",
      "Epoch 12905: train_loss=533.76501, val_loss=548.84595\n",
      "Epoch 12906: train_loss=533.73450, val_loss=548.86755\n",
      "Epoch 12907: train_loss=533.71759, val_loss=548.77979\n",
      "Epoch 12908: train_loss=533.70691, val_loss=548.87805\n",
      "Epoch 12909: train_loss=533.69672, val_loss=548.73535\n",
      "Epoch 12910: train_loss=533.68030, val_loss=548.84784\n",
      "Epoch 12911: train_loss=533.65637, val_loss=548.67865\n",
      "Epoch 12912: train_loss=533.62390, val_loss=548.76617\n",
      "Epoch 12913: train_loss=533.58527, val_loss=548.61371\n",
      "Epoch 12914: train_loss=533.54407, val_loss=548.66339\n",
      "Epoch 12915: train_loss=533.50330, val_loss=548.55670\n",
      "Epoch 12916: train_loss=533.46478, val_loss=548.56329\n",
      "Epoch 12917: train_loss=533.43011, val_loss=548.51483\n",
      "Epoch 12918: train_loss=533.39966, val_loss=548.48083\n",
      "Epoch 12919: train_loss=533.37311, val_loss=548.48541\n",
      "Epoch 12920: train_loss=533.34937, val_loss=548.41479\n",
      "Epoch 12921: train_loss=533.32690, val_loss=548.45477\n",
      "Epoch 12922: train_loss=533.30518, val_loss=548.35535\n",
      "Epoch 12923: train_loss=533.28290, val_loss=548.41632\n",
      "Epoch 12924: train_loss=533.25977, val_loss=548.29852\n",
      "Epoch 12925: train_loss=533.23523, val_loss=548.36627\n",
      "Epoch 12926: train_loss=533.20917, val_loss=548.24109\n",
      "Epoch 12927: train_loss=533.18140, val_loss=548.30481\n",
      "Epoch 12928: train_loss=533.15253, val_loss=548.18250\n",
      "Epoch 12929: train_loss=533.12280, val_loss=548.23688\n",
      "Epoch 12930: train_loss=533.09216, val_loss=548.12604\n",
      "Epoch 12931: train_loss=533.06146, val_loss=548.16809\n",
      "Epoch 12932: train_loss=533.03113, val_loss=548.07104\n",
      "Epoch 12933: train_loss=533.00073, val_loss=548.09845\n",
      "Epoch 12934: train_loss=532.97101, val_loss=548.01624\n",
      "Epoch 12935: train_loss=532.94147, val_loss=548.03156\n",
      "Epoch 12936: train_loss=532.91272, val_loss=547.96289\n",
      "Epoch 12937: train_loss=532.88428, val_loss=547.96942\n",
      "Epoch 12938: train_loss=532.85632, val_loss=547.90906\n",
      "Epoch 12939: train_loss=532.82861, val_loss=547.91083\n",
      "Epoch 12940: train_loss=532.80133, val_loss=547.85333\n",
      "Epoch 12941: train_loss=532.77441, val_loss=547.85693\n",
      "Epoch 12942: train_loss=532.74768, val_loss=547.79669\n",
      "Epoch 12943: train_loss=532.72156, val_loss=547.80847\n",
      "Epoch 12944: train_loss=532.69592, val_loss=547.73944\n",
      "Epoch 12945: train_loss=532.67084, val_loss=547.76825\n",
      "Epoch 12946: train_loss=532.64703, val_loss=547.68555\n",
      "Epoch 12947: train_loss=532.62439, val_loss=547.74164\n",
      "Epoch 12948: train_loss=532.60400, val_loss=547.63684\n",
      "Epoch 12949: train_loss=532.58575, val_loss=547.72809\n",
      "Epoch 12950: train_loss=532.57025, val_loss=547.59583\n",
      "Epoch 12951: train_loss=532.55695, val_loss=547.72577\n",
      "Epoch 12952: train_loss=532.54596, val_loss=547.56146\n",
      "Epoch 12953: train_loss=532.53522, val_loss=547.72296\n",
      "Epoch 12954: train_loss=532.52380, val_loss=547.52716\n",
      "Epoch 12955: train_loss=532.50909, val_loss=547.70135\n",
      "Epoch 12956: train_loss=532.49005, val_loss=547.48273\n",
      "Epoch 12957: train_loss=532.46460, val_loss=547.64685\n",
      "Epoch 12958: train_loss=532.43359, val_loss=547.42334\n",
      "Epoch 12959: train_loss=532.39581, val_loss=547.55804\n",
      "Epoch 12960: train_loss=532.35370, val_loss=547.35425\n",
      "Epoch 12961: train_loss=532.30792, val_loss=547.44873\n",
      "Epoch 12962: train_loss=532.26257, val_loss=547.29004\n",
      "Epoch 12963: train_loss=532.21832, val_loss=547.34033\n",
      "Epoch 12964: train_loss=532.17737, val_loss=547.24030\n",
      "Epoch 12965: train_loss=532.14038, val_loss=547.24884\n",
      "Epoch 12966: train_loss=532.10809, val_loss=547.20331\n",
      "Epoch 12967: train_loss=532.07910, val_loss=547.17371\n",
      "Epoch 12968: train_loss=532.05316, val_loss=547.17249\n",
      "Epoch 12969: train_loss=532.02893, val_loss=547.11169\n",
      "Epoch 12970: train_loss=532.00616, val_loss=547.14331\n",
      "Epoch 12971: train_loss=531.98425, val_loss=547.05646\n",
      "Epoch 12972: train_loss=531.96222, val_loss=547.11108\n",
      "Epoch 12973: train_loss=531.94073, val_loss=547.00397\n",
      "Epoch 12974: train_loss=531.91888, val_loss=547.07715\n",
      "Epoch 12975: train_loss=531.89752, val_loss=546.95349\n",
      "Epoch 12976: train_loss=531.87622, val_loss=547.04358\n",
      "Epoch 12977: train_loss=531.85547, val_loss=546.90424\n",
      "Epoch 12978: train_loss=531.83545, val_loss=547.01263\n",
      "Epoch 12979: train_loss=531.81604, val_loss=546.85712\n",
      "Epoch 12980: train_loss=531.79688, val_loss=546.98230\n",
      "Epoch 12981: train_loss=531.77753, val_loss=546.81177\n",
      "Epoch 12982: train_loss=531.75836, val_loss=546.95013\n",
      "Epoch 12983: train_loss=531.73828, val_loss=546.76544\n",
      "Epoch 12984: train_loss=531.71765, val_loss=546.90973\n",
      "Epoch 12985: train_loss=531.69452, val_loss=546.71454\n",
      "Epoch 12986: train_loss=531.66931, val_loss=546.85461\n",
      "Epoch 12987: train_loss=531.64111, val_loss=546.65790\n",
      "Epoch 12988: train_loss=531.61060, val_loss=546.78448\n",
      "Epoch 12989: train_loss=531.57764, val_loss=546.59753\n",
      "Epoch 12990: train_loss=531.54248, val_loss=546.70221\n",
      "Epoch 12991: train_loss=531.50629, val_loss=546.53748\n",
      "Epoch 12992: train_loss=531.46899, val_loss=546.61536\n",
      "Epoch 12993: train_loss=531.43250, val_loss=546.48181\n",
      "Epoch 12994: train_loss=531.39624, val_loss=546.53088\n",
      "Epoch 12995: train_loss=531.36249, val_loss=546.43237\n",
      "Epoch 12996: train_loss=531.32996, val_loss=546.45343\n",
      "Epoch 12997: train_loss=531.29938, val_loss=546.38666\n",
      "Epoch 12998: train_loss=531.27020, val_loss=546.38232\n",
      "Epoch 12999: train_loss=531.24207, val_loss=546.34424\n",
      "Epoch 13000: train_loss=531.21509, val_loss=546.31842\n",
      "Epoch 13001: train_loss=531.18896, val_loss=546.30432\n",
      "Epoch 13002: train_loss=531.16351, val_loss=546.25928\n",
      "Epoch 13003: train_loss=531.13861, val_loss=546.26605\n",
      "Epoch 13004: train_loss=531.11438, val_loss=546.20190\n",
      "Epoch 13005: train_loss=531.09088, val_loss=546.23254\n",
      "Epoch 13006: train_loss=531.06866, val_loss=546.14673\n",
      "Epoch 13007: train_loss=531.04755, val_loss=546.20563\n",
      "Epoch 13008: train_loss=531.02820, val_loss=546.09625\n",
      "Epoch 13009: train_loss=531.01038, val_loss=546.18976\n",
      "Epoch 13010: train_loss=530.99561, val_loss=546.05341\n",
      "Epoch 13011: train_loss=530.98309, val_loss=546.18915\n",
      "Epoch 13012: train_loss=530.97467, val_loss=546.02234\n",
      "Epoch 13013: train_loss=530.97028, val_loss=546.20538\n",
      "Epoch 13014: train_loss=530.96875, val_loss=546.00195\n",
      "Epoch 13015: train_loss=530.96912, val_loss=546.22681\n",
      "Epoch 13016: train_loss=530.96930, val_loss=545.98297\n",
      "Epoch 13017: train_loss=530.96515, val_loss=546.22412\n",
      "Epoch 13018: train_loss=530.95441, val_loss=545.94489\n",
      "Epoch 13019: train_loss=530.93317, val_loss=546.16931\n",
      "Epoch 13020: train_loss=530.90021, val_loss=545.87524\n",
      "Epoch 13021: train_loss=530.85400, val_loss=546.05115\n",
      "Epoch 13022: train_loss=530.79816, val_loss=545.78009\n",
      "Epoch 13023: train_loss=530.73547, val_loss=545.89301\n",
      "Epoch 13024: train_loss=530.67224, val_loss=545.69019\n",
      "Epoch 13025: train_loss=530.61237, val_loss=545.74243\n",
      "Epoch 13026: train_loss=530.56104, val_loss=545.63483\n",
      "Epoch 13027: train_loss=530.51898, val_loss=545.63153\n",
      "Epoch 13028: train_loss=530.48682, val_loss=545.61230\n",
      "Epoch 13029: train_loss=530.46228, val_loss=545.55823\n",
      "Epoch 13030: train_loss=530.44312, val_loss=545.60480\n",
      "Epoch 13031: train_loss=530.42737, val_loss=545.50732\n",
      "Epoch 13032: train_loss=530.41217, val_loss=545.59241\n",
      "Epoch 13033: train_loss=530.39636, val_loss=545.46179\n",
      "Epoch 13034: train_loss=530.37744, val_loss=545.55908\n",
      "Epoch 13035: train_loss=530.35590, val_loss=545.41217\n",
      "Epoch 13036: train_loss=530.33081, val_loss=545.50366\n",
      "Epoch 13037: train_loss=530.30267, val_loss=545.35864\n",
      "Epoch 13038: train_loss=530.27252, val_loss=545.43591\n",
      "Epoch 13039: train_loss=530.24164, val_loss=545.30609\n",
      "Epoch 13040: train_loss=530.20947, val_loss=545.36188\n",
      "Epoch 13041: train_loss=530.17780, val_loss=545.25574\n",
      "Epoch 13042: train_loss=530.14587, val_loss=545.28601\n",
      "Epoch 13043: train_loss=530.11523, val_loss=545.20862\n",
      "Epoch 13044: train_loss=530.08588, val_loss=545.21436\n",
      "Epoch 13045: train_loss=530.05780, val_loss=545.16455\n",
      "Epoch 13046: train_loss=530.03082, val_loss=545.14905\n",
      "Epoch 13047: train_loss=530.00488, val_loss=545.12323\n",
      "Epoch 13048: train_loss=529.97986, val_loss=545.08911\n",
      "Epoch 13049: train_loss=529.95514, val_loss=545.08417\n",
      "Epoch 13050: train_loss=529.93121, val_loss=545.03351\n",
      "Epoch 13051: train_loss=529.90784, val_loss=545.04962\n",
      "Epoch 13052: train_loss=529.88550, val_loss=544.97876\n",
      "Epoch 13053: train_loss=529.86481, val_loss=545.02344\n",
      "Epoch 13054: train_loss=529.84583, val_loss=544.92773\n",
      "Epoch 13055: train_loss=529.82935, val_loss=545.01215\n",
      "Epoch 13056: train_loss=529.81647, val_loss=544.88599\n",
      "Epoch 13057: train_loss=529.80627, val_loss=545.01727\n",
      "Epoch 13058: train_loss=529.80054, val_loss=544.85626\n",
      "Epoch 13059: train_loss=529.79736, val_loss=545.03528\n",
      "Epoch 13060: train_loss=529.79736, val_loss=544.83716\n",
      "Epoch 13061: train_loss=529.79791, val_loss=545.05646\n",
      "Epoch 13062: train_loss=529.79883, val_loss=544.82013\n",
      "Epoch 13063: train_loss=529.79578, val_loss=545.05798\n",
      "Epoch 13064: train_loss=529.78748, val_loss=544.78601\n",
      "Epoch 13065: train_loss=529.76794, val_loss=545.00806\n",
      "Epoch 13066: train_loss=529.73779, val_loss=544.71979\n",
      "Epoch 13067: train_loss=529.69421, val_loss=544.89508\n",
      "Epoch 13068: train_loss=529.64056, val_loss=544.62622\n",
      "Epoch 13069: train_loss=529.57825, val_loss=544.73639\n",
      "Epoch 13070: train_loss=529.51501, val_loss=544.53680\n",
      "Epoch 13071: train_loss=529.45483, val_loss=544.58527\n",
      "Epoch 13072: train_loss=529.40399, val_loss=544.48651\n",
      "Epoch 13073: train_loss=529.36359, val_loss=544.47778\n",
      "Epoch 13074: train_loss=529.33380, val_loss=544.47186\n",
      "Epoch 13075: train_loss=529.31262, val_loss=544.40979\n",
      "Epoch 13076: train_loss=529.29712, val_loss=544.47070\n",
      "Epoch 13077: train_loss=529.28424, val_loss=544.36365\n",
      "Epoch 13078: train_loss=529.27075, val_loss=544.45758\n",
      "Epoch 13079: train_loss=529.25439, val_loss=544.31921\n",
      "Epoch 13080: train_loss=529.23389, val_loss=544.41632\n",
      "Epoch 13081: train_loss=529.20947, val_loss=544.26880\n",
      "Epoch 13082: train_loss=529.18121, val_loss=544.35236\n",
      "Epoch 13083: train_loss=529.15094, val_loss=544.21515\n",
      "Epoch 13084: train_loss=529.11877, val_loss=544.27600\n",
      "Epoch 13085: train_loss=529.08673, val_loss=544.16229\n",
      "Epoch 13086: train_loss=529.05487, val_loss=544.19873\n",
      "Epoch 13087: train_loss=529.02411, val_loss=544.11365\n",
      "Epoch 13088: train_loss=528.99463, val_loss=544.12805\n",
      "Epoch 13089: train_loss=528.96655, val_loss=544.06940\n",
      "Epoch 13090: train_loss=528.93970, val_loss=544.06372\n",
      "Epoch 13091: train_loss=528.91376, val_loss=544.02582\n",
      "Epoch 13092: train_loss=528.88837, val_loss=544.00378\n",
      "Epoch 13093: train_loss=528.86365, val_loss=543.98370\n",
      "Epoch 13094: train_loss=528.83936, val_loss=543.94885\n",
      "Epoch 13095: train_loss=528.81543, val_loss=543.94440\n",
      "Epoch 13096: train_loss=528.79187, val_loss=543.89569\n",
      "Epoch 13097: train_loss=528.76868, val_loss=543.90765\n",
      "Epoch 13098: train_loss=528.74622, val_loss=543.84351\n",
      "Epoch 13099: train_loss=528.72479, val_loss=543.88116\n",
      "Epoch 13100: train_loss=528.70557, val_loss=543.79407\n",
      "Epoch 13101: train_loss=528.68866, val_loss=543.86890\n",
      "Epoch 13102: train_loss=528.67480, val_loss=543.75226\n",
      "Epoch 13103: train_loss=528.66400, val_loss=543.87305\n",
      "Epoch 13104: train_loss=528.65710, val_loss=543.72253\n",
      "Epoch 13105: train_loss=528.65210, val_loss=543.89001\n",
      "Epoch 13106: train_loss=528.65088, val_loss=543.70264\n",
      "Epoch 13107: train_loss=528.65002, val_loss=543.90845\n",
      "Epoch 13108: train_loss=528.64966, val_loss=543.68317\n",
      "Epoch 13109: train_loss=528.64459, val_loss=543.90839\n",
      "Epoch 13110: train_loss=528.63623, val_loss=543.65057\n",
      "Epoch 13111: train_loss=528.61749, val_loss=543.86322\n",
      "Epoch 13112: train_loss=528.59003, val_loss=543.58911\n",
      "Epoch 13113: train_loss=528.54987, val_loss=543.76001\n",
      "Epoch 13114: train_loss=528.50189, val_loss=543.50470\n",
      "Epoch 13115: train_loss=528.44666, val_loss=543.62115\n",
      "Epoch 13116: train_loss=528.38983, val_loss=543.42395\n",
      "Epoch 13117: train_loss=528.33392, val_loss=543.48346\n",
      "Epoch 13118: train_loss=528.28510, val_loss=543.36731\n",
      "Epoch 13119: train_loss=528.24353, val_loss=543.37250\n",
      "Epoch 13120: train_loss=528.21027, val_loss=543.33917\n",
      "Epoch 13121: train_loss=528.18433, val_loss=543.29852\n",
      "Epoch 13122: train_loss=528.16388, val_loss=543.33020\n",
      "Epoch 13123: train_loss=528.14667, val_loss=543.24713\n",
      "Epoch 13124: train_loss=528.13080, val_loss=543.31927\n",
      "Epoch 13125: train_loss=528.11664, val_loss=543.20190\n",
      "Epoch 13126: train_loss=528.10217, val_loss=543.30219\n",
      "Epoch 13127: train_loss=528.08759, val_loss=543.15887\n",
      "Epoch 13128: train_loss=528.07080, val_loss=543.27319\n",
      "Epoch 13129: train_loss=528.05200, val_loss=543.11359\n",
      "Epoch 13130: train_loss=528.02991, val_loss=543.22736\n",
      "Epoch 13131: train_loss=528.00568, val_loss=543.06366\n",
      "Epoch 13132: train_loss=527.97833, val_loss=543.16864\n",
      "Epoch 13133: train_loss=527.95032, val_loss=543.01257\n",
      "Epoch 13134: train_loss=527.92059, val_loss=543.10260\n",
      "Epoch 13135: train_loss=527.89099, val_loss=542.95984\n",
      "Epoch 13136: train_loss=527.86060, val_loss=543.03394\n",
      "Epoch 13137: train_loss=527.83093, val_loss=542.90967\n",
      "Epoch 13138: train_loss=527.80121, val_loss=542.96777\n",
      "Epoch 13139: train_loss=527.77240, val_loss=542.86237\n",
      "Epoch 13140: train_loss=527.74390, val_loss=542.90424\n",
      "Epoch 13141: train_loss=527.71686, val_loss=542.81567\n",
      "Epoch 13142: train_loss=527.68988, val_loss=542.84229\n",
      "Epoch 13143: train_loss=527.66370, val_loss=542.76917\n",
      "Epoch 13144: train_loss=527.63751, val_loss=542.78198\n",
      "Epoch 13145: train_loss=527.61212, val_loss=542.72412\n",
      "Epoch 13146: train_loss=527.58704, val_loss=542.72589\n",
      "Epoch 13147: train_loss=527.56238, val_loss=542.67883\n",
      "Epoch 13148: train_loss=527.53815, val_loss=542.67401\n",
      "Epoch 13149: train_loss=527.51392, val_loss=542.63171\n",
      "Epoch 13150: train_loss=527.49017, val_loss=542.62598\n",
      "Epoch 13151: train_loss=527.46655, val_loss=542.58368\n",
      "Epoch 13152: train_loss=527.44312, val_loss=542.58282\n",
      "Epoch 13153: train_loss=527.41974, val_loss=542.53503\n",
      "Epoch 13154: train_loss=527.39691, val_loss=542.54651\n",
      "Epoch 13155: train_loss=527.37463, val_loss=542.48462\n",
      "Epoch 13156: train_loss=527.35364, val_loss=542.51843\n",
      "Epoch 13157: train_loss=527.33484, val_loss=542.43457\n",
      "Epoch 13158: train_loss=527.31897, val_loss=542.51019\n",
      "Epoch 13159: train_loss=527.30737, val_loss=542.39581\n",
      "Epoch 13160: train_loss=527.30176, val_loss=542.53320\n",
      "Epoch 13161: train_loss=527.30328, val_loss=542.38104\n",
      "Epoch 13162: train_loss=527.31342, val_loss=542.59656\n",
      "Epoch 13163: train_loss=527.33331, val_loss=542.39758\n",
      "Epoch 13164: train_loss=527.35986, val_loss=542.69232\n",
      "Epoch 13165: train_loss=527.39441, val_loss=542.43640\n",
      "Epoch 13166: train_loss=527.42438, val_loss=542.77386\n",
      "Epoch 13167: train_loss=527.44885, val_loss=542.44574\n",
      "Epoch 13168: train_loss=527.44714, val_loss=542.75171\n",
      "Epoch 13169: train_loss=527.42175, val_loss=542.36499\n",
      "Epoch 13170: train_loss=527.35583, val_loss=542.56995\n",
      "Epoch 13171: train_loss=527.26569, val_loss=542.20386\n",
      "Epoch 13172: train_loss=527.15637, val_loss=542.30029\n",
      "Epoch 13173: train_loss=527.05206, val_loss=542.06842\n",
      "Epoch 13174: train_loss=526.96490, val_loss=542.08643\n",
      "Epoch 13175: train_loss=526.90607, val_loss=542.03955\n",
      "Epoch 13176: train_loss=526.87592, val_loss=541.99164\n",
      "Epoch 13177: train_loss=526.86896, val_loss=542.09076\n",
      "Epoch 13178: train_loss=526.87506, val_loss=541.96967\n",
      "Epoch 13179: train_loss=526.88129, val_loss=542.12463\n",
      "Epoch 13180: train_loss=526.87970, val_loss=541.94214\n",
      "Epoch 13181: train_loss=526.86316, val_loss=542.07843\n",
      "Epoch 13182: train_loss=526.83252, val_loss=541.88031\n",
      "Epoch 13183: train_loss=526.78967, val_loss=541.96478\n",
      "Epoch 13184: train_loss=526.74249, val_loss=541.81183\n",
      "Epoch 13185: train_loss=526.69537, val_loss=541.84088\n",
      "Epoch 13186: train_loss=526.65515, val_loss=541.77179\n",
      "Epoch 13187: train_loss=526.62317, val_loss=541.75159\n",
      "Epoch 13188: train_loss=526.59949, val_loss=541.76166\n",
      "Epoch 13189: train_loss=526.58197, val_loss=541.69672\n",
      "Epoch 13190: train_loss=526.56750, val_loss=541.75623\n",
      "Epoch 13191: train_loss=526.55402, val_loss=541.65375\n",
      "Epoch 13192: train_loss=526.53900, val_loss=541.73529\n",
      "Epoch 13193: train_loss=526.52228, val_loss=541.61066\n",
      "Epoch 13194: train_loss=526.50305, val_loss=541.69763\n",
      "Epoch 13195: train_loss=526.48108, val_loss=541.56549\n",
      "Epoch 13196: train_loss=526.45660, val_loss=541.64386\n",
      "Epoch 13197: train_loss=526.43005, val_loss=541.51697\n",
      "Epoch 13198: train_loss=526.40253, val_loss=541.58002\n",
      "Epoch 13199: train_loss=526.37408, val_loss=541.46777\n",
      "Epoch 13200: train_loss=526.34552, val_loss=541.51233\n",
      "Epoch 13201: train_loss=526.31720, val_loss=541.42029\n",
      "Epoch 13202: train_loss=526.28925, val_loss=541.44611\n",
      "Epoch 13203: train_loss=526.26221, val_loss=541.37598\n",
      "Epoch 13204: train_loss=526.23584, val_loss=541.38312\n",
      "Epoch 13205: train_loss=526.21039, val_loss=541.33331\n",
      "Epoch 13206: train_loss=526.18573, val_loss=541.32300\n",
      "Epoch 13207: train_loss=526.16187, val_loss=541.29132\n",
      "Epoch 13208: train_loss=526.13855, val_loss=541.26672\n",
      "Epoch 13209: train_loss=526.11548, val_loss=541.24921\n",
      "Epoch 13210: train_loss=526.09265, val_loss=541.21277\n",
      "Epoch 13211: train_loss=526.07037, val_loss=541.20886\n",
      "Epoch 13212: train_loss=526.04816, val_loss=541.16321\n",
      "Epoch 13213: train_loss=526.02631, val_loss=541.17163\n",
      "Epoch 13214: train_loss=526.00482, val_loss=541.11505\n",
      "Epoch 13215: train_loss=525.98352, val_loss=541.13660\n",
      "Epoch 13216: train_loss=525.96313, val_loss=541.06744\n",
      "Epoch 13217: train_loss=525.94342, val_loss=541.10931\n",
      "Epoch 13218: train_loss=525.92517, val_loss=541.02472\n",
      "Epoch 13219: train_loss=525.90833, val_loss=541.09271\n",
      "Epoch 13220: train_loss=525.89331, val_loss=540.98627\n",
      "Epoch 13221: train_loss=525.88000, val_loss=541.08282\n",
      "Epoch 13222: train_loss=525.86816, val_loss=540.95276\n",
      "Epoch 13223: train_loss=525.85834, val_loss=541.07892\n",
      "Epoch 13224: train_loss=525.84930, val_loss=540.92340\n",
      "Epoch 13225: train_loss=525.84052, val_loss=541.07184\n",
      "Epoch 13226: train_loss=525.83087, val_loss=540.89209\n",
      "Epoch 13227: train_loss=525.81891, val_loss=541.05182\n",
      "Epoch 13228: train_loss=525.80457, val_loss=540.85406\n",
      "Epoch 13229: train_loss=525.78552, val_loss=541.01038\n",
      "Epoch 13230: train_loss=525.76276, val_loss=540.80426\n",
      "Epoch 13231: train_loss=525.73480, val_loss=540.94226\n",
      "Epoch 13232: train_loss=525.70300, val_loss=540.74194\n",
      "Epoch 13233: train_loss=525.66724, val_loss=540.85211\n",
      "Epoch 13234: train_loss=525.62927, val_loss=540.67493\n",
      "Epoch 13235: train_loss=525.58960, val_loss=540.75201\n",
      "Epoch 13236: train_loss=525.55005, val_loss=540.61230\n",
      "Epoch 13237: train_loss=525.51196, val_loss=540.65302\n",
      "Epoch 13238: train_loss=525.47656, val_loss=540.55981\n",
      "Epoch 13239: train_loss=525.44470, val_loss=540.56793\n",
      "Epoch 13240: train_loss=525.41632, val_loss=540.52234\n",
      "Epoch 13241: train_loss=525.39105, val_loss=540.50159\n",
      "Epoch 13242: train_loss=525.36829, val_loss=540.49286\n",
      "Epoch 13243: train_loss=525.34760, val_loss=540.44397\n",
      "Epoch 13244: train_loss=525.32825, val_loss=540.46509\n",
      "Epoch 13245: train_loss=525.31018, val_loss=540.39343\n",
      "Epoch 13246: train_loss=525.29285, val_loss=540.43970\n",
      "Epoch 13247: train_loss=525.27612, val_loss=540.34747\n",
      "Epoch 13248: train_loss=525.26025, val_loss=540.41394\n",
      "Epoch 13249: train_loss=525.24445, val_loss=540.30292\n",
      "Epoch 13250: train_loss=525.22974, val_loss=540.38922\n",
      "Epoch 13251: train_loss=525.21460, val_loss=540.26117\n",
      "Epoch 13252: train_loss=525.20050, val_loss=540.36633\n",
      "Epoch 13253: train_loss=525.18671, val_loss=540.22174\n",
      "Epoch 13254: train_loss=525.17419, val_loss=540.34393\n",
      "Epoch 13255: train_loss=525.16089, val_loss=540.18237\n",
      "Epoch 13256: train_loss=525.14697, val_loss=540.31555\n",
      "Epoch 13257: train_loss=525.13086, val_loss=540.14178\n",
      "Epoch 13258: train_loss=525.11353, val_loss=540.27692\n",
      "Epoch 13259: train_loss=525.09314, val_loss=540.09497\n",
      "Epoch 13260: train_loss=525.07080, val_loss=540.22296\n",
      "Epoch 13261: train_loss=525.04523, val_loss=540.04156\n",
      "Epoch 13262: train_loss=525.01764, val_loss=540.15588\n",
      "Epoch 13263: train_loss=524.98718, val_loss=539.98596\n",
      "Epoch 13264: train_loss=524.95569, val_loss=540.07916\n",
      "Epoch 13265: train_loss=524.92194, val_loss=539.92822\n",
      "Epoch 13266: train_loss=524.88885, val_loss=539.99567\n",
      "Epoch 13267: train_loss=524.85504, val_loss=539.87128\n",
      "Epoch 13268: train_loss=524.82269, val_loss=539.91113\n",
      "Epoch 13269: train_loss=524.79120, val_loss=539.82007\n",
      "Epoch 13270: train_loss=524.76184, val_loss=539.83295\n",
      "Epoch 13271: train_loss=524.73450, val_loss=539.77637\n",
      "Epoch 13272: train_loss=524.70929, val_loss=539.76550\n",
      "Epoch 13273: train_loss=524.68597, val_loss=539.74048\n",
      "Epoch 13274: train_loss=524.66400, val_loss=539.70923\n",
      "Epoch 13275: train_loss=524.64313, val_loss=539.70709\n",
      "Epoch 13276: train_loss=524.62299, val_loss=539.65759\n",
      "Epoch 13277: train_loss=524.60345, val_loss=539.67255\n",
      "Epoch 13278: train_loss=524.58435, val_loss=539.60699\n",
      "Epoch 13279: train_loss=524.56567, val_loss=539.63983\n",
      "Epoch 13280: train_loss=524.54761, val_loss=539.56116\n",
      "Epoch 13281: train_loss=524.53040, val_loss=539.61346\n",
      "Epoch 13282: train_loss=524.51404, val_loss=539.51917\n",
      "Epoch 13283: train_loss=524.49908, val_loss=539.59186\n",
      "Epoch 13284: train_loss=524.48523, val_loss=539.48016\n",
      "Epoch 13285: train_loss=524.47430, val_loss=539.58136\n",
      "Epoch 13286: train_loss=524.46527, val_loss=539.44995\n",
      "Epoch 13287: train_loss=524.46008, val_loss=539.58728\n",
      "Epoch 13288: train_loss=524.45776, val_loss=539.43121\n",
      "Epoch 13289: train_loss=524.45905, val_loss=539.60846\n",
      "Epoch 13290: train_loss=524.46375, val_loss=539.42389\n",
      "Epoch 13291: train_loss=524.47028, val_loss=539.63867\n",
      "Epoch 13292: train_loss=524.47827, val_loss=539.42072\n",
      "Epoch 13293: train_loss=524.48248, val_loss=539.65387\n",
      "Epoch 13294: train_loss=524.48285, val_loss=539.39777\n",
      "Epoch 13295: train_loss=524.46985, val_loss=539.61285\n",
      "Epoch 13296: train_loss=524.44550, val_loss=539.33136\n",
      "Epoch 13297: train_loss=524.40271, val_loss=539.49268\n",
      "Epoch 13298: train_loss=524.34650, val_loss=539.22461\n",
      "Epoch 13299: train_loss=524.27997, val_loss=539.32123\n",
      "Epoch 13300: train_loss=524.21100, val_loss=539.11951\n",
      "Epoch 13301: train_loss=524.14581, val_loss=539.15668\n",
      "Epoch 13302: train_loss=524.09180, val_loss=539.05811\n",
      "Epoch 13303: train_loss=524.05170, val_loss=539.04492\n",
      "Epoch 13304: train_loss=524.02515, val_loss=539.04688\n",
      "Epoch 13305: train_loss=524.01001, val_loss=538.98724\n",
      "Epoch 13306: train_loss=524.00208, val_loss=539.05597\n",
      "Epoch 13307: train_loss=523.99670, val_loss=538.95386\n",
      "Epoch 13308: train_loss=523.99078, val_loss=539.05481\n",
      "Epoch 13309: train_loss=523.98199, val_loss=538.92084\n",
      "Epoch 13310: train_loss=523.96790, val_loss=539.02313\n",
      "Epoch 13311: train_loss=523.94824, val_loss=538.87524\n",
      "Epoch 13312: train_loss=523.92377, val_loss=538.96234\n",
      "Epoch 13313: train_loss=523.89569, val_loss=538.82257\n",
      "Epoch 13314: train_loss=523.86542, val_loss=538.88818\n",
      "Epoch 13315: train_loss=523.83411, val_loss=538.77216\n",
      "Epoch 13316: train_loss=523.80359, val_loss=538.81488\n",
      "Epoch 13317: train_loss=523.77399, val_loss=538.72778\n",
      "Epoch 13318: train_loss=523.74597, val_loss=538.74438\n",
      "Epoch 13319: train_loss=523.71924, val_loss=538.68762\n",
      "Epoch 13320: train_loss=523.69464, val_loss=538.68018\n",
      "Epoch 13321: train_loss=523.67181, val_loss=538.65277\n",
      "Epoch 13322: train_loss=523.65063, val_loss=538.62408\n",
      "Epoch 13323: train_loss=523.63086, val_loss=538.62189\n",
      "Epoch 13324: train_loss=523.61188, val_loss=538.57617\n",
      "Epoch 13325: train_loss=523.59357, val_loss=538.59497\n",
      "Epoch 13326: train_loss=523.57593, val_loss=538.53247\n",
      "Epoch 13327: train_loss=523.55945, val_loss=538.57159\n",
      "Epoch 13328: train_loss=523.54401, val_loss=538.49097\n",
      "Epoch 13329: train_loss=523.53046, val_loss=538.55518\n",
      "Epoch 13330: train_loss=523.51843, val_loss=538.45435\n",
      "Epoch 13331: train_loss=523.50940, val_loss=538.54926\n",
      "Epoch 13332: train_loss=523.50153, val_loss=538.42700\n",
      "Epoch 13333: train_loss=523.49731, val_loss=538.55634\n",
      "Epoch 13334: train_loss=523.49463, val_loss=538.40875\n",
      "Epoch 13335: train_loss=523.49414, val_loss=538.56982\n",
      "Epoch 13336: train_loss=523.49445, val_loss=538.39398\n",
      "Epoch 13337: train_loss=523.49475, val_loss=538.57428\n",
      "Epoch 13338: train_loss=523.49170, val_loss=538.36951\n",
      "Epoch 13339: train_loss=523.48370, val_loss=538.54987\n",
      "Epoch 13340: train_loss=523.46765, val_loss=538.32422\n",
      "Epoch 13341: train_loss=523.44183, val_loss=538.47998\n",
      "Epoch 13342: train_loss=523.40649, val_loss=538.25256\n",
      "Epoch 13343: train_loss=523.36230, val_loss=538.36603\n",
      "Epoch 13344: train_loss=523.31299, val_loss=538.16748\n",
      "Epoch 13345: train_loss=523.26166, val_loss=538.23676\n",
      "Epoch 13346: train_loss=523.21320, val_loss=538.09601\n",
      "Epoch 13347: train_loss=523.16925, val_loss=538.12347\n",
      "Epoch 13348: train_loss=523.13135, val_loss=538.05310\n",
      "Epoch 13349: train_loss=523.10095, val_loss=538.04205\n",
      "Epoch 13350: train_loss=523.07776, val_loss=538.03687\n",
      "Epoch 13351: train_loss=523.06000, val_loss=537.98981\n",
      "Epoch 13352: train_loss=523.04596, val_loss=538.02838\n",
      "Epoch 13353: train_loss=523.03351, val_loss=537.94879\n",
      "Epoch 13354: train_loss=523.02124, val_loss=538.00891\n",
      "Epoch 13355: train_loss=523.00757, val_loss=537.90637\n",
      "Epoch 13356: train_loss=522.99207, val_loss=537.97491\n",
      "Epoch 13357: train_loss=522.97443, val_loss=537.86346\n",
      "Epoch 13358: train_loss=522.95477, val_loss=537.93170\n",
      "Epoch 13359: train_loss=522.93402, val_loss=537.81995\n",
      "Epoch 13360: train_loss=522.91162, val_loss=537.87933\n",
      "Epoch 13361: train_loss=522.88818, val_loss=537.77399\n",
      "Epoch 13362: train_loss=522.86389, val_loss=537.82092\n",
      "Epoch 13363: train_loss=522.83929, val_loss=537.72894\n",
      "Epoch 13364: train_loss=522.81482, val_loss=537.76233\n",
      "Epoch 13365: train_loss=522.79077, val_loss=537.68622\n",
      "Epoch 13366: train_loss=522.76715, val_loss=537.70508\n",
      "Epoch 13367: train_loss=522.74402, val_loss=537.64520\n",
      "Epoch 13368: train_loss=522.72150, val_loss=537.65021\n",
      "Epoch 13369: train_loss=522.69965, val_loss=537.60681\n",
      "Epoch 13370: train_loss=522.67834, val_loss=537.59882\n",
      "Epoch 13371: train_loss=522.65747, val_loss=537.56873\n",
      "Epoch 13372: train_loss=522.63715, val_loss=537.54944\n",
      "Epoch 13373: train_loss=522.61719, val_loss=537.53027\n",
      "Epoch 13374: train_loss=522.59735, val_loss=537.50128\n",
      "Epoch 13375: train_loss=522.57782, val_loss=537.49152\n",
      "Epoch 13376: train_loss=522.55841, val_loss=537.45367\n",
      "Epoch 13377: train_loss=522.53925, val_loss=537.45459\n",
      "Epoch 13378: train_loss=522.52051, val_loss=537.40680\n",
      "Epoch 13379: train_loss=522.50214, val_loss=537.42108\n",
      "Epoch 13380: train_loss=522.48450, val_loss=537.36121\n",
      "Epoch 13381: train_loss=522.46796, val_loss=537.39410\n",
      "Epoch 13382: train_loss=522.45245, val_loss=537.31842\n",
      "Epoch 13383: train_loss=522.43903, val_loss=537.37695\n",
      "Epoch 13384: train_loss=522.42749, val_loss=537.28223\n",
      "Epoch 13385: train_loss=522.41931, val_loss=537.37646\n",
      "Epoch 13386: train_loss=522.41437, val_loss=537.25940\n",
      "Epoch 13387: train_loss=522.41486, val_loss=537.40021\n",
      "Epoch 13388: train_loss=522.42041, val_loss=537.25348\n",
      "Epoch 13389: train_loss=522.43085, val_loss=537.44379\n",
      "Epoch 13390: train_loss=522.44592, val_loss=537.26337\n",
      "Epoch 13391: train_loss=522.46368, val_loss=537.49823\n",
      "Epoch 13392: train_loss=522.48218, val_loss=537.27545\n",
      "Epoch 13393: train_loss=522.49182, val_loss=537.51813\n",
      "Epoch 13394: train_loss=522.49133, val_loss=537.24841\n",
      "Epoch 13395: train_loss=522.47064, val_loss=537.45056\n",
      "Epoch 13396: train_loss=522.43225, val_loss=537.15912\n",
      "Epoch 13397: train_loss=522.37201, val_loss=537.29193\n",
      "Epoch 13398: train_loss=522.30096, val_loss=537.03821\n",
      "Epoch 13399: train_loss=522.22498, val_loss=537.10413\n",
      "Epoch 13400: train_loss=522.15375, val_loss=536.94458\n",
      "Epoch 13401: train_loss=522.09564, val_loss=536.95868\n",
      "Epoch 13402: train_loss=522.05328, val_loss=536.91272\n",
      "Epoch 13403: train_loss=522.02704, val_loss=536.88031\n",
      "Epoch 13404: train_loss=522.01367, val_loss=536.92432\n",
      "Epoch 13405: train_loss=522.00854, val_loss=536.84393\n",
      "Epoch 13406: train_loss=522.00714, val_loss=536.93750\n",
      "Epoch 13407: train_loss=522.00500, val_loss=536.81635\n",
      "Epoch 13408: train_loss=521.99854, val_loss=536.92493\n",
      "Epoch 13409: train_loss=521.98645, val_loss=536.77966\n",
      "Epoch 13410: train_loss=521.96741, val_loss=536.87646\n",
      "Epoch 13411: train_loss=521.94232, val_loss=536.73004\n",
      "Epoch 13412: train_loss=521.91235, val_loss=536.80084\n",
      "Epoch 13413: train_loss=521.87964, val_loss=536.67670\n",
      "Epoch 13414: train_loss=521.84662, val_loss=536.71674\n",
      "Epoch 13415: train_loss=521.81470, val_loss=536.63068\n",
      "Epoch 13416: train_loss=521.78571, val_loss=536.64026\n",
      "Epoch 13417: train_loss=521.75970, val_loss=536.59650\n",
      "Epoch 13418: train_loss=521.73682, val_loss=536.57684\n",
      "Epoch 13419: train_loss=521.71722, val_loss=536.57263\n",
      "Epoch 13420: train_loss=521.69989, val_loss=536.52802\n",
      "Epoch 13421: train_loss=521.68390, val_loss=536.55115\n",
      "Epoch 13422: train_loss=521.66858, val_loss=536.48645\n",
      "Epoch 13423: train_loss=521.65338, val_loss=536.52594\n",
      "Epoch 13424: train_loss=521.63776, val_loss=536.44574\n",
      "Epoch 13425: train_loss=521.62250, val_loss=536.49457\n",
      "Epoch 13426: train_loss=521.60590, val_loss=536.40552\n",
      "Epoch 13427: train_loss=521.58893, val_loss=536.46155\n",
      "Epoch 13428: train_loss=521.57153, val_loss=536.36682\n",
      "Epoch 13429: train_loss=521.55463, val_loss=536.42731\n",
      "Epoch 13430: train_loss=521.53687, val_loss=536.32806\n",
      "Epoch 13431: train_loss=521.51935, val_loss=536.39069\n",
      "Epoch 13432: train_loss=521.50098, val_loss=536.28839\n",
      "Epoch 13433: train_loss=521.48364, val_loss=536.35309\n",
      "Epoch 13434: train_loss=521.46521, val_loss=536.24731\n",
      "Epoch 13435: train_loss=521.44794, val_loss=536.31531\n",
      "Epoch 13436: train_loss=521.42963, val_loss=536.20697\n",
      "Epoch 13437: train_loss=521.41211, val_loss=536.27704\n",
      "Epoch 13438: train_loss=521.39313, val_loss=536.16669\n",
      "Epoch 13439: train_loss=521.37463, val_loss=536.23578\n",
      "Epoch 13440: train_loss=521.35492, val_loss=536.12506\n",
      "Epoch 13441: train_loss=521.33569, val_loss=536.19189\n",
      "Epoch 13442: train_loss=521.31549, val_loss=536.08197\n",
      "Epoch 13443: train_loss=521.29578, val_loss=536.14551\n",
      "Epoch 13444: train_loss=521.27502, val_loss=536.03735\n",
      "Epoch 13445: train_loss=521.25513, val_loss=536.09735\n",
      "Epoch 13446: train_loss=521.23438, val_loss=535.99188\n",
      "Epoch 13447: train_loss=521.21405, val_loss=536.04865\n",
      "Epoch 13448: train_loss=521.19299, val_loss=535.94800\n",
      "Epoch 13449: train_loss=521.17218, val_loss=536.00006\n",
      "Epoch 13450: train_loss=521.15082, val_loss=535.90417\n",
      "Epoch 13451: train_loss=521.12976, val_loss=535.94983\n",
      "Epoch 13452: train_loss=521.10864, val_loss=535.85962\n",
      "Epoch 13453: train_loss=521.08789, val_loss=535.90125\n",
      "Epoch 13454: train_loss=521.06744, val_loss=535.81622\n",
      "Epoch 13455: train_loss=521.04749, val_loss=535.85516\n",
      "Epoch 13456: train_loss=521.02765, val_loss=535.77301\n",
      "Epoch 13457: train_loss=521.00879, val_loss=535.81403\n",
      "Epoch 13458: train_loss=520.99005, val_loss=535.73248\n",
      "Epoch 13459: train_loss=520.97253, val_loss=535.77942\n",
      "Epoch 13460: train_loss=520.95538, val_loss=535.69348\n",
      "Epoch 13461: train_loss=520.93958, val_loss=535.75006\n",
      "Epoch 13462: train_loss=520.92438, val_loss=535.65497\n",
      "Epoch 13463: train_loss=520.91180, val_loss=535.72968\n",
      "Epoch 13464: train_loss=520.90039, val_loss=535.62280\n",
      "Epoch 13465: train_loss=520.89362, val_loss=535.72858\n",
      "Epoch 13466: train_loss=520.88885, val_loss=535.60406\n",
      "Epoch 13467: train_loss=520.88934, val_loss=535.74872\n",
      "Epoch 13468: train_loss=520.89362, val_loss=535.60162\n",
      "Epoch 13469: train_loss=520.90381, val_loss=535.79034\n",
      "Epoch 13470: train_loss=520.91656, val_loss=535.61298\n",
      "Epoch 13471: train_loss=520.93176, val_loss=535.83472\n",
      "Epoch 13472: train_loss=520.94470, val_loss=535.61841\n",
      "Epoch 13473: train_loss=520.95111, val_loss=535.84314\n",
      "Epoch 13474: train_loss=520.94653, val_loss=535.58813\n",
      "Epoch 13475: train_loss=520.92542, val_loss=535.77606\n",
      "Epoch 13476: train_loss=520.88635, val_loss=535.50421\n",
      "Epoch 13477: train_loss=520.82977, val_loss=535.62744\n",
      "Epoch 13478: train_loss=520.76099, val_loss=535.38635\n",
      "Epoch 13479: train_loss=520.68683, val_loss=535.44305\n",
      "Epoch 13480: train_loss=520.61688, val_loss=535.29303\n",
      "Epoch 13481: train_loss=520.56042, val_loss=535.30194\n",
      "Epoch 13482: train_loss=520.51996, val_loss=535.26562\n",
      "Epoch 13483: train_loss=520.49622, val_loss=535.23151\n",
      "Epoch 13484: train_loss=520.48572, val_loss=535.28333\n",
      "Epoch 13485: train_loss=520.48267, val_loss=535.20447\n",
      "Epoch 13486: train_loss=520.48175, val_loss=535.29736\n",
      "Epoch 13487: train_loss=520.47821, val_loss=535.17963\n",
      "Epoch 13488: train_loss=520.46906, val_loss=535.27625\n",
      "Epoch 13489: train_loss=520.45300, val_loss=535.13971\n",
      "Epoch 13490: train_loss=520.43085, val_loss=535.21924\n",
      "Epoch 13491: train_loss=520.40338, val_loss=535.08856\n",
      "Epoch 13492: train_loss=520.37250, val_loss=535.14117\n",
      "Epoch 13493: train_loss=520.34045, val_loss=535.03900\n",
      "Epoch 13494: train_loss=520.30902, val_loss=535.06348\n",
      "Epoch 13495: train_loss=520.28003, val_loss=535.00226\n",
      "Epoch 13496: train_loss=520.25409, val_loss=534.99731\n",
      "Epoch 13497: train_loss=520.23169, val_loss=534.97687\n",
      "Epoch 13498: train_loss=520.21271, val_loss=534.94501\n",
      "Epoch 13499: train_loss=520.19604, val_loss=534.95709\n",
      "Epoch 13500: train_loss=520.18091, val_loss=534.90356\n",
      "Epoch 13501: train_loss=520.16608, val_loss=534.93604\n",
      "Epoch 13502: train_loss=520.15155, val_loss=534.86591\n",
      "Epoch 13503: train_loss=520.13684, val_loss=534.91223\n",
      "Epoch 13504: train_loss=520.12195, val_loss=534.82892\n",
      "Epoch 13505: train_loss=520.10681, val_loss=534.88354\n",
      "Epoch 13506: train_loss=520.09088, val_loss=534.79028\n",
      "Epoch 13507: train_loss=520.07501, val_loss=534.85095\n",
      "Epoch 13508: train_loss=520.05841, val_loss=534.75104\n",
      "Epoch 13509: train_loss=520.04205, val_loss=534.81677\n",
      "Epoch 13510: train_loss=520.02527, val_loss=534.71246\n",
      "Epoch 13511: train_loss=520.00916, val_loss=534.78375\n",
      "Epoch 13512: train_loss=519.99261, val_loss=534.67578\n",
      "Epoch 13513: train_loss=519.97705, val_loss=534.75482\n",
      "Epoch 13514: train_loss=519.96075, val_loss=534.64209\n",
      "Epoch 13515: train_loss=519.94507, val_loss=534.72339\n",
      "Epoch 13516: train_loss=519.92792, val_loss=534.60437\n",
      "Epoch 13517: train_loss=519.91193, val_loss=534.68842\n",
      "Epoch 13518: train_loss=519.89404, val_loss=534.56628\n",
      "Epoch 13519: train_loss=519.87769, val_loss=534.65295\n",
      "Epoch 13520: train_loss=519.85870, val_loss=534.52856\n",
      "Epoch 13521: train_loss=519.84100, val_loss=534.61383\n",
      "Epoch 13522: train_loss=519.82111, val_loss=534.48767\n",
      "Epoch 13523: train_loss=519.80182, val_loss=534.56842\n",
      "Epoch 13524: train_loss=519.77997, val_loss=534.44507\n",
      "Epoch 13525: train_loss=519.75885, val_loss=534.51794\n",
      "Epoch 13526: train_loss=519.73529, val_loss=534.40045\n",
      "Epoch 13527: train_loss=519.71204, val_loss=534.46173\n",
      "Epoch 13528: train_loss=519.68738, val_loss=534.35406\n",
      "Epoch 13529: train_loss=519.66309, val_loss=534.40100\n",
      "Epoch 13530: train_loss=519.63788, val_loss=534.30701\n",
      "Epoch 13531: train_loss=519.61328, val_loss=534.33954\n",
      "Epoch 13532: train_loss=519.58856, val_loss=534.26349\n",
      "Epoch 13533: train_loss=519.56470, val_loss=534.28149\n",
      "Epoch 13534: train_loss=519.54163, val_loss=534.22443\n",
      "Epoch 13535: train_loss=519.51953, val_loss=534.22766\n",
      "Epoch 13536: train_loss=519.49854, val_loss=534.18823\n",
      "Epoch 13537: train_loss=519.47833, val_loss=534.17798\n",
      "Epoch 13538: train_loss=519.45862, val_loss=534.15332\n",
      "Epoch 13539: train_loss=519.43964, val_loss=534.13239\n",
      "Epoch 13540: train_loss=519.42108, val_loss=534.12006\n",
      "Epoch 13541: train_loss=519.40277, val_loss=534.09021\n",
      "Epoch 13542: train_loss=519.38483, val_loss=534.08917\n",
      "Epoch 13543: train_loss=519.36719, val_loss=534.04871\n",
      "Epoch 13544: train_loss=519.35010, val_loss=534.05963\n",
      "Epoch 13545: train_loss=519.33344, val_loss=534.00836\n",
      "Epoch 13546: train_loss=519.31769, val_loss=534.03540\n",
      "Epoch 13547: train_loss=519.30310, val_loss=533.97076\n",
      "Epoch 13548: train_loss=519.29010, val_loss=534.01813\n",
      "Epoch 13549: train_loss=519.27863, val_loss=533.93744\n",
      "Epoch 13550: train_loss=519.27020, val_loss=534.01532\n",
      "Epoch 13551: train_loss=519.26508, val_loss=533.91760\n",
      "Epoch 13552: train_loss=519.26562, val_loss=534.03925\n",
      "Epoch 13553: train_loss=519.27130, val_loss=533.91968\n",
      "Epoch 13554: train_loss=519.28571, val_loss=534.09503\n",
      "Epoch 13555: train_loss=519.30560, val_loss=533.94757\n",
      "Epoch 13556: train_loss=519.33380, val_loss=534.17798\n",
      "Epoch 13557: train_loss=519.36554, val_loss=533.99237\n",
      "Epoch 13558: train_loss=519.39734, val_loss=534.25201\n",
      "Epoch 13559: train_loss=519.42096, val_loss=534.01202\n",
      "Epoch 13560: train_loss=519.42725, val_loss=534.24554\n",
      "Epoch 13561: train_loss=519.40985, val_loss=533.94958\n",
      "Epoch 13562: train_loss=519.35980, val_loss=534.09802\n",
      "Epoch 13563: train_loss=519.28107, val_loss=533.79779\n",
      "Epoch 13564: train_loss=519.18408, val_loss=533.85638\n",
      "Epoch 13565: train_loss=519.08264, val_loss=533.65002\n",
      "Epoch 13566: train_loss=518.99591, val_loss=533.65851\n",
      "Epoch 13567: train_loss=518.93585, val_loss=533.60449\n",
      "Epoch 13568: train_loss=518.90472, val_loss=533.57452\n",
      "Epoch 13569: train_loss=518.89844, val_loss=533.64392\n",
      "Epoch 13570: train_loss=518.90704, val_loss=533.56531\n",
      "Epoch 13571: train_loss=518.91858, val_loss=533.68439\n",
      "Epoch 13572: train_loss=518.92419, val_loss=533.55334\n",
      "Epoch 13573: train_loss=518.91766, val_loss=533.65924\n",
      "Epoch 13574: train_loss=518.89722, val_loss=533.50311\n",
      "Epoch 13575: train_loss=518.86481, val_loss=533.57202\n",
      "Epoch 13576: train_loss=518.82513, val_loss=533.43774\n",
      "Epoch 13577: train_loss=518.78326, val_loss=533.46790\n",
      "Epoch 13578: train_loss=518.74426, val_loss=533.38928\n",
      "Epoch 13579: train_loss=518.71143, val_loss=533.38458\n",
      "Epoch 13580: train_loss=518.68683, val_loss=533.36987\n",
      "Epoch 13581: train_loss=518.66956, val_loss=533.33411\n",
      "Epoch 13582: train_loss=518.65735, val_loss=533.36627\n",
      "Epoch 13583: train_loss=518.64764, val_loss=533.30194\n",
      "Epoch 13584: train_loss=518.63782, val_loss=533.35492\n",
      "Epoch 13585: train_loss=518.62683, val_loss=533.26849\n",
      "Epoch 13586: train_loss=518.61334, val_loss=533.32581\n",
      "Epoch 13587: train_loss=518.59711, val_loss=533.23090\n",
      "Epoch 13588: train_loss=518.57831, val_loss=533.28351\n",
      "Epoch 13589: train_loss=518.55731, val_loss=533.19092\n",
      "Epoch 13590: train_loss=518.53461, val_loss=533.23096\n",
      "Epoch 13591: train_loss=518.51154, val_loss=533.14905\n",
      "Epoch 13592: train_loss=518.48792, val_loss=533.17468\n",
      "Epoch 13593: train_loss=518.46478, val_loss=533.10962\n",
      "Epoch 13594: train_loss=518.44226, val_loss=533.12061\n",
      "Epoch 13595: train_loss=518.42059, val_loss=533.07275\n",
      "Epoch 13596: train_loss=518.39984, val_loss=533.06909\n",
      "Epoch 13597: train_loss=518.37994, val_loss=533.03882\n",
      "Epoch 13598: train_loss=518.36072, val_loss=533.02399\n",
      "Epoch 13599: train_loss=518.34235, val_loss=533.00775\n",
      "Epoch 13600: train_loss=518.32434, val_loss=532.98285\n",
      "Epoch 13601: train_loss=518.30664, val_loss=532.97754\n",
      "Epoch 13602: train_loss=518.28943, val_loss=532.94312\n",
      "Epoch 13603: train_loss=518.27252, val_loss=532.94952\n",
      "Epoch 13604: train_loss=518.25598, val_loss=532.90552\n",
      "Epoch 13605: train_loss=518.24030, val_loss=532.92578\n",
      "Epoch 13606: train_loss=518.22534, val_loss=532.86926\n",
      "Epoch 13607: train_loss=518.21112, val_loss=532.90570\n",
      "Epoch 13608: train_loss=518.19836, val_loss=532.83618\n",
      "Epoch 13609: train_loss=518.18689, val_loss=532.89325\n",
      "Epoch 13610: train_loss=518.17737, val_loss=532.80841\n",
      "Epoch 13611: train_loss=518.16919, val_loss=532.88770\n",
      "Epoch 13612: train_loss=518.16278, val_loss=532.78540\n",
      "Epoch 13613: train_loss=518.15814, val_loss=532.88599\n",
      "Epoch 13614: train_loss=518.15356, val_loss=532.76508\n",
      "Epoch 13615: train_loss=518.14935, val_loss=532.88104\n",
      "Epoch 13616: train_loss=518.14276, val_loss=532.74353\n",
      "Epoch 13617: train_loss=518.13501, val_loss=532.86389\n",
      "Epoch 13618: train_loss=518.12225, val_loss=532.71161\n",
      "Epoch 13619: train_loss=518.10638, val_loss=532.82434\n",
      "Epoch 13620: train_loss=518.08459, val_loss=532.66699\n",
      "Epoch 13621: train_loss=518.05902, val_loss=532.76178\n",
      "Epoch 13622: train_loss=518.02832, val_loss=532.60974\n",
      "Epoch 13623: train_loss=517.99384, val_loss=532.67712\n",
      "Epoch 13624: train_loss=517.95764, val_loss=532.54846\n",
      "Epoch 13625: train_loss=517.92145, val_loss=532.58948\n",
      "Epoch 13626: train_loss=517.88763, val_loss=532.49719\n",
      "Epoch 13627: train_loss=517.85706, val_loss=532.51483\n",
      "Epoch 13628: train_loss=517.82990, val_loss=532.46075\n",
      "Epoch 13629: train_loss=517.80609, val_loss=532.45673\n",
      "Epoch 13630: train_loss=517.78516, val_loss=532.43488\n",
      "Epoch 13631: train_loss=517.76666, val_loss=532.41083\n",
      "Epoch 13632: train_loss=517.74988, val_loss=532.41339\n",
      "Epoch 13633: train_loss=517.73444, val_loss=532.37115\n",
      "Epoch 13634: train_loss=517.72003, val_loss=532.39319\n",
      "Epoch 13635: train_loss=517.70660, val_loss=532.33514\n",
      "Epoch 13636: train_loss=517.69360, val_loss=532.37646\n",
      "Epoch 13637: train_loss=517.68152, val_loss=532.30542\n",
      "Epoch 13638: train_loss=517.67017, val_loss=532.36407\n",
      "Epoch 13639: train_loss=517.65985, val_loss=532.27844\n",
      "Epoch 13640: train_loss=517.65033, val_loss=532.35437\n",
      "Epoch 13641: train_loss=517.64203, val_loss=532.25397\n",
      "Epoch 13642: train_loss=517.63416, val_loss=532.34607\n",
      "Epoch 13643: train_loss=517.62732, val_loss=532.23077\n",
      "Epoch 13644: train_loss=517.61957, val_loss=532.33508\n",
      "Epoch 13645: train_loss=517.61151, val_loss=532.20581\n",
      "Epoch 13646: train_loss=517.60236, val_loss=532.31647\n",
      "Epoch 13647: train_loss=517.59149, val_loss=532.17523\n",
      "Epoch 13648: train_loss=517.57788, val_loss=532.28406\n",
      "Epoch 13649: train_loss=517.56122, val_loss=532.13562\n",
      "Epoch 13650: train_loss=517.54211, val_loss=532.23651\n",
      "Epoch 13651: train_loss=517.52002, val_loss=532.08679\n",
      "Epoch 13652: train_loss=517.49432, val_loss=532.17273\n",
      "Epoch 13653: train_loss=517.46570, val_loss=532.03168\n",
      "Epoch 13654: train_loss=517.43396, val_loss=532.09583\n",
      "Epoch 13655: train_loss=517.40112, val_loss=531.97449\n",
      "Epoch 13656: train_loss=517.36810, val_loss=532.01440\n",
      "Epoch 13657: train_loss=517.33618, val_loss=531.92230\n",
      "Epoch 13658: train_loss=517.30646, val_loss=531.93970\n",
      "Epoch 13659: train_loss=517.27942, val_loss=531.87921\n",
      "Epoch 13660: train_loss=517.25519, val_loss=531.87677\n",
      "Epoch 13661: train_loss=517.23328, val_loss=531.84497\n",
      "Epoch 13662: train_loss=517.21362, val_loss=531.82269\n",
      "Epoch 13663: train_loss=517.19580, val_loss=531.81482\n",
      "Epoch 13664: train_loss=517.17920, val_loss=531.77844\n",
      "Epoch 13665: train_loss=517.16357, val_loss=531.78931\n",
      "Epoch 13666: train_loss=517.14844, val_loss=531.73871\n",
      "Epoch 13667: train_loss=517.13397, val_loss=531.76440\n",
      "Epoch 13668: train_loss=517.11993, val_loss=531.70135\n",
      "Epoch 13669: train_loss=517.10706, val_loss=531.74188\n",
      "Epoch 13670: train_loss=517.09406, val_loss=531.66711\n",
      "Epoch 13671: train_loss=517.08215, val_loss=531.72284\n",
      "Epoch 13672: train_loss=517.07068, val_loss=531.63562\n",
      "Epoch 13673: train_loss=517.06042, val_loss=531.70703\n",
      "Epoch 13674: train_loss=517.05072, val_loss=531.60730\n",
      "Epoch 13675: train_loss=517.04248, val_loss=531.69489\n",
      "Epoch 13676: train_loss=517.03479, val_loss=531.58160\n",
      "Epoch 13677: train_loss=517.02820, val_loss=531.68323\n",
      "Epoch 13678: train_loss=517.02106, val_loss=531.55511\n",
      "Epoch 13679: train_loss=517.01398, val_loss=531.66779\n",
      "Epoch 13680: train_loss=517.00586, val_loss=531.52710\n",
      "Epoch 13681: train_loss=516.99567, val_loss=531.64355\n",
      "Epoch 13682: train_loss=516.98230, val_loss=531.49084\n",
      "Epoch 13683: train_loss=516.96503, val_loss=531.59833\n",
      "Epoch 13684: train_loss=516.94299, val_loss=531.44141\n",
      "Epoch 13685: train_loss=516.91693, val_loss=531.53186\n",
      "Epoch 13686: train_loss=516.88647, val_loss=531.38177\n",
      "Epoch 13687: train_loss=516.85394, val_loss=531.45056\n",
      "Epoch 13688: train_loss=516.81836, val_loss=531.31940\n",
      "Epoch 13689: train_loss=516.78381, val_loss=531.36517\n",
      "Epoch 13690: train_loss=516.74927, val_loss=531.26160\n",
      "Epoch 13691: train_loss=516.71753, val_loss=531.28558\n",
      "Epoch 13692: train_loss=516.68768, val_loss=531.21326\n",
      "Epoch 13693: train_loss=516.66064, val_loss=531.21716\n",
      "Epoch 13694: train_loss=516.63660, val_loss=531.17645\n",
      "Epoch 13695: train_loss=516.61499, val_loss=531.16217\n",
      "Epoch 13696: train_loss=516.59552, val_loss=531.14728\n",
      "Epoch 13697: train_loss=516.57770, val_loss=531.11652\n",
      "Epoch 13698: train_loss=516.56128, val_loss=531.12103\n",
      "Epoch 13699: train_loss=516.54547, val_loss=531.07477\n",
      "Epoch 13700: train_loss=516.53070, val_loss=531.09528\n",
      "Epoch 13701: train_loss=516.51660, val_loss=531.03583\n",
      "Epoch 13702: train_loss=516.50311, val_loss=531.07202\n",
      "Epoch 13703: train_loss=516.48993, val_loss=531.00110\n",
      "Epoch 13704: train_loss=516.47742, val_loss=531.05096\n",
      "Epoch 13705: train_loss=516.46484, val_loss=530.96918\n",
      "Epoch 13706: train_loss=516.45312, val_loss=531.03113\n",
      "Epoch 13707: train_loss=516.44153, val_loss=530.93890\n",
      "Epoch 13708: train_loss=516.43109, val_loss=531.01569\n",
      "Epoch 13709: train_loss=516.42120, val_loss=530.91382\n",
      "Epoch 13710: train_loss=516.41266, val_loss=531.00476\n",
      "Epoch 13711: train_loss=516.40417, val_loss=530.89166\n",
      "Epoch 13712: train_loss=516.39624, val_loss=530.99438\n",
      "Epoch 13713: train_loss=516.38776, val_loss=530.86932\n",
      "Epoch 13714: train_loss=516.37872, val_loss=530.97845\n",
      "Epoch 13715: train_loss=516.36792, val_loss=530.84174\n",
      "Epoch 13716: train_loss=516.35565, val_loss=530.95184\n",
      "Epoch 13717: train_loss=516.34100, val_loss=530.80688\n",
      "Epoch 13718: train_loss=516.32330, val_loss=530.91187\n",
      "Epoch 13719: train_loss=516.30304, val_loss=530.76276\n",
      "Epoch 13720: train_loss=516.27734, val_loss=530.85205\n",
      "Epoch 13721: train_loss=516.24884, val_loss=530.70703\n",
      "Epoch 13722: train_loss=516.21661, val_loss=530.77484\n",
      "Epoch 13723: train_loss=516.18292, val_loss=530.64557\n",
      "Epoch 13724: train_loss=516.14838, val_loss=530.69104\n",
      "Epoch 13725: train_loss=516.11444, val_loss=530.58868\n",
      "Epoch 13726: train_loss=516.08191, val_loss=530.61310\n",
      "Epoch 13727: train_loss=516.05182, val_loss=530.54285\n",
      "Epoch 13728: train_loss=516.02454, val_loss=530.54761\n",
      "Epoch 13729: train_loss=516.00031, val_loss=530.50775\n",
      "Epoch 13730: train_loss=515.97876, val_loss=530.49347\n",
      "Epoch 13731: train_loss=515.95947, val_loss=530.47858\n",
      "Epoch 13732: train_loss=515.94196, val_loss=530.44751\n",
      "Epoch 13733: train_loss=515.92578, val_loss=530.45294\n",
      "Epoch 13734: train_loss=515.91052, val_loss=530.40747\n",
      "Epoch 13735: train_loss=515.89557, val_loss=530.42847\n",
      "Epoch 13736: train_loss=515.88086, val_loss=530.37238\n",
      "Epoch 13737: train_loss=515.86694, val_loss=530.40808\n",
      "Epoch 13738: train_loss=515.85309, val_loss=530.34320\n",
      "Epoch 13739: train_loss=515.84003, val_loss=530.39203\n",
      "Epoch 13740: train_loss=515.82733, val_loss=530.31641\n",
      "Epoch 13741: train_loss=515.81573, val_loss=530.37817\n",
      "Epoch 13742: train_loss=515.80450, val_loss=530.29150\n",
      "Epoch 13743: train_loss=515.79541, val_loss=530.36896\n",
      "Epoch 13744: train_loss=515.78662, val_loss=530.27063\n",
      "Epoch 13745: train_loss=515.78058, val_loss=530.36511\n",
      "Epoch 13746: train_loss=515.77405, val_loss=530.25311\n",
      "Epoch 13747: train_loss=515.76923, val_loss=530.36273\n",
      "Epoch 13748: train_loss=515.76324, val_loss=530.23663\n",
      "Epoch 13749: train_loss=515.75671, val_loss=530.35437\n",
      "Epoch 13750: train_loss=515.74823, val_loss=530.21399\n",
      "Epoch 13751: train_loss=515.73730, val_loss=530.33075\n",
      "Epoch 13752: train_loss=515.72296, val_loss=530.17950\n",
      "Epoch 13753: train_loss=515.70404, val_loss=530.28601\n",
      "Epoch 13754: train_loss=515.68109, val_loss=530.13184\n",
      "Epoch 13755: train_loss=515.65283, val_loss=530.22064\n",
      "Epoch 13756: train_loss=515.62140, val_loss=530.07385\n",
      "Epoch 13757: train_loss=515.58618, val_loss=530.13916\n",
      "Epoch 13758: train_loss=515.54956, val_loss=530.01233\n",
      "Epoch 13759: train_loss=515.51282, val_loss=530.05286\n",
      "Epoch 13760: train_loss=515.47699, val_loss=529.95789\n",
      "Epoch 13761: train_loss=515.44379, val_loss=529.97528\n",
      "Epoch 13762: train_loss=515.41388, val_loss=529.91736\n",
      "Epoch 13763: train_loss=515.38788, val_loss=529.91296\n",
      "Epoch 13764: train_loss=515.36548, val_loss=529.89166\n",
      "Epoch 13765: train_loss=515.34662, val_loss=529.86755\n",
      "Epoch 13766: train_loss=515.33051, val_loss=529.87488\n",
      "Epoch 13767: train_loss=515.31586, val_loss=529.83221\n",
      "Epoch 13768: train_loss=515.30219, val_loss=529.85760\n",
      "Epoch 13769: train_loss=515.28864, val_loss=529.80005\n",
      "Epoch 13770: train_loss=515.27490, val_loss=529.83673\n",
      "Epoch 13771: train_loss=515.26093, val_loss=529.76910\n",
      "Epoch 13772: train_loss=515.24695, val_loss=529.81458\n",
      "Epoch 13773: train_loss=515.23260, val_loss=529.73871\n",
      "Epoch 13774: train_loss=515.21893, val_loss=529.79163\n",
      "Epoch 13775: train_loss=515.20514, val_loss=529.70837\n",
      "Epoch 13776: train_loss=515.19275, val_loss=529.77228\n",
      "Epoch 13777: train_loss=515.18097, val_loss=529.68268\n",
      "Epoch 13778: train_loss=515.17072, val_loss=529.76013\n",
      "Epoch 13779: train_loss=515.16101, val_loss=529.66077\n",
      "Epoch 13780: train_loss=515.15216, val_loss=529.75122\n",
      "Epoch 13781: train_loss=515.14374, val_loss=529.64038\n",
      "Epoch 13782: train_loss=515.13477, val_loss=529.73999\n",
      "Epoch 13783: train_loss=515.12549, val_loss=529.61725\n",
      "Epoch 13784: train_loss=515.11450, val_loss=529.72162\n",
      "Epoch 13785: train_loss=515.10248, val_loss=529.58911\n",
      "Epoch 13786: train_loss=515.08771, val_loss=529.69275\n",
      "Epoch 13787: train_loss=515.07050, val_loss=529.55530\n",
      "Epoch 13788: train_loss=515.05005, val_loss=529.65021\n",
      "Epoch 13789: train_loss=515.02612, val_loss=529.51245\n",
      "Epoch 13790: train_loss=514.99908, val_loss=529.59210\n",
      "Epoch 13791: train_loss=514.97003, val_loss=529.46289\n",
      "Epoch 13792: train_loss=514.93878, val_loss=529.52386\n",
      "Epoch 13793: train_loss=514.90698, val_loss=529.41119\n",
      "Epoch 13794: train_loss=514.87537, val_loss=529.45349\n",
      "Epoch 13795: train_loss=514.84436, val_loss=529.36316\n",
      "Epoch 13796: train_loss=514.81482, val_loss=529.38770\n",
      "Epoch 13797: train_loss=514.78711, val_loss=529.32147\n",
      "Epoch 13798: train_loss=514.76111, val_loss=529.32861\n",
      "Epoch 13799: train_loss=514.73773, val_loss=529.28741\n",
      "Epoch 13800: train_loss=514.71600, val_loss=529.27905\n",
      "Epoch 13801: train_loss=514.69629, val_loss=529.26202\n",
      "Epoch 13802: train_loss=514.67847, val_loss=529.23999\n",
      "Epoch 13803: train_loss=514.66162, val_loss=529.24078\n",
      "Epoch 13804: train_loss=514.64563, val_loss=529.20496\n",
      "Epoch 13805: train_loss=514.63007, val_loss=529.21814\n",
      "Epoch 13806: train_loss=514.61511, val_loss=529.17126\n",
      "Epoch 13807: train_loss=514.60040, val_loss=529.19714\n",
      "Epoch 13808: train_loss=514.58630, val_loss=529.14154\n",
      "Epoch 13809: train_loss=514.57324, val_loss=529.18103\n",
      "Epoch 13810: train_loss=514.56061, val_loss=529.11530\n",
      "Epoch 13811: train_loss=514.54944, val_loss=529.17029\n",
      "Epoch 13812: train_loss=514.53937, val_loss=529.09381\n",
      "Epoch 13813: train_loss=514.53137, val_loss=529.16779\n",
      "Epoch 13814: train_loss=514.52509, val_loss=529.07880\n",
      "Epoch 13815: train_loss=514.52130, val_loss=529.17310\n",
      "Epoch 13816: train_loss=514.51910, val_loss=529.06995\n",
      "Epoch 13817: train_loss=514.51886, val_loss=529.18707\n",
      "Epoch 13818: train_loss=514.52045, val_loss=529.06915\n",
      "Epoch 13819: train_loss=514.52258, val_loss=529.20532\n",
      "Epoch 13820: train_loss=514.52582, val_loss=529.06769\n",
      "Epoch 13821: train_loss=514.52545, val_loss=529.21075\n",
      "Epoch 13822: train_loss=514.52332, val_loss=529.05255\n",
      "Epoch 13823: train_loss=514.51288, val_loss=529.18604\n",
      "Epoch 13824: train_loss=514.49585, val_loss=529.00989\n",
      "Epoch 13825: train_loss=514.46716, val_loss=529.11609\n",
      "Epoch 13826: train_loss=514.43048, val_loss=528.93524\n",
      "Epoch 13827: train_loss=514.38385, val_loss=529.00464\n",
      "Epoch 13828: train_loss=514.33356, val_loss=528.84644\n",
      "Epoch 13829: train_loss=514.28082, val_loss=528.88135\n",
      "Epoch 13830: train_loss=514.23102, val_loss=528.77338\n",
      "Epoch 13831: train_loss=514.18787, val_loss=528.78101\n",
      "Epoch 13832: train_loss=514.15271, val_loss=528.73297\n",
      "Epoch 13833: train_loss=514.12640, val_loss=528.71533\n",
      "Epoch 13834: train_loss=514.10791, val_loss=528.71967\n",
      "Epoch 13835: train_loss=514.09503, val_loss=528.67682\n",
      "Epoch 13836: train_loss=514.08575, val_loss=528.71515\n",
      "Epoch 13837: train_loss=514.07776, val_loss=528.64856\n",
      "Epoch 13838: train_loss=514.06976, val_loss=528.70508\n",
      "Epoch 13839: train_loss=514.06036, val_loss=528.62073\n",
      "Epoch 13840: train_loss=514.04944, val_loss=528.68390\n",
      "Epoch 13841: train_loss=514.03571, val_loss=528.58844\n",
      "Epoch 13842: train_loss=514.01959, val_loss=528.65021\n",
      "Epoch 13843: train_loss=514.00031, val_loss=528.55078\n",
      "Epoch 13844: train_loss=513.97913, val_loss=528.60339\n",
      "Epoch 13845: train_loss=513.95587, val_loss=528.50720\n",
      "Epoch 13846: train_loss=513.93195, val_loss=528.54730\n",
      "Epoch 13847: train_loss=513.90710, val_loss=528.46130\n",
      "Epoch 13848: train_loss=513.88269, val_loss=528.48914\n",
      "Epoch 13849: train_loss=513.85834, val_loss=528.41797\n",
      "Epoch 13850: train_loss=513.83466, val_loss=528.43445\n",
      "Epoch 13851: train_loss=513.81189, val_loss=528.37970\n",
      "Epoch 13852: train_loss=513.79022, val_loss=528.38611\n",
      "Epoch 13853: train_loss=513.76935, val_loss=528.34485\n",
      "Epoch 13854: train_loss=513.74927, val_loss=528.34167\n",
      "Epoch 13855: train_loss=513.72974, val_loss=528.31012\n",
      "Epoch 13856: train_loss=513.71045, val_loss=528.29913\n",
      "Epoch 13857: train_loss=513.69159, val_loss=528.27576\n",
      "Epoch 13858: train_loss=513.67285, val_loss=528.25824\n",
      "Epoch 13859: train_loss=513.65448, val_loss=528.24005\n",
      "Epoch 13860: train_loss=513.63617, val_loss=528.21637\n",
      "Epoch 13861: train_loss=513.61804, val_loss=528.20367\n",
      "Epoch 13862: train_loss=513.59991, val_loss=528.17676\n",
      "Epoch 13863: train_loss=513.58191, val_loss=528.17041\n",
      "Epoch 13864: train_loss=513.56415, val_loss=528.13861\n",
      "Epoch 13865: train_loss=513.54626, val_loss=528.13599\n",
      "Epoch 13866: train_loss=513.52850, val_loss=528.09705\n",
      "Epoch 13867: train_loss=513.51141, val_loss=528.10352\n",
      "Epoch 13868: train_loss=513.49475, val_loss=528.05963\n",
      "Epoch 13869: train_loss=513.47882, val_loss=528.07983\n",
      "Epoch 13870: train_loss=513.46405, val_loss=528.02594\n",
      "Epoch 13871: train_loss=513.45117, val_loss=528.06323\n",
      "Epoch 13872: train_loss=513.44043, val_loss=527.99640\n",
      "Epoch 13873: train_loss=513.43311, val_loss=528.06256\n",
      "Epoch 13874: train_loss=513.42896, val_loss=527.98297\n",
      "Epoch 13875: train_loss=513.43030, val_loss=528.08795\n",
      "Epoch 13876: train_loss=513.43719, val_loss=527.99176\n",
      "Epoch 13877: train_loss=513.45221, val_loss=528.14520\n",
      "Epoch 13878: train_loss=513.47461, val_loss=528.02911\n",
      "Epoch 13879: train_loss=513.50543, val_loss=528.23523\n",
      "Epoch 13880: train_loss=513.54346, val_loss=528.09186\n",
      "Epoch 13881: train_loss=513.58496, val_loss=528.33557\n",
      "Epoch 13882: train_loss=513.62604, val_loss=528.14502\n",
      "Epoch 13883: train_loss=513.65137, val_loss=528.37146\n",
      "Epoch 13884: train_loss=513.65399, val_loss=528.10699\n",
      "Epoch 13885: train_loss=513.61414, val_loss=528.24377\n",
      "Epoch 13886: train_loss=513.53827, val_loss=527.93854\n",
      "Epoch 13887: train_loss=513.42859, val_loss=527.97656\n",
      "Epoch 13888: train_loss=513.30811, val_loss=527.74054\n",
      "Epoch 13889: train_loss=513.19727, val_loss=527.73193\n",
      "Epoch 13890: train_loss=513.11658, val_loss=527.66241\n",
      "Epoch 13891: train_loss=513.07605, val_loss=527.64001\n",
      "Epoch 13892: train_loss=513.07123, val_loss=527.71326\n",
      "Epoch 13893: train_loss=513.08862, val_loss=527.64874\n",
      "Epoch 13894: train_loss=513.11182, val_loss=527.77057\n",
      "Epoch 13895: train_loss=513.12555, val_loss=527.64368\n",
      "Epoch 13896: train_loss=513.11877, val_loss=527.73480\n",
      "Epoch 13897: train_loss=513.08923, val_loss=527.57916\n",
      "Epoch 13898: train_loss=513.04401, val_loss=527.61951\n",
      "Epoch 13899: train_loss=512.99200, val_loss=527.50134\n",
      "Epoch 13900: train_loss=512.94330, val_loss=527.50513\n",
      "Epoch 13901: train_loss=512.90564, val_loss=527.46680\n",
      "Epoch 13902: train_loss=512.88123, val_loss=527.44415\n",
      "Epoch 13903: train_loss=512.86847, val_loss=527.47504\n",
      "Epoch 13904: train_loss=512.86292, val_loss=527.42096\n",
      "Epoch 13905: train_loss=512.85901, val_loss=527.48071\n",
      "Epoch 13906: train_loss=512.85236, val_loss=527.39771\n",
      "Epoch 13907: train_loss=512.84119, val_loss=527.45520\n",
      "Epoch 13908: train_loss=512.82373, val_loss=527.36041\n",
      "Epoch 13909: train_loss=512.80139, val_loss=527.40112\n",
      "Epoch 13910: train_loss=512.77478, val_loss=527.31567\n",
      "Epoch 13911: train_loss=512.74695, val_loss=527.33496\n",
      "Epoch 13912: train_loss=512.71936, val_loss=527.27765\n",
      "Epoch 13913: train_loss=512.69421, val_loss=527.27728\n",
      "Epoch 13914: train_loss=512.67194, val_loss=527.25311\n",
      "Epoch 13915: train_loss=512.65283, val_loss=527.23193\n",
      "Epoch 13916: train_loss=512.63647, val_loss=527.23352\n",
      "Epoch 13917: train_loss=512.62177, val_loss=527.19507\n",
      "Epoch 13918: train_loss=512.60785, val_loss=527.21515\n",
      "Epoch 13919: train_loss=512.59418, val_loss=527.16431\n",
      "Epoch 13920: train_loss=512.58051, val_loss=527.19452\n",
      "Epoch 13921: train_loss=512.56610, val_loss=527.13391\n",
      "Epoch 13922: train_loss=512.55103, val_loss=527.16602\n",
      "Epoch 13923: train_loss=512.53485, val_loss=527.09955\n",
      "Epoch 13924: train_loss=512.51782, val_loss=527.13068\n",
      "Epoch 13925: train_loss=512.49963, val_loss=527.06500\n",
      "Epoch 13926: train_loss=512.48114, val_loss=527.09393\n",
      "Epoch 13927: train_loss=512.46136, val_loss=527.03223\n",
      "Epoch 13928: train_loss=512.44196, val_loss=527.05511\n",
      "Epoch 13929: train_loss=512.42206, val_loss=526.99805\n",
      "Epoch 13930: train_loss=512.40247, val_loss=527.01532\n",
      "Epoch 13931: train_loss=512.38293, val_loss=526.96454\n",
      "Epoch 13932: train_loss=512.36328, val_loss=526.97485\n",
      "Epoch 13933: train_loss=512.34387, val_loss=526.92993\n",
      "Epoch 13934: train_loss=512.32477, val_loss=526.93225\n",
      "Epoch 13935: train_loss=512.30560, val_loss=526.89490\n",
      "Epoch 13936: train_loss=512.28687, val_loss=526.89215\n",
      "Epoch 13937: train_loss=512.26837, val_loss=526.86273\n",
      "Epoch 13938: train_loss=512.25006, val_loss=526.85590\n",
      "Epoch 13939: train_loss=512.23199, val_loss=526.83240\n",
      "Epoch 13940: train_loss=512.21393, val_loss=526.82068\n",
      "Epoch 13941: train_loss=512.19604, val_loss=526.79987\n",
      "Epoch 13942: train_loss=512.17822, val_loss=526.78381\n",
      "Epoch 13943: train_loss=512.16040, val_loss=526.76465\n",
      "Epoch 13944: train_loss=512.14264, val_loss=526.74738\n",
      "Epoch 13945: train_loss=512.12488, val_loss=526.73102\n",
      "Epoch 13946: train_loss=512.10718, val_loss=526.71399\n",
      "Epoch 13947: train_loss=512.08942, val_loss=526.69946\n",
      "Epoch 13948: train_loss=512.07172, val_loss=526.67975\n",
      "Epoch 13949: train_loss=512.05377, val_loss=526.66711\n",
      "Epoch 13950: train_loss=512.03619, val_loss=526.64307\n",
      "Epoch 13951: train_loss=512.01874, val_loss=526.63684\n",
      "Epoch 13952: train_loss=512.00165, val_loss=526.60681\n",
      "Epoch 13953: train_loss=511.98511, val_loss=526.61224\n",
      "Epoch 13954: train_loss=511.96951, val_loss=526.57349\n",
      "Epoch 13955: train_loss=511.95554, val_loss=526.59711\n",
      "Epoch 13956: train_loss=511.94327, val_loss=526.54553\n",
      "Epoch 13957: train_loss=511.93390, val_loss=526.59540\n",
      "Epoch 13958: train_loss=511.92776, val_loss=526.52887\n",
      "Epoch 13959: train_loss=511.92627, val_loss=526.61224\n",
      "Epoch 13960: train_loss=511.92953, val_loss=526.52911\n",
      "Epoch 13961: train_loss=511.93869, val_loss=526.65265\n",
      "Epoch 13962: train_loss=511.95245, val_loss=526.54987\n",
      "Epoch 13963: train_loss=511.97110, val_loss=526.71515\n",
      "Epoch 13964: train_loss=511.99466, val_loss=526.58936\n",
      "Epoch 13965: train_loss=512.01837, val_loss=526.78265\n",
      "Epoch 13966: train_loss=512.04175, val_loss=526.62244\n",
      "Epoch 13967: train_loss=512.05640, val_loss=526.81366\n",
      "Epoch 13968: train_loss=512.06165, val_loss=526.60730\n",
      "Epoch 13969: train_loss=512.04315, val_loss=526.75311\n",
      "Epoch 13970: train_loss=512.00446, val_loss=526.51111\n",
      "Epoch 13971: train_loss=511.93796, val_loss=526.58563\n",
      "Epoch 13972: train_loss=511.85568, val_loss=526.36121\n",
      "Epoch 13973: train_loss=511.76373, val_loss=526.37860\n",
      "Epoch 13974: train_loss=511.67929, val_loss=526.24719\n",
      "Epoch 13975: train_loss=511.61420, val_loss=526.23956\n",
      "Epoch 13976: train_loss=511.57468, val_loss=526.22937\n",
      "Epoch 13977: train_loss=511.55945, val_loss=526.19696\n",
      "Epoch 13978: train_loss=511.56119, val_loss=526.26801\n",
      "Epoch 13979: train_loss=511.57043, val_loss=526.19708\n",
      "Epoch 13980: train_loss=511.57819, val_loss=526.29181\n",
      "Epoch 13981: train_loss=511.57773, val_loss=526.18231\n",
      "Epoch 13982: train_loss=511.56509, val_loss=526.25818\n",
      "Epoch 13983: train_loss=511.54041, val_loss=526.13300\n",
      "Epoch 13984: train_loss=511.50610, val_loss=526.17615\n",
      "Epoch 13985: train_loss=511.46695, val_loss=526.07214\n",
      "Epoch 13986: train_loss=511.42780, val_loss=526.08728\n",
      "Epoch 13987: train_loss=511.39285, val_loss=526.02954\n",
      "Epoch 13988: train_loss=511.36395, val_loss=526.02277\n",
      "Epoch 13989: train_loss=511.34177, val_loss=526.01257\n",
      "Epoch 13990: train_loss=511.32513, val_loss=525.98370\n",
      "Epoch 13991: train_loss=511.31226, val_loss=526.00513\n",
      "Epoch 13992: train_loss=511.30142, val_loss=525.95514\n",
      "Epoch 13993: train_loss=511.29089, val_loss=525.99310\n",
      "Epoch 13994: train_loss=511.27905, val_loss=525.92798\n",
      "Epoch 13995: train_loss=511.26584, val_loss=525.97064\n",
      "Epoch 13996: train_loss=511.25015, val_loss=525.89728\n",
      "Epoch 13997: train_loss=511.23254, val_loss=525.93567\n",
      "Epoch 13998: train_loss=511.21283, val_loss=525.86212\n",
      "Epoch 13999: train_loss=511.19199, val_loss=525.89166\n",
      "Epoch 14000: train_loss=511.16971, val_loss=525.82495\n",
      "Epoch 14001: train_loss=511.14752, val_loss=525.84473\n",
      "Epoch 14002: train_loss=511.12527, val_loss=525.78918\n",
      "Epoch 14003: train_loss=511.10352, val_loss=525.79895\n",
      "Epoch 14004: train_loss=511.08221, val_loss=525.75439\n",
      "Epoch 14005: train_loss=511.06161, val_loss=525.75470\n",
      "Epoch 14006: train_loss=511.04172, val_loss=525.72217\n",
      "Epoch 14007: train_loss=511.02231, val_loss=525.71417\n",
      "Epoch 14008: train_loss=511.00351, val_loss=525.69128\n",
      "Epoch 14009: train_loss=510.98511, val_loss=525.67645\n",
      "Epoch 14010: train_loss=510.96713, val_loss=525.66077\n",
      "Epoch 14011: train_loss=510.94943, val_loss=525.64093\n",
      "Epoch 14012: train_loss=510.93173, val_loss=525.63086\n",
      "Epoch 14013: train_loss=510.91437, val_loss=525.60516\n",
      "Epoch 14014: train_loss=510.89716, val_loss=525.60052\n",
      "Epoch 14015: train_loss=510.88022, val_loss=525.56860\n",
      "Epoch 14016: train_loss=510.86374, val_loss=525.57196\n",
      "Epoch 14017: train_loss=510.84790, val_loss=525.53278\n",
      "Epoch 14018: train_loss=510.83289, val_loss=525.54712\n",
      "Epoch 14019: train_loss=510.81870, val_loss=525.50049\n",
      "Epoch 14020: train_loss=510.80563, val_loss=525.52911\n",
      "Epoch 14021: train_loss=510.79395, val_loss=525.47388\n",
      "Epoch 14022: train_loss=510.78400, val_loss=525.52106\n",
      "Epoch 14023: train_loss=510.77643, val_loss=525.45654\n",
      "Epoch 14024: train_loss=510.77100, val_loss=525.52478\n",
      "Epoch 14025: train_loss=510.76828, val_loss=525.44739\n",
      "Epoch 14026: train_loss=510.76669, val_loss=525.53516\n",
      "Epoch 14027: train_loss=510.76773, val_loss=525.44452\n",
      "Epoch 14028: train_loss=510.76898, val_loss=525.55017\n",
      "Epoch 14029: train_loss=510.77109, val_loss=525.44385\n",
      "Epoch 14030: train_loss=510.76984, val_loss=525.55511\n",
      "Epoch 14031: train_loss=510.76648, val_loss=525.43054\n",
      "Epoch 14032: train_loss=510.75714, val_loss=525.53510\n",
      "Epoch 14033: train_loss=510.74228, val_loss=525.39520\n",
      "Epoch 14034: train_loss=510.71875, val_loss=525.47931\n",
      "Epoch 14035: train_loss=510.68790, val_loss=525.33282\n",
      "Epoch 14036: train_loss=510.64902, val_loss=525.38837\n",
      "Epoch 14037: train_loss=510.60553, val_loss=525.25238\n",
      "Epoch 14038: train_loss=510.55875, val_loss=525.28046\n",
      "Epoch 14039: train_loss=510.51254, val_loss=525.17877\n",
      "Epoch 14040: train_loss=510.47058, val_loss=525.18793\n",
      "Epoch 14041: train_loss=510.43423, val_loss=525.13062\n",
      "Epoch 14042: train_loss=510.40460, val_loss=525.12299\n",
      "Epoch 14043: train_loss=510.38153, val_loss=525.10724\n",
      "Epoch 14044: train_loss=510.36395, val_loss=525.08252\n",
      "Epoch 14045: train_loss=510.35025, val_loss=525.09631\n",
      "Epoch 14046: train_loss=510.33923, val_loss=525.05383\n",
      "Epoch 14047: train_loss=510.32901, val_loss=525.08496\n",
      "Epoch 14048: train_loss=510.31897, val_loss=525.02863\n",
      "Epoch 14049: train_loss=510.30814, val_loss=525.07031\n",
      "Epoch 14050: train_loss=510.29630, val_loss=525.00458\n",
      "Epoch 14051: train_loss=510.28351, val_loss=525.05170\n",
      "Epoch 14052: train_loss=510.26968, val_loss=524.97852\n",
      "Epoch 14053: train_loss=510.25510, val_loss=525.02643\n",
      "Epoch 14054: train_loss=510.23996, val_loss=524.94824\n",
      "Epoch 14055: train_loss=510.22406, val_loss=524.99646\n",
      "Epoch 14056: train_loss=510.20746, val_loss=524.91589\n",
      "Epoch 14057: train_loss=510.18985, val_loss=524.96320\n",
      "Epoch 14058: train_loss=510.17194, val_loss=524.88220\n",
      "Epoch 14059: train_loss=510.15320, val_loss=524.92810\n",
      "Epoch 14060: train_loss=510.13431, val_loss=524.84723\n",
      "Epoch 14061: train_loss=510.11417, val_loss=524.88873\n",
      "Epoch 14062: train_loss=510.09442, val_loss=524.81036\n",
      "Epoch 14063: train_loss=510.07419, val_loss=524.84894\n",
      "Epoch 14064: train_loss=510.05426, val_loss=524.77411\n",
      "Epoch 14065: train_loss=510.03397, val_loss=524.80847\n",
      "Epoch 14066: train_loss=510.01385, val_loss=524.73645\n",
      "Epoch 14067: train_loss=509.99310, val_loss=524.76642\n",
      "Epoch 14068: train_loss=509.97302, val_loss=524.69867\n",
      "Epoch 14069: train_loss=509.95276, val_loss=524.72626\n",
      "Epoch 14070: train_loss=509.93314, val_loss=524.66284\n",
      "Epoch 14071: train_loss=509.91327, val_loss=524.68683\n",
      "Epoch 14072: train_loss=509.89365, val_loss=524.62640\n",
      "Epoch 14073: train_loss=509.87421, val_loss=524.64630\n",
      "Epoch 14074: train_loss=509.85489, val_loss=524.58881\n",
      "Epoch 14075: train_loss=509.83557, val_loss=524.60602\n",
      "Epoch 14076: train_loss=509.81653, val_loss=524.55280\n",
      "Epoch 14077: train_loss=509.79782, val_loss=524.56897\n",
      "Epoch 14078: train_loss=509.77917, val_loss=524.51898\n",
      "Epoch 14079: train_loss=509.76062, val_loss=524.53308\n",
      "Epoch 14080: train_loss=509.74243, val_loss=524.48456\n",
      "Epoch 14081: train_loss=509.72464, val_loss=524.49811\n",
      "Epoch 14082: train_loss=509.70721, val_loss=524.44977\n",
      "Epoch 14083: train_loss=509.69012, val_loss=524.46588\n",
      "Epoch 14084: train_loss=509.67386, val_loss=524.41766\n",
      "Epoch 14085: train_loss=509.65796, val_loss=524.44000\n",
      "Epoch 14086: train_loss=509.64328, val_loss=524.38861\n",
      "Epoch 14087: train_loss=509.62964, val_loss=524.42041\n",
      "Epoch 14088: train_loss=509.61765, val_loss=524.36340\n",
      "Epoch 14089: train_loss=509.60794, val_loss=524.41241\n",
      "Epoch 14090: train_loss=509.60147, val_loss=524.34833\n",
      "Epoch 14091: train_loss=509.59885, val_loss=524.42346\n",
      "Epoch 14092: train_loss=509.60144, val_loss=524.35040\n",
      "Epoch 14093: train_loss=509.60828, val_loss=524.45947\n",
      "Epoch 14094: train_loss=509.62241, val_loss=524.37689\n",
      "Epoch 14095: train_loss=509.64221, val_loss=524.52283\n",
      "Epoch 14096: train_loss=509.66968, val_loss=524.42426\n",
      "Epoch 14097: train_loss=509.69922, val_loss=524.59760\n",
      "Epoch 14098: train_loss=509.73010, val_loss=524.46625\n",
      "Epoch 14099: train_loss=509.74866, val_loss=524.62927\n",
      "Epoch 14100: train_loss=509.75409, val_loss=524.44525\n",
      "Epoch 14101: train_loss=509.72849, val_loss=524.54785\n",
      "Epoch 14102: train_loss=509.67816, val_loss=524.32251\n",
      "Epoch 14103: train_loss=509.59583, val_loss=524.34937\n",
      "Epoch 14104: train_loss=509.50101, val_loss=524.15057\n",
      "Epoch 14105: train_loss=509.40414, val_loss=524.14056\n",
      "Epoch 14106: train_loss=509.32455, val_loss=524.04413\n",
      "Epoch 14107: train_loss=509.27023, val_loss=524.02777\n",
      "Epoch 14108: train_loss=509.24353, val_loss=524.04034\n",
      "Epoch 14109: train_loss=509.23904, val_loss=524.00970\n",
      "Epoch 14110: train_loss=509.24774, val_loss=524.08118\n",
      "Epoch 14111: train_loss=509.25964, val_loss=524.01477\n",
      "Epoch 14112: train_loss=509.26556, val_loss=524.09155\n",
      "Epoch 14113: train_loss=509.26151, val_loss=523.99158\n",
      "Epoch 14114: train_loss=509.24344, val_loss=524.04510\n",
      "Epoch 14115: train_loss=509.21524, val_loss=523.93420\n",
      "Epoch 14116: train_loss=509.17831, val_loss=523.95764\n",
      "Epoch 14117: train_loss=509.13892, val_loss=523.86798\n",
      "Epoch 14118: train_loss=509.10056, val_loss=523.87018\n",
      "Epoch 14119: train_loss=509.06726, val_loss=523.82422\n",
      "Epoch 14120: train_loss=509.04062, val_loss=523.81122\n",
      "Epoch 14121: train_loss=509.02106, val_loss=523.80658\n",
      "Epoch 14122: train_loss=509.00729, val_loss=523.77625\n",
      "Epoch 14123: train_loss=508.99710, val_loss=523.79724\n",
      "Epoch 14124: train_loss=508.98782, val_loss=523.74957\n",
      "Epoch 14125: train_loss=508.97766, val_loss=523.77924\n",
      "Epoch 14126: train_loss=508.96521, val_loss=523.71851\n",
      "Epoch 14127: train_loss=508.95013, val_loss=523.74542\n",
      "Epoch 14128: train_loss=508.93216, val_loss=523.68170\n",
      "Epoch 14129: train_loss=508.91214, val_loss=523.70172\n",
      "Epoch 14130: train_loss=508.89041, val_loss=523.64337\n",
      "Epoch 14131: train_loss=508.86838, val_loss=523.65277\n",
      "Epoch 14132: train_loss=508.84613, val_loss=523.60431\n",
      "Epoch 14133: train_loss=508.82416, val_loss=523.60162\n",
      "Epoch 14134: train_loss=508.80292, val_loss=523.56793\n",
      "Epoch 14135: train_loss=508.78296, val_loss=523.55530\n",
      "Epoch 14136: train_loss=508.76456, val_loss=523.53772\n",
      "Epoch 14137: train_loss=508.74744, val_loss=523.51569\n",
      "Epoch 14138: train_loss=508.73111, val_loss=523.51050\n",
      "Epoch 14139: train_loss=508.71570, val_loss=523.48096\n",
      "Epoch 14140: train_loss=508.70059, val_loss=523.48529\n",
      "Epoch 14141: train_loss=508.68564, val_loss=523.44843\n",
      "Epoch 14142: train_loss=508.67087, val_loss=523.45892\n",
      "Epoch 14143: train_loss=508.65622, val_loss=523.41504\n",
      "Epoch 14144: train_loss=508.64157, val_loss=523.43091\n",
      "Epoch 14145: train_loss=508.62674, val_loss=523.38275\n",
      "Epoch 14146: train_loss=508.61185, val_loss=523.40344\n",
      "Epoch 14147: train_loss=508.59717, val_loss=523.35193\n",
      "Epoch 14148: train_loss=508.58246, val_loss=523.37714\n",
      "Epoch 14149: train_loss=508.56824, val_loss=523.32135\n",
      "Epoch 14150: train_loss=508.55389, val_loss=523.35114\n",
      "Epoch 14151: train_loss=508.54028, val_loss=523.29102\n",
      "Epoch 14152: train_loss=508.52679, val_loss=523.32715\n",
      "Epoch 14153: train_loss=508.51465, val_loss=523.26343\n",
      "Epoch 14154: train_loss=508.50281, val_loss=523.30786\n",
      "Epoch 14155: train_loss=508.49225, val_loss=523.23914\n",
      "Epoch 14156: train_loss=508.48224, val_loss=523.29315\n",
      "Epoch 14157: train_loss=508.47382, val_loss=523.21814\n",
      "Epoch 14158: train_loss=508.46512, val_loss=523.28131\n",
      "Epoch 14159: train_loss=508.45795, val_loss=523.19873\n",
      "Epoch 14160: train_loss=508.45029, val_loss=523.27112\n",
      "Epoch 14161: train_loss=508.44495, val_loss=523.18182\n",
      "Epoch 14162: train_loss=508.43860, val_loss=523.26215\n",
      "Epoch 14163: train_loss=508.43222, val_loss=523.16400\n",
      "Epoch 14164: train_loss=508.42215, val_loss=523.24304\n",
      "Epoch 14165: train_loss=508.40982, val_loss=523.13428\n",
      "Epoch 14166: train_loss=508.39172, val_loss=523.20227\n",
      "Epoch 14167: train_loss=508.36984, val_loss=523.08649\n",
      "Epoch 14168: train_loss=508.34210, val_loss=523.13818\n",
      "Epoch 14169: train_loss=508.31171, val_loss=523.02509\n",
      "Epoch 14170: train_loss=508.27692, val_loss=523.06024\n",
      "Epoch 14171: train_loss=508.24216, val_loss=522.96179\n",
      "Epoch 14172: train_loss=508.20609, val_loss=522.98151\n",
      "Epoch 14173: train_loss=508.17252, val_loss=522.90570\n",
      "Epoch 14174: train_loss=508.14069, val_loss=522.91150\n",
      "Epoch 14175: train_loss=508.11221, val_loss=522.86182\n",
      "Epoch 14176: train_loss=508.08713, val_loss=522.85638\n",
      "Epoch 14177: train_loss=508.06525, val_loss=522.83105\n",
      "Epoch 14178: train_loss=508.04617, val_loss=522.81464\n",
      "Epoch 14179: train_loss=508.02917, val_loss=522.80713\n",
      "Epoch 14180: train_loss=508.01379, val_loss=522.78021\n",
      "Epoch 14181: train_loss=507.99963, val_loss=522.78711\n",
      "Epoch 14182: train_loss=507.98645, val_loss=522.75043\n",
      "Epoch 14183: train_loss=507.97446, val_loss=522.76971\n",
      "Epoch 14184: train_loss=507.96289, val_loss=522.72314\n",
      "Epoch 14185: train_loss=507.95245, val_loss=522.75433\n",
      "Epoch 14186: train_loss=507.94254, val_loss=522.69995\n",
      "Epoch 14187: train_loss=507.93375, val_loss=522.74261\n",
      "Epoch 14188: train_loss=507.92493, val_loss=522.67944\n",
      "Epoch 14189: train_loss=507.91660, val_loss=522.73218\n",
      "Epoch 14190: train_loss=507.90945, val_loss=522.66150\n",
      "Epoch 14191: train_loss=507.90283, val_loss=522.72437\n",
      "Epoch 14192: train_loss=507.89740, val_loss=522.64661\n",
      "Epoch 14193: train_loss=507.89114, val_loss=522.72052\n",
      "Epoch 14194: train_loss=507.88660, val_loss=522.63495\n",
      "Epoch 14195: train_loss=507.87927, val_loss=522.71210\n",
      "Epoch 14196: train_loss=507.87164, val_loss=522.61481\n",
      "Epoch 14197: train_loss=507.85904, val_loss=522.68622\n",
      "Epoch 14198: train_loss=507.84402, val_loss=522.58057\n",
      "Epoch 14199: train_loss=507.82303, val_loss=522.64197\n",
      "Epoch 14200: train_loss=507.79904, val_loss=522.53418\n",
      "Epoch 14201: train_loss=507.76871, val_loss=522.58044\n",
      "Epoch 14202: train_loss=507.73737, val_loss=522.47900\n",
      "Epoch 14203: train_loss=507.70218, val_loss=522.50769\n",
      "Epoch 14204: train_loss=507.66852, val_loss=522.42078\n",
      "Epoch 14205: train_loss=507.63504, val_loss=522.43524\n",
      "Epoch 14206: train_loss=507.60364, val_loss=522.37061\n",
      "Epoch 14207: train_loss=507.57465, val_loss=522.37366\n",
      "Epoch 14208: train_loss=507.54846, val_loss=522.33301\n",
      "Epoch 14209: train_loss=507.52560, val_loss=522.32562\n",
      "Epoch 14210: train_loss=507.50565, val_loss=522.30457\n",
      "Epoch 14211: train_loss=507.48764, val_loss=522.28729\n",
      "Epoch 14212: train_loss=507.47116, val_loss=522.28168\n",
      "Epoch 14213: train_loss=507.45590, val_loss=522.25574\n",
      "Epoch 14214: train_loss=507.44162, val_loss=522.26178\n",
      "Epoch 14215: train_loss=507.42834, val_loss=522.22681\n",
      "Epoch 14216: train_loss=507.41608, val_loss=522.24512\n",
      "Epoch 14217: train_loss=507.40518, val_loss=522.20203\n",
      "Epoch 14218: train_loss=507.39575, val_loss=522.23511\n",
      "Epoch 14219: train_loss=507.38757, val_loss=522.18347\n",
      "Epoch 14220: train_loss=507.38107, val_loss=522.23041\n",
      "Epoch 14221: train_loss=507.37567, val_loss=522.16901\n",
      "Epoch 14222: train_loss=507.37219, val_loss=522.23224\n",
      "Epoch 14223: train_loss=507.37085, val_loss=522.16223\n",
      "Epoch 14224: train_loss=507.36996, val_loss=522.23865\n",
      "Epoch 14225: train_loss=507.37030, val_loss=522.15637\n",
      "Epoch 14226: train_loss=507.36911, val_loss=522.24164\n",
      "Epoch 14227: train_loss=507.36789, val_loss=522.14758\n",
      "Epoch 14228: train_loss=507.36264, val_loss=522.23279\n",
      "Epoch 14229: train_loss=507.35471, val_loss=522.12476\n",
      "Epoch 14230: train_loss=507.34006, val_loss=522.19897\n",
      "Epoch 14231: train_loss=507.32111, val_loss=522.08002\n",
      "Epoch 14232: train_loss=507.29376, val_loss=522.13562\n",
      "Epoch 14233: train_loss=507.26141, val_loss=522.01422\n",
      "Epoch 14234: train_loss=507.22083, val_loss=522.04681\n",
      "Epoch 14235: train_loss=507.17889, val_loss=521.93896\n",
      "Epoch 14236: train_loss=507.13483, val_loss=521.95172\n",
      "Epoch 14237: train_loss=507.09457, val_loss=521.87305\n",
      "Epoch 14238: train_loss=507.05762, val_loss=521.87207\n",
      "Epoch 14239: train_loss=507.02664, val_loss=521.83093\n",
      "Epoch 14240: train_loss=507.00150, val_loss=521.81989\n",
      "Epoch 14241: train_loss=506.98181, val_loss=521.80920\n",
      "Epoch 14242: train_loss=506.96628, val_loss=521.78473\n",
      "Epoch 14243: train_loss=506.95395, val_loss=521.79517\n",
      "Epoch 14244: train_loss=506.94360, val_loss=521.75787\n",
      "Epoch 14245: train_loss=506.93405, val_loss=521.78296\n",
      "Epoch 14246: train_loss=506.92496, val_loss=521.73541\n",
      "Epoch 14247: train_loss=506.91513, val_loss=521.76862\n",
      "Epoch 14248: train_loss=506.90466, val_loss=521.71167\n",
      "Epoch 14249: train_loss=506.89343, val_loss=521.74823\n",
      "Epoch 14250: train_loss=506.88138, val_loss=521.68457\n",
      "Epoch 14251: train_loss=506.86771, val_loss=521.72327\n",
      "Epoch 14252: train_loss=506.85379, val_loss=521.65497\n",
      "Epoch 14253: train_loss=506.83804, val_loss=521.69202\n",
      "Epoch 14254: train_loss=506.82184, val_loss=521.62024\n",
      "Epoch 14255: train_loss=506.80417, val_loss=521.65393\n",
      "Epoch 14256: train_loss=506.78580, val_loss=521.58289\n",
      "Epoch 14257: train_loss=506.76657, val_loss=521.61414\n",
      "Epoch 14258: train_loss=506.74689, val_loss=521.54614\n",
      "Epoch 14259: train_loss=506.72681, val_loss=521.57324\n",
      "Epoch 14260: train_loss=506.70621, val_loss=521.50818\n",
      "Epoch 14261: train_loss=506.68530, val_loss=521.52917\n",
      "Epoch 14262: train_loss=506.66443, val_loss=521.46832\n",
      "Epoch 14263: train_loss=506.64349, val_loss=521.48535\n",
      "Epoch 14264: train_loss=506.62311, val_loss=521.43085\n",
      "Epoch 14265: train_loss=506.60284, val_loss=521.44366\n",
      "Epoch 14266: train_loss=506.58264, val_loss=521.39459\n",
      "Epoch 14267: train_loss=506.56274, val_loss=521.40240\n",
      "Epoch 14268: train_loss=506.54306, val_loss=521.35864\n",
      "Epoch 14269: train_loss=506.52420, val_loss=521.36328\n",
      "Epoch 14270: train_loss=506.50528, val_loss=521.32422\n",
      "Epoch 14271: train_loss=506.48709, val_loss=521.32654\n",
      "Epoch 14272: train_loss=506.46906, val_loss=521.28973\n",
      "Epoch 14273: train_loss=506.45145, val_loss=521.28918\n",
      "Epoch 14274: train_loss=506.43396, val_loss=521.25366\n",
      "Epoch 14275: train_loss=506.41693, val_loss=521.25281\n",
      "Epoch 14276: train_loss=506.39987, val_loss=521.21954\n",
      "Epoch 14277: train_loss=506.38318, val_loss=521.22034\n",
      "Epoch 14278: train_loss=506.36700, val_loss=521.18579\n",
      "Epoch 14279: train_loss=506.35114, val_loss=521.18994\n",
      "Epoch 14280: train_loss=506.33609, val_loss=521.15228\n",
      "Epoch 14281: train_loss=506.32251, val_loss=521.16565\n",
      "Epoch 14282: train_loss=506.31018, val_loss=521.12573\n",
      "Epoch 14283: train_loss=506.30032, val_loss=521.15637\n",
      "Epoch 14284: train_loss=506.29388, val_loss=521.11279\n",
      "Epoch 14285: train_loss=506.29181, val_loss=521.16754\n",
      "Epoch 14286: train_loss=506.29507, val_loss=521.11877\n",
      "Epoch 14287: train_loss=506.30490, val_loss=521.20660\n",
      "Epoch 14288: train_loss=506.32309, val_loss=521.15375\n",
      "Epoch 14289: train_loss=506.34869, val_loss=521.27856\n",
      "Epoch 14290: train_loss=506.38144, val_loss=521.21375\n",
      "Epoch 14291: train_loss=506.41498, val_loss=521.36011\n",
      "Epoch 14292: train_loss=506.44922, val_loss=521.26270\n",
      "Epoch 14293: train_loss=506.46796, val_loss=521.38849\n",
      "Epoch 14294: train_loss=506.47134, val_loss=521.23499\n",
      "Epoch 14295: train_loss=506.44043, val_loss=521.29437\n",
      "Epoch 14296: train_loss=506.38370, val_loss=521.09888\n",
      "Epoch 14297: train_loss=506.29709, val_loss=521.09277\n",
      "Epoch 14298: train_loss=506.19992, val_loss=520.92371\n",
      "Epoch 14299: train_loss=506.10397, val_loss=520.89813\n",
      "Epoch 14300: train_loss=506.02716, val_loss=520.82153\n",
      "Epoch 14301: train_loss=505.97772, val_loss=520.80389\n",
      "Epoch 14302: train_loss=505.95609, val_loss=520.82007\n",
      "Epoch 14303: train_loss=505.95618, val_loss=520.79572\n",
      "Epoch 14304: train_loss=505.96817, val_loss=520.85742\n",
      "Epoch 14305: train_loss=505.98132, val_loss=520.80408\n",
      "Epoch 14306: train_loss=505.98563, val_loss=520.86127\n",
      "Epoch 14307: train_loss=505.97726, val_loss=520.77606\n",
      "Epoch 14308: train_loss=505.95505, val_loss=520.80499\n",
      "Epoch 14309: train_loss=505.92184, val_loss=520.71112\n",
      "Epoch 14310: train_loss=505.88171, val_loss=520.71552\n",
      "Epoch 14311: train_loss=505.84082, val_loss=520.64606\n",
      "Epoch 14312: train_loss=505.80420, val_loss=520.63806\n",
      "Epoch 14313: train_loss=505.77438, val_loss=520.60876\n",
      "Epoch 14314: train_loss=505.75247, val_loss=520.59180\n",
      "Epoch 14315: train_loss=505.73706, val_loss=520.59546\n",
      "Epoch 14316: train_loss=505.72629, val_loss=520.56549\n",
      "Epoch 14317: train_loss=505.71802, val_loss=520.58563\n",
      "Epoch 14318: train_loss=505.70981, val_loss=520.54028\n",
      "Epoch 14319: train_loss=505.69989, val_loss=520.56354\n",
      "Epoch 14320: train_loss=505.68741, val_loss=520.50842\n",
      "Epoch 14321: train_loss=505.67145, val_loss=520.52832\n",
      "Epoch 14322: train_loss=505.65271, val_loss=520.47107\n",
      "Epoch 14323: train_loss=505.63156, val_loss=520.48193\n",
      "Epoch 14324: train_loss=505.60919, val_loss=520.42902\n",
      "Epoch 14325: train_loss=505.58655, val_loss=520.43243\n",
      "Epoch 14326: train_loss=505.56375, val_loss=520.38959\n",
      "Epoch 14327: train_loss=505.54178, val_loss=520.38617\n",
      "Epoch 14328: train_loss=505.52072, val_loss=520.35516\n",
      "Epoch 14329: train_loss=505.50082, val_loss=520.34326\n",
      "Epoch 14330: train_loss=505.48199, val_loss=520.32269\n",
      "Epoch 14331: train_loss=505.46448, val_loss=520.30438\n",
      "Epoch 14332: train_loss=505.44778, val_loss=520.29352\n",
      "Epoch 14333: train_loss=505.43176, val_loss=520.26990\n",
      "Epoch 14334: train_loss=505.41611, val_loss=520.26471\n",
      "Epoch 14335: train_loss=505.40079, val_loss=520.23615\n",
      "Epoch 14336: train_loss=505.38580, val_loss=520.23730\n",
      "Epoch 14337: train_loss=505.37076, val_loss=520.20563\n",
      "Epoch 14338: train_loss=505.35562, val_loss=520.21130\n",
      "Epoch 14339: train_loss=505.34055, val_loss=520.17535\n",
      "Epoch 14340: train_loss=505.32544, val_loss=520.18378\n",
      "Epoch 14341: train_loss=505.31012, val_loss=520.14630\n",
      "Epoch 14342: train_loss=505.29483, val_loss=520.15820\n",
      "Epoch 14343: train_loss=505.27982, val_loss=520.11749\n",
      "Epoch 14344: train_loss=505.26459, val_loss=520.12994\n",
      "Epoch 14345: train_loss=505.24969, val_loss=520.08630\n",
      "Epoch 14346: train_loss=505.23505, val_loss=520.10284\n",
      "Epoch 14347: train_loss=505.22083, val_loss=520.05762\n",
      "Epoch 14348: train_loss=505.20636, val_loss=520.07751\n",
      "Epoch 14349: train_loss=505.19202, val_loss=520.02948\n",
      "Epoch 14350: train_loss=505.17783, val_loss=520.05115\n",
      "Epoch 14351: train_loss=505.16400, val_loss=520.00024\n",
      "Epoch 14352: train_loss=505.15039, val_loss=520.02606\n",
      "Epoch 14353: train_loss=505.13708, val_loss=519.97437\n",
      "Epoch 14354: train_loss=505.12439, val_loss=520.00629\n",
      "Epoch 14355: train_loss=505.11246, val_loss=519.95166\n",
      "Epoch 14356: train_loss=505.10104, val_loss=519.98798\n",
      "Epoch 14357: train_loss=505.09073, val_loss=519.92981\n",
      "Epoch 14358: train_loss=505.08038, val_loss=519.97192\n",
      "Epoch 14359: train_loss=505.07034, val_loss=519.90936\n",
      "Epoch 14360: train_loss=505.05975, val_loss=519.95331\n",
      "Epoch 14361: train_loss=505.04785, val_loss=519.88446\n",
      "Epoch 14362: train_loss=505.03467, val_loss=519.92621\n",
      "Epoch 14363: train_loss=505.01938, val_loss=519.85303\n",
      "Epoch 14364: train_loss=505.00272, val_loss=519.89178\n",
      "Epoch 14365: train_loss=504.98367, val_loss=519.81573\n",
      "Epoch 14366: train_loss=504.96265, val_loss=519.84711\n",
      "Epoch 14367: train_loss=504.93881, val_loss=519.76978\n",
      "Epoch 14368: train_loss=504.91348, val_loss=519.79187\n",
      "Epoch 14369: train_loss=504.88614, val_loss=519.71716\n",
      "Epoch 14370: train_loss=504.85782, val_loss=519.73004\n",
      "Epoch 14371: train_loss=504.82910, val_loss=519.66461\n",
      "Epoch 14372: train_loss=504.80103, val_loss=519.67059\n",
      "Epoch 14373: train_loss=504.77383, val_loss=519.61780\n",
      "Epoch 14374: train_loss=504.74805, val_loss=519.61694\n",
      "Epoch 14375: train_loss=504.72409, val_loss=519.57794\n",
      "Epoch 14376: train_loss=504.70175, val_loss=519.57080\n",
      "Epoch 14377: train_loss=504.68097, val_loss=519.54370\n",
      "Epoch 14378: train_loss=504.66150, val_loss=519.53033\n",
      "Epoch 14379: train_loss=504.64310, val_loss=519.51245\n",
      "Epoch 14380: train_loss=504.62561, val_loss=519.49335\n",
      "Epoch 14381: train_loss=504.60880, val_loss=519.48285\n",
      "Epoch 14382: train_loss=504.59259, val_loss=519.45917\n",
      "Epoch 14383: train_loss=504.57684, val_loss=519.45526\n",
      "Epoch 14384: train_loss=504.56149, val_loss=519.42712\n",
      "Epoch 14385: train_loss=504.54688, val_loss=519.43158\n",
      "Epoch 14386: train_loss=504.53302, val_loss=519.39917\n",
      "Epoch 14387: train_loss=504.52060, val_loss=519.41357\n",
      "Epoch 14388: train_loss=504.50967, val_loss=519.37579\n",
      "Epoch 14389: train_loss=504.50070, val_loss=519.40155\n",
      "Epoch 14390: train_loss=504.49344, val_loss=519.35944\n",
      "Epoch 14391: train_loss=504.48962, val_loss=519.40234\n",
      "Epoch 14392: train_loss=504.48853, val_loss=519.35626\n",
      "Epoch 14393: train_loss=504.49161, val_loss=519.42078\n",
      "Epoch 14394: train_loss=504.49899, val_loss=519.37091\n",
      "Epoch 14395: train_loss=504.51129, val_loss=519.45728\n",
      "Epoch 14396: train_loss=504.52759, val_loss=519.39746\n",
      "Epoch 14397: train_loss=504.54477, val_loss=519.49817\n",
      "Epoch 14398: train_loss=504.56226, val_loss=519.41876\n",
      "Epoch 14399: train_loss=504.57153, val_loss=519.51318\n",
      "Epoch 14400: train_loss=504.57309, val_loss=519.40094\n",
      "Epoch 14401: train_loss=504.55463, val_loss=519.45886\n",
      "Epoch 14402: train_loss=504.52051, val_loss=519.31396\n",
      "Epoch 14403: train_loss=504.46457, val_loss=519.32526\n",
      "Epoch 14404: train_loss=504.39804, val_loss=519.17938\n",
      "Epoch 14405: train_loss=504.32278, val_loss=519.16095\n",
      "Epoch 14406: train_loss=504.25143, val_loss=519.05975\n",
      "Epoch 14407: train_loss=504.19186, val_loss=519.03912\n",
      "Epoch 14408: train_loss=504.14880, val_loss=519.00446\n",
      "Epoch 14409: train_loss=504.12378, val_loss=518.98395\n",
      "Epoch 14410: train_loss=504.11313, val_loss=519.00183\n",
      "Epoch 14411: train_loss=504.11151, val_loss=518.97083\n",
      "Epoch 14412: train_loss=504.11331, val_loss=519.00958\n",
      "Epoch 14413: train_loss=504.11389, val_loss=518.95776\n",
      "Epoch 14414: train_loss=504.10864, val_loss=518.99335\n",
      "Epoch 14415: train_loss=504.09686, val_loss=518.92303\n",
      "Epoch 14416: train_loss=504.07620, val_loss=518.94409\n",
      "Epoch 14417: train_loss=504.04990, val_loss=518.86768\n",
      "Epoch 14418: train_loss=504.01874, val_loss=518.87311\n",
      "Epoch 14419: train_loss=503.98633, val_loss=518.80646\n",
      "Epoch 14420: train_loss=503.95447, val_loss=518.79993\n",
      "Epoch 14421: train_loss=503.92499, val_loss=518.75409\n",
      "Epoch 14422: train_loss=503.89908, val_loss=518.74030\n",
      "Epoch 14423: train_loss=503.87708, val_loss=518.72052\n",
      "Epoch 14424: train_loss=503.85886, val_loss=518.69971\n",
      "Epoch 14425: train_loss=503.84323, val_loss=518.69745\n",
      "Epoch 14426: train_loss=503.82925, val_loss=518.66583\n",
      "Epoch 14427: train_loss=503.81619, val_loss=518.67249\n",
      "Epoch 14428: train_loss=503.80289, val_loss=518.63281\n",
      "Epoch 14429: train_loss=503.78891, val_loss=518.64520\n",
      "Epoch 14430: train_loss=503.77429, val_loss=518.59979\n",
      "Epoch 14431: train_loss=503.75858, val_loss=518.61163\n",
      "Epoch 14432: train_loss=503.74213, val_loss=518.56219\n",
      "Epoch 14433: train_loss=503.72482, val_loss=518.57367\n",
      "Epoch 14434: train_loss=503.70715, val_loss=518.52441\n",
      "Epoch 14435: train_loss=503.68896, val_loss=518.53491\n",
      "Epoch 14436: train_loss=503.67059, val_loss=518.48492\n",
      "Epoch 14437: train_loss=503.65164, val_loss=518.49219\n",
      "Epoch 14438: train_loss=503.63290, val_loss=518.44299\n",
      "Epoch 14439: train_loss=503.61377, val_loss=518.45007\n",
      "Epoch 14440: train_loss=503.59476, val_loss=518.40564\n",
      "Epoch 14441: train_loss=503.57553, val_loss=518.41119\n",
      "Epoch 14442: train_loss=503.55667, val_loss=518.36798\n",
      "Epoch 14443: train_loss=503.53766, val_loss=518.37018\n",
      "Epoch 14444: train_loss=503.51907, val_loss=518.32770\n",
      "Epoch 14445: train_loss=503.50037, val_loss=518.32886\n",
      "Epoch 14446: train_loss=503.48199, val_loss=518.28949\n",
      "Epoch 14447: train_loss=503.46384, val_loss=518.29047\n",
      "Epoch 14448: train_loss=503.44620, val_loss=518.25153\n",
      "Epoch 14449: train_loss=503.42862, val_loss=518.25342\n",
      "Epoch 14450: train_loss=503.41162, val_loss=518.21497\n",
      "Epoch 14451: train_loss=503.39478, val_loss=518.22009\n",
      "Epoch 14452: train_loss=503.37851, val_loss=518.17993\n",
      "Epoch 14453: train_loss=503.36252, val_loss=518.18750\n",
      "Epoch 14454: train_loss=503.34702, val_loss=518.14423\n",
      "Epoch 14455: train_loss=503.33286, val_loss=518.16064\n",
      "Epoch 14456: train_loss=503.32016, val_loss=518.11737\n",
      "Epoch 14457: train_loss=503.30923, val_loss=518.14740\n",
      "Epoch 14458: train_loss=503.30084, val_loss=518.09943\n",
      "Epoch 14459: train_loss=503.29474, val_loss=518.14539\n",
      "Epoch 14460: train_loss=503.29294, val_loss=518.09192\n",
      "Epoch 14461: train_loss=503.29465, val_loss=518.16095\n",
      "Epoch 14462: train_loss=503.30255, val_loss=518.10406\n",
      "Epoch 14463: train_loss=503.31433, val_loss=518.20135\n",
      "Epoch 14464: train_loss=503.33267, val_loss=518.13556\n",
      "Epoch 14465: train_loss=503.35193, val_loss=518.25262\n",
      "Epoch 14466: train_loss=503.37433, val_loss=518.16687\n",
      "Epoch 14467: train_loss=503.38913, val_loss=518.28223\n",
      "Epoch 14468: train_loss=503.39792, val_loss=518.16187\n",
      "Epoch 14469: train_loss=503.38571, val_loss=518.24023\n",
      "Epoch 14470: train_loss=503.35654, val_loss=518.07886\n",
      "Epoch 14471: train_loss=503.30045, val_loss=518.10022\n",
      "Epoch 14472: train_loss=503.22949, val_loss=517.93378\n",
      "Epoch 14473: train_loss=503.14801, val_loss=517.92236\n",
      "Epoch 14474: train_loss=503.07147, val_loss=517.80469\n",
      "Epoch 14475: train_loss=503.00473, val_loss=517.78595\n",
      "Epoch 14476: train_loss=502.95587, val_loss=517.74231\n",
      "Epoch 14477: train_loss=502.92609, val_loss=517.72339\n",
      "Epoch 14478: train_loss=502.91293, val_loss=517.74182\n",
      "Epoch 14479: train_loss=502.91119, val_loss=517.71259\n",
      "Epoch 14480: train_loss=502.91434, val_loss=517.75983\n",
      "Epoch 14481: train_loss=502.91733, val_loss=517.70685\n",
      "Epoch 14482: train_loss=502.91379, val_loss=517.75012\n",
      "Epoch 14483: train_loss=502.90250, val_loss=517.67444\n",
      "Epoch 14484: train_loss=502.88107, val_loss=517.69946\n",
      "Epoch 14485: train_loss=502.85361, val_loss=517.61932\n",
      "Epoch 14486: train_loss=502.82031, val_loss=517.62659\n",
      "Epoch 14487: train_loss=502.78668, val_loss=517.56091\n",
      "Epoch 14488: train_loss=502.75427, val_loss=517.55634\n",
      "Epoch 14489: train_loss=502.72562, val_loss=517.51331\n",
      "Epoch 14490: train_loss=502.70068, val_loss=517.50055\n",
      "Epoch 14491: train_loss=502.67935, val_loss=517.48041\n",
      "Epoch 14492: train_loss=502.66092, val_loss=517.46075\n",
      "Epoch 14493: train_loss=502.64456, val_loss=517.45728\n",
      "Epoch 14494: train_loss=502.62979, val_loss=517.42865\n",
      "Epoch 14495: train_loss=502.61621, val_loss=517.43561\n",
      "Epoch 14496: train_loss=502.60324, val_loss=517.39905\n",
      "Epoch 14497: train_loss=502.59128, val_loss=517.41675\n",
      "Epoch 14498: train_loss=502.57986, val_loss=517.37445\n",
      "Epoch 14499: train_loss=502.56870, val_loss=517.40112\n",
      "Epoch 14500: train_loss=502.55795, val_loss=517.35114\n",
      "Epoch 14501: train_loss=502.54669, val_loss=517.38275\n",
      "Epoch 14502: train_loss=502.53543, val_loss=517.32562\n",
      "Epoch 14503: train_loss=502.52319, val_loss=517.36127\n",
      "Epoch 14504: train_loss=502.51053, val_loss=517.29895\n",
      "Epoch 14505: train_loss=502.49628, val_loss=517.33435\n",
      "Epoch 14506: train_loss=502.48129, val_loss=517.26672\n",
      "Epoch 14507: train_loss=502.46417, val_loss=517.29968\n",
      "Epoch 14508: train_loss=502.44647, val_loss=517.23029\n",
      "Epoch 14509: train_loss=502.42667, val_loss=517.25928\n",
      "Epoch 14510: train_loss=502.40628, val_loss=517.18927\n",
      "Epoch 14511: train_loss=502.38403, val_loss=517.21198\n",
      "Epoch 14512: train_loss=502.36163, val_loss=517.14423\n",
      "Epoch 14513: train_loss=502.33823, val_loss=517.16150\n",
      "Epoch 14514: train_loss=502.31467, val_loss=517.09888\n",
      "Epoch 14515: train_loss=502.29086, val_loss=517.11121\n",
      "Epoch 14516: train_loss=502.26788, val_loss=517.05585\n",
      "Epoch 14517: train_loss=502.24493, val_loss=517.06329\n",
      "Epoch 14518: train_loss=502.22305, val_loss=517.01520\n",
      "Epoch 14519: train_loss=502.20181, val_loss=517.02026\n",
      "Epoch 14520: train_loss=502.18173, val_loss=516.97754\n",
      "Epoch 14521: train_loss=502.16232, val_loss=516.98181\n",
      "Epoch 14522: train_loss=502.14374, val_loss=516.94147\n",
      "Epoch 14523: train_loss=502.12527, val_loss=516.94568\n",
      "Epoch 14524: train_loss=502.10739, val_loss=516.90723\n",
      "Epoch 14525: train_loss=502.08990, val_loss=516.91284\n",
      "Epoch 14526: train_loss=502.07291, val_loss=516.87402\n",
      "Epoch 14527: train_loss=502.05634, val_loss=516.88184\n",
      "Epoch 14528: train_loss=502.04028, val_loss=516.84143\n",
      "Epoch 14529: train_loss=502.02487, val_loss=516.85559\n",
      "Epoch 14530: train_loss=502.01093, val_loss=516.81238\n",
      "Epoch 14531: train_loss=501.99780, val_loss=516.83490\n",
      "Epoch 14532: train_loss=501.98645, val_loss=516.78760\n",
      "Epoch 14533: train_loss=501.97678, val_loss=516.82141\n",
      "Epoch 14534: train_loss=501.96942, val_loss=516.76941\n",
      "Epoch 14535: train_loss=501.96411, val_loss=516.81830\n",
      "Epoch 14536: train_loss=501.96167, val_loss=516.75995\n",
      "Epoch 14537: train_loss=501.96082, val_loss=516.82410\n",
      "Epoch 14538: train_loss=501.96259, val_loss=516.75714\n",
      "Epoch 14539: train_loss=501.96405, val_loss=516.83380\n",
      "Epoch 14540: train_loss=501.96732, val_loss=516.75458\n",
      "Epoch 14541: train_loss=501.96652, val_loss=516.83490\n",
      "Epoch 14542: train_loss=501.96472, val_loss=516.73962\n",
      "Epoch 14543: train_loss=501.95483, val_loss=516.80963\n",
      "Epoch 14544: train_loss=501.93994, val_loss=516.69592\n",
      "Epoch 14545: train_loss=501.91232, val_loss=516.74384\n",
      "Epoch 14546: train_loss=501.87872, val_loss=516.62311\n",
      "Epoch 14547: train_loss=501.83566, val_loss=516.64783\n",
      "Epoch 14548: train_loss=501.78958, val_loss=516.53467\n",
      "Epoch 14549: train_loss=501.73984, val_loss=516.53925\n",
      "Epoch 14550: train_loss=501.69290, val_loss=516.45264\n",
      "Epoch 14551: train_loss=501.64966, val_loss=516.44611\n",
      "Epoch 14552: train_loss=501.61282, val_loss=516.39465\n",
      "Epoch 14553: train_loss=501.58264, val_loss=516.38123\n",
      "Epoch 14554: train_loss=501.55905, val_loss=516.35938\n",
      "Epoch 14555: train_loss=501.54007, val_loss=516.33813\n",
      "Epoch 14556: train_loss=501.52454, val_loss=516.33899\n",
      "Epoch 14557: train_loss=501.51147, val_loss=516.31030\n",
      "Epoch 14558: train_loss=501.50015, val_loss=516.32721\n",
      "Epoch 14559: train_loss=501.49048, val_loss=516.28815\n",
      "Epoch 14560: train_loss=501.48126, val_loss=516.31555\n",
      "Epoch 14561: train_loss=501.47263, val_loss=516.26691\n",
      "Epoch 14562: train_loss=501.46313, val_loss=516.30225\n",
      "Epoch 14563: train_loss=501.45337, val_loss=516.24518\n",
      "Epoch 14564: train_loss=501.44147, val_loss=516.28278\n",
      "Epoch 14565: train_loss=501.42899, val_loss=516.21802\n",
      "Epoch 14566: train_loss=501.41409, val_loss=516.25488\n",
      "Epoch 14567: train_loss=501.39877, val_loss=516.18549\n",
      "Epoch 14568: train_loss=501.38110, val_loss=516.22021\n",
      "Epoch 14569: train_loss=501.36310, val_loss=516.14850\n",
      "Epoch 14570: train_loss=501.34296, val_loss=516.18042\n",
      "Epoch 14571: train_loss=501.32281, val_loss=516.10834\n",
      "Epoch 14572: train_loss=501.30020, val_loss=516.13611\n",
      "Epoch 14573: train_loss=501.27847, val_loss=516.06567\n",
      "Epoch 14574: train_loss=501.25446, val_loss=516.08551\n",
      "Epoch 14575: train_loss=501.23019, val_loss=516.01813\n",
      "Epoch 14576: train_loss=501.20483, val_loss=516.03168\n",
      "Epoch 14577: train_loss=501.18018, val_loss=515.97211\n",
      "Epoch 14578: train_loss=501.15540, val_loss=515.98016\n",
      "Epoch 14579: train_loss=501.13135, val_loss=515.92883\n",
      "Epoch 14580: train_loss=501.10767, val_loss=515.93115\n",
      "Epoch 14581: train_loss=501.08508, val_loss=515.88770\n",
      "Epoch 14582: train_loss=501.06393, val_loss=515.88763\n",
      "Epoch 14583: train_loss=501.04346, val_loss=515.85022\n",
      "Epoch 14584: train_loss=501.02374, val_loss=515.84894\n",
      "Epoch 14585: train_loss=501.00491, val_loss=515.81445\n",
      "Epoch 14586: train_loss=500.98663, val_loss=515.81378\n",
      "Epoch 14587: train_loss=500.96887, val_loss=515.77942\n",
      "Epoch 14588: train_loss=500.95175, val_loss=515.78320\n",
      "Epoch 14589: train_loss=500.93530, val_loss=515.74829\n",
      "Epoch 14590: train_loss=500.91983, val_loss=515.75916\n",
      "Epoch 14591: train_loss=500.90543, val_loss=515.72070\n",
      "Epoch 14592: train_loss=500.89285, val_loss=515.74139\n",
      "Epoch 14593: train_loss=500.88248, val_loss=515.69855\n",
      "Epoch 14594: train_loss=500.87457, val_loss=515.73669\n",
      "Epoch 14595: train_loss=500.87018, val_loss=515.68909\n",
      "Epoch 14596: train_loss=500.86893, val_loss=515.74750\n",
      "Epoch 14597: train_loss=500.87167, val_loss=515.69342\n",
      "Epoch 14598: train_loss=500.87775, val_loss=515.77325\n",
      "Epoch 14599: train_loss=500.88797, val_loss=515.70898\n",
      "Epoch 14600: train_loss=500.89847, val_loss=515.80499\n",
      "Epoch 14601: train_loss=500.91129, val_loss=515.72260\n",
      "Epoch 14602: train_loss=500.91733, val_loss=515.81848\n",
      "Epoch 14603: train_loss=500.91953, val_loss=515.71063\n",
      "Epoch 14604: train_loss=500.90680, val_loss=515.78491\n",
      "Epoch 14605: train_loss=500.88422, val_loss=515.65179\n",
      "Epoch 14606: train_loss=500.84329, val_loss=515.68866\n",
      "Epoch 14607: train_loss=500.79272, val_loss=515.54724\n",
      "Epoch 14608: train_loss=500.73071, val_loss=515.55194\n",
      "Epoch 14609: train_loss=500.66788, val_loss=515.43634\n",
      "Epoch 14610: train_loss=500.60812, val_loss=515.42657\n",
      "Epoch 14611: train_loss=500.55704, val_loss=515.35962\n",
      "Epoch 14612: train_loss=500.51752, val_loss=515.34528\n",
      "Epoch 14613: train_loss=500.48911, val_loss=515.32587\n",
      "Epoch 14614: train_loss=500.47037, val_loss=515.30304\n",
      "Epoch 14615: train_loss=500.45871, val_loss=515.31720\n",
      "Epoch 14616: train_loss=500.45212, val_loss=515.28271\n",
      "Epoch 14617: train_loss=500.44855, val_loss=515.31830\n",
      "Epoch 14618: train_loss=500.44513, val_loss=515.26971\n",
      "Epoch 14619: train_loss=500.44022, val_loss=515.31201\n",
      "Epoch 14620: train_loss=500.43185, val_loss=515.24854\n",
      "Epoch 14621: train_loss=500.41895, val_loss=515.28485\n",
      "Epoch 14622: train_loss=500.40112, val_loss=515.21155\n",
      "Epoch 14623: train_loss=500.37881, val_loss=515.23663\n",
      "Epoch 14624: train_loss=500.35309, val_loss=515.16235\n",
      "Epoch 14625: train_loss=500.32535, val_loss=515.17627\n",
      "Epoch 14626: train_loss=500.29633, val_loss=515.11053\n",
      "Epoch 14627: train_loss=500.26855, val_loss=515.11749\n",
      "Epoch 14628: train_loss=500.24112, val_loss=515.06458\n",
      "Epoch 14629: train_loss=500.21558, val_loss=515.06543\n",
      "Epoch 14630: train_loss=500.19122, val_loss=515.02411\n",
      "Epoch 14631: train_loss=500.16855, val_loss=515.01862\n",
      "Epoch 14632: train_loss=500.14722, val_loss=514.98468\n",
      "Epoch 14633: train_loss=500.12674, val_loss=514.97333\n",
      "Epoch 14634: train_loss=500.10706, val_loss=514.94708\n",
      "Epoch 14635: train_loss=500.08783, val_loss=514.93347\n",
      "Epoch 14636: train_loss=500.06906, val_loss=514.91364\n",
      "Epoch 14637: train_loss=500.05060, val_loss=514.89825\n",
      "Epoch 14638: train_loss=500.03210, val_loss=514.88086\n",
      "Epoch 14639: train_loss=500.01389, val_loss=514.86261\n",
      "Epoch 14640: train_loss=499.99573, val_loss=514.84662\n",
      "Epoch 14641: train_loss=499.97760, val_loss=514.82550\n",
      "Epoch 14642: train_loss=499.95963, val_loss=514.81219\n",
      "Epoch 14643: train_loss=499.94174, val_loss=514.78821\n",
      "Epoch 14644: train_loss=499.92416, val_loss=514.78003\n",
      "Epoch 14645: train_loss=499.90686, val_loss=514.75293\n",
      "Epoch 14646: train_loss=499.89032, val_loss=514.75214\n",
      "Epoch 14647: train_loss=499.87488, val_loss=514.72156\n",
      "Epoch 14648: train_loss=499.86096, val_loss=514.73383\n",
      "Epoch 14649: train_loss=499.84906, val_loss=514.69812\n",
      "Epoch 14650: train_loss=499.83963, val_loss=514.72699\n",
      "Epoch 14651: train_loss=499.83356, val_loss=514.68469\n",
      "Epoch 14652: train_loss=499.83093, val_loss=514.73505\n",
      "Epoch 14653: train_loss=499.83221, val_loss=514.68665\n",
      "Epoch 14654: train_loss=499.83768, val_loss=514.76178\n",
      "Epoch 14655: train_loss=499.84784, val_loss=514.70483\n",
      "Epoch 14656: train_loss=499.86172, val_loss=514.80359\n",
      "Epoch 14657: train_loss=499.88025, val_loss=514.73175\n",
      "Epoch 14658: train_loss=499.89606, val_loss=514.84106\n",
      "Epoch 14659: train_loss=499.91086, val_loss=514.74304\n",
      "Epoch 14660: train_loss=499.91171, val_loss=514.83588\n",
      "Epoch 14661: train_loss=499.90228, val_loss=514.70184\n",
      "Epoch 14662: train_loss=499.86914, val_loss=514.75024\n",
      "Epoch 14663: train_loss=499.82083, val_loss=514.59412\n",
      "Epoch 14664: train_loss=499.75467, val_loss=514.60022\n",
      "Epoch 14665: train_loss=499.68292, val_loss=514.46234\n",
      "Epoch 14666: train_loss=499.61072, val_loss=514.44775\n",
      "Epoch 14667: train_loss=499.54797, val_loss=514.36615\n",
      "Epoch 14668: train_loss=499.49942, val_loss=514.34900\n",
      "Epoch 14669: train_loss=499.46716, val_loss=514.32983\n",
      "Epoch 14670: train_loss=499.44855, val_loss=514.30865\n",
      "Epoch 14671: train_loss=499.44000, val_loss=514.33240\n",
      "Epoch 14672: train_loss=499.43744, val_loss=514.29657\n",
      "Epoch 14673: train_loss=499.43637, val_loss=514.33685\n",
      "Epoch 14674: train_loss=499.43329, val_loss=514.28064\n",
      "Epoch 14675: train_loss=499.42487, val_loss=514.31677\n",
      "Epoch 14676: train_loss=499.41010, val_loss=514.24530\n",
      "Epoch 14677: train_loss=499.38843, val_loss=514.26727\n",
      "Epoch 14678: train_loss=499.36151, val_loss=514.19397\n",
      "Epoch 14679: train_loss=499.33127, val_loss=514.20184\n",
      "Epoch 14680: train_loss=499.29996, val_loss=514.13971\n",
      "Epoch 14681: train_loss=499.26956, val_loss=514.13757\n",
      "Epoch 14682: train_loss=499.24133, val_loss=514.09412\n",
      "Epoch 14683: train_loss=499.21600, val_loss=514.08405\n",
      "Epoch 14684: train_loss=499.19336, val_loss=514.05841\n",
      "Epoch 14685: train_loss=499.17307, val_loss=514.04034\n",
      "Epoch 14686: train_loss=499.15454, val_loss=514.02783\n",
      "Epoch 14687: train_loss=499.13751, val_loss=514.00250\n",
      "Epoch 14688: train_loss=499.12140, val_loss=514.00110\n",
      "Epoch 14689: train_loss=499.10620, val_loss=513.96954\n",
      "Epoch 14690: train_loss=499.09177, val_loss=513.97797\n",
      "Epoch 14691: train_loss=499.07800, val_loss=513.94019\n",
      "Epoch 14692: train_loss=499.06500, val_loss=513.95728\n",
      "Epoch 14693: train_loss=499.05283, val_loss=513.91327\n",
      "Epoch 14694: train_loss=499.04147, val_loss=513.93829\n",
      "Epoch 14695: train_loss=499.03055, val_loss=513.88727\n",
      "Epoch 14696: train_loss=499.01901, val_loss=513.91931\n",
      "Epoch 14697: train_loss=499.00806, val_loss=513.86237\n",
      "Epoch 14698: train_loss=498.99554, val_loss=513.89703\n",
      "Epoch 14699: train_loss=498.98285, val_loss=513.83374\n",
      "Epoch 14700: train_loss=498.96838, val_loss=513.86786\n",
      "Epoch 14701: train_loss=498.95328, val_loss=513.79962\n",
      "Epoch 14702: train_loss=498.93588, val_loss=513.83313\n",
      "Epoch 14703: train_loss=498.91855, val_loss=513.76251\n",
      "Epoch 14704: train_loss=498.89847, val_loss=513.79205\n",
      "Epoch 14705: train_loss=498.87772, val_loss=513.71960\n",
      "Epoch 14706: train_loss=498.85400, val_loss=513.74103\n",
      "Epoch 14707: train_loss=498.82895, val_loss=513.67096\n",
      "Epoch 14708: train_loss=498.80219, val_loss=513.68433\n",
      "Epoch 14709: train_loss=498.77509, val_loss=513.62122\n",
      "Epoch 14710: train_loss=498.74762, val_loss=513.62665\n",
      "Epoch 14711: train_loss=498.72107, val_loss=513.57391\n",
      "Epoch 14712: train_loss=498.69531, val_loss=513.57117\n",
      "Epoch 14713: train_loss=498.67065, val_loss=513.53021\n",
      "Epoch 14714: train_loss=498.64752, val_loss=513.52069\n",
      "Epoch 14715: train_loss=498.62567, val_loss=513.49115\n",
      "Epoch 14716: train_loss=498.60535, val_loss=513.47742\n",
      "Epoch 14717: train_loss=498.58578, val_loss=513.45703\n",
      "Epoch 14718: train_loss=498.56686, val_loss=513.43921\n",
      "Epoch 14719: train_loss=498.54858, val_loss=513.42426\n",
      "Epoch 14720: train_loss=498.53043, val_loss=513.40179\n",
      "Epoch 14721: train_loss=498.51254, val_loss=513.39111\n",
      "Epoch 14722: train_loss=498.49506, val_loss=513.36542\n",
      "Epoch 14723: train_loss=498.47803, val_loss=513.36163\n",
      "Epoch 14724: train_loss=498.46140, val_loss=513.33173\n",
      "Epoch 14725: train_loss=498.44601, val_loss=513.33685\n",
      "Epoch 14726: train_loss=498.43201, val_loss=513.30206\n",
      "Epoch 14727: train_loss=498.42014, val_loss=513.32147\n",
      "Epoch 14728: train_loss=498.41086, val_loss=513.28113\n",
      "Epoch 14729: train_loss=498.40439, val_loss=513.31970\n",
      "Epoch 14730: train_loss=498.40234, val_loss=513.27332\n",
      "Epoch 14731: train_loss=498.40417, val_loss=513.33514\n",
      "Epoch 14732: train_loss=498.41129, val_loss=513.28180\n",
      "Epoch 14733: train_loss=498.42191, val_loss=513.37097\n",
      "Epoch 14734: train_loss=498.43893, val_loss=513.31104\n",
      "Epoch 14735: train_loss=498.45728, val_loss=513.42316\n",
      "Epoch 14736: train_loss=498.47958, val_loss=513.34698\n",
      "Epoch 14737: train_loss=498.49600, val_loss=513.46100\n",
      "Epoch 14738: train_loss=498.50809, val_loss=513.35144\n",
      "Epoch 14739: train_loss=498.50101, val_loss=513.43701\n",
      "Epoch 14740: train_loss=498.48102, val_loss=513.28815\n",
      "Epoch 14741: train_loss=498.43338, val_loss=513.32123\n",
      "Epoch 14742: train_loss=498.37100, val_loss=513.15741\n",
      "Epoch 14743: train_loss=498.29266, val_loss=513.14893\n",
      "Epoch 14744: train_loss=498.21231, val_loss=513.01672\n",
      "Epoch 14745: train_loss=498.13657, val_loss=512.99493\n",
      "Epoch 14746: train_loss=498.07611, val_loss=512.93414\n",
      "Epoch 14747: train_loss=498.03549, val_loss=512.91632\n",
      "Epoch 14748: train_loss=498.01416, val_loss=512.92462\n",
      "Epoch 14749: train_loss=498.00772, val_loss=512.90131\n",
      "Epoch 14750: train_loss=498.00977, val_loss=512.94458\n",
      "Epoch 14751: train_loss=498.01321, val_loss=512.89813\n",
      "Epoch 14752: train_loss=498.01187, val_loss=512.94037\n",
      "Epoch 14753: train_loss=498.00256, val_loss=512.86981\n",
      "Epoch 14754: train_loss=497.98367, val_loss=512.89478\n",
      "Epoch 14755: train_loss=497.95657, val_loss=512.81635\n",
      "Epoch 14756: train_loss=497.92371, val_loss=512.82355\n",
      "Epoch 14757: train_loss=497.88870, val_loss=512.75641\n",
      "Epoch 14758: train_loss=497.85431, val_loss=512.75134\n",
      "Epoch 14759: train_loss=497.82324, val_loss=512.70758\n",
      "Epoch 14760: train_loss=497.79620, val_loss=512.69421\n",
      "Epoch 14761: train_loss=497.77344, val_loss=512.67468\n",
      "Epoch 14762: train_loss=497.75446, val_loss=512.65338\n",
      "Epoch 14763: train_loss=497.73840, val_loss=512.65308\n",
      "Epoch 14764: train_loss=497.72443, val_loss=512.62390\n",
      "Epoch 14765: train_loss=497.71146, val_loss=512.63483\n",
      "Epoch 14766: train_loss=497.69870, val_loss=512.59723\n",
      "Epoch 14767: train_loss=497.68555, val_loss=512.61426\n",
      "Epoch 14768: train_loss=497.67203, val_loss=512.56982\n",
      "Epoch 14769: train_loss=497.65720, val_loss=512.58850\n",
      "Epoch 14770: train_loss=497.64169, val_loss=512.53815\n",
      "Epoch 14771: train_loss=497.62482, val_loss=512.55573\n",
      "Epoch 14772: train_loss=497.60739, val_loss=512.50189\n",
      "Epoch 14773: train_loss=497.58871, val_loss=512.51849\n",
      "Epoch 14774: train_loss=497.56998, val_loss=512.46509\n",
      "Epoch 14775: train_loss=497.55008, val_loss=512.47998\n",
      "Epoch 14776: train_loss=497.53009, val_loss=512.42712\n",
      "Epoch 14777: train_loss=497.50919, val_loss=512.43774\n",
      "Epoch 14778: train_loss=497.48813, val_loss=512.38684\n",
      "Epoch 14779: train_loss=497.46686, val_loss=512.39429\n",
      "Epoch 14780: train_loss=497.44568, val_loss=512.34735\n",
      "Epoch 14781: train_loss=497.42459, val_loss=512.35193\n",
      "Epoch 14782: train_loss=497.40375, val_loss=512.30811\n",
      "Epoch 14783: train_loss=497.38312, val_loss=512.30908\n",
      "Epoch 14784: train_loss=497.36285, val_loss=512.26752\n",
      "Epoch 14785: train_loss=497.34302, val_loss=512.26617\n",
      "Epoch 14786: train_loss=497.32294, val_loss=512.22833\n",
      "Epoch 14787: train_loss=497.30325, val_loss=512.22681\n",
      "Epoch 14788: train_loss=497.28366, val_loss=512.19189\n",
      "Epoch 14789: train_loss=497.26462, val_loss=512.18964\n",
      "Epoch 14790: train_loss=497.24567, val_loss=512.15576\n",
      "Epoch 14791: train_loss=497.22711, val_loss=512.15399\n",
      "Epoch 14792: train_loss=497.20923, val_loss=512.12006\n",
      "Epoch 14793: train_loss=497.19189, val_loss=512.12103\n",
      "Epoch 14794: train_loss=497.17520, val_loss=512.08575\n",
      "Epoch 14795: train_loss=497.15930, val_loss=512.09296\n",
      "Epoch 14796: train_loss=497.14465, val_loss=512.05536\n",
      "Epoch 14797: train_loss=497.13147, val_loss=512.07245\n",
      "Epoch 14798: train_loss=497.11996, val_loss=512.03137\n",
      "Epoch 14799: train_loss=497.11139, val_loss=512.06238\n",
      "Epoch 14800: train_loss=497.10574, val_loss=512.01740\n",
      "Epoch 14801: train_loss=497.10385, val_loss=512.06683\n",
      "Epoch 14802: train_loss=497.10547, val_loss=512.01752\n",
      "Epoch 14803: train_loss=497.11063, val_loss=512.08850\n",
      "Epoch 14804: train_loss=497.11972, val_loss=512.03168\n",
      "Epoch 14805: train_loss=497.12982, val_loss=512.12103\n",
      "Epoch 14806: train_loss=497.14398, val_loss=512.05151\n",
      "Epoch 14807: train_loss=497.15424, val_loss=512.14807\n",
      "Epoch 14808: train_loss=497.16382, val_loss=512.05688\n",
      "Epoch 14809: train_loss=497.16080, val_loss=512.13672\n",
      "Epoch 14810: train_loss=497.14874, val_loss=512.01440\n",
      "Epoch 14811: train_loss=497.11597, val_loss=512.05457\n",
      "Epoch 14812: train_loss=497.07016, val_loss=511.91113\n",
      "Epoch 14813: train_loss=497.00626, val_loss=511.90903\n",
      "Epoch 14814: train_loss=496.93594, val_loss=511.78018\n",
      "Epoch 14815: train_loss=496.86435, val_loss=511.75937\n",
      "Epoch 14816: train_loss=496.80276, val_loss=511.68204\n",
      "Epoch 14817: train_loss=496.75446, val_loss=511.66150\n",
      "Epoch 14818: train_loss=496.72198, val_loss=511.64307\n",
      "Epoch 14819: train_loss=496.70383, val_loss=511.62323\n",
      "Epoch 14820: train_loss=496.69601, val_loss=511.64392\n",
      "Epoch 14821: train_loss=496.69363, val_loss=511.61227\n",
      "Epoch 14822: train_loss=496.69211, val_loss=511.64621\n",
      "Epoch 14823: train_loss=496.68866, val_loss=511.59616\n",
      "Epoch 14824: train_loss=496.67999, val_loss=511.62497\n",
      "Epoch 14825: train_loss=496.66504, val_loss=511.55988\n",
      "Epoch 14826: train_loss=496.64359, val_loss=511.57458\n",
      "Epoch 14827: train_loss=496.61615, val_loss=511.50623\n",
      "Epoch 14828: train_loss=496.58551, val_loss=511.50797\n",
      "Epoch 14829: train_loss=496.55377, val_loss=511.44995\n",
      "Epoch 14830: train_loss=496.52231, val_loss=511.44244\n",
      "Epoch 14831: train_loss=496.49368, val_loss=511.40219\n",
      "Epoch 14832: train_loss=496.46805, val_loss=511.38770\n",
      "Epoch 14833: train_loss=496.44577, val_loss=511.36566\n",
      "Epoch 14834: train_loss=496.42630, val_loss=511.34573\n",
      "Epoch 14835: train_loss=496.40909, val_loss=511.33823\n",
      "Epoch 14836: train_loss=496.39346, val_loss=511.31207\n",
      "Epoch 14837: train_loss=496.37854, val_loss=511.31357\n",
      "Epoch 14838: train_loss=496.36401, val_loss=511.28085\n",
      "Epoch 14839: train_loss=496.34949, val_loss=511.28683\n",
      "Epoch 14840: train_loss=496.33469, val_loss=511.24817\n",
      "Epoch 14841: train_loss=496.31982, val_loss=511.25656\n",
      "Epoch 14842: train_loss=496.30460, val_loss=511.21350\n",
      "Epoch 14843: train_loss=496.28891, val_loss=511.22440\n",
      "Epoch 14844: train_loss=496.27286, val_loss=511.17883\n",
      "Epoch 14845: train_loss=496.25601, val_loss=511.19034\n",
      "Epoch 14846: train_loss=496.23874, val_loss=511.14282\n",
      "Epoch 14847: train_loss=496.22067, val_loss=511.15436\n",
      "Epoch 14848: train_loss=496.20248, val_loss=511.10660\n",
      "Epoch 14849: train_loss=496.18356, val_loss=511.11874\n",
      "Epoch 14850: train_loss=496.16510, val_loss=511.07169\n",
      "Epoch 14851: train_loss=496.14560, val_loss=511.08282\n",
      "Epoch 14852: train_loss=496.12714, val_loss=511.03546\n",
      "Epoch 14853: train_loss=496.10800, val_loss=511.04510\n",
      "Epoch 14854: train_loss=496.08969, val_loss=510.99750\n",
      "Epoch 14855: train_loss=496.07089, val_loss=511.00809\n",
      "Epoch 14856: train_loss=496.05307, val_loss=510.96146\n",
      "Epoch 14857: train_loss=496.03473, val_loss=510.97263\n",
      "Epoch 14858: train_loss=496.01730, val_loss=510.92651\n",
      "Epoch 14859: train_loss=495.99973, val_loss=510.94006\n",
      "Epoch 14860: train_loss=495.98279, val_loss=510.89392\n",
      "Epoch 14861: train_loss=495.96594, val_loss=510.90997\n",
      "Epoch 14862: train_loss=495.94989, val_loss=510.86240\n",
      "Epoch 14863: train_loss=495.93411, val_loss=510.87985\n",
      "Epoch 14864: train_loss=495.91873, val_loss=510.83072\n",
      "Epoch 14865: train_loss=495.90359, val_loss=510.85193\n",
      "Epoch 14866: train_loss=495.88916, val_loss=510.80267\n",
      "Epoch 14867: train_loss=495.87576, val_loss=510.82980\n",
      "Epoch 14868: train_loss=495.86331, val_loss=510.77863\n",
      "Epoch 14869: train_loss=495.85168, val_loss=510.81015\n",
      "Epoch 14870: train_loss=495.84030, val_loss=510.75522\n",
      "Epoch 14871: train_loss=495.82898, val_loss=510.78940\n",
      "Epoch 14872: train_loss=495.81674, val_loss=510.73001\n",
      "Epoch 14873: train_loss=495.80377, val_loss=510.76514\n",
      "Epoch 14874: train_loss=495.78976, val_loss=510.70047\n",
      "Epoch 14875: train_loss=495.77380, val_loss=510.73364\n",
      "Epoch 14876: train_loss=495.75638, val_loss=510.66415\n",
      "Epoch 14877: train_loss=495.73657, val_loss=510.69083\n",
      "Epoch 14878: train_loss=495.71429, val_loss=510.61768\n",
      "Epoch 14879: train_loss=495.68942, val_loss=510.63467\n",
      "Epoch 14880: train_loss=495.66135, val_loss=510.56299\n",
      "Epoch 14881: train_loss=495.63190, val_loss=510.57101\n",
      "Epoch 14882: train_loss=495.60077, val_loss=510.50537\n",
      "Epoch 14883: train_loss=495.56921, val_loss=510.50574\n",
      "Epoch 14884: train_loss=495.53860, val_loss=510.45090\n",
      "Epoch 14885: train_loss=495.50903, val_loss=510.44409\n",
      "Epoch 14886: train_loss=495.48178, val_loss=510.40329\n",
      "Epoch 14887: train_loss=495.45700, val_loss=510.39133\n",
      "Epoch 14888: train_loss=495.43420, val_loss=510.36328\n",
      "Epoch 14889: train_loss=495.41333, val_loss=510.34714\n",
      "Epoch 14890: train_loss=495.39401, val_loss=510.32938\n",
      "Epoch 14891: train_loss=495.37555, val_loss=510.30893\n",
      "Epoch 14892: train_loss=495.35788, val_loss=510.29855\n",
      "Epoch 14893: train_loss=495.34082, val_loss=510.27426\n",
      "Epoch 14894: train_loss=495.32455, val_loss=510.27066\n",
      "Epoch 14895: train_loss=495.30905, val_loss=510.24219\n",
      "Epoch 14896: train_loss=495.29434, val_loss=510.24606\n",
      "Epoch 14897: train_loss=495.28094, val_loss=510.21271\n",
      "Epoch 14898: train_loss=495.26862, val_loss=510.22589\n",
      "Epoch 14899: train_loss=495.25836, val_loss=510.18997\n",
      "Epoch 14900: train_loss=495.24957, val_loss=510.21521\n",
      "Epoch 14901: train_loss=495.24326, val_loss=510.17575\n",
      "Epoch 14902: train_loss=495.23917, val_loss=510.21414\n",
      "Epoch 14903: train_loss=495.23804, val_loss=510.17169\n",
      "Epoch 14904: train_loss=495.24014, val_loss=510.22705\n",
      "Epoch 14905: train_loss=495.24625, val_loss=510.18088\n",
      "Epoch 14906: train_loss=495.25534, val_loss=510.25238\n",
      "Epoch 14907: train_loss=495.26648, val_loss=510.19678\n",
      "Epoch 14908: train_loss=495.27615, val_loss=510.27625\n",
      "Epoch 14909: train_loss=495.28476, val_loss=510.20227\n",
      "Epoch 14910: train_loss=495.28372, val_loss=510.26901\n",
      "Epoch 14911: train_loss=495.27423, val_loss=510.16617\n",
      "Epoch 14912: train_loss=495.24738, val_loss=510.19843\n",
      "Epoch 14913: train_loss=495.20676, val_loss=510.07294\n",
      "Epoch 14914: train_loss=495.15012, val_loss=510.06879\n",
      "Epoch 14915: train_loss=495.08539, val_loss=509.94824\n",
      "Epoch 14916: train_loss=495.01776, val_loss=509.92490\n",
      "Epoch 14917: train_loss=494.95511, val_loss=509.84177\n",
      "Epoch 14918: train_loss=494.90250, val_loss=509.81946\n",
      "Epoch 14919: train_loss=494.86423, val_loss=509.78903\n",
      "Epoch 14920: train_loss=494.83954, val_loss=509.77106\n",
      "Epoch 14921: train_loss=494.82559, val_loss=509.77985\n",
      "Epoch 14922: train_loss=494.81912, val_loss=509.75589\n",
      "Epoch 14923: train_loss=494.81677, val_loss=509.78220\n",
      "Epoch 14924: train_loss=494.81470, val_loss=509.74313\n",
      "Epoch 14925: train_loss=494.80917, val_loss=509.77036\n",
      "Epoch 14926: train_loss=494.79919, val_loss=509.71521\n",
      "Epoch 14927: train_loss=494.78314, val_loss=509.73318\n",
      "Epoch 14928: train_loss=494.76227, val_loss=509.66852\n",
      "Epoch 14929: train_loss=494.73633, val_loss=509.67474\n",
      "Epoch 14930: train_loss=494.70758, val_loss=509.61191\n",
      "Epoch 14931: train_loss=494.67661, val_loss=509.60977\n",
      "Epoch 14932: train_loss=494.64609, val_loss=509.55750\n",
      "Epoch 14933: train_loss=494.61661, val_loss=509.54846\n",
      "Epoch 14934: train_loss=494.58966, val_loss=509.51144\n",
      "Epoch 14935: train_loss=494.56506, val_loss=509.49744\n",
      "Epoch 14936: train_loss=494.54324, val_loss=509.47565\n",
      "Epoch 14937: train_loss=494.52344, val_loss=509.45740\n",
      "Epoch 14938: train_loss=494.50516, val_loss=509.44620\n",
      "Epoch 14939: train_loss=494.48798, val_loss=509.42346\n",
      "Epoch 14940: train_loss=494.47180, val_loss=509.41965\n",
      "Epoch 14941: train_loss=494.45630, val_loss=509.39169\n",
      "Epoch 14942: train_loss=494.44128, val_loss=509.39380\n",
      "Epoch 14943: train_loss=494.42670, val_loss=509.36038\n",
      "Epoch 14944: train_loss=494.41202, val_loss=509.36566\n",
      "Epoch 14945: train_loss=494.39743, val_loss=509.32721\n",
      "Epoch 14946: train_loss=494.38251, val_loss=509.33624\n",
      "Epoch 14947: train_loss=494.36786, val_loss=509.29553\n",
      "Epoch 14948: train_loss=494.35294, val_loss=509.30917\n",
      "Epoch 14949: train_loss=494.33887, val_loss=509.26627\n",
      "Epoch 14950: train_loss=494.32413, val_loss=509.28265\n",
      "Epoch 14951: train_loss=494.31064, val_loss=509.23663\n",
      "Epoch 14952: train_loss=494.29657, val_loss=509.25522\n",
      "Epoch 14953: train_loss=494.28284, val_loss=509.20676\n",
      "Epoch 14954: train_loss=494.26810, val_loss=509.22870\n",
      "Epoch 14955: train_loss=494.25421, val_loss=509.17831\n",
      "Epoch 14956: train_loss=494.23892, val_loss=509.20044\n",
      "Epoch 14957: train_loss=494.22382, val_loss=509.14719\n",
      "Epoch 14958: train_loss=494.20718, val_loss=509.16785\n",
      "Epoch 14959: train_loss=494.18979, val_loss=509.11145\n",
      "Epoch 14960: train_loss=494.17090, val_loss=509.12866\n",
      "Epoch 14961: train_loss=494.15051, val_loss=509.06949\n",
      "Epoch 14962: train_loss=494.12833, val_loss=509.08136\n",
      "Epoch 14963: train_loss=494.10489, val_loss=509.02200\n",
      "Epoch 14964: train_loss=494.07986, val_loss=509.02957\n",
      "Epoch 14965: train_loss=494.05472, val_loss=508.97452\n",
      "Epoch 14966: train_loss=494.02872, val_loss=508.97794\n",
      "Epoch 14967: train_loss=494.00385, val_loss=508.92697\n",
      "Epoch 14968: train_loss=493.97897, val_loss=508.92520\n",
      "Epoch 14969: train_loss=493.95465, val_loss=508.87921\n",
      "Epoch 14970: train_loss=493.93054, val_loss=508.87506\n",
      "Epoch 14971: train_loss=493.90741, val_loss=508.83542\n",
      "Epoch 14972: train_loss=493.88495, val_loss=508.82913\n",
      "Epoch 14973: train_loss=493.86334, val_loss=508.79364\n",
      "Epoch 14974: train_loss=493.84229, val_loss=508.78604\n",
      "Epoch 14975: train_loss=493.82181, val_loss=508.75595\n",
      "Epoch 14976: train_loss=493.80203, val_loss=508.74963\n",
      "Epoch 14977: train_loss=493.78305, val_loss=508.72025\n",
      "Epoch 14978: train_loss=493.76413, val_loss=508.71262\n",
      "Epoch 14979: train_loss=493.74579, val_loss=508.68219\n",
      "Epoch 14980: train_loss=493.72769, val_loss=508.67697\n",
      "Epoch 14981: train_loss=493.71002, val_loss=508.64856\n",
      "Epoch 14982: train_loss=493.69287, val_loss=508.64789\n",
      "Epoch 14983: train_loss=493.67654, val_loss=508.61844\n",
      "Epoch 14984: train_loss=493.66132, val_loss=508.62274\n",
      "Epoch 14985: train_loss=493.64774, val_loss=508.59161\n",
      "Epoch 14986: train_loss=493.63620, val_loss=508.60651\n",
      "Epoch 14987: train_loss=493.62717, val_loss=508.57623\n",
      "Epoch 14988: train_loss=493.62146, val_loss=508.60635\n",
      "Epoch 14989: train_loss=493.61951, val_loss=508.57544\n",
      "Epoch 14990: train_loss=493.62231, val_loss=508.62064\n",
      "Epoch 14991: train_loss=493.62878, val_loss=508.58682\n",
      "Epoch 14992: train_loss=493.63922, val_loss=508.65097\n",
      "Epoch 14993: train_loss=493.65399, val_loss=508.61505\n",
      "Epoch 14994: train_loss=493.67032, val_loss=508.69046\n",
      "Epoch 14995: train_loss=493.68655, val_loss=508.63654\n",
      "Epoch 14996: train_loss=493.69424, val_loss=508.70126\n",
      "Epoch 14997: train_loss=493.69431, val_loss=508.61642\n",
      "Epoch 14998: train_loss=493.67444, val_loss=508.64520\n",
      "Epoch 14999: train_loss=493.63831, val_loss=508.52652\n",
      "Epoch 15000: train_loss=493.58041, val_loss=508.50958\n",
      "Epoch 15001: train_loss=493.51022, val_loss=508.38361\n",
      "Epoch 15002: train_loss=493.43372, val_loss=508.34650\n",
      "Epoch 15003: train_loss=493.36151, val_loss=508.25864\n",
      "Epoch 15004: train_loss=493.30066, val_loss=508.23172\n",
      "Epoch 15005: train_loss=493.25720, val_loss=508.20148\n",
      "Epoch 15006: train_loss=493.23114, val_loss=508.18475\n",
      "Epoch 15007: train_loss=493.21896, val_loss=508.19388\n",
      "Epoch 15008: train_loss=493.21555, val_loss=508.17490\n",
      "Epoch 15009: train_loss=493.21591, val_loss=508.20032\n",
      "Epoch 15010: train_loss=493.21552, val_loss=508.16824\n",
      "Epoch 15011: train_loss=493.21075, val_loss=508.18930\n",
      "Epoch 15012: train_loss=493.19949, val_loss=508.13879\n",
      "Epoch 15013: train_loss=493.18091, val_loss=508.14581\n",
      "Epoch 15014: train_loss=493.15622, val_loss=508.08646\n",
      "Epoch 15015: train_loss=493.12592, val_loss=508.08154\n",
      "Epoch 15016: train_loss=493.09351, val_loss=508.02643\n",
      "Epoch 15017: train_loss=493.06018, val_loss=508.01413\n",
      "Epoch 15018: train_loss=493.02835, val_loss=507.96933\n",
      "Epoch 15019: train_loss=492.99878, val_loss=507.95264\n",
      "Epoch 15020: train_loss=492.97269, val_loss=507.92236\n",
      "Epoch 15021: train_loss=492.94955, val_loss=507.90359\n",
      "Epoch 15022: train_loss=492.92953, val_loss=507.88736\n",
      "Epoch 15023: train_loss=492.91156, val_loss=507.86597\n",
      "Epoch 15024: train_loss=492.89511, val_loss=507.85873\n",
      "Epoch 15025: train_loss=492.87991, val_loss=507.83408\n",
      "Epoch 15026: train_loss=492.86569, val_loss=507.83395\n",
      "Epoch 15027: train_loss=492.85236, val_loss=507.80658\n",
      "Epoch 15028: train_loss=492.83939, val_loss=507.81219\n",
      "Epoch 15029: train_loss=492.82657, val_loss=507.78195\n",
      "Epoch 15030: train_loss=492.81384, val_loss=507.79138\n",
      "Epoch 15031: train_loss=492.80112, val_loss=507.75705\n",
      "Epoch 15032: train_loss=492.78809, val_loss=507.76855\n",
      "Epoch 15033: train_loss=492.77512, val_loss=507.72980\n",
      "Epoch 15034: train_loss=492.76083, val_loss=507.74252\n",
      "Epoch 15035: train_loss=492.74677, val_loss=507.69977\n",
      "Epoch 15036: train_loss=492.73035, val_loss=507.71021\n",
      "Epoch 15037: train_loss=492.71426, val_loss=507.66364\n",
      "Epoch 15038: train_loss=492.69540, val_loss=507.67105\n",
      "Epoch 15039: train_loss=492.67630, val_loss=507.62158\n",
      "Epoch 15040: train_loss=492.65442, val_loss=507.62534\n",
      "Epoch 15041: train_loss=492.63193, val_loss=507.57425\n",
      "Epoch 15042: train_loss=492.60721, val_loss=507.57214\n",
      "Epoch 15043: train_loss=492.58231, val_loss=507.52258\n",
      "Epoch 15044: train_loss=492.55646, val_loss=507.51669\n",
      "Epoch 15045: train_loss=492.53061, val_loss=507.47198\n",
      "Epoch 15046: train_loss=492.50473, val_loss=507.46393\n",
      "Epoch 15047: train_loss=492.47943, val_loss=507.42422\n",
      "Epoch 15048: train_loss=492.45453, val_loss=507.41299\n",
      "Epoch 15049: train_loss=492.43069, val_loss=507.37851\n",
      "Epoch 15050: train_loss=492.40762, val_loss=507.36493\n",
      "Epoch 15051: train_loss=492.38531, val_loss=507.33624\n",
      "Epoch 15052: train_loss=492.36389, val_loss=507.32007\n",
      "Epoch 15053: train_loss=492.34296, val_loss=507.29333\n",
      "Epoch 15054: train_loss=492.32281, val_loss=507.27341\n",
      "Epoch 15055: train_loss=492.30280, val_loss=507.24930\n",
      "Epoch 15056: train_loss=492.28293, val_loss=507.22925\n",
      "Epoch 15057: train_loss=492.26352, val_loss=507.20862\n",
      "Epoch 15058: train_loss=492.24408, val_loss=507.18680\n",
      "Epoch 15059: train_loss=492.22458, val_loss=507.16635\n",
      "Epoch 15060: train_loss=492.20532, val_loss=507.14301\n",
      "Epoch 15061: train_loss=492.18613, val_loss=507.12494\n",
      "Epoch 15062: train_loss=492.16708, val_loss=507.10172\n",
      "Epoch 15063: train_loss=492.14795, val_loss=507.08597\n",
      "Epoch 15064: train_loss=492.12921, val_loss=507.06079\n",
      "Epoch 15065: train_loss=492.11053, val_loss=507.04715\n",
      "Epoch 15066: train_loss=492.09238, val_loss=507.02213\n",
      "Epoch 15067: train_loss=492.07449, val_loss=507.01379\n",
      "Epoch 15068: train_loss=492.05737, val_loss=506.98822\n",
      "Epoch 15069: train_loss=492.04123, val_loss=506.98486\n",
      "Epoch 15070: train_loss=492.02658, val_loss=506.95758\n",
      "Epoch 15071: train_loss=492.01355, val_loss=506.96283\n",
      "Epoch 15072: train_loss=492.00323, val_loss=506.93713\n",
      "Epoch 15073: train_loss=491.99643, val_loss=506.95758\n",
      "Epoch 15074: train_loss=491.99429, val_loss=506.93558\n",
      "Epoch 15075: train_loss=491.99817, val_loss=506.97757\n",
      "Epoch 15076: train_loss=492.00928, val_loss=506.96149\n",
      "Epoch 15077: train_loss=492.02823, val_loss=507.03256\n",
      "Epoch 15078: train_loss=492.05652, val_loss=507.02380\n",
      "Epoch 15079: train_loss=492.09210, val_loss=507.12399\n",
      "Epoch 15080: train_loss=492.13736, val_loss=507.10809\n",
      "Epoch 15081: train_loss=492.17773, val_loss=507.20895\n",
      "Epoch 15082: train_loss=492.21417, val_loss=507.14822\n",
      "Epoch 15083: train_loss=492.21729, val_loss=507.19058\n",
      "Epoch 15084: train_loss=492.19193, val_loss=507.04929\n",
      "Epoch 15085: train_loss=492.11383, val_loss=507.00015\n",
      "Epoch 15086: train_loss=492.00690, val_loss=506.82132\n",
      "Epoch 15087: train_loss=491.87827, val_loss=506.73679\n",
      "Epoch 15088: train_loss=491.75934, val_loss=506.62234\n",
      "Epoch 15089: train_loss=491.67023, val_loss=506.58295\n",
      "Epoch 15090: train_loss=491.62241, val_loss=506.57419\n",
      "Epoch 15091: train_loss=491.61121, val_loss=506.57260\n",
      "Epoch 15092: train_loss=491.62430, val_loss=506.61789\n",
      "Epoch 15093: train_loss=491.64621, val_loss=506.60150\n",
      "Epoch 15094: train_loss=491.66019, val_loss=506.63293\n",
      "Epoch 15095: train_loss=491.65732, val_loss=506.57489\n",
      "Epoch 15096: train_loss=491.63290, val_loss=506.56674\n",
      "Epoch 15097: train_loss=491.59091, val_loss=506.48505\n",
      "Epoch 15098: train_loss=491.53793, val_loss=506.45435\n",
      "Epoch 15099: train_loss=491.48514, val_loss=506.39401\n",
      "Epoch 15100: train_loss=491.44028, val_loss=506.36996\n",
      "Epoch 15101: train_loss=491.40836, val_loss=506.35260\n",
      "Epoch 15102: train_loss=491.38962, val_loss=506.33670\n",
      "Epoch 15103: train_loss=491.38034, val_loss=506.34512\n",
      "Epoch 15104: train_loss=491.37494, val_loss=506.32132\n",
      "Epoch 15105: train_loss=491.36868, val_loss=506.33264\n",
      "Epoch 15106: train_loss=491.35855, val_loss=506.29486\n",
      "Epoch 15107: train_loss=491.34189, val_loss=506.29587\n",
      "Epoch 15108: train_loss=491.31909, val_loss=506.24863\n",
      "Epoch 15109: train_loss=491.29160, val_loss=506.23660\n",
      "Epoch 15110: train_loss=491.26175, val_loss=506.18970\n",
      "Epoch 15111: train_loss=491.23102, val_loss=506.17102\n",
      "Epoch 15112: train_loss=491.20203, val_loss=506.13803\n",
      "Epoch 15113: train_loss=491.17596, val_loss=506.11942\n",
      "Epoch 15114: train_loss=491.15329, val_loss=506.10132\n",
      "Epoch 15115: train_loss=491.13412, val_loss=506.08102\n",
      "Epoch 15116: train_loss=491.11710, val_loss=506.07159\n",
      "Epoch 15117: train_loss=491.10141, val_loss=506.04770\n",
      "Epoch 15118: train_loss=491.08606, val_loss=506.04251\n",
      "Epoch 15119: train_loss=491.07034, val_loss=506.01392\n",
      "Epoch 15120: train_loss=491.05350, val_loss=506.00903\n",
      "Epoch 15121: train_loss=491.03564, val_loss=505.97687\n",
      "Epoch 15122: train_loss=491.01642, val_loss=505.96902\n",
      "Epoch 15123: train_loss=490.99643, val_loss=505.93420\n",
      "Epoch 15124: train_loss=490.97546, val_loss=505.92297\n",
      "Epoch 15125: train_loss=490.95395, val_loss=505.88901\n",
      "Epoch 15126: train_loss=490.93216, val_loss=505.87695\n",
      "Epoch 15127: train_loss=490.91003, val_loss=505.84558\n",
      "Epoch 15128: train_loss=490.88779, val_loss=505.83224\n",
      "Epoch 15129: train_loss=490.86560, val_loss=505.80286\n",
      "Epoch 15130: train_loss=490.84360, val_loss=505.78720\n",
      "Epoch 15131: train_loss=490.82193, val_loss=505.76013\n",
      "Epoch 15132: train_loss=490.80054, val_loss=505.74268\n",
      "Epoch 15133: train_loss=490.77960, val_loss=505.71851\n",
      "Epoch 15134: train_loss=490.75882, val_loss=505.69955\n",
      "Epoch 15135: train_loss=490.73846, val_loss=505.67773\n",
      "Epoch 15136: train_loss=490.71829, val_loss=505.65820\n",
      "Epoch 15137: train_loss=490.69821, val_loss=505.63901\n",
      "Epoch 15138: train_loss=490.67819, val_loss=505.61914\n",
      "Epoch 15139: train_loss=490.65820, val_loss=505.60132\n",
      "Epoch 15140: train_loss=490.63834, val_loss=505.58005\n",
      "Epoch 15141: train_loss=490.61862, val_loss=505.56262\n",
      "Epoch 15142: train_loss=490.59894, val_loss=505.54001\n",
      "Epoch 15143: train_loss=490.57962, val_loss=505.52478\n",
      "Epoch 15144: train_loss=490.56076, val_loss=505.50070\n",
      "Epoch 15145: train_loss=490.54221, val_loss=505.48871\n",
      "Epoch 15146: train_loss=490.52432, val_loss=505.46408\n",
      "Epoch 15147: train_loss=490.50729, val_loss=505.45779\n",
      "Epoch 15148: train_loss=490.49152, val_loss=505.43311\n",
      "Epoch 15149: train_loss=490.47757, val_loss=505.43506\n",
      "Epoch 15150: train_loss=490.46530, val_loss=505.41098\n",
      "Epoch 15151: train_loss=490.45630, val_loss=505.42383\n",
      "Epoch 15152: train_loss=490.44962, val_loss=505.40079\n",
      "Epoch 15153: train_loss=490.44754, val_loss=505.42886\n",
      "Epoch 15154: train_loss=490.44940, val_loss=505.40796\n",
      "Epoch 15155: train_loss=490.45499, val_loss=505.45340\n",
      "Epoch 15156: train_loss=490.46619, val_loss=505.43121\n",
      "Epoch 15157: train_loss=490.47821, val_loss=505.48596\n",
      "Epoch 15158: train_loss=490.49323, val_loss=505.45334\n",
      "Epoch 15159: train_loss=490.50272, val_loss=505.50220\n",
      "Epoch 15160: train_loss=490.50739, val_loss=505.44373\n",
      "Epoch 15161: train_loss=490.49448, val_loss=505.46399\n",
      "Epoch 15162: train_loss=490.46921, val_loss=505.36972\n",
      "Epoch 15163: train_loss=490.41986, val_loss=505.34891\n",
      "Epoch 15164: train_loss=490.35989, val_loss=505.23560\n",
      "Epoch 15165: train_loss=490.28522, val_loss=505.18970\n",
      "Epoch 15166: train_loss=490.21155, val_loss=505.09607\n",
      "Epoch 15167: train_loss=490.14346, val_loss=505.05560\n",
      "Epoch 15168: train_loss=490.08932, val_loss=505.00809\n",
      "Epoch 15169: train_loss=490.05136, val_loss=504.98676\n",
      "Epoch 15170: train_loss=490.02881, val_loss=504.98291\n",
      "Epoch 15171: train_loss=490.01846, val_loss=504.96964\n",
      "Epoch 15172: train_loss=490.01437, val_loss=504.98462\n",
      "Epoch 15173: train_loss=490.01193, val_loss=504.96173\n",
      "Epoch 15174: train_loss=490.00610, val_loss=504.97302\n",
      "Epoch 15175: train_loss=489.99396, val_loss=504.93350\n",
      "Epoch 15176: train_loss=489.97473, val_loss=504.93137\n",
      "Epoch 15177: train_loss=489.94901, val_loss=504.87936\n",
      "Epoch 15178: train_loss=489.91745, val_loss=504.86362\n",
      "Epoch 15179: train_loss=489.88293, val_loss=504.81277\n",
      "Epoch 15180: train_loss=489.84857, val_loss=504.79224\n",
      "Epoch 15181: train_loss=489.81592, val_loss=504.75293\n",
      "Epoch 15182: train_loss=489.78635, val_loss=504.73166\n",
      "Epoch 15183: train_loss=489.76059, val_loss=504.70859\n",
      "Epoch 15184: train_loss=489.73880, val_loss=504.68805\n",
      "Epoch 15185: train_loss=489.71970, val_loss=504.67624\n",
      "Epoch 15186: train_loss=489.70248, val_loss=504.65359\n",
      "Epoch 15187: train_loss=489.68631, val_loss=504.64801\n",
      "Epoch 15188: train_loss=489.67032, val_loss=504.62119\n",
      "Epoch 15189: train_loss=489.65359, val_loss=504.61664\n",
      "Epoch 15190: train_loss=489.63596, val_loss=504.58646\n",
      "Epoch 15191: train_loss=489.61703, val_loss=504.58157\n",
      "Epoch 15192: train_loss=489.59744, val_loss=504.54886\n",
      "Epoch 15193: train_loss=489.57651, val_loss=504.54126\n",
      "Epoch 15194: train_loss=489.55475, val_loss=504.50665\n",
      "Epoch 15195: train_loss=489.53210, val_loss=504.49612\n",
      "Epoch 15196: train_loss=489.50888, val_loss=504.46133\n",
      "Epoch 15197: train_loss=489.48523, val_loss=504.44839\n",
      "Epoch 15198: train_loss=489.46124, val_loss=504.41599\n",
      "Epoch 15199: train_loss=489.43735, val_loss=504.40247\n",
      "Epoch 15200: train_loss=489.41360, val_loss=504.37296\n",
      "Epoch 15201: train_loss=489.39001, val_loss=504.35754\n",
      "Epoch 15202: train_loss=489.36685, val_loss=504.32950\n",
      "Epoch 15203: train_loss=489.34427, val_loss=504.31146\n",
      "Epoch 15204: train_loss=489.32162, val_loss=504.28549\n",
      "Epoch 15205: train_loss=489.29953, val_loss=504.26688\n",
      "Epoch 15206: train_loss=489.27744, val_loss=504.24323\n",
      "Epoch 15207: train_loss=489.25577, val_loss=504.22354\n",
      "Epoch 15208: train_loss=489.23401, val_loss=504.19952\n",
      "Epoch 15209: train_loss=489.21246, val_loss=504.17874\n",
      "Epoch 15210: train_loss=489.19086, val_loss=504.15604\n",
      "Epoch 15211: train_loss=489.16931, val_loss=504.13544\n",
      "Epoch 15212: train_loss=489.14780, val_loss=504.11356\n",
      "Epoch 15213: train_loss=489.12619, val_loss=504.09317\n",
      "Epoch 15214: train_loss=489.10471, val_loss=504.07074\n",
      "Epoch 15215: train_loss=489.08328, val_loss=504.05136\n",
      "Epoch 15216: train_loss=489.06177, val_loss=504.02902\n",
      "Epoch 15217: train_loss=489.04034, val_loss=504.01138\n",
      "Epoch 15218: train_loss=489.01920, val_loss=503.98871\n",
      "Epoch 15219: train_loss=488.99826, val_loss=503.97287\n",
      "Epoch 15220: train_loss=488.97803, val_loss=503.94952\n",
      "Epoch 15221: train_loss=488.95862, val_loss=503.93930\n",
      "Epoch 15222: train_loss=488.94037, val_loss=503.91632\n",
      "Epoch 15223: train_loss=488.92398, val_loss=503.91382\n",
      "Epoch 15224: train_loss=488.90997, val_loss=503.89175\n",
      "Epoch 15225: train_loss=488.89975, val_loss=503.90234\n",
      "Epoch 15226: train_loss=488.89447, val_loss=503.88736\n",
      "Epoch 15227: train_loss=488.89749, val_loss=503.92557\n",
      "Epoch 15228: train_loss=488.91147, val_loss=503.92639\n",
      "Epoch 15229: train_loss=488.93875, val_loss=504.00540\n",
      "Epoch 15230: train_loss=488.98395, val_loss=504.02518\n",
      "Epoch 15231: train_loss=489.04071, val_loss=504.14243\n",
      "Epoch 15232: train_loss=489.11279, val_loss=504.16171\n",
      "Epoch 15233: train_loss=489.17755, val_loss=504.27640\n",
      "Epoch 15234: train_loss=489.23560, val_loss=504.23184\n",
      "Epoch 15235: train_loss=489.24429, val_loss=504.24768\n",
      "Epoch 15236: train_loss=489.20355, val_loss=504.07523\n",
      "Epoch 15237: train_loss=489.08420, val_loss=503.96024\n",
      "Epoch 15238: train_loss=488.92404, val_loss=503.74506\n",
      "Epoch 15239: train_loss=488.74564, val_loss=503.62711\n",
      "Epoch 15240: train_loss=488.60397, val_loss=503.53302\n",
      "Epoch 15241: train_loss=488.52258, val_loss=503.51208\n",
      "Epoch 15242: train_loss=488.50339, val_loss=503.54852\n",
      "Epoch 15243: train_loss=488.52890, val_loss=503.57059\n",
      "Epoch 15244: train_loss=488.57031, val_loss=503.62964\n",
      "Epoch 15245: train_loss=488.60254, val_loss=503.60046\n",
      "Epoch 15246: train_loss=488.60187, val_loss=503.59506\n",
      "Epoch 15247: train_loss=488.56738, val_loss=503.50113\n",
      "Epoch 15248: train_loss=488.50058, val_loss=503.44675\n",
      "Epoch 15249: train_loss=488.42438, val_loss=503.36108\n",
      "Epoch 15250: train_loss=488.35370, val_loss=503.31937\n",
      "Epoch 15251: train_loss=488.30386, val_loss=503.29160\n",
      "Epoch 15252: train_loss=488.27823, val_loss=503.27859\n",
      "Epoch 15253: train_loss=488.27142, val_loss=503.29114\n",
      "Epoch 15254: train_loss=488.27338, val_loss=503.27725\n",
      "Epoch 15255: train_loss=488.27277, val_loss=503.28494\n",
      "Epoch 15256: train_loss=488.26196, val_loss=503.24384\n",
      "Epoch 15257: train_loss=488.23694, val_loss=503.22528\n",
      "Epoch 15258: train_loss=488.20160, val_loss=503.17056\n",
      "Epoch 15259: train_loss=488.16046, val_loss=503.14188\n",
      "Epoch 15260: train_loss=488.12064, val_loss=503.10117\n",
      "Epoch 15261: train_loss=488.08588, val_loss=503.07748\n",
      "Epoch 15262: train_loss=488.05832, val_loss=503.05750\n",
      "Epoch 15263: train_loss=488.03760, val_loss=503.03687\n",
      "Epoch 15264: train_loss=488.02179, val_loss=503.02948\n",
      "Epoch 15265: train_loss=488.00793, val_loss=503.00769\n",
      "Epoch 15266: train_loss=487.99341, val_loss=503.00314\n",
      "Epoch 15267: train_loss=487.97668, val_loss=502.97372\n",
      "Epoch 15268: train_loss=487.95621, val_loss=502.96252\n",
      "Epoch 15269: train_loss=487.93304, val_loss=502.92651\n",
      "Epoch 15270: train_loss=487.90695, val_loss=502.90915\n",
      "Epoch 15271: train_loss=487.87958, val_loss=502.87405\n",
      "Epoch 15272: train_loss=487.85110, val_loss=502.85358\n",
      "Epoch 15273: train_loss=487.82336, val_loss=502.82159\n",
      "Epoch 15274: train_loss=487.79688, val_loss=502.79733\n",
      "Epoch 15275: train_loss=487.77209, val_loss=502.77148\n",
      "Epoch 15276: train_loss=487.74887, val_loss=502.74973\n",
      "Epoch 15277: train_loss=487.72675, val_loss=502.73199\n",
      "Epoch 15278: train_loss=487.70563, val_loss=502.71060\n",
      "Epoch 15279: train_loss=487.68521, val_loss=502.69510\n",
      "Epoch 15280: train_loss=487.66513, val_loss=502.66965\n",
      "Epoch 15281: train_loss=487.64505, val_loss=502.65460\n",
      "Epoch 15282: train_loss=487.62466, val_loss=502.62778\n",
      "Epoch 15283: train_loss=487.60376, val_loss=502.61380\n",
      "Epoch 15284: train_loss=487.58273, val_loss=502.58527\n",
      "Epoch 15285: train_loss=487.56140, val_loss=502.57068\n",
      "Epoch 15286: train_loss=487.53989, val_loss=502.54062\n",
      "Epoch 15287: train_loss=487.51764, val_loss=502.52713\n",
      "Epoch 15288: train_loss=487.49518, val_loss=502.49927\n",
      "Epoch 15289: train_loss=487.47235, val_loss=502.48557\n",
      "Epoch 15290: train_loss=487.44928, val_loss=502.45569\n",
      "Epoch 15291: train_loss=487.42584, val_loss=502.43887\n",
      "Epoch 15292: train_loss=487.40231, val_loss=502.40768\n",
      "Epoch 15293: train_loss=487.37872, val_loss=502.38974\n",
      "Epoch 15294: train_loss=487.35480, val_loss=502.35977\n",
      "Epoch 15295: train_loss=487.33167, val_loss=502.34158\n",
      "Epoch 15296: train_loss=487.30832, val_loss=502.31287\n",
      "Epoch 15297: train_loss=487.28543, val_loss=502.29633\n",
      "Epoch 15298: train_loss=487.26260, val_loss=502.26880\n",
      "Epoch 15299: train_loss=487.23965, val_loss=502.25235\n",
      "Epoch 15300: train_loss=487.21698, val_loss=502.22415\n",
      "Epoch 15301: train_loss=487.19443, val_loss=502.20694\n",
      "Epoch 15302: train_loss=487.17184, val_loss=502.17938\n",
      "Epoch 15303: train_loss=487.14990, val_loss=502.16409\n",
      "Epoch 15304: train_loss=487.12793, val_loss=502.13699\n",
      "Epoch 15305: train_loss=487.10648, val_loss=502.12289\n",
      "Epoch 15306: train_loss=487.08536, val_loss=502.09467\n",
      "Epoch 15307: train_loss=487.06509, val_loss=502.08310\n",
      "Epoch 15308: train_loss=487.04520, val_loss=502.05569\n",
      "Epoch 15309: train_loss=487.02603, val_loss=502.04901\n",
      "Epoch 15310: train_loss=487.00806, val_loss=502.02179\n",
      "Epoch 15311: train_loss=486.99094, val_loss=502.01834\n",
      "Epoch 15312: train_loss=486.97519, val_loss=501.99042\n",
      "Epoch 15313: train_loss=486.96075, val_loss=501.99475\n",
      "Epoch 15314: train_loss=486.94876, val_loss=501.96954\n",
      "Epoch 15315: train_loss=486.93915, val_loss=501.98291\n",
      "Epoch 15316: train_loss=486.93225, val_loss=501.95804\n",
      "Epoch 15317: train_loss=486.92776, val_loss=501.97946\n",
      "Epoch 15318: train_loss=486.92480, val_loss=501.95239\n",
      "Epoch 15319: train_loss=486.92163, val_loss=501.97437\n",
      "Epoch 15320: train_loss=486.91559, val_loss=501.93741\n",
      "Epoch 15321: train_loss=486.90546, val_loss=501.95084\n",
      "Epoch 15322: train_loss=486.88922, val_loss=501.89816\n",
      "Epoch 15323: train_loss=486.86502, val_loss=501.89450\n",
      "Epoch 15324: train_loss=486.83237, val_loss=501.82718\n",
      "Epoch 15325: train_loss=486.79156, val_loss=501.80627\n",
      "Epoch 15326: train_loss=486.74478, val_loss=501.73221\n",
      "Epoch 15327: train_loss=486.69315, val_loss=501.70056\n",
      "Epoch 15328: train_loss=486.64215, val_loss=501.63608\n",
      "Epoch 15329: train_loss=486.59317, val_loss=501.60660\n",
      "Epoch 15330: train_loss=486.55042, val_loss=501.56079\n",
      "Epoch 15331: train_loss=486.51276, val_loss=501.53348\n",
      "Epoch 15332: train_loss=486.48102, val_loss=501.50458\n",
      "Epoch 15333: train_loss=486.45486, val_loss=501.48160\n",
      "Epoch 15334: train_loss=486.43298, val_loss=501.46783\n",
      "Epoch 15335: train_loss=486.41406, val_loss=501.44772\n",
      "Epoch 15336: train_loss=486.39722, val_loss=501.44156\n",
      "Epoch 15337: train_loss=486.38150, val_loss=501.41672\n",
      "Epoch 15338: train_loss=486.36575, val_loss=501.41168\n",
      "Epoch 15339: train_loss=486.34998, val_loss=501.38281\n",
      "Epoch 15340: train_loss=486.33325, val_loss=501.38089\n",
      "Epoch 15341: train_loss=486.31689, val_loss=501.34848\n",
      "Epoch 15342: train_loss=486.29840, val_loss=501.34494\n",
      "Epoch 15343: train_loss=486.27969, val_loss=501.30627\n",
      "Epoch 15344: train_loss=486.25760, val_loss=501.30038\n",
      "Epoch 15345: train_loss=486.23560, val_loss=501.25995\n",
      "Epoch 15346: train_loss=486.21069, val_loss=501.25192\n",
      "Epoch 15347: train_loss=486.18542, val_loss=501.21036\n",
      "Epoch 15348: train_loss=486.15817, val_loss=501.19757\n",
      "Epoch 15349: train_loss=486.13083, val_loss=501.15466\n",
      "Epoch 15350: train_loss=486.10272, val_loss=501.13977\n",
      "Epoch 15351: train_loss=486.07489, val_loss=501.09814\n",
      "Epoch 15352: train_loss=486.04620, val_loss=501.08038\n",
      "Epoch 15353: train_loss=486.01730, val_loss=501.04047\n",
      "Epoch 15354: train_loss=485.98795, val_loss=501.02109\n",
      "Epoch 15355: train_loss=485.95908, val_loss=500.98553\n",
      "Epoch 15356: train_loss=485.93030, val_loss=500.96533\n",
      "Epoch 15357: train_loss=485.90225, val_loss=500.93372\n",
      "Epoch 15358: train_loss=485.87506, val_loss=500.91223\n",
      "Epoch 15359: train_loss=485.84869, val_loss=500.88480\n",
      "Epoch 15360: train_loss=485.82324, val_loss=500.86267\n",
      "Epoch 15361: train_loss=485.79865, val_loss=500.83847\n",
      "Epoch 15362: train_loss=485.77466, val_loss=500.81537\n",
      "Epoch 15363: train_loss=485.75125, val_loss=500.79333\n",
      "Epoch 15364: train_loss=485.72818, val_loss=500.76935\n",
      "Epoch 15365: train_loss=485.70535, val_loss=500.74942\n",
      "Epoch 15366: train_loss=485.68283, val_loss=500.72552\n",
      "Epoch 15367: train_loss=485.66049, val_loss=500.70840\n",
      "Epoch 15368: train_loss=485.63873, val_loss=500.68405\n",
      "Epoch 15369: train_loss=485.61761, val_loss=500.66965\n",
      "Epoch 15370: train_loss=485.59756, val_loss=500.64429\n",
      "Epoch 15371: train_loss=485.57852, val_loss=500.63489\n",
      "Epoch 15372: train_loss=485.56149, val_loss=500.61163\n",
      "Epoch 15373: train_loss=485.54675, val_loss=500.61267\n",
      "Epoch 15374: train_loss=485.53644, val_loss=500.59277\n",
      "Epoch 15375: train_loss=485.52951, val_loss=500.60632\n",
      "Epoch 15376: train_loss=485.52893, val_loss=500.59271\n",
      "Epoch 15377: train_loss=485.53384, val_loss=500.62396\n",
      "Epoch 15378: train_loss=485.54495, val_loss=500.61789\n",
      "Epoch 15379: train_loss=485.56061, val_loss=500.66611\n",
      "Epoch 15380: train_loss=485.58157, val_loss=500.65860\n",
      "Epoch 15381: train_loss=485.60080, val_loss=500.70331\n",
      "Epoch 15382: train_loss=485.61496, val_loss=500.67084\n",
      "Epoch 15383: train_loss=485.61328, val_loss=500.68289\n",
      "Epoch 15384: train_loss=485.59369, val_loss=500.60352\n",
      "Epoch 15385: train_loss=485.54495, val_loss=500.56174\n",
      "Epoch 15386: train_loss=485.47485, val_loss=500.44464\n",
      "Epoch 15387: train_loss=485.38528, val_loss=500.37131\n",
      "Epoch 15388: train_loss=485.29269, val_loss=500.26736\n",
      "Epoch 15389: train_loss=485.20676, val_loss=500.21011\n",
      "Epoch 15390: train_loss=485.13855, val_loss=500.16110\n",
      "Epoch 15391: train_loss=485.09369, val_loss=500.13928\n",
      "Epoch 15392: train_loss=485.07034, val_loss=500.13748\n",
      "Epoch 15393: train_loss=485.06290, val_loss=500.12933\n",
      "Epoch 15394: train_loss=485.06308, val_loss=500.14142\n",
      "Epoch 15395: train_loss=485.06381, val_loss=500.12323\n",
      "Epoch 15396: train_loss=485.05963, val_loss=500.12479\n",
      "Epoch 15397: train_loss=485.04651, val_loss=500.08557\n",
      "Epoch 15398: train_loss=485.02298, val_loss=500.06714\n",
      "Epoch 15399: train_loss=484.99039, val_loss=500.01294\n",
      "Epoch 15400: train_loss=484.95044, val_loss=499.98138\n",
      "Epoch 15401: train_loss=484.90622, val_loss=499.92822\n",
      "Epoch 15402: train_loss=484.86258, val_loss=499.89709\n",
      "Epoch 15403: train_loss=484.82205, val_loss=499.85913\n",
      "Epoch 15404: train_loss=484.78723, val_loss=499.83475\n",
      "Epoch 15405: train_loss=484.75824, val_loss=499.81238\n",
      "Epoch 15406: train_loss=484.73438, val_loss=499.79129\n",
      "Epoch 15407: train_loss=484.71457, val_loss=499.77887\n",
      "Epoch 15408: train_loss=484.69656, val_loss=499.75726\n",
      "Epoch 15409: train_loss=484.67953, val_loss=499.74872\n",
      "Epoch 15410: train_loss=484.66281, val_loss=499.72321\n",
      "Epoch 15411: train_loss=484.64499, val_loss=499.71207\n",
      "Epoch 15412: train_loss=484.62589, val_loss=499.68109\n",
      "Epoch 15413: train_loss=484.60434, val_loss=499.66727\n",
      "Epoch 15414: train_loss=484.58151, val_loss=499.63333\n",
      "Epoch 15415: train_loss=484.55600, val_loss=499.61572\n",
      "Epoch 15416: train_loss=484.52881, val_loss=499.57938\n",
      "Epoch 15417: train_loss=484.50009, val_loss=499.55859\n",
      "Epoch 15418: train_loss=484.47095, val_loss=499.52344\n",
      "Epoch 15419: train_loss=484.44128, val_loss=499.50333\n",
      "Epoch 15420: train_loss=484.41223, val_loss=499.47263\n",
      "Epoch 15421: train_loss=484.38373, val_loss=499.45154\n",
      "Epoch 15422: train_loss=484.35611, val_loss=499.42117\n",
      "Epoch 15423: train_loss=484.32880, val_loss=499.39749\n",
      "Epoch 15424: train_loss=484.30273, val_loss=499.36877\n",
      "Epoch 15425: train_loss=484.27707, val_loss=499.34628\n",
      "Epoch 15426: train_loss=484.25186, val_loss=499.32047\n",
      "Epoch 15427: train_loss=484.22696, val_loss=499.29913\n",
      "Epoch 15428: train_loss=484.20227, val_loss=499.27289\n",
      "Epoch 15429: train_loss=484.17758, val_loss=499.25027\n",
      "Epoch 15430: train_loss=484.15329, val_loss=499.22519\n",
      "Epoch 15431: train_loss=484.12900, val_loss=499.20612\n",
      "Epoch 15432: train_loss=484.10519, val_loss=499.18283\n",
      "Epoch 15433: train_loss=484.08188, val_loss=499.16501\n",
      "Epoch 15434: train_loss=484.05984, val_loss=499.14017\n",
      "Epoch 15435: train_loss=484.03900, val_loss=499.12640\n",
      "Epoch 15436: train_loss=484.02103, val_loss=499.10425\n",
      "Epoch 15437: train_loss=484.00534, val_loss=499.10068\n",
      "Epoch 15438: train_loss=483.99380, val_loss=499.08392\n",
      "Epoch 15439: train_loss=483.98566, val_loss=499.09332\n",
      "Epoch 15440: train_loss=483.98230, val_loss=499.08099\n",
      "Epoch 15441: train_loss=483.98212, val_loss=499.10025\n",
      "Epoch 15442: train_loss=483.98486, val_loss=499.08755\n",
      "Epoch 15443: train_loss=483.98737, val_loss=499.10971\n",
      "Epoch 15444: train_loss=483.98978, val_loss=499.08795\n",
      "Epoch 15445: train_loss=483.98706, val_loss=499.10193\n",
      "Epoch 15446: train_loss=483.97983, val_loss=499.06195\n",
      "Epoch 15447: train_loss=483.96115, val_loss=499.05505\n",
      "Epoch 15448: train_loss=483.93265, val_loss=498.99252\n",
      "Epoch 15449: train_loss=483.89108, val_loss=498.96133\n",
      "Epoch 15450: train_loss=483.83954, val_loss=498.88193\n",
      "Epoch 15451: train_loss=483.77811, val_loss=498.83646\n",
      "Epoch 15452: train_loss=483.71545, val_loss=498.76181\n",
      "Epoch 15453: train_loss=483.65323, val_loss=498.71790\n",
      "Epoch 15454: train_loss=483.59830, val_loss=498.66354\n",
      "Epoch 15455: train_loss=483.55133, val_loss=498.63086\n",
      "Epoch 15456: train_loss=483.51401, val_loss=498.59998\n",
      "Epoch 15457: train_loss=483.48441, val_loss=498.57626\n",
      "Epoch 15458: train_loss=483.46078, val_loss=498.55960\n",
      "Epoch 15459: train_loss=483.44138, val_loss=498.53809\n",
      "Epoch 15460: train_loss=483.42502, val_loss=498.53000\n",
      "Epoch 15461: train_loss=483.41119, val_loss=498.50729\n",
      "Epoch 15462: train_loss=483.39764, val_loss=498.50369\n",
      "Epoch 15463: train_loss=483.38406, val_loss=498.47906\n",
      "Epoch 15464: train_loss=483.36743, val_loss=498.47519\n",
      "Epoch 15465: train_loss=483.34912, val_loss=498.44370\n",
      "Epoch 15466: train_loss=483.32629, val_loss=498.43149\n",
      "Epoch 15467: train_loss=483.30038, val_loss=498.39066\n",
      "Epoch 15468: train_loss=483.27100, val_loss=498.37195\n",
      "Epoch 15469: train_loss=483.23956, val_loss=498.32886\n",
      "Epoch 15470: train_loss=483.20605, val_loss=498.30737\n",
      "Epoch 15471: train_loss=483.17227, val_loss=498.26532\n",
      "Epoch 15472: train_loss=483.13806, val_loss=498.24136\n",
      "Epoch 15473: train_loss=483.10477, val_loss=498.20270\n",
      "Epoch 15474: train_loss=483.07275, val_loss=498.17923\n",
      "Epoch 15475: train_loss=483.04233, val_loss=498.14685\n",
      "Epoch 15476: train_loss=483.01285, val_loss=498.12411\n",
      "Epoch 15477: train_loss=482.98416, val_loss=498.09448\n",
      "Epoch 15478: train_loss=482.95624, val_loss=498.07062\n",
      "Epoch 15479: train_loss=482.92902, val_loss=498.04352\n",
      "Epoch 15480: train_loss=482.90256, val_loss=498.02048\n",
      "Epoch 15481: train_loss=482.87637, val_loss=497.99631\n",
      "Epoch 15482: train_loss=482.85056, val_loss=497.97192\n",
      "Epoch 15483: train_loss=482.82492, val_loss=497.94797\n",
      "Epoch 15484: train_loss=482.79932, val_loss=497.92270\n",
      "Epoch 15485: train_loss=482.77396, val_loss=497.90063\n",
      "Epoch 15486: train_loss=482.74869, val_loss=497.87540\n",
      "Epoch 15487: train_loss=482.72372, val_loss=497.85632\n",
      "Epoch 15488: train_loss=482.69934, val_loss=497.83078\n",
      "Epoch 15489: train_loss=482.67554, val_loss=497.81290\n",
      "Epoch 15490: train_loss=482.65240, val_loss=497.78720\n",
      "Epoch 15491: train_loss=482.63077, val_loss=497.77487\n",
      "Epoch 15492: train_loss=482.61038, val_loss=497.75256\n",
      "Epoch 15493: train_loss=482.59338, val_loss=497.74887\n",
      "Epoch 15494: train_loss=482.57837, val_loss=497.72919\n",
      "Epoch 15495: train_loss=482.56726, val_loss=497.73523\n",
      "Epoch 15496: train_loss=482.55911, val_loss=497.72040\n",
      "Epoch 15497: train_loss=482.55667, val_loss=497.73904\n",
      "Epoch 15498: train_loss=482.55725, val_loss=497.72925\n",
      "Epoch 15499: train_loss=482.56287, val_loss=497.75867\n",
      "Epoch 15500: train_loss=482.57001, val_loss=497.74652\n",
      "Epoch 15501: train_loss=482.57758, val_loss=497.77655\n",
      "Epoch 15502: train_loss=482.58255, val_loss=497.74933\n",
      "Epoch 15503: train_loss=482.57883, val_loss=497.76526\n",
      "Epoch 15504: train_loss=482.56653, val_loss=497.70886\n",
      "Epoch 15505: train_loss=482.53485, val_loss=497.68903\n",
      "Epoch 15506: train_loss=482.48740, val_loss=497.59796\n",
      "Epoch 15507: train_loss=482.42166, val_loss=497.54343\n",
      "Epoch 15508: train_loss=482.34528, val_loss=497.44266\n",
      "Epoch 15509: train_loss=482.26471, val_loss=497.38181\n",
      "Epoch 15510: train_loss=482.18796, val_loss=497.30493\n",
      "Epoch 15511: train_loss=482.12073, val_loss=497.26230\n",
      "Epoch 15512: train_loss=482.07095, val_loss=497.22821\n",
      "Epoch 15513: train_loss=482.03815, val_loss=497.20691\n",
      "Epoch 15514: train_loss=482.01913, val_loss=497.20334\n",
      "Epoch 15515: train_loss=482.00870, val_loss=497.18832\n",
      "Epoch 15516: train_loss=482.00089, val_loss=497.19287\n",
      "Epoch 15517: train_loss=481.99216, val_loss=497.16580\n",
      "Epoch 15518: train_loss=481.97626, val_loss=497.15842\n",
      "Epoch 15519: train_loss=481.95407, val_loss=497.11465\n",
      "Epoch 15520: train_loss=481.92221, val_loss=497.09369\n",
      "Epoch 15521: train_loss=481.88568, val_loss=497.04330\n",
      "Epoch 15522: train_loss=481.84448, val_loss=497.01443\n",
      "Epoch 15523: train_loss=481.80304, val_loss=496.96616\n",
      "Epoch 15524: train_loss=481.76260, val_loss=496.93503\n",
      "Epoch 15525: train_loss=481.72467, val_loss=496.89542\n",
      "Epoch 15526: train_loss=481.68945, val_loss=496.86722\n",
      "Epoch 15527: train_loss=481.65729, val_loss=496.83792\n",
      "Epoch 15528: train_loss=481.62814, val_loss=496.81122\n",
      "Epoch 15529: train_loss=481.60153, val_loss=496.78958\n",
      "Epoch 15530: train_loss=481.57642, val_loss=496.76318\n",
      "Epoch 15531: train_loss=481.55231, val_loss=496.74643\n",
      "Epoch 15532: train_loss=481.52884, val_loss=496.72046\n",
      "Epoch 15533: train_loss=481.50534, val_loss=496.70587\n",
      "Epoch 15534: train_loss=481.48178, val_loss=496.67615\n",
      "Epoch 15535: train_loss=481.45752, val_loss=496.66101\n",
      "Epoch 15536: train_loss=481.43323, val_loss=496.62906\n",
      "Epoch 15537: train_loss=481.40805, val_loss=496.61258\n",
      "Epoch 15538: train_loss=481.38263, val_loss=496.57819\n",
      "Epoch 15539: train_loss=481.35638, val_loss=496.56119\n",
      "Epoch 15540: train_loss=481.33032, val_loss=496.52533\n",
      "Epoch 15541: train_loss=481.30322, val_loss=496.50671\n",
      "Epoch 15542: train_loss=481.27582, val_loss=496.46970\n",
      "Epoch 15543: train_loss=481.24707, val_loss=496.45059\n",
      "Epoch 15544: train_loss=481.21805, val_loss=496.41306\n",
      "Epoch 15545: train_loss=481.18817, val_loss=496.39145\n",
      "Epoch 15546: train_loss=481.15750, val_loss=496.35303\n",
      "Epoch 15547: train_loss=481.12604, val_loss=496.33011\n",
      "Epoch 15548: train_loss=481.09451, val_loss=496.29239\n",
      "Epoch 15549: train_loss=481.06277, val_loss=496.26862\n",
      "Epoch 15550: train_loss=481.03140, val_loss=496.23227\n",
      "Epoch 15551: train_loss=481.00024, val_loss=496.20767\n",
      "Epoch 15552: train_loss=480.96954, val_loss=496.17285\n",
      "Epoch 15553: train_loss=480.93912, val_loss=496.14859\n",
      "Epoch 15554: train_loss=480.90945, val_loss=496.11511\n",
      "Epoch 15555: train_loss=480.88010, val_loss=496.09106\n",
      "Epoch 15556: train_loss=480.85135, val_loss=496.05820\n",
      "Epoch 15557: train_loss=480.82309, val_loss=496.03656\n",
      "Epoch 15558: train_loss=480.79584, val_loss=496.00620\n",
      "Epoch 15559: train_loss=480.76929, val_loss=495.98743\n",
      "Epoch 15560: train_loss=480.74374, val_loss=495.95868\n",
      "Epoch 15561: train_loss=480.71936, val_loss=495.94238\n",
      "Epoch 15562: train_loss=480.69635, val_loss=495.91370\n",
      "Epoch 15563: train_loss=480.67474, val_loss=495.90097\n",
      "Epoch 15564: train_loss=480.65527, val_loss=495.87524\n",
      "Epoch 15565: train_loss=480.63757, val_loss=495.87067\n",
      "Epoch 15566: train_loss=480.62378, val_loss=495.85086\n",
      "Epoch 15567: train_loss=480.61166, val_loss=495.85715\n",
      "Epoch 15568: train_loss=480.60626, val_loss=495.84250\n",
      "Epoch 15569: train_loss=480.60129, val_loss=495.85828\n",
      "Epoch 15570: train_loss=480.60352, val_loss=495.84476\n",
      "Epoch 15571: train_loss=480.60150, val_loss=495.86038\n",
      "Epoch 15572: train_loss=480.60275, val_loss=495.83575\n",
      "Epoch 15573: train_loss=480.59186, val_loss=495.83472\n",
      "Epoch 15574: train_loss=480.57681, val_loss=495.78574\n",
      "Epoch 15575: train_loss=480.54184, val_loss=495.75595\n",
      "Epoch 15576: train_loss=480.49771, val_loss=495.68134\n",
      "Epoch 15577: train_loss=480.43478, val_loss=495.62509\n",
      "Epoch 15578: train_loss=480.36523, val_loss=495.54001\n",
      "Epoch 15579: train_loss=480.29025, val_loss=495.47775\n",
      "Epoch 15580: train_loss=480.21939, val_loss=495.40408\n",
      "Epoch 15581: train_loss=480.15353, val_loss=495.35278\n",
      "Epoch 15582: train_loss=480.09824, val_loss=495.30548\n",
      "Epoch 15583: train_loss=480.05441, val_loss=495.27313\n",
      "Epoch 15584: train_loss=480.02145, val_loss=495.25012\n",
      "Epoch 15585: train_loss=479.99722, val_loss=495.22931\n",
      "Epoch 15586: train_loss=479.97855, val_loss=495.21780\n",
      "Epoch 15587: train_loss=479.96252, val_loss=495.19748\n",
      "Epoch 15588: train_loss=479.94608, val_loss=495.18597\n",
      "Epoch 15589: train_loss=479.92761, val_loss=495.15875\n",
      "Epoch 15590: train_loss=479.90500, val_loss=495.14062\n",
      "Epoch 15591: train_loss=479.87936, val_loss=495.10443\n",
      "Epoch 15592: train_loss=479.84805, val_loss=495.07776\n",
      "Epoch 15593: train_loss=479.81348, val_loss=495.03546\n",
      "Epoch 15594: train_loss=479.77521, val_loss=495.00299\n",
      "Epoch 15595: train_loss=479.73526, val_loss=494.95914\n",
      "Epoch 15596: train_loss=479.69458, val_loss=494.92422\n",
      "Epoch 15597: train_loss=479.65436, val_loss=494.88290\n",
      "Epoch 15598: train_loss=479.61554, val_loss=494.84976\n",
      "Epoch 15599: train_loss=479.57901, val_loss=494.81467\n",
      "Epoch 15600: train_loss=479.54483, val_loss=494.78384\n",
      "Epoch 15601: train_loss=479.51257, val_loss=494.75305\n",
      "Epoch 15602: train_loss=479.48221, val_loss=494.72235\n",
      "Epoch 15603: train_loss=479.45328, val_loss=494.69513\n",
      "Epoch 15604: train_loss=479.42502, val_loss=494.66660\n",
      "Epoch 15605: train_loss=479.39743, val_loss=494.64328\n",
      "Epoch 15606: train_loss=479.37009, val_loss=494.61484\n",
      "Epoch 15607: train_loss=479.34311, val_loss=494.59186\n",
      "Epoch 15608: train_loss=479.31631, val_loss=494.56287\n",
      "Epoch 15609: train_loss=479.29007, val_loss=494.54172\n",
      "Epoch 15610: train_loss=479.26410, val_loss=494.51364\n",
      "Epoch 15611: train_loss=479.23865, val_loss=494.49490\n",
      "Epoch 15612: train_loss=479.21368, val_loss=494.46628\n",
      "Epoch 15613: train_loss=479.18912, val_loss=494.44815\n",
      "Epoch 15614: train_loss=479.16483, val_loss=494.41803\n",
      "Epoch 15615: train_loss=479.13986, val_loss=494.39999\n",
      "Epoch 15616: train_loss=479.11444, val_loss=494.36740\n",
      "Epoch 15617: train_loss=479.08719, val_loss=494.34805\n",
      "Epoch 15618: train_loss=479.05963, val_loss=494.31195\n",
      "Epoch 15619: train_loss=479.03015, val_loss=494.29031\n",
      "Epoch 15620: train_loss=479.00110, val_loss=494.25287\n",
      "Epoch 15621: train_loss=478.97009, val_loss=494.23035\n",
      "Epoch 15622: train_loss=478.93948, val_loss=494.19223\n",
      "Epoch 15623: train_loss=478.90707, val_loss=494.16870\n",
      "Epoch 15624: train_loss=478.87579, val_loss=494.12988\n",
      "Epoch 15625: train_loss=478.84283, val_loss=494.10675\n",
      "Epoch 15626: train_loss=478.81183, val_loss=494.06952\n",
      "Epoch 15627: train_loss=478.77975, val_loss=494.04568\n",
      "Epoch 15628: train_loss=478.74860, val_loss=494.00784\n",
      "Epoch 15629: train_loss=478.71667, val_loss=493.98199\n",
      "Epoch 15630: train_loss=478.68503, val_loss=493.94498\n",
      "Epoch 15631: train_loss=478.65359, val_loss=493.92056\n",
      "Epoch 15632: train_loss=478.62225, val_loss=493.88565\n",
      "Epoch 15633: train_loss=478.59091, val_loss=493.86176\n",
      "Epoch 15634: train_loss=478.56000, val_loss=493.82562\n",
      "Epoch 15635: train_loss=478.52936, val_loss=493.79941\n",
      "Epoch 15636: train_loss=478.49857, val_loss=493.76221\n",
      "Epoch 15637: train_loss=478.46741, val_loss=493.73691\n",
      "Epoch 15638: train_loss=478.43607, val_loss=493.70258\n",
      "Epoch 15639: train_loss=478.40384, val_loss=493.67789\n",
      "Epoch 15640: train_loss=478.37180, val_loss=493.64148\n",
      "Epoch 15641: train_loss=478.33896, val_loss=493.61322\n",
      "Epoch 15642: train_loss=478.30618, val_loss=493.57593\n",
      "Epoch 15643: train_loss=478.27304, val_loss=493.54724\n",
      "Epoch 15644: train_loss=478.23975, val_loss=493.51105\n",
      "Epoch 15645: train_loss=478.20618, val_loss=493.48227\n",
      "Epoch 15646: train_loss=478.17245, val_loss=493.44501\n",
      "Epoch 15647: train_loss=478.13849, val_loss=493.41446\n",
      "Epoch 15648: train_loss=478.10455, val_loss=493.37875\n",
      "Epoch 15649: train_loss=478.07095, val_loss=493.35016\n",
      "Epoch 15650: train_loss=478.03738, val_loss=493.31613\n",
      "Epoch 15651: train_loss=478.00433, val_loss=493.28705\n",
      "Epoch 15652: train_loss=477.97171, val_loss=493.25223\n",
      "Epoch 15653: train_loss=477.93976, val_loss=493.22250\n",
      "Epoch 15654: train_loss=477.90854, val_loss=493.19028\n",
      "Epoch 15655: train_loss=477.87805, val_loss=493.16464\n",
      "Epoch 15656: train_loss=477.84830, val_loss=493.13580\n",
      "Epoch 15657: train_loss=477.81970, val_loss=493.11191\n",
      "Epoch 15658: train_loss=477.79227, val_loss=493.08350\n",
      "Epoch 15659: train_loss=477.76624, val_loss=493.06107\n",
      "Epoch 15660: train_loss=477.74197, val_loss=493.03549\n",
      "Epoch 15661: train_loss=477.71939, val_loss=493.01935\n",
      "Epoch 15662: train_loss=477.69931, val_loss=493.00043\n",
      "Epoch 15663: train_loss=477.68210, val_loss=492.99399\n",
      "Epoch 15664: train_loss=477.67053, val_loss=492.98312\n",
      "Epoch 15665: train_loss=477.66284, val_loss=492.98648\n",
      "Epoch 15666: train_loss=477.66141, val_loss=492.98282\n",
      "Epoch 15667: train_loss=477.66245, val_loss=492.99881\n",
      "Epoch 15668: train_loss=477.67117, val_loss=493.00256\n",
      "Epoch 15669: train_loss=477.67923, val_loss=493.02032\n",
      "Epoch 15670: train_loss=477.68973, val_loss=493.01379\n",
      "Epoch 15671: train_loss=477.68985, val_loss=493.01123\n",
      "Epoch 15672: train_loss=477.68054, val_loss=492.96667\n",
      "Epoch 15673: train_loss=477.64276, val_loss=492.91599\n",
      "Epoch 15674: train_loss=477.58521, val_loss=492.82166\n",
      "Epoch 15675: train_loss=477.49719, val_loss=492.72629\n",
      "Epoch 15676: train_loss=477.39728, val_loss=492.61340\n",
      "Epoch 15677: train_loss=477.29025, val_loss=492.52191\n",
      "Epoch 15678: train_loss=477.19638, val_loss=492.44550\n",
      "Epoch 15679: train_loss=477.12225, val_loss=492.39795\n",
      "Epoch 15680: train_loss=477.07391, val_loss=492.37344\n",
      "Epoch 15681: train_loss=477.04874, val_loss=492.36163\n",
      "Epoch 15682: train_loss=477.03848, val_loss=492.35962\n",
      "Epoch 15683: train_loss=477.03409, val_loss=492.34863\n",
      "Epoch 15684: train_loss=477.02551, val_loss=492.33417\n",
      "Epoch 15685: train_loss=477.00787, val_loss=492.30026\n",
      "Epoch 15686: train_loss=476.97745, val_loss=492.26251\n",
      "Epoch 15687: train_loss=476.93683, val_loss=492.21069\n",
      "Epoch 15688: train_loss=476.88855, val_loss=492.16025\n",
      "Epoch 15689: train_loss=476.83618, val_loss=492.10699\n",
      "Epoch 15690: train_loss=476.78439, val_loss=492.06204\n",
      "Epoch 15691: train_loss=476.73776, val_loss=492.02158\n",
      "Epoch 15692: train_loss=476.69769, val_loss=491.98816\n",
      "Epoch 15693: train_loss=476.66455, val_loss=491.96024\n",
      "Epoch 15694: train_loss=476.63660, val_loss=491.93491\n",
      "Epoch 15695: train_loss=476.61172, val_loss=491.91272\n",
      "Epoch 15696: train_loss=476.58813, val_loss=491.88831\n",
      "Epoch 15697: train_loss=476.56354, val_loss=491.86438\n",
      "Epoch 15698: train_loss=476.53711, val_loss=491.83499\n",
      "Epoch 15699: train_loss=476.50809, val_loss=491.80423\n",
      "Epoch 15700: train_loss=476.47595, val_loss=491.76917\n",
      "Epoch 15701: train_loss=476.44196, val_loss=491.73318\n",
      "Epoch 15702: train_loss=476.40579, val_loss=491.69547\n",
      "Epoch 15703: train_loss=476.36859, val_loss=491.65771\n",
      "Epoch 15704: train_loss=476.33084, val_loss=491.62024\n",
      "Epoch 15705: train_loss=476.29306, val_loss=491.58322\n",
      "Epoch 15706: train_loss=476.25623, val_loss=491.54770\n",
      "Epoch 15707: train_loss=476.22083, val_loss=491.51309\n",
      "Epoch 15708: train_loss=476.18695, val_loss=491.47968\n",
      "Epoch 15709: train_loss=476.15427, val_loss=491.44739\n",
      "Epoch 15710: train_loss=476.12271, val_loss=491.41556\n",
      "Epoch 15711: train_loss=476.09161, val_loss=491.38510\n",
      "Epoch 15712: train_loss=476.06082, val_loss=491.35513\n",
      "Epoch 15713: train_loss=476.03021, val_loss=491.32620\n",
      "Epoch 15714: train_loss=475.99963, val_loss=491.29593\n",
      "Epoch 15715: train_loss=475.96933, val_loss=491.26523\n",
      "Epoch 15716: train_loss=475.93851, val_loss=491.23294\n",
      "Epoch 15717: train_loss=475.90750, val_loss=491.20221\n",
      "Epoch 15718: train_loss=475.87662, val_loss=491.17139\n",
      "Epoch 15719: train_loss=475.84579, val_loss=491.14203\n",
      "Epoch 15720: train_loss=475.81491, val_loss=491.11176\n",
      "Epoch 15721: train_loss=475.78452, val_loss=491.08200\n",
      "Epoch 15722: train_loss=475.75412, val_loss=491.05075\n",
      "Epoch 15723: train_loss=475.72409, val_loss=491.02078\n",
      "Epoch 15724: train_loss=475.69336, val_loss=490.98950\n",
      "Epoch 15725: train_loss=475.66287, val_loss=490.95972\n",
      "Epoch 15726: train_loss=475.63254, val_loss=490.93011\n",
      "Epoch 15727: train_loss=475.60281, val_loss=490.90097\n",
      "Epoch 15728: train_loss=475.57324, val_loss=490.87302\n",
      "Epoch 15729: train_loss=475.54404, val_loss=490.84311\n",
      "Epoch 15730: train_loss=475.51382, val_loss=490.81415\n",
      "Epoch 15731: train_loss=475.48334, val_loss=490.78168\n",
      "Epoch 15732: train_loss=475.45206, val_loss=490.75098\n",
      "Epoch 15733: train_loss=475.42004, val_loss=490.71701\n",
      "Epoch 15734: train_loss=475.38647, val_loss=490.68533\n",
      "Epoch 15735: train_loss=475.35242, val_loss=490.64993\n",
      "Epoch 15736: train_loss=475.31680, val_loss=490.61380\n",
      "Epoch 15737: train_loss=475.27930, val_loss=490.57294\n",
      "Epoch 15738: train_loss=475.23981, val_loss=490.53165\n",
      "Epoch 15739: train_loss=475.19803, val_loss=490.48807\n",
      "Epoch 15740: train_loss=475.15454, val_loss=490.44510\n",
      "Epoch 15741: train_loss=475.10959, val_loss=490.40039\n",
      "Epoch 15742: train_loss=475.06424, val_loss=490.35596\n",
      "Epoch 15743: train_loss=475.01892, val_loss=490.31027\n",
      "Epoch 15744: train_loss=474.97443, val_loss=490.26636\n",
      "Epoch 15745: train_loss=474.93097, val_loss=490.22464\n",
      "Epoch 15746: train_loss=474.88922, val_loss=490.18494\n",
      "Epoch 15747: train_loss=474.84875, val_loss=490.14722\n",
      "Epoch 15748: train_loss=474.81003, val_loss=490.11005\n",
      "Epoch 15749: train_loss=474.77243, val_loss=490.07373\n",
      "Epoch 15750: train_loss=474.73569, val_loss=490.03821\n",
      "Epoch 15751: train_loss=474.69946, val_loss=490.00299\n",
      "Epoch 15752: train_loss=474.66367, val_loss=489.96762\n",
      "Epoch 15753: train_loss=474.62811, val_loss=489.93240\n",
      "Epoch 15754: train_loss=474.59280, val_loss=489.89670\n",
      "Epoch 15755: train_loss=474.55759, val_loss=489.86227\n",
      "Epoch 15756: train_loss=474.52280, val_loss=489.82846\n",
      "Epoch 15757: train_loss=474.48843, val_loss=489.79538\n",
      "Epoch 15758: train_loss=474.45419, val_loss=489.76221\n",
      "Epoch 15759: train_loss=474.42053, val_loss=489.73004\n",
      "Epoch 15760: train_loss=474.38748, val_loss=489.69815\n",
      "Epoch 15761: train_loss=474.35513, val_loss=489.66745\n",
      "Epoch 15762: train_loss=474.32394, val_loss=489.63748\n",
      "Epoch 15763: train_loss=474.29404, val_loss=489.60831\n",
      "Epoch 15764: train_loss=474.26544, val_loss=489.58102\n",
      "Epoch 15765: train_loss=474.23856, val_loss=489.55670\n",
      "Epoch 15766: train_loss=474.21445, val_loss=489.53513\n",
      "Epoch 15767: train_loss=474.19281, val_loss=489.51703\n",
      "Epoch 15768: train_loss=474.17438, val_loss=489.50046\n",
      "Epoch 15769: train_loss=474.15735, val_loss=489.48804\n",
      "Epoch 15770: train_loss=474.14417, val_loss=489.47781\n",
      "Epoch 15771: train_loss=474.13354, val_loss=489.47000\n",
      "Epoch 15772: train_loss=474.12546, val_loss=489.45898\n",
      "Epoch 15773: train_loss=474.11356, val_loss=489.44427\n",
      "Epoch 15774: train_loss=474.09821, val_loss=489.41785\n",
      "Epoch 15775: train_loss=474.07071, val_loss=489.37863\n",
      "Epoch 15776: train_loss=474.03204, val_loss=489.32141\n",
      "Epoch 15777: train_loss=473.97415, val_loss=489.24957\n",
      "Epoch 15778: train_loss=473.90289, val_loss=489.16260\n",
      "Epoch 15779: train_loss=473.81552, val_loss=489.07214\n",
      "Epoch 15780: train_loss=473.72595, val_loss=488.98407\n",
      "Epoch 15781: train_loss=473.63818, val_loss=488.90643\n",
      "Epoch 15782: train_loss=473.56186, val_loss=488.84485\n",
      "Epoch 15783: train_loss=473.50082, val_loss=488.80054\n",
      "Epoch 15784: train_loss=473.45645, val_loss=488.77026\n",
      "Epoch 15785: train_loss=473.42569, val_loss=488.74902\n",
      "Epoch 15786: train_loss=473.40338, val_loss=488.72870\n",
      "Epoch 15787: train_loss=473.38336, val_loss=488.70627\n",
      "Epoch 15788: train_loss=473.36050, val_loss=488.67807\n",
      "Epoch 15789: train_loss=473.33249, val_loss=488.64511\n",
      "Epoch 15790: train_loss=473.29684, val_loss=488.60321\n",
      "Epoch 15791: train_loss=473.25482, val_loss=488.55658\n",
      "Epoch 15792: train_loss=473.20703, val_loss=488.50458\n",
      "Epoch 15793: train_loss=473.15649, val_loss=488.45325\n",
      "Epoch 15794: train_loss=473.10562, val_loss=488.40414\n",
      "Epoch 15795: train_loss=473.05679, val_loss=488.35928\n",
      "Epoch 15796: train_loss=473.01086, val_loss=488.31796\n",
      "Epoch 15797: train_loss=472.96869, val_loss=488.28012\n",
      "Epoch 15798: train_loss=472.93011, val_loss=488.24435\n",
      "Epoch 15799: train_loss=472.89420, val_loss=488.20993\n",
      "Epoch 15800: train_loss=472.86005, val_loss=488.17725\n",
      "Epoch 15801: train_loss=472.82672, val_loss=488.14392\n",
      "Epoch 15802: train_loss=472.79349, val_loss=488.11145\n",
      "Epoch 15803: train_loss=472.76007, val_loss=488.07748\n",
      "Epoch 15804: train_loss=472.72632, val_loss=488.04468\n",
      "Epoch 15805: train_loss=472.69238, val_loss=488.00980\n",
      "Epoch 15806: train_loss=472.65781, val_loss=487.97601\n",
      "Epoch 15807: train_loss=472.62289, val_loss=487.94058\n",
      "Epoch 15808: train_loss=472.58762, val_loss=487.90564\n",
      "Epoch 15809: train_loss=472.55206, val_loss=487.86862\n",
      "Epoch 15810: train_loss=472.51630, val_loss=487.83334\n",
      "Epoch 15811: train_loss=472.48001, val_loss=487.79529\n",
      "Epoch 15812: train_loss=472.44315, val_loss=487.75931\n",
      "Epoch 15813: train_loss=472.40555, val_loss=487.71936\n",
      "Epoch 15814: train_loss=472.36743, val_loss=487.68262\n",
      "Epoch 15815: train_loss=472.32852, val_loss=487.64148\n",
      "Epoch 15816: train_loss=472.28925, val_loss=487.60403\n",
      "Epoch 15817: train_loss=472.24945, val_loss=487.56235\n",
      "Epoch 15818: train_loss=472.20972, val_loss=487.52393\n",
      "Epoch 15819: train_loss=472.16949, val_loss=487.48083\n",
      "Epoch 15820: train_loss=472.12939, val_loss=487.44260\n",
      "Epoch 15821: train_loss=472.08905, val_loss=487.40112\n",
      "Epoch 15822: train_loss=472.04907, val_loss=487.36462\n",
      "Epoch 15823: train_loss=472.00919, val_loss=487.32388\n",
      "Epoch 15824: train_loss=471.96967, val_loss=487.28635\n",
      "Epoch 15825: train_loss=471.93039, val_loss=487.24542\n",
      "Epoch 15826: train_loss=471.89172, val_loss=487.20816\n",
      "Epoch 15827: train_loss=471.85330, val_loss=487.16989\n",
      "Epoch 15828: train_loss=471.81570, val_loss=487.13522\n",
      "Epoch 15829: train_loss=471.77887, val_loss=487.09970\n",
      "Epoch 15830: train_loss=471.74292, val_loss=487.06644\n",
      "Epoch 15831: train_loss=471.70770, val_loss=487.03162\n",
      "Epoch 15832: train_loss=471.67331, val_loss=487.00052\n",
      "Epoch 15833: train_loss=471.63989, val_loss=486.96863\n",
      "Epoch 15834: train_loss=471.60812, val_loss=486.94244\n",
      "Epoch 15835: train_loss=471.57785, val_loss=486.91299\n",
      "Epoch 15836: train_loss=471.55017, val_loss=486.89111\n",
      "Epoch 15837: train_loss=471.52493, val_loss=486.86517\n",
      "Epoch 15838: train_loss=471.50266, val_loss=486.85074\n",
      "Epoch 15839: train_loss=471.48236, val_loss=486.83011\n",
      "Epoch 15840: train_loss=471.46475, val_loss=486.82114\n",
      "Epoch 15841: train_loss=471.44775, val_loss=486.79999\n",
      "Epoch 15842: train_loss=471.43185, val_loss=486.78827\n",
      "Epoch 15843: train_loss=471.41312, val_loss=486.76083\n",
      "Epoch 15844: train_loss=471.39307, val_loss=486.74173\n",
      "Epoch 15845: train_loss=471.36520, val_loss=486.70227\n",
      "Epoch 15846: train_loss=471.33231, val_loss=486.66745\n",
      "Epoch 15847: train_loss=471.28729, val_loss=486.60654\n",
      "Epoch 15848: train_loss=471.23468, val_loss=486.55109\n",
      "Epoch 15849: train_loss=471.17065, val_loss=486.47522\n",
      "Epoch 15850: train_loss=471.10260, val_loss=486.41061\n",
      "Epoch 15851: train_loss=471.02979, val_loss=486.33582\n",
      "Epoch 15852: train_loss=470.95950, val_loss=486.27576\n",
      "Epoch 15853: train_loss=470.89395, val_loss=486.21451\n",
      "Epoch 15854: train_loss=470.83600, val_loss=486.16687\n",
      "Epoch 15855: train_loss=470.78607, val_loss=486.12460\n",
      "Epoch 15856: train_loss=470.74408, val_loss=486.08975\n",
      "Epoch 15857: train_loss=470.70789, val_loss=486.06110\n",
      "Epoch 15858: train_loss=470.67590, val_loss=486.03082\n",
      "Epoch 15859: train_loss=470.64648, val_loss=486.00729\n",
      "Epoch 15860: train_loss=470.61835, val_loss=485.97610\n",
      "Epoch 15861: train_loss=470.59030, val_loss=485.95340\n",
      "Epoch 15862: train_loss=470.56219, val_loss=485.92133\n",
      "Epoch 15863: train_loss=470.53339, val_loss=485.89905\n",
      "Epoch 15864: train_loss=470.50317, val_loss=485.86389\n",
      "Epoch 15865: train_loss=470.47162, val_loss=485.83823\n",
      "Epoch 15866: train_loss=470.43835, val_loss=485.79785\n",
      "Epoch 15867: train_loss=470.40344, val_loss=485.76697\n",
      "Epoch 15868: train_loss=470.36603, val_loss=485.72293\n",
      "Epoch 15869: train_loss=470.32712, val_loss=485.68961\n",
      "Epoch 15870: train_loss=470.28561, val_loss=485.64227\n",
      "Epoch 15871: train_loss=470.24295, val_loss=485.60556\n",
      "Epoch 15872: train_loss=470.19876, val_loss=485.55508\n",
      "Epoch 15873: train_loss=470.15369, val_loss=485.51462\n",
      "Epoch 15874: train_loss=470.10886, val_loss=485.46487\n",
      "Epoch 15875: train_loss=470.06415, val_loss=485.42554\n",
      "Epoch 15876: train_loss=470.01935, val_loss=485.37906\n",
      "Epoch 15877: train_loss=469.97540, val_loss=485.34042\n",
      "Epoch 15878: train_loss=469.93210, val_loss=485.29510\n",
      "Epoch 15879: train_loss=469.88956, val_loss=485.25500\n",
      "Epoch 15880: train_loss=469.84799, val_loss=485.21298\n",
      "Epoch 15881: train_loss=469.80737, val_loss=485.17609\n",
      "Epoch 15882: train_loss=469.76752, val_loss=485.13803\n",
      "Epoch 15883: train_loss=469.72864, val_loss=485.10141\n",
      "Epoch 15884: train_loss=469.69028, val_loss=485.06265\n",
      "Epoch 15885: train_loss=469.65207, val_loss=485.02423\n",
      "Epoch 15886: train_loss=469.61444, val_loss=484.98746\n",
      "Epoch 15887: train_loss=469.57690, val_loss=484.95099\n",
      "Epoch 15888: train_loss=469.53955, val_loss=484.91583\n",
      "Epoch 15889: train_loss=469.50229, val_loss=484.87915\n",
      "Epoch 15890: train_loss=469.46533, val_loss=484.84409\n",
      "Epoch 15891: train_loss=469.42880, val_loss=484.80692\n",
      "Epoch 15892: train_loss=469.39273, val_loss=484.77396\n",
      "Epoch 15893: train_loss=469.35745, val_loss=484.73834\n",
      "Epoch 15894: train_loss=469.32297, val_loss=484.70901\n",
      "Epoch 15895: train_loss=469.29025, val_loss=484.67435\n",
      "Epoch 15896: train_loss=469.25906, val_loss=484.65125\n",
      "Epoch 15897: train_loss=469.23074, val_loss=484.62119\n",
      "Epoch 15898: train_loss=469.20605, val_loss=484.60956\n",
      "Epoch 15899: train_loss=469.18570, val_loss=484.58823\n",
      "Epoch 15900: train_loss=469.17191, val_loss=484.59216\n",
      "Epoch 15901: train_loss=469.16409, val_loss=484.58075\n",
      "Epoch 15902: train_loss=469.16483, val_loss=484.60333\n",
      "Epoch 15903: train_loss=469.17163, val_loss=484.60007\n",
      "Epoch 15904: train_loss=469.18475, val_loss=484.63318\n",
      "Epoch 15905: train_loss=469.19763, val_loss=484.62329\n",
      "Epoch 15906: train_loss=469.20770, val_loss=484.63885\n",
      "Epoch 15907: train_loss=469.19919, val_loss=484.58636\n",
      "Epoch 15908: train_loss=469.16980, val_loss=484.54654\n",
      "Epoch 15909: train_loss=469.10495, val_loss=484.43015\n",
      "Epoch 15910: train_loss=469.01248, val_loss=484.33215\n",
      "Epoch 15911: train_loss=468.89548, val_loss=484.19067\n",
      "Epoch 15912: train_loss=468.77396, val_loss=484.09137\n",
      "Epoch 15913: train_loss=468.66397, val_loss=484.00015\n",
      "Epoch 15914: train_loss=468.58081, val_loss=483.95062\n",
      "Epoch 15915: train_loss=468.52823, val_loss=483.92615\n",
      "Epoch 15916: train_loss=468.50143, val_loss=483.90979\n",
      "Epoch 15917: train_loss=468.49097, val_loss=483.91348\n",
      "Epoch 15918: train_loss=468.48508, val_loss=483.88919\n",
      "Epoch 15919: train_loss=468.47266, val_loss=483.87753\n",
      "Epoch 15920: train_loss=468.44577, val_loss=483.82214\n",
      "Epoch 15921: train_loss=468.40381, val_loss=483.78030\n",
      "Epoch 15922: train_loss=468.34854, val_loss=483.70621\n",
      "Epoch 15923: train_loss=468.28674, val_loss=483.65311\n",
      "Epoch 15924: train_loss=468.22437, val_loss=483.59039\n",
      "Epoch 15925: train_loss=468.16745, val_loss=483.54639\n",
      "Epoch 15926: train_loss=468.11890, val_loss=483.50583\n",
      "Epoch 15927: train_loss=468.07880, val_loss=483.47009\n",
      "Epoch 15928: train_loss=468.04559, val_loss=483.44385\n",
      "Epoch 15929: train_loss=468.01624, val_loss=483.41043\n",
      "Epoch 15930: train_loss=467.98825, val_loss=483.39059\n",
      "Epoch 15931: train_loss=467.95932, val_loss=483.35144\n",
      "Epoch 15932: train_loss=467.92776, val_loss=483.32550\n",
      "Epoch 15933: train_loss=467.89261, val_loss=483.27655\n",
      "Epoch 15934: train_loss=467.85403, val_loss=483.24371\n",
      "Epoch 15935: train_loss=467.81271, val_loss=483.19217\n",
      "Epoch 15936: train_loss=467.76959, val_loss=483.15662\n",
      "Epoch 15937: train_loss=467.72543, val_loss=483.10568\n",
      "Epoch 15938: train_loss=467.68130, val_loss=483.06726\n",
      "Epoch 15939: train_loss=467.63760, val_loss=483.02008\n",
      "Epoch 15940: train_loss=467.59546, val_loss=482.98227\n",
      "Epoch 15941: train_loss=467.55478, val_loss=482.94046\n",
      "Epoch 15942: train_loss=467.51508, val_loss=482.90274\n",
      "Epoch 15943: train_loss=467.47647, val_loss=482.86423\n",
      "Epoch 15944: train_loss=467.43869, val_loss=482.82523\n",
      "Epoch 15945: train_loss=467.40149, val_loss=482.78964\n",
      "Epoch 15946: train_loss=467.36456, val_loss=482.75162\n",
      "Epoch 15947: train_loss=467.32837, val_loss=482.71921\n",
      "Epoch 15948: train_loss=467.29236, val_loss=482.68039\n",
      "Epoch 15949: train_loss=467.25684, val_loss=482.64957\n",
      "Epoch 15950: train_loss=467.22186, val_loss=482.60971\n",
      "Epoch 15951: train_loss=467.18753, val_loss=482.58224\n",
      "Epoch 15952: train_loss=467.15396, val_loss=482.54385\n",
      "Epoch 15953: train_loss=467.12170, val_loss=482.52158\n",
      "Epoch 15954: train_loss=467.09021, val_loss=482.48239\n",
      "Epoch 15955: train_loss=467.05908, val_loss=482.46262\n",
      "Epoch 15956: train_loss=467.02875, val_loss=482.42224\n",
      "Epoch 15957: train_loss=466.99869, val_loss=482.40448\n",
      "Epoch 15958: train_loss=466.96851, val_loss=482.36127\n",
      "Epoch 15959: train_loss=466.93790, val_loss=482.34338\n",
      "Epoch 15960: train_loss=466.90686, val_loss=482.29742\n",
      "Epoch 15961: train_loss=466.87531, val_loss=482.27890\n",
      "Epoch 15962: train_loss=466.84253, val_loss=482.22879\n",
      "Epoch 15963: train_loss=466.80811, val_loss=482.20786\n",
      "Epoch 15964: train_loss=466.77231, val_loss=482.15256\n",
      "Epoch 15965: train_loss=466.73318, val_loss=482.12634\n",
      "Epoch 15966: train_loss=466.69247, val_loss=482.06674\n",
      "Epoch 15967: train_loss=466.64935, val_loss=482.03601\n",
      "Epoch 15968: train_loss=466.60504, val_loss=481.97501\n",
      "Epoch 15969: train_loss=466.55896, val_loss=481.94006\n",
      "Epoch 15970: train_loss=466.51199, val_loss=481.88058\n",
      "Epoch 15971: train_loss=466.46472, val_loss=481.84399\n",
      "Epoch 15972: train_loss=466.41794, val_loss=481.78848\n",
      "Epoch 15973: train_loss=466.37247, val_loss=481.75195\n",
      "Epoch 15974: train_loss=466.32828, val_loss=481.70084\n",
      "Epoch 15975: train_loss=466.28522, val_loss=481.66348\n",
      "Epoch 15976: train_loss=466.24368, val_loss=481.61725\n",
      "Epoch 15977: train_loss=466.20306, val_loss=481.58154\n",
      "Epoch 15978: train_loss=466.16367, val_loss=481.54047\n",
      "Epoch 15979: train_loss=466.12500, val_loss=481.50479\n",
      "Epoch 15980: train_loss=466.08704, val_loss=481.46533\n",
      "Epoch 15981: train_loss=466.04935, val_loss=481.42712\n",
      "Epoch 15982: train_loss=466.01227, val_loss=481.38925\n",
      "Epoch 15983: train_loss=465.97525, val_loss=481.35214\n",
      "Epoch 15984: train_loss=465.93832, val_loss=481.31754\n",
      "Epoch 15985: train_loss=465.90179, val_loss=481.28046\n",
      "Epoch 15986: train_loss=465.86542, val_loss=481.24527\n",
      "Epoch 15987: train_loss=465.82910, val_loss=481.20529\n",
      "Epoch 15988: train_loss=465.79300, val_loss=481.17020\n",
      "Epoch 15989: train_loss=465.75735, val_loss=481.13101\n",
      "Epoch 15990: train_loss=465.72226, val_loss=481.10062\n",
      "Epoch 15991: train_loss=465.68774, val_loss=481.06339\n",
      "Epoch 15992: train_loss=465.65445, val_loss=481.03851\n",
      "Epoch 15993: train_loss=465.62305, val_loss=481.00256\n",
      "Epoch 15994: train_loss=465.59464, val_loss=480.98566\n",
      "Epoch 15995: train_loss=465.56989, val_loss=480.95364\n",
      "Epoch 15996: train_loss=465.54977, val_loss=480.95319\n",
      "Epoch 15997: train_loss=465.53564, val_loss=480.93271\n",
      "Epoch 15998: train_loss=465.52945, val_loss=480.95499\n",
      "Epoch 15999: train_loss=465.53241, val_loss=480.95114\n",
      "Epoch 16000: train_loss=465.54807, val_loss=480.99789\n",
      "Epoch 16001: train_loss=465.57050, val_loss=481.00824\n",
      "Epoch 16002: train_loss=465.60547, val_loss=481.07040\n",
      "Epoch 16003: train_loss=465.63721, val_loss=481.07208\n",
      "Epoch 16004: train_loss=465.66821, val_loss=481.10376\n",
      "Epoch 16005: train_loss=465.66623, val_loss=481.03632\n",
      "Epoch 16006: train_loss=465.63309, val_loss=480.97659\n",
      "Epoch 16007: train_loss=465.54236, val_loss=480.81741\n",
      "Epoch 16008: train_loss=465.41522, val_loss=480.68784\n",
      "Epoch 16009: train_loss=465.26031, val_loss=480.52145\n",
      "Epoch 16010: train_loss=465.11444, val_loss=480.42038\n",
      "Epoch 16011: train_loss=465.00119, val_loss=480.34619\n",
      "Epoch 16012: train_loss=464.93350, val_loss=480.31787\n",
      "Epoch 16013: train_loss=464.90793, val_loss=480.32709\n",
      "Epoch 16014: train_loss=464.90958, val_loss=480.32440\n",
      "Epoch 16015: train_loss=464.91968, val_loss=480.34329\n",
      "Epoch 16016: train_loss=464.91998, val_loss=480.30707\n",
      "Epoch 16017: train_loss=464.90067, val_loss=480.28244\n",
      "Epoch 16018: train_loss=464.85620, val_loss=480.20065\n",
      "Epoch 16019: train_loss=464.79282, val_loss=480.14203\n",
      "Epoch 16020: train_loss=464.71991, val_loss=480.05930\n",
      "Epoch 16021: train_loss=464.64969, val_loss=480.00879\n",
      "Epoch 16022: train_loss=464.59024, val_loss=479.96378\n",
      "Epoch 16023: train_loss=464.54602, val_loss=479.93387\n",
      "Epoch 16024: train_loss=464.51587, val_loss=479.91992\n",
      "Epoch 16025: train_loss=464.49466, val_loss=479.89362\n",
      "Epoch 16026: train_loss=464.47610, val_loss=479.88318\n",
      "Epoch 16027: train_loss=464.45428, val_loss=479.84244\n",
      "Epoch 16028: train_loss=464.42505, val_loss=479.81778\n",
      "Epoch 16029: train_loss=464.38782, val_loss=479.76282\n",
      "Epoch 16030: train_loss=464.34421, val_loss=479.72589\n",
      "Epoch 16031: train_loss=464.29706, val_loss=479.67017\n",
      "Epoch 16032: train_loss=464.24994, val_loss=479.63089\n",
      "Epoch 16033: train_loss=464.20557, val_loss=479.58646\n",
      "Epoch 16034: train_loss=464.16525, val_loss=479.55145\n",
      "Epoch 16035: train_loss=464.12894, val_loss=479.52063\n",
      "Epoch 16036: train_loss=464.09576, val_loss=479.48779\n",
      "Epoch 16037: train_loss=464.06491, val_loss=479.46243\n",
      "Epoch 16038: train_loss=464.03479, val_loss=479.42630\n",
      "Epoch 16039: train_loss=464.00430, val_loss=479.40167\n",
      "Epoch 16040: train_loss=463.97357, val_loss=479.36322\n",
      "Epoch 16041: train_loss=463.94156, val_loss=479.33856\n",
      "Epoch 16042: train_loss=463.90848, val_loss=479.29788\n",
      "Epoch 16043: train_loss=463.87387, val_loss=479.26950\n",
      "Epoch 16044: train_loss=463.83844, val_loss=479.22565\n",
      "Epoch 16045: train_loss=463.80191, val_loss=479.19382\n",
      "Epoch 16046: train_loss=463.76492, val_loss=479.15048\n",
      "Epoch 16047: train_loss=463.72769, val_loss=479.11914\n",
      "Epoch 16048: train_loss=463.69052, val_loss=479.07953\n",
      "Epoch 16049: train_loss=463.65405, val_loss=479.04758\n",
      "Epoch 16050: train_loss=463.61783, val_loss=479.00946\n",
      "Epoch 16051: train_loss=463.58231, val_loss=478.97592\n",
      "Epoch 16052: train_loss=463.54742, val_loss=478.94061\n",
      "Epoch 16053: train_loss=463.51291, val_loss=478.90778\n",
      "Epoch 16054: train_loss=463.47867, val_loss=478.87482\n",
      "Epoch 16055: train_loss=463.44492, val_loss=478.84067\n",
      "Epoch 16056: train_loss=463.41144, val_loss=478.80762\n",
      "Epoch 16057: train_loss=463.37802, val_loss=478.77161\n",
      "Epoch 16058: train_loss=463.34515, val_loss=478.74088\n",
      "Epoch 16059: train_loss=463.31232, val_loss=478.70636\n",
      "Epoch 16060: train_loss=463.27982, val_loss=478.67899\n",
      "Epoch 16061: train_loss=463.24792, val_loss=478.64328\n",
      "Epoch 16062: train_loss=463.21646, val_loss=478.61575\n",
      "Epoch 16063: train_loss=463.18530, val_loss=478.57889\n",
      "Epoch 16064: train_loss=463.15518, val_loss=478.55475\n",
      "Epoch 16065: train_loss=463.12579, val_loss=478.52008\n",
      "Epoch 16066: train_loss=463.09781, val_loss=478.50113\n",
      "Epoch 16067: train_loss=463.07071, val_loss=478.46722\n",
      "Epoch 16068: train_loss=463.04529, val_loss=478.45279\n",
      "Epoch 16069: train_loss=463.02100, val_loss=478.41907\n",
      "Epoch 16070: train_loss=462.99893, val_loss=478.40894\n",
      "Epoch 16071: train_loss=462.97672, val_loss=478.37531\n",
      "Epoch 16072: train_loss=462.95560, val_loss=478.36807\n",
      "Epoch 16073: train_loss=462.93359, val_loss=478.33200\n",
      "Epoch 16074: train_loss=462.91254, val_loss=478.32315\n",
      "Epoch 16075: train_loss=462.88831, val_loss=478.28079\n",
      "Epoch 16076: train_loss=462.86377, val_loss=478.26752\n",
      "Epoch 16077: train_loss=462.83408, val_loss=478.21921\n",
      "Epoch 16078: train_loss=462.80234, val_loss=478.20059\n",
      "Epoch 16079: train_loss=462.76505, val_loss=478.14291\n",
      "Epoch 16080: train_loss=462.72467, val_loss=478.11349\n",
      "Epoch 16081: train_loss=462.67926, val_loss=478.04706\n",
      "Epoch 16082: train_loss=462.63077, val_loss=478.01041\n",
      "Epoch 16083: train_loss=462.57962, val_loss=477.94580\n",
      "Epoch 16084: train_loss=462.52817, val_loss=477.90799\n",
      "Epoch 16085: train_loss=462.47784, val_loss=477.85089\n",
      "Epoch 16086: train_loss=462.43011, val_loss=477.81342\n",
      "Epoch 16087: train_loss=462.38556, val_loss=477.76620\n",
      "Epoch 16088: train_loss=462.34442, val_loss=477.73257\n",
      "Epoch 16089: train_loss=462.30646, val_loss=477.69617\n",
      "Epoch 16090: train_loss=462.27103, val_loss=477.66376\n",
      "Epoch 16091: train_loss=462.23776, val_loss=477.63278\n",
      "Epoch 16092: train_loss=462.20593, val_loss=477.59836\n",
      "Epoch 16093: train_loss=462.17514, val_loss=477.57178\n",
      "Epoch 16094: train_loss=462.14520, val_loss=477.53821\n",
      "Epoch 16095: train_loss=462.11566, val_loss=477.51578\n",
      "Epoch 16096: train_loss=462.08655, val_loss=477.48093\n",
      "Epoch 16097: train_loss=462.05804, val_loss=477.45953\n",
      "Epoch 16098: train_loss=462.03030, val_loss=477.42331\n",
      "Epoch 16099: train_loss=462.00323, val_loss=477.40668\n",
      "Epoch 16100: train_loss=461.97733, val_loss=477.37213\n",
      "Epoch 16101: train_loss=461.95221, val_loss=477.35928\n",
      "Epoch 16102: train_loss=461.92798, val_loss=477.32385\n",
      "Epoch 16103: train_loss=461.90466, val_loss=477.31491\n",
      "Epoch 16104: train_loss=461.88245, val_loss=477.27921\n",
      "Epoch 16105: train_loss=461.86105, val_loss=477.27536\n",
      "Epoch 16106: train_loss=461.84058, val_loss=477.23923\n",
      "Epoch 16107: train_loss=461.82086, val_loss=477.23734\n",
      "Epoch 16108: train_loss=461.80075, val_loss=477.19666\n",
      "Epoch 16109: train_loss=461.78061, val_loss=477.19342\n",
      "Epoch 16110: train_loss=461.75650, val_loss=477.14658\n",
      "Epoch 16111: train_loss=461.73132, val_loss=477.13763\n",
      "Epoch 16112: train_loss=461.69940, val_loss=477.07944\n",
      "Epoch 16113: train_loss=461.66467, val_loss=477.05685\n",
      "Epoch 16114: train_loss=461.62152, val_loss=476.98486\n",
      "Epoch 16115: train_loss=461.57410, val_loss=476.94836\n",
      "Epoch 16116: train_loss=461.51923, val_loss=476.87286\n",
      "Epoch 16117: train_loss=461.46191, val_loss=476.83038\n",
      "Epoch 16118: train_loss=461.40320, val_loss=476.76334\n",
      "Epoch 16119: train_loss=461.34821, val_loss=476.72189\n",
      "Epoch 16120: train_loss=461.29810, val_loss=476.67020\n",
      "Epoch 16121: train_loss=461.25418, val_loss=476.63385\n",
      "Epoch 16122: train_loss=461.21628, val_loss=476.59991\n",
      "Epoch 16123: train_loss=461.18350, val_loss=476.56833\n",
      "Epoch 16124: train_loss=461.15451, val_loss=476.54803\n",
      "Epoch 16125: train_loss=461.12781, val_loss=476.51688\n",
      "Epoch 16126: train_loss=461.10275, val_loss=476.50266\n",
      "Epoch 16127: train_loss=461.07840, val_loss=476.46722\n",
      "Epoch 16128: train_loss=461.05429, val_loss=476.45389\n",
      "Epoch 16129: train_loss=461.02951, val_loss=476.41464\n",
      "Epoch 16130: train_loss=461.00482, val_loss=476.40228\n",
      "Epoch 16131: train_loss=460.97873, val_loss=476.36017\n",
      "Epoch 16132: train_loss=460.95145, val_loss=476.34760\n",
      "Epoch 16133: train_loss=460.92285, val_loss=476.30252\n",
      "Epoch 16134: train_loss=460.89328, val_loss=476.28705\n",
      "Epoch 16135: train_loss=460.86185, val_loss=476.23804\n",
      "Epoch 16136: train_loss=460.82959, val_loss=476.22070\n",
      "Epoch 16137: train_loss=460.79593, val_loss=476.16995\n",
      "Epoch 16138: train_loss=460.76160, val_loss=476.15021\n",
      "Epoch 16139: train_loss=460.72556, val_loss=476.09674\n",
      "Epoch 16140: train_loss=460.68875, val_loss=476.07346\n",
      "Epoch 16141: train_loss=460.65106, val_loss=476.01883\n",
      "Epoch 16142: train_loss=460.61292, val_loss=475.99408\n",
      "Epoch 16143: train_loss=460.57425, val_loss=475.94208\n",
      "Epoch 16144: train_loss=460.53586, val_loss=475.91608\n",
      "Epoch 16145: train_loss=460.49771, val_loss=475.86475\n",
      "Epoch 16146: train_loss=460.45984, val_loss=475.83624\n",
      "Epoch 16147: train_loss=460.42227, val_loss=475.78650\n",
      "Epoch 16148: train_loss=460.38455, val_loss=475.75757\n",
      "Epoch 16149: train_loss=460.34775, val_loss=475.71310\n",
      "Epoch 16150: train_loss=460.31125, val_loss=475.68515\n",
      "Epoch 16151: train_loss=460.27557, val_loss=475.64456\n",
      "Epoch 16152: train_loss=460.24042, val_loss=475.61514\n",
      "Epoch 16153: train_loss=460.20599, val_loss=475.57507\n",
      "Epoch 16154: train_loss=460.17200, val_loss=475.54446\n",
      "Epoch 16155: train_loss=460.13843, val_loss=475.50580\n",
      "Epoch 16156: train_loss=460.10501, val_loss=475.47562\n",
      "Epoch 16157: train_loss=460.07181, val_loss=475.43820\n",
      "Epoch 16158: train_loss=460.03894, val_loss=475.40894\n",
      "Epoch 16159: train_loss=460.00632, val_loss=475.37311\n",
      "Epoch 16160: train_loss=459.97369, val_loss=475.34540\n",
      "Epoch 16161: train_loss=459.94135, val_loss=475.30975\n",
      "Epoch 16162: train_loss=459.90973, val_loss=475.28235\n",
      "Epoch 16163: train_loss=459.87851, val_loss=475.24454\n",
      "Epoch 16164: train_loss=459.84824, val_loss=475.22012\n",
      "Epoch 16165: train_loss=459.81888, val_loss=475.18338\n",
      "Epoch 16166: train_loss=459.79123, val_loss=475.16647\n",
      "Epoch 16167: train_loss=459.76556, val_loss=475.13266\n",
      "Epoch 16168: train_loss=459.74289, val_loss=475.12576\n",
      "Epoch 16169: train_loss=459.72333, val_loss=475.09512\n",
      "Epoch 16170: train_loss=459.70807, val_loss=475.10101\n",
      "Epoch 16171: train_loss=459.69727, val_loss=475.07553\n",
      "Epoch 16172: train_loss=459.69263, val_loss=475.09711\n",
      "Epoch 16173: train_loss=459.69272, val_loss=475.07855\n",
      "Epoch 16174: train_loss=459.70056, val_loss=475.11594\n",
      "Epoch 16175: train_loss=459.70984, val_loss=475.10025\n",
      "Epoch 16176: train_loss=459.72400, val_loss=475.14020\n",
      "Epoch 16177: train_loss=459.72821, val_loss=475.10370\n",
      "Epoch 16178: train_loss=459.72635, val_loss=475.11273\n",
      "Epoch 16179: train_loss=459.69940, val_loss=475.02658\n",
      "Epoch 16180: train_loss=459.65265, val_loss=474.98077\n",
      "Epoch 16181: train_loss=459.57422, val_loss=474.84988\n",
      "Epoch 16182: train_loss=459.47827, val_loss=474.76950\n",
      "Epoch 16183: train_loss=459.36987, val_loss=474.64337\n",
      "Epoch 16184: train_loss=459.26633, val_loss=474.57278\n",
      "Epoch 16185: train_loss=459.17993, val_loss=474.50229\n",
      "Epoch 16186: train_loss=459.11914, val_loss=474.46545\n",
      "Epoch 16187: train_loss=459.08328, val_loss=474.45239\n",
      "Epoch 16188: train_loss=459.06644, val_loss=474.43353\n",
      "Epoch 16189: train_loss=459.06027, val_loss=474.44400\n",
      "Epoch 16190: train_loss=459.05466, val_loss=474.41232\n",
      "Epoch 16191: train_loss=459.04239, val_loss=474.40707\n",
      "Epoch 16192: train_loss=459.01715, val_loss=474.34811\n",
      "Epoch 16193: train_loss=458.98022, val_loss=474.31897\n",
      "Epoch 16194: train_loss=458.93185, val_loss=474.24686\n",
      "Epoch 16195: train_loss=458.87811, val_loss=474.20636\n",
      "Epoch 16196: train_loss=458.82303, val_loss=474.14203\n",
      "Epoch 16197: train_loss=458.77136, val_loss=474.10242\n",
      "Epoch 16198: train_loss=458.72586, val_loss=474.05795\n",
      "Epoch 16199: train_loss=458.68710, val_loss=474.02362\n",
      "Epoch 16200: train_loss=458.65381, val_loss=473.99625\n",
      "Epoch 16201: train_loss=458.62436, val_loss=473.96252\n",
      "Epoch 16202: train_loss=458.59766, val_loss=473.94266\n",
      "Epoch 16203: train_loss=458.57184, val_loss=473.90454\n",
      "Epoch 16204: train_loss=458.54584, val_loss=473.88690\n",
      "Epoch 16205: train_loss=458.51877, val_loss=473.84448\n",
      "Epoch 16206: train_loss=458.48929, val_loss=473.82535\n",
      "Epoch 16207: train_loss=458.45795, val_loss=473.77866\n",
      "Epoch 16208: train_loss=458.42438, val_loss=473.75446\n",
      "Epoch 16209: train_loss=458.38867, val_loss=473.70505\n",
      "Epoch 16210: train_loss=458.35159, val_loss=473.67847\n",
      "Epoch 16211: train_loss=458.31360, val_loss=473.63089\n",
      "Epoch 16212: train_loss=458.27515, val_loss=473.60059\n",
      "Epoch 16213: train_loss=458.23672, val_loss=473.55475\n",
      "Epoch 16214: train_loss=458.19901, val_loss=473.52240\n",
      "Epoch 16215: train_loss=458.16193, val_loss=473.48077\n",
      "Epoch 16216: train_loss=458.12579, val_loss=473.44809\n",
      "Epoch 16217: train_loss=458.09055, val_loss=473.41141\n",
      "Epoch 16218: train_loss=458.05597, val_loss=473.37869\n",
      "Epoch 16219: train_loss=458.02231, val_loss=473.34518\n",
      "Epoch 16220: train_loss=457.98889, val_loss=473.31110\n",
      "Epoch 16221: train_loss=457.95593, val_loss=473.28024\n",
      "Epoch 16222: train_loss=457.92331, val_loss=473.24548\n",
      "Epoch 16223: train_loss=457.89096, val_loss=473.21710\n",
      "Epoch 16224: train_loss=457.85870, val_loss=473.18146\n",
      "Epoch 16225: train_loss=457.82669, val_loss=473.15530\n",
      "Epoch 16226: train_loss=457.79514, val_loss=473.11838\n",
      "Epoch 16227: train_loss=457.76422, val_loss=473.09479\n",
      "Epoch 16228: train_loss=457.73373, val_loss=473.05710\n",
      "Epoch 16229: train_loss=457.70419, val_loss=473.03732\n",
      "Epoch 16230: train_loss=457.67529, val_loss=472.99933\n",
      "Epoch 16231: train_loss=457.64737, val_loss=472.98361\n",
      "Epoch 16232: train_loss=457.62061, val_loss=472.94528\n",
      "Epoch 16233: train_loss=457.59521, val_loss=472.93460\n",
      "Epoch 16234: train_loss=457.57083, val_loss=472.89670\n",
      "Epoch 16235: train_loss=457.54858, val_loss=472.89337\n",
      "Epoch 16236: train_loss=457.52792, val_loss=472.85608\n",
      "Epoch 16237: train_loss=457.50937, val_loss=472.85828\n",
      "Epoch 16238: train_loss=457.49097, val_loss=472.81952\n",
      "Epoch 16239: train_loss=457.47412, val_loss=472.82608\n",
      "Epoch 16240: train_loss=457.45599, val_loss=472.78299\n",
      "Epoch 16241: train_loss=457.43723, val_loss=472.78693\n",
      "Epoch 16242: train_loss=457.41455, val_loss=472.73413\n",
      "Epoch 16243: train_loss=457.38904, val_loss=472.72925\n",
      "Epoch 16244: train_loss=457.35663, val_loss=472.66492\n",
      "Epoch 16245: train_loss=457.31995, val_loss=472.64795\n",
      "Epoch 16246: train_loss=457.27524, val_loss=472.57349\n",
      "Epoch 16247: train_loss=457.22641, val_loss=472.54205\n",
      "Epoch 16248: train_loss=457.17151, val_loss=472.46011\n",
      "Epoch 16249: train_loss=457.11310, val_loss=472.41946\n",
      "Epoch 16250: train_loss=457.05377, val_loss=472.34671\n",
      "Epoch 16251: train_loss=456.99710, val_loss=472.30682\n",
      "Epoch 16252: train_loss=456.94431, val_loss=472.25040\n",
      "Epoch 16253: train_loss=456.89743, val_loss=472.21216\n",
      "Epoch 16254: train_loss=456.85571, val_loss=472.17117\n",
      "Epoch 16255: train_loss=456.81940, val_loss=472.13721\n",
      "Epoch 16256: train_loss=456.78683, val_loss=472.11255\n",
      "Epoch 16257: train_loss=456.75739, val_loss=472.07990\n",
      "Epoch 16258: train_loss=456.73004, val_loss=472.06174\n",
      "Epoch 16259: train_loss=456.70374, val_loss=472.02408\n",
      "Epoch 16260: train_loss=456.67899, val_loss=472.00964\n",
      "Epoch 16261: train_loss=456.65439, val_loss=471.97043\n",
      "Epoch 16262: train_loss=456.63004, val_loss=471.96152\n",
      "Epoch 16263: train_loss=456.60425, val_loss=471.91864\n",
      "Epoch 16264: train_loss=456.57767, val_loss=471.90652\n",
      "Epoch 16265: train_loss=456.54883, val_loss=471.85483\n",
      "Epoch 16266: train_loss=456.51797, val_loss=471.83850\n",
      "Epoch 16267: train_loss=456.48447, val_loss=471.78494\n",
      "Epoch 16268: train_loss=456.44983, val_loss=471.76721\n",
      "Epoch 16269: train_loss=456.41299, val_loss=471.71271\n",
      "Epoch 16270: train_loss=456.37595, val_loss=471.69098\n",
      "Epoch 16271: train_loss=456.33749, val_loss=471.63562\n",
      "Epoch 16272: train_loss=456.29953, val_loss=471.61264\n",
      "Epoch 16273: train_loss=456.26035, val_loss=471.55939\n",
      "Epoch 16274: train_loss=456.22168, val_loss=471.53458\n",
      "Epoch 16275: train_loss=456.18222, val_loss=471.48279\n",
      "Epoch 16276: train_loss=456.14401, val_loss=471.45554\n",
      "Epoch 16277: train_loss=456.10538, val_loss=471.40530\n",
      "Epoch 16278: train_loss=456.06754, val_loss=471.37796\n",
      "Epoch 16279: train_loss=456.02972, val_loss=471.33066\n",
      "Epoch 16280: train_loss=455.99234, val_loss=471.30200\n",
      "Epoch 16281: train_loss=455.95514, val_loss=471.25742\n",
      "Epoch 16282: train_loss=455.91861, val_loss=471.22729\n",
      "Epoch 16283: train_loss=455.88217, val_loss=471.18533\n",
      "Epoch 16284: train_loss=455.84628, val_loss=471.15466\n",
      "Epoch 16285: train_loss=455.81082, val_loss=471.11615\n",
      "Epoch 16286: train_loss=455.77560, val_loss=471.08423\n",
      "Epoch 16287: train_loss=455.74078, val_loss=471.04770\n",
      "Epoch 16288: train_loss=455.70636, val_loss=471.01553\n",
      "Epoch 16289: train_loss=455.67194, val_loss=470.98227\n",
      "Epoch 16290: train_loss=455.63791, val_loss=470.94910\n",
      "Epoch 16291: train_loss=455.60391, val_loss=470.91577\n",
      "Epoch 16292: train_loss=455.56973, val_loss=470.88055\n",
      "Epoch 16293: train_loss=455.53595, val_loss=470.84787\n",
      "Epoch 16294: train_loss=455.50220, val_loss=470.81223\n",
      "Epoch 16295: train_loss=455.46863, val_loss=470.78165\n",
      "Epoch 16296: train_loss=455.43539, val_loss=470.74557\n",
      "Epoch 16297: train_loss=455.40234, val_loss=470.71777\n",
      "Epoch 16298: train_loss=455.37003, val_loss=470.68088\n",
      "Epoch 16299: train_loss=455.33823, val_loss=470.65686\n",
      "Epoch 16300: train_loss=455.30743, val_loss=470.61972\n",
      "Epoch 16301: train_loss=455.27780, val_loss=470.60181\n",
      "Epoch 16302: train_loss=455.25018, val_loss=470.56564\n",
      "Epoch 16303: train_loss=455.22549, val_loss=470.55746\n",
      "Epoch 16304: train_loss=455.20425, val_loss=470.52530\n",
      "Epoch 16305: train_loss=455.18915, val_loss=470.53830\n",
      "Epoch 16306: train_loss=455.18207, val_loss=470.52252\n",
      "Epoch 16307: train_loss=455.18921, val_loss=470.57523\n",
      "Epoch 16308: train_loss=455.21112, val_loss=470.58563\n",
      "Epoch 16309: train_loss=455.25525, val_loss=470.68643\n",
      "Epoch 16310: train_loss=455.31445, val_loss=470.72043\n",
      "Epoch 16311: train_loss=455.39523, val_loss=470.84683\n",
      "Epoch 16312: train_loss=455.46622, val_loss=470.84619\n",
      "Epoch 16313: train_loss=455.52216, val_loss=470.89093\n",
      "Epoch 16314: train_loss=455.50391, val_loss=470.74179\n",
      "Epoch 16315: train_loss=455.41696, val_loss=470.61362\n",
      "Epoch 16316: train_loss=455.23456, val_loss=470.34546\n",
      "Epoch 16317: train_loss=455.01862, val_loss=470.16956\n",
      "Epoch 16318: train_loss=454.81189, val_loss=470.00797\n",
      "Epoch 16319: train_loss=454.67209, val_loss=469.95602\n",
      "Epoch 16320: train_loss=454.61661, val_loss=469.98172\n",
      "Epoch 16321: train_loss=454.63089, val_loss=470.00638\n",
      "Epoch 16322: train_loss=454.67715, val_loss=470.07333\n",
      "Epoch 16323: train_loss=454.71167, val_loss=470.03339\n",
      "Epoch 16324: train_loss=454.70755, val_loss=470.00964\n",
      "Epoch 16325: train_loss=454.64847, val_loss=469.88232\n",
      "Epoch 16326: train_loss=454.55493, val_loss=469.80093\n",
      "Epoch 16327: train_loss=454.44879, val_loss=469.69818\n",
      "Epoch 16328: train_loss=454.36172, val_loss=469.65121\n",
      "Epoch 16329: train_loss=454.30759, val_loss=469.63535\n",
      "Epoch 16330: train_loss=454.28656, val_loss=469.61938\n",
      "Epoch 16331: train_loss=454.28357, val_loss=469.63278\n",
      "Epoch 16332: train_loss=454.27954, val_loss=469.59207\n",
      "Epoch 16333: train_loss=454.26227, val_loss=469.57678\n",
      "Epoch 16334: train_loss=454.22354, val_loss=469.50275\n",
      "Epoch 16335: train_loss=454.16989, val_loss=469.45984\n",
      "Epoch 16336: train_loss=454.10770, val_loss=469.38858\n",
      "Epoch 16337: train_loss=454.04965, val_loss=469.34634\n",
      "Epoch 16338: train_loss=454.00180, val_loss=469.30942\n",
      "Epoch 16339: train_loss=453.96698, val_loss=469.27792\n",
      "Epoch 16340: train_loss=453.94183, val_loss=469.26569\n",
      "Epoch 16341: train_loss=453.91949, val_loss=469.22830\n",
      "Epoch 16342: train_loss=453.89511, val_loss=469.21246\n",
      "Epoch 16343: train_loss=453.86420, val_loss=469.15952\n",
      "Epoch 16344: train_loss=453.82669, val_loss=469.12875\n",
      "Epoch 16345: train_loss=453.78381, val_loss=469.07242\n",
      "Epoch 16346: train_loss=453.73975, val_loss=469.03714\n",
      "Epoch 16347: train_loss=453.69690, val_loss=468.99435\n",
      "Epoch 16348: train_loss=453.65747, val_loss=468.96063\n",
      "Epoch 16349: train_loss=453.62222, val_loss=468.93130\n",
      "Epoch 16350: train_loss=453.59027, val_loss=468.89502\n",
      "Epoch 16351: train_loss=453.56003, val_loss=468.87149\n",
      "Epoch 16352: train_loss=453.52991, val_loss=468.83063\n",
      "Epoch 16353: train_loss=453.49832, val_loss=468.80740\n",
      "Epoch 16354: train_loss=453.46469, val_loss=468.76242\n",
      "Epoch 16355: train_loss=453.42889, val_loss=468.73380\n",
      "Epoch 16356: train_loss=453.39145, val_loss=468.68619\n",
      "Epoch 16357: train_loss=453.35336, val_loss=468.65326\n",
      "Epoch 16358: train_loss=453.31522, val_loss=468.61081\n",
      "Epoch 16359: train_loss=453.27777, val_loss=468.57779\n",
      "Epoch 16360: train_loss=453.24142, val_loss=468.54211\n",
      "Epoch 16361: train_loss=453.20615, val_loss=468.50552\n",
      "Epoch 16362: train_loss=453.17200, val_loss=468.47318\n",
      "Epoch 16363: train_loss=453.13837, val_loss=468.43448\n",
      "Epoch 16364: train_loss=453.10504, val_loss=468.40573\n",
      "Epoch 16365: train_loss=453.07150, val_loss=468.36627\n",
      "Epoch 16366: train_loss=453.03802, val_loss=468.33823\n",
      "Epoch 16367: train_loss=453.00415, val_loss=468.29489\n",
      "Epoch 16368: train_loss=452.96985, val_loss=468.26660\n",
      "Epoch 16369: train_loss=452.93549, val_loss=468.22391\n",
      "Epoch 16370: train_loss=452.90079, val_loss=468.19702\n",
      "Epoch 16371: train_loss=452.86569, val_loss=468.15424\n",
      "Epoch 16372: train_loss=452.83047, val_loss=468.12589\n",
      "Epoch 16373: train_loss=452.79498, val_loss=468.08118\n",
      "Epoch 16374: train_loss=452.75882, val_loss=468.05078\n",
      "Epoch 16375: train_loss=452.72229, val_loss=468.00748\n",
      "Epoch 16376: train_loss=452.68539, val_loss=467.97546\n",
      "Epoch 16377: train_loss=452.64835, val_loss=467.93301\n",
      "Epoch 16378: train_loss=452.61157, val_loss=467.89819\n",
      "Epoch 16379: train_loss=452.57492, val_loss=467.85785\n",
      "Epoch 16380: train_loss=452.53864, val_loss=467.82248\n",
      "Epoch 16381: train_loss=452.50250, val_loss=467.78558\n",
      "Epoch 16382: train_loss=452.46661, val_loss=467.74933\n",
      "Epoch 16383: train_loss=452.43088, val_loss=467.71365\n",
      "Epoch 16384: train_loss=452.39526, val_loss=467.67447\n",
      "Epoch 16385: train_loss=452.35962, val_loss=467.63968\n",
      "Epoch 16386: train_loss=452.32413, val_loss=467.60040\n",
      "Epoch 16387: train_loss=452.28876, val_loss=467.56732\n",
      "Epoch 16388: train_loss=452.25339, val_loss=467.52762\n",
      "Epoch 16389: train_loss=452.21826, val_loss=467.49545\n",
      "Epoch 16390: train_loss=452.18314, val_loss=467.45392\n",
      "Epoch 16391: train_loss=452.14804, val_loss=467.42346\n",
      "Epoch 16392: train_loss=452.11307, val_loss=467.38141\n",
      "Epoch 16393: train_loss=452.07831, val_loss=467.35333\n",
      "Epoch 16394: train_loss=452.04373, val_loss=467.31097\n",
      "Epoch 16395: train_loss=452.00946, val_loss=467.28439\n",
      "Epoch 16396: train_loss=451.97552, val_loss=467.23978\n",
      "Epoch 16397: train_loss=451.94174, val_loss=467.21506\n",
      "Epoch 16398: train_loss=451.90845, val_loss=467.17029\n",
      "Epoch 16399: train_loss=451.87540, val_loss=467.14932\n",
      "Epoch 16400: train_loss=451.84323, val_loss=467.10486\n",
      "Epoch 16401: train_loss=451.81168, val_loss=467.08755\n",
      "Epoch 16402: train_loss=451.78137, val_loss=467.04260\n",
      "Epoch 16403: train_loss=451.75259, val_loss=467.03064\n",
      "Epoch 16404: train_loss=451.72580, val_loss=466.98676\n",
      "Epoch 16405: train_loss=451.70132, val_loss=466.98276\n",
      "Epoch 16406: train_loss=451.67889, val_loss=466.94000\n",
      "Epoch 16407: train_loss=451.65961, val_loss=466.94635\n",
      "Epoch 16408: train_loss=451.64240, val_loss=466.90250\n",
      "Epoch 16409: train_loss=451.62659, val_loss=466.91553\n",
      "Epoch 16410: train_loss=451.61160, val_loss=466.86856\n",
      "Epoch 16411: train_loss=451.59637, val_loss=466.88196\n",
      "Epoch 16412: train_loss=451.57764, val_loss=466.82181\n",
      "Epoch 16413: train_loss=451.55298, val_loss=466.82047\n",
      "Epoch 16414: train_loss=451.51822, val_loss=466.73996\n",
      "Epoch 16415: train_loss=451.47385, val_loss=466.71463\n",
      "Epoch 16416: train_loss=451.41602, val_loss=466.61700\n",
      "Epoch 16417: train_loss=451.35059, val_loss=466.57089\n",
      "Epoch 16418: train_loss=451.27808, val_loss=466.47446\n",
      "Epoch 16419: train_loss=451.20734, val_loss=466.42334\n",
      "Epoch 16420: train_loss=451.13980, val_loss=466.34760\n",
      "Epoch 16421: train_loss=451.08029, val_loss=466.30371\n",
      "Epoch 16422: train_loss=451.02921, val_loss=466.25552\n",
      "Epoch 16423: train_loss=450.98645, val_loss=466.21817\n",
      "Epoch 16424: train_loss=450.95068, val_loss=466.19046\n",
      "Epoch 16425: train_loss=450.92020, val_loss=466.15332\n",
      "Epoch 16426: train_loss=450.89252, val_loss=466.13583\n",
      "Epoch 16427: train_loss=450.86594, val_loss=466.09659\n",
      "Epoch 16428: train_loss=450.83917, val_loss=466.08417\n",
      "Epoch 16429: train_loss=450.81143, val_loss=466.04050\n",
      "Epoch 16430: train_loss=450.78235, val_loss=466.02527\n",
      "Epoch 16431: train_loss=450.75058, val_loss=465.97479\n",
      "Epoch 16432: train_loss=450.71735, val_loss=465.95502\n",
      "Epoch 16433: train_loss=450.68079, val_loss=465.89999\n",
      "Epoch 16434: train_loss=450.64261, val_loss=465.87592\n",
      "Epoch 16435: train_loss=450.60178, val_loss=465.81891\n",
      "Epoch 16436: train_loss=450.56076, val_loss=465.79004\n",
      "Epoch 16437: train_loss=450.51822, val_loss=465.73340\n",
      "Epoch 16438: train_loss=450.47610, val_loss=465.70346\n",
      "Epoch 16439: train_loss=450.43320, val_loss=465.65103\n",
      "Epoch 16440: train_loss=450.39102, val_loss=465.61948\n",
      "Epoch 16441: train_loss=450.34900, val_loss=465.56979\n",
      "Epoch 16442: train_loss=450.30795, val_loss=465.53577\n",
      "Epoch 16443: train_loss=450.26764, val_loss=465.48932\n",
      "Epoch 16444: train_loss=450.22821, val_loss=465.45523\n",
      "Epoch 16445: train_loss=450.18948, val_loss=465.41403\n",
      "Epoch 16446: train_loss=450.15152, val_loss=465.37881\n",
      "Epoch 16447: train_loss=450.11417, val_loss=465.33997\n",
      "Epoch 16448: train_loss=450.07730, val_loss=465.30270\n",
      "Epoch 16449: train_loss=450.04068, val_loss=465.26596\n",
      "Epoch 16450: train_loss=450.00439, val_loss=465.22849\n",
      "Epoch 16451: train_loss=449.96823, val_loss=465.19373\n",
      "Epoch 16452: train_loss=449.93222, val_loss=465.15414\n",
      "Epoch 16453: train_loss=449.89651, val_loss=465.12054\n",
      "Epoch 16454: train_loss=449.86093, val_loss=465.08109\n",
      "Epoch 16455: train_loss=449.82581, val_loss=465.05154\n",
      "Epoch 16456: train_loss=449.79120, val_loss=465.01239\n",
      "Epoch 16457: train_loss=449.75766, val_loss=464.98605\n",
      "Epoch 16458: train_loss=449.72519, val_loss=464.94553\n",
      "Epoch 16459: train_loss=449.69501, val_loss=464.92651\n",
      "Epoch 16460: train_loss=449.66687, val_loss=464.88824\n",
      "Epoch 16461: train_loss=449.64212, val_loss=464.88181\n",
      "Epoch 16462: train_loss=449.62076, val_loss=464.84814\n",
      "Epoch 16463: train_loss=449.60458, val_loss=464.85803\n",
      "Epoch 16464: train_loss=449.59421, val_loss=464.82971\n",
      "Epoch 16465: train_loss=449.58990, val_loss=464.85944\n",
      "Epoch 16466: train_loss=449.59180, val_loss=464.83615\n",
      "Epoch 16467: train_loss=449.59857, val_loss=464.88028\n",
      "Epoch 16468: train_loss=449.60678, val_loss=464.85281\n",
      "Epoch 16469: train_loss=449.61639, val_loss=464.89102\n",
      "Epoch 16470: train_loss=449.61371, val_loss=464.83087\n",
      "Epoch 16471: train_loss=449.59750, val_loss=464.82605\n",
      "Epoch 16472: train_loss=449.54971, val_loss=464.71201\n",
      "Epoch 16473: train_loss=449.47800, val_loss=464.64966\n",
      "Epoch 16474: train_loss=449.37711, val_loss=464.50201\n",
      "Epoch 16475: train_loss=449.26529, val_loss=464.41370\n",
      "Epoch 16476: train_loss=449.15201, val_loss=464.29834\n",
      "Epoch 16477: train_loss=449.05762, val_loss=464.23795\n",
      "Epoch 16478: train_loss=448.98792, val_loss=464.19138\n",
      "Epoch 16479: train_loss=448.94440, val_loss=464.16281\n",
      "Epoch 16480: train_loss=448.92169, val_loss=464.16397\n",
      "Epoch 16481: train_loss=448.91092, val_loss=464.13843\n",
      "Epoch 16482: train_loss=448.90295, val_loss=464.14603\n",
      "Epoch 16483: train_loss=448.88873, val_loss=464.09787\n",
      "Epoch 16484: train_loss=448.86346, val_loss=464.08307\n",
      "Epoch 16485: train_loss=448.82437, val_loss=464.00925\n",
      "Epoch 16486: train_loss=448.77405, val_loss=463.97119\n",
      "Epoch 16487: train_loss=448.71582, val_loss=463.89395\n",
      "Epoch 16488: train_loss=448.65555, val_loss=463.85083\n",
      "Epoch 16489: train_loss=448.59818, val_loss=463.79288\n",
      "Epoch 16490: train_loss=448.54697, val_loss=463.75439\n",
      "Epoch 16491: train_loss=448.50385, val_loss=463.71906\n",
      "Epoch 16492: train_loss=448.46780, val_loss=463.68262\n",
      "Epoch 16493: train_loss=448.43680, val_loss=463.66083\n",
      "Epoch 16494: train_loss=448.40799, val_loss=463.62122\n",
      "Epoch 16495: train_loss=448.37939, val_loss=463.60388\n",
      "Epoch 16496: train_loss=448.34888, val_loss=463.55685\n",
      "Epoch 16497: train_loss=448.31552, val_loss=463.53421\n",
      "Epoch 16498: train_loss=448.27887, val_loss=463.47925\n",
      "Epoch 16499: train_loss=448.23911, val_loss=463.45044\n",
      "Epoch 16500: train_loss=448.19705, val_loss=463.39368\n",
      "Epoch 16501: train_loss=448.15350, val_loss=463.36130\n",
      "Epoch 16502: train_loss=448.10944, val_loss=463.30768\n",
      "Epoch 16503: train_loss=448.06561, val_loss=463.27173\n",
      "Epoch 16504: train_loss=448.02277, val_loss=463.22226\n",
      "Epoch 16505: train_loss=447.98090, val_loss=463.18344\n",
      "Epoch 16506: train_loss=447.94025, val_loss=463.14099\n",
      "Epoch 16507: train_loss=447.90103, val_loss=463.10101\n",
      "Epoch 16508: train_loss=447.86285, val_loss=463.06436\n",
      "Epoch 16509: train_loss=447.82565, val_loss=463.02289\n",
      "Epoch 16510: train_loss=447.78900, val_loss=462.98917\n",
      "Epoch 16511: train_loss=447.75250, val_loss=462.94391\n",
      "Epoch 16512: train_loss=447.71594, val_loss=462.91107\n",
      "Epoch 16513: train_loss=447.67957, val_loss=462.86542\n",
      "Epoch 16514: train_loss=447.64313, val_loss=462.83548\n",
      "Epoch 16515: train_loss=447.60654, val_loss=462.78937\n",
      "Epoch 16516: train_loss=447.56992, val_loss=462.75977\n",
      "Epoch 16517: train_loss=447.53345, val_loss=462.71191\n",
      "Epoch 16518: train_loss=447.49680, val_loss=462.68195\n",
      "Epoch 16519: train_loss=447.46039, val_loss=462.63412\n",
      "Epoch 16520: train_loss=447.42401, val_loss=462.60626\n",
      "Epoch 16521: train_loss=447.38657, val_loss=462.56009\n",
      "Epoch 16522: train_loss=447.34937, val_loss=462.53452\n",
      "Epoch 16523: train_loss=447.31281, val_loss=462.48813\n",
      "Epoch 16524: train_loss=447.27704, val_loss=462.46378\n",
      "Epoch 16525: train_loss=447.24231, val_loss=462.41882\n",
      "Epoch 16526: train_loss=447.20798, val_loss=462.39658\n",
      "Epoch 16527: train_loss=447.17422, val_loss=462.35126\n",
      "Epoch 16528: train_loss=447.14066, val_loss=462.32861\n",
      "Epoch 16529: train_loss=447.10767, val_loss=462.28210\n",
      "Epoch 16530: train_loss=447.07452, val_loss=462.26178\n",
      "Epoch 16531: train_loss=447.04239, val_loss=462.21680\n",
      "Epoch 16532: train_loss=447.00998, val_loss=462.19803\n",
      "Epoch 16533: train_loss=446.97726, val_loss=462.15012\n",
      "Epoch 16534: train_loss=446.94373, val_loss=462.12848\n",
      "Epoch 16535: train_loss=446.90903, val_loss=462.07480\n",
      "Epoch 16536: train_loss=446.87219, val_loss=462.04971\n",
      "Epoch 16537: train_loss=446.83362, val_loss=461.99176\n",
      "Epoch 16538: train_loss=446.79184, val_loss=461.96259\n",
      "Epoch 16539: train_loss=446.74832, val_loss=461.90097\n",
      "Epoch 16540: train_loss=446.70105, val_loss=461.86642\n",
      "Epoch 16541: train_loss=446.65314, val_loss=461.80118\n",
      "Epoch 16542: train_loss=446.60226, val_loss=461.76059\n",
      "Epoch 16543: train_loss=446.55145, val_loss=461.69684\n",
      "Epoch 16544: train_loss=446.49976, val_loss=461.65460\n",
      "Epoch 16545: train_loss=446.44894, val_loss=461.59741\n",
      "Epoch 16546: train_loss=446.39981, val_loss=461.55615\n",
      "Epoch 16547: train_loss=446.35330, val_loss=461.50644\n",
      "Epoch 16548: train_loss=446.30893, val_loss=461.46542\n",
      "Epoch 16549: train_loss=446.26697, val_loss=461.42307\n",
      "Epoch 16550: train_loss=446.22696, val_loss=461.38400\n",
      "Epoch 16551: train_loss=446.18811, val_loss=461.34814\n",
      "Epoch 16552: train_loss=446.15042, val_loss=461.30862\n",
      "Epoch 16553: train_loss=446.11362, val_loss=461.27505\n",
      "Epoch 16554: train_loss=446.07739, val_loss=461.23294\n",
      "Epoch 16555: train_loss=446.04141, val_loss=461.20157\n",
      "Epoch 16556: train_loss=446.00577, val_loss=461.15945\n",
      "Epoch 16557: train_loss=445.97009, val_loss=461.13177\n",
      "Epoch 16558: train_loss=445.93506, val_loss=461.09027\n",
      "Epoch 16559: train_loss=445.90042, val_loss=461.06485\n",
      "Epoch 16560: train_loss=445.86655, val_loss=461.02158\n",
      "Epoch 16561: train_loss=445.83328, val_loss=460.99796\n",
      "Epoch 16562: train_loss=445.80060, val_loss=460.95435\n",
      "Epoch 16563: train_loss=445.76932, val_loss=460.93546\n",
      "Epoch 16564: train_loss=445.73889, val_loss=460.89307\n",
      "Epoch 16565: train_loss=445.70981, val_loss=460.87949\n",
      "Epoch 16566: train_loss=445.68152, val_loss=460.83789\n",
      "Epoch 16567: train_loss=445.65485, val_loss=460.82953\n",
      "Epoch 16568: train_loss=445.63031, val_loss=460.78714\n",
      "Epoch 16569: train_loss=445.60663, val_loss=460.78250\n",
      "Epoch 16570: train_loss=445.58426, val_loss=460.73770\n",
      "Epoch 16571: train_loss=445.56119, val_loss=460.73340\n",
      "Epoch 16572: train_loss=445.53668, val_loss=460.68185\n",
      "Epoch 16573: train_loss=445.50772, val_loss=460.66995\n",
      "Epoch 16574: train_loss=445.47214, val_loss=460.60373\n",
      "Epoch 16575: train_loss=445.42874, val_loss=460.57388\n",
      "Epoch 16576: train_loss=445.37604, val_loss=460.48981\n",
      "Epoch 16577: train_loss=445.31531, val_loss=460.43985\n",
      "Epoch 16578: train_loss=445.24756, val_loss=460.34964\n",
      "Epoch 16579: train_loss=445.17758, val_loss=460.29504\n",
      "Epoch 16580: train_loss=445.10925, val_loss=460.21918\n",
      "Epoch 16581: train_loss=445.04532, val_loss=460.17145\n",
      "Epoch 16582: train_loss=444.98831, val_loss=460.11694\n",
      "Epoch 16583: train_loss=444.93872, val_loss=460.07535\n",
      "Epoch 16584: train_loss=444.89563, val_loss=460.03619\n",
      "Epoch 16585: train_loss=444.85791, val_loss=459.99585\n",
      "Epoch 16586: train_loss=444.82404, val_loss=459.96838\n",
      "Epoch 16587: train_loss=444.79257, val_loss=459.92862\n",
      "Epoch 16588: train_loss=444.76163, val_loss=459.90717\n",
      "Epoch 16589: train_loss=444.73044, val_loss=459.86346\n",
      "Epoch 16590: train_loss=444.69736, val_loss=459.83939\n",
      "Epoch 16591: train_loss=444.66281, val_loss=459.78909\n",
      "Epoch 16592: train_loss=444.62610, val_loss=459.76166\n",
      "Epoch 16593: train_loss=444.58743, val_loss=459.70834\n",
      "Epoch 16594: train_loss=444.54745, val_loss=459.67889\n",
      "Epoch 16595: train_loss=444.50598, val_loss=459.62262\n",
      "Epoch 16596: train_loss=444.46341, val_loss=459.58945\n",
      "Epoch 16597: train_loss=444.42023, val_loss=459.53302\n",
      "Epoch 16598: train_loss=444.37595, val_loss=459.49902\n",
      "Epoch 16599: train_loss=444.33157, val_loss=459.44492\n",
      "Epoch 16600: train_loss=444.28680, val_loss=459.40808\n",
      "Epoch 16601: train_loss=444.24255, val_loss=459.35507\n",
      "Epoch 16602: train_loss=444.19864, val_loss=459.31647\n",
      "Epoch 16603: train_loss=444.15573, val_loss=459.26886\n",
      "Epoch 16604: train_loss=444.11340, val_loss=459.23138\n",
      "Epoch 16605: train_loss=444.07199, val_loss=459.18863\n",
      "Epoch 16606: train_loss=444.03128, val_loss=459.14862\n",
      "Epoch 16607: train_loss=443.99136, val_loss=459.10748\n",
      "Epoch 16608: train_loss=443.95187, val_loss=459.06619\n",
      "Epoch 16609: train_loss=443.91278, val_loss=459.02908\n",
      "Epoch 16610: train_loss=443.87415, val_loss=458.98785\n",
      "Epoch 16611: train_loss=443.83578, val_loss=458.95334\n",
      "Epoch 16612: train_loss=443.79813, val_loss=458.91071\n",
      "Epoch 16613: train_loss=443.76138, val_loss=458.88004\n",
      "Epoch 16614: train_loss=443.72617, val_loss=458.83762\n",
      "Epoch 16615: train_loss=443.69278, val_loss=458.81686\n",
      "Epoch 16616: train_loss=443.66245, val_loss=458.77625\n",
      "Epoch 16617: train_loss=443.63477, val_loss=458.76675\n",
      "Epoch 16618: train_loss=443.61191, val_loss=458.72925\n",
      "Epoch 16619: train_loss=443.59396, val_loss=458.73578\n",
      "Epoch 16620: train_loss=443.58099, val_loss=458.70602\n",
      "Epoch 16621: train_loss=443.57449, val_loss=458.73160\n",
      "Epoch 16622: train_loss=443.57141, val_loss=458.70221\n",
      "Epoch 16623: train_loss=443.57227, val_loss=458.73404\n",
      "Epoch 16624: train_loss=443.57047, val_loss=458.68997\n",
      "Epoch 16625: train_loss=443.56415, val_loss=458.70642\n",
      "Epoch 16626: train_loss=443.54312, val_loss=458.63019\n",
      "Epoch 16627: train_loss=443.50504, val_loss=458.60660\n",
      "Epoch 16628: train_loss=443.44290, val_loss=458.49042\n",
      "Epoch 16629: train_loss=443.36215, val_loss=458.42493\n",
      "Epoch 16630: train_loss=443.26584, val_loss=458.29489\n",
      "Epoch 16631: train_loss=443.16571, val_loss=458.21689\n",
      "Epoch 16632: train_loss=443.06967, val_loss=458.11905\n",
      "Epoch 16633: train_loss=442.98935, val_loss=458.06400\n",
      "Epoch 16634: train_loss=442.92938, val_loss=458.02164\n",
      "Epoch 16635: train_loss=442.88870, val_loss=457.98959\n",
      "Epoch 16636: train_loss=442.86243, val_loss=457.98050\n",
      "Epoch 16637: train_loss=442.84351, val_loss=457.94556\n",
      "Epoch 16638: train_loss=442.82538, val_loss=457.93860\n",
      "Epoch 16639: train_loss=442.80179, val_loss=457.88489\n",
      "Epoch 16640: train_loss=442.76956, val_loss=457.86273\n",
      "Epoch 16641: train_loss=442.72696, val_loss=457.79364\n",
      "Epoch 16642: train_loss=442.67661, val_loss=457.75574\n",
      "Epoch 16643: train_loss=442.62085, val_loss=457.68353\n",
      "Epoch 16644: train_loss=442.56390, val_loss=457.63962\n",
      "Epoch 16645: train_loss=442.50922, val_loss=457.58087\n",
      "Epoch 16646: train_loss=442.45862, val_loss=457.54047\n",
      "Epoch 16647: train_loss=442.41357, val_loss=457.49948\n",
      "Epoch 16648: train_loss=442.37323, val_loss=457.45859\n",
      "Epoch 16649: train_loss=442.33676, val_loss=457.42746\n",
      "Epoch 16650: train_loss=442.30249, val_loss=457.38370\n",
      "Epoch 16651: train_loss=442.26944, val_loss=457.36005\n",
      "Epoch 16652: train_loss=442.23645, val_loss=457.31372\n",
      "Epoch 16653: train_loss=442.20209, val_loss=457.29019\n",
      "Epoch 16654: train_loss=442.16586, val_loss=457.23553\n",
      "Epoch 16655: train_loss=442.12671, val_loss=457.20572\n",
      "Epoch 16656: train_loss=442.08530, val_loss=457.14722\n",
      "Epoch 16657: train_loss=442.04172, val_loss=457.11420\n",
      "Epoch 16658: train_loss=441.99667, val_loss=457.05783\n",
      "Epoch 16659: train_loss=441.95123, val_loss=457.02078\n",
      "Epoch 16660: train_loss=441.90616, val_loss=456.96799\n",
      "Epoch 16661: train_loss=441.86182, val_loss=456.92862\n",
      "Epoch 16662: train_loss=441.81863, val_loss=456.88251\n",
      "Epoch 16663: train_loss=441.77649, val_loss=456.84344\n",
      "Epoch 16664: train_loss=441.73535, val_loss=456.80209\n",
      "Epoch 16665: train_loss=441.69507, val_loss=456.75967\n",
      "Epoch 16666: train_loss=441.65518, val_loss=456.71960\n",
      "Epoch 16667: train_loss=441.61572, val_loss=456.67548\n",
      "Epoch 16668: train_loss=441.57675, val_loss=456.63977\n",
      "Epoch 16669: train_loss=441.53830, val_loss=456.59586\n",
      "Epoch 16670: train_loss=441.50034, val_loss=456.56354\n",
      "Epoch 16671: train_loss=441.46271, val_loss=456.51749\n",
      "Epoch 16672: train_loss=441.42566, val_loss=456.48813\n",
      "Epoch 16673: train_loss=441.38943, val_loss=456.44183\n",
      "Epoch 16674: train_loss=441.35391, val_loss=456.41867\n",
      "Epoch 16675: train_loss=441.31940, val_loss=456.37201\n",
      "Epoch 16676: train_loss=441.28525, val_loss=456.35196\n",
      "Epoch 16677: train_loss=441.25186, val_loss=456.30197\n",
      "Epoch 16678: train_loss=441.21890, val_loss=456.28503\n",
      "Epoch 16679: train_loss=441.18610, val_loss=456.23560\n",
      "Epoch 16680: train_loss=441.15405, val_loss=456.22348\n",
      "Epoch 16681: train_loss=441.12143, val_loss=456.17197\n",
      "Epoch 16682: train_loss=441.09042, val_loss=456.16040\n",
      "Epoch 16683: train_loss=441.05823, val_loss=456.10370\n",
      "Epoch 16684: train_loss=441.02768, val_loss=456.09506\n",
      "Epoch 16685: train_loss=440.99509, val_loss=456.03766\n",
      "Epoch 16686: train_loss=440.96304, val_loss=456.02972\n",
      "Epoch 16687: train_loss=440.92752, val_loss=455.96652\n",
      "Epoch 16688: train_loss=440.89233, val_loss=455.95184\n",
      "Epoch 16689: train_loss=440.85236, val_loss=455.87961\n",
      "Epoch 16690: train_loss=440.81097, val_loss=455.85852\n",
      "Epoch 16691: train_loss=440.76431, val_loss=455.78189\n",
      "Epoch 16692: train_loss=440.71472, val_loss=455.75409\n",
      "Epoch 16693: train_loss=440.66174, val_loss=455.67340\n",
      "Epoch 16694: train_loss=440.60657, val_loss=455.63666\n",
      "Epoch 16695: train_loss=440.55063, val_loss=455.55838\n",
      "Epoch 16696: train_loss=440.49438, val_loss=455.51764\n",
      "Epoch 16697: train_loss=440.43912, val_loss=455.45044\n",
      "Epoch 16698: train_loss=440.38583, val_loss=455.40918\n",
      "Epoch 16699: train_loss=440.33563, val_loss=455.35349\n",
      "Epoch 16700: train_loss=440.28864, val_loss=455.31058\n",
      "Epoch 16701: train_loss=440.24475, val_loss=455.26620\n",
      "Epoch 16702: train_loss=440.20370, val_loss=455.22388\n",
      "Epoch 16703: train_loss=440.16461, val_loss=455.18997\n",
      "Epoch 16704: train_loss=440.12671, val_loss=455.14581\n",
      "Epoch 16705: train_loss=440.08936, val_loss=455.11533\n",
      "Epoch 16706: train_loss=440.05191, val_loss=455.06662\n",
      "Epoch 16707: train_loss=440.01483, val_loss=455.03925\n",
      "Epoch 16708: train_loss=439.97760, val_loss=454.98996\n",
      "Epoch 16709: train_loss=439.94058, val_loss=454.96799\n",
      "Epoch 16710: train_loss=439.90396, val_loss=454.91812\n",
      "Epoch 16711: train_loss=439.86798, val_loss=454.89774\n",
      "Epoch 16712: train_loss=439.83215, val_loss=454.84375\n",
      "Epoch 16713: train_loss=439.79694, val_loss=454.82596\n",
      "Epoch 16714: train_loss=439.76212, val_loss=454.77136\n",
      "Epoch 16715: train_loss=439.72858, val_loss=454.75797\n",
      "Epoch 16716: train_loss=439.69452, val_loss=454.70120\n",
      "Epoch 16717: train_loss=439.66168, val_loss=454.68909\n",
      "Epoch 16718: train_loss=439.62689, val_loss=454.62811\n",
      "Epoch 16719: train_loss=439.59296, val_loss=454.61694\n",
      "Epoch 16720: train_loss=439.55630, val_loss=454.55246\n",
      "Epoch 16721: train_loss=439.52051, val_loss=454.54083\n",
      "Epoch 16722: train_loss=439.48126, val_loss=454.47174\n",
      "Epoch 16723: train_loss=439.44229, val_loss=454.45758\n",
      "Epoch 16724: train_loss=439.39981, val_loss=454.38391\n",
      "Epoch 16725: train_loss=439.35663, val_loss=454.36493\n",
      "Epoch 16726: train_loss=439.30917, val_loss=454.28659\n",
      "Epoch 16727: train_loss=439.26031, val_loss=454.25934\n",
      "Epoch 16728: train_loss=439.20691, val_loss=454.17764\n",
      "Epoch 16729: train_loss=439.15250, val_loss=454.14352\n",
      "Epoch 16730: train_loss=439.09705, val_loss=454.06650\n",
      "Epoch 16731: train_loss=439.04242, val_loss=454.02893\n",
      "Epoch 16732: train_loss=438.98849, val_loss=453.96048\n",
      "Epoch 16733: train_loss=438.93616, val_loss=453.92056\n",
      "Epoch 16734: train_loss=438.88602, val_loss=453.86243\n",
      "Epoch 16735: train_loss=438.83786, val_loss=453.82111\n",
      "Epoch 16736: train_loss=438.79205, val_loss=453.77252\n",
      "Epoch 16737: train_loss=438.74792, val_loss=453.72958\n",
      "Epoch 16738: train_loss=438.70520, val_loss=453.68790\n",
      "Epoch 16739: train_loss=438.66360, val_loss=453.64182\n",
      "Epoch 16740: train_loss=438.62271, val_loss=453.60565\n",
      "Epoch 16741: train_loss=438.58246, val_loss=453.55850\n",
      "Epoch 16742: train_loss=438.54306, val_loss=453.52887\n",
      "Epoch 16743: train_loss=438.50443, val_loss=453.47958\n",
      "Epoch 16744: train_loss=438.46692, val_loss=453.45505\n",
      "Epoch 16745: train_loss=438.43066, val_loss=453.40414\n",
      "Epoch 16746: train_loss=438.39587, val_loss=453.38824\n",
      "Epoch 16747: train_loss=438.36237, val_loss=453.33862\n",
      "Epoch 16748: train_loss=438.33157, val_loss=453.33246\n",
      "Epoch 16749: train_loss=438.30215, val_loss=453.27921\n",
      "Epoch 16750: train_loss=438.27509, val_loss=453.28125\n",
      "Epoch 16751: train_loss=438.24976, val_loss=453.22754\n",
      "Epoch 16752: train_loss=438.22803, val_loss=453.24158\n",
      "Epoch 16753: train_loss=438.20630, val_loss=453.18588\n",
      "Epoch 16754: train_loss=438.18747, val_loss=453.20282\n",
      "Epoch 16755: train_loss=438.16547, val_loss=453.13599\n",
      "Epoch 16756: train_loss=438.14316, val_loss=453.14703\n",
      "Epoch 16757: train_loss=438.11191, val_loss=453.06464\n",
      "Epoch 16758: train_loss=438.07562, val_loss=453.05960\n",
      "Epoch 16759: train_loss=438.02509, val_loss=452.95889\n",
      "Epoch 16760: train_loss=437.96875, val_loss=452.92957\n",
      "Epoch 16761: train_loss=437.89957, val_loss=452.81552\n",
      "Epoch 16762: train_loss=437.82706, val_loss=452.76807\n",
      "Epoch 16763: train_loss=437.74915, val_loss=452.66275\n",
      "Epoch 16764: train_loss=437.67377, val_loss=452.61380\n",
      "Epoch 16765: train_loss=437.60349, val_loss=452.53506\n",
      "Epoch 16766: train_loss=437.54120, val_loss=452.48795\n",
      "Epoch 16767: train_loss=437.48734, val_loss=452.43451\n",
      "Epoch 16768: train_loss=437.44089, val_loss=452.38885\n",
      "Epoch 16769: train_loss=437.40039, val_loss=452.35593\n",
      "Epoch 16770: train_loss=437.36389, val_loss=452.30899\n",
      "Epoch 16771: train_loss=437.32965, val_loss=452.28592\n",
      "Epoch 16772: train_loss=437.29608, val_loss=452.23169\n",
      "Epoch 16773: train_loss=437.26190, val_loss=452.21317\n",
      "Epoch 16774: train_loss=437.22726, val_loss=452.15451\n",
      "Epoch 16775: train_loss=437.19135, val_loss=452.13980\n",
      "Epoch 16776: train_loss=437.15497, val_loss=452.07724\n",
      "Epoch 16777: train_loss=437.11667, val_loss=452.06000\n",
      "Epoch 16778: train_loss=437.07635, val_loss=451.99005\n",
      "Epoch 16779: train_loss=437.03387, val_loss=451.96667\n",
      "Epoch 16780: train_loss=436.98886, val_loss=451.89246\n",
      "Epoch 16781: train_loss=436.94180, val_loss=451.86493\n",
      "Epoch 16782: train_loss=436.89322, val_loss=451.79132\n",
      "Epoch 16783: train_loss=436.84375, val_loss=451.75827\n",
      "Epoch 16784: train_loss=436.79367, val_loss=451.68777\n",
      "Epoch 16785: train_loss=436.74420, val_loss=451.65036\n",
      "Epoch 16786: train_loss=436.69543, val_loss=451.58533\n",
      "Epoch 16787: train_loss=436.64767, val_loss=451.54544\n",
      "Epoch 16788: train_loss=436.60110, val_loss=451.48721\n",
      "Epoch 16789: train_loss=436.55515, val_loss=451.44705\n",
      "Epoch 16790: train_loss=436.51047, val_loss=451.39603\n",
      "Epoch 16791: train_loss=436.46628, val_loss=451.35443\n",
      "Epoch 16792: train_loss=436.42255, val_loss=451.30667\n",
      "Epoch 16793: train_loss=436.37933, val_loss=451.26132\n",
      "Epoch 16794: train_loss=436.33646, val_loss=451.21686\n",
      "Epoch 16795: train_loss=436.29388, val_loss=451.17090\n",
      "Epoch 16796: train_loss=436.25137, val_loss=451.13028\n",
      "Epoch 16797: train_loss=436.20908, val_loss=451.08298\n",
      "Epoch 16798: train_loss=436.16696, val_loss=451.04413\n",
      "Epoch 16799: train_loss=436.12512, val_loss=450.99490\n",
      "Epoch 16800: train_loss=436.08389, val_loss=450.96063\n",
      "Epoch 16801: train_loss=436.04324, val_loss=450.91098\n",
      "Epoch 16802: train_loss=436.00354, val_loss=450.88293\n",
      "Epoch 16803: train_loss=435.96521, val_loss=450.83130\n",
      "Epoch 16804: train_loss=435.92847, val_loss=450.81079\n",
      "Epoch 16805: train_loss=435.89413, val_loss=450.75894\n",
      "Epoch 16806: train_loss=435.86224, val_loss=450.75134\n",
      "Epoch 16807: train_loss=435.83389, val_loss=450.69992\n",
      "Epoch 16808: train_loss=435.80817, val_loss=450.70587\n",
      "Epoch 16809: train_loss=435.78641, val_loss=450.65533\n",
      "Epoch 16810: train_loss=435.76895, val_loss=450.67868\n",
      "Epoch 16811: train_loss=435.75592, val_loss=450.62759\n",
      "Epoch 16812: train_loss=435.74628, val_loss=450.66321\n",
      "Epoch 16813: train_loss=435.73801, val_loss=450.60352\n",
      "Epoch 16814: train_loss=435.72806, val_loss=450.63763\n",
      "Epoch 16815: train_loss=435.71088, val_loss=450.55701\n",
      "Epoch 16816: train_loss=435.68466, val_loss=450.56723\n",
      "Epoch 16817: train_loss=435.64029, val_loss=450.44949\n",
      "Epoch 16818: train_loss=435.57858, val_loss=450.41644\n",
      "Epoch 16819: train_loss=435.49680, val_loss=450.27164\n",
      "Epoch 16820: train_loss=435.40338, val_loss=450.20953\n",
      "Epoch 16821: train_loss=435.30283, val_loss=450.07816\n",
      "Epoch 16822: train_loss=435.20728, val_loss=450.01596\n",
      "Epoch 16823: train_loss=435.12228, val_loss=449.93137\n",
      "Epoch 16824: train_loss=435.05447, val_loss=449.88141\n",
      "Epoch 16825: train_loss=435.00424, val_loss=449.84592\n",
      "Epoch 16826: train_loss=434.96817, val_loss=449.80518\n",
      "Epoch 16827: train_loss=434.94144, val_loss=449.80283\n",
      "Epoch 16828: train_loss=434.91867, val_loss=449.75513\n",
      "Epoch 16829: train_loss=434.89502, val_loss=449.75333\n",
      "Epoch 16830: train_loss=434.86548, val_loss=449.68301\n",
      "Epoch 16831: train_loss=434.82886, val_loss=449.66580\n",
      "Epoch 16832: train_loss=434.78415, val_loss=449.58319\n",
      "Epoch 16833: train_loss=434.73242, val_loss=449.55475\n",
      "Epoch 16834: train_loss=434.67590, val_loss=449.47217\n",
      "Epoch 16835: train_loss=434.61719, val_loss=449.43228\n",
      "Epoch 16836: train_loss=434.55835, val_loss=449.35654\n",
      "Epoch 16837: train_loss=434.50192, val_loss=449.31128\n",
      "Epoch 16838: train_loss=434.44904, val_loss=449.25537\n",
      "Epoch 16839: train_loss=434.40094, val_loss=449.21042\n",
      "Epoch 16840: train_loss=434.35715, val_loss=449.17142\n",
      "Epoch 16841: train_loss=434.31659, val_loss=449.12173\n",
      "Epoch 16842: train_loss=434.27783, val_loss=449.09177\n",
      "Epoch 16843: train_loss=434.23975, val_loss=449.03812\n",
      "Epoch 16844: train_loss=434.20169, val_loss=449.01324\n",
      "Epoch 16845: train_loss=434.16299, val_loss=448.95624\n",
      "Epoch 16846: train_loss=434.12357, val_loss=448.93137\n",
      "Epoch 16847: train_loss=434.08286, val_loss=448.86877\n",
      "Epoch 16848: train_loss=434.04095, val_loss=448.84283\n",
      "Epoch 16849: train_loss=433.99820, val_loss=448.77866\n",
      "Epoch 16850: train_loss=433.95425, val_loss=448.75192\n",
      "Epoch 16851: train_loss=433.90952, val_loss=448.68713\n",
      "Epoch 16852: train_loss=433.86389, val_loss=448.65668\n",
      "Epoch 16853: train_loss=433.81763, val_loss=448.59091\n",
      "Epoch 16854: train_loss=433.77072, val_loss=448.55670\n",
      "Epoch 16855: train_loss=433.72342, val_loss=448.49380\n",
      "Epoch 16856: train_loss=433.67636, val_loss=448.45804\n",
      "Epoch 16857: train_loss=433.62955, val_loss=448.39813\n",
      "Epoch 16858: train_loss=433.58292, val_loss=448.35852\n",
      "Epoch 16859: train_loss=433.53668, val_loss=448.30173\n",
      "Epoch 16860: train_loss=433.49048, val_loss=448.26074\n",
      "Epoch 16861: train_loss=433.44516, val_loss=448.20911\n",
      "Epoch 16862: train_loss=433.40002, val_loss=448.16620\n",
      "Epoch 16863: train_loss=433.35526, val_loss=448.11734\n",
      "Epoch 16864: train_loss=433.31073, val_loss=448.07083\n",
      "Epoch 16865: train_loss=433.26669, val_loss=448.02582\n",
      "Epoch 16866: train_loss=433.22296, val_loss=447.97882\n",
      "Epoch 16867: train_loss=433.17935, val_loss=447.93741\n",
      "Epoch 16868: train_loss=433.13586, val_loss=447.88815\n",
      "Epoch 16869: train_loss=433.09265, val_loss=447.84888\n",
      "Epoch 16870: train_loss=433.04980, val_loss=447.79807\n",
      "Epoch 16871: train_loss=433.00760, val_loss=447.76395\n",
      "Epoch 16872: train_loss=432.96606, val_loss=447.71231\n",
      "Epoch 16873: train_loss=432.92566, val_loss=447.68475\n",
      "Epoch 16874: train_loss=432.88693, val_loss=447.63098\n",
      "Epoch 16875: train_loss=432.85043, val_loss=447.61349\n",
      "Epoch 16876: train_loss=432.81662, val_loss=447.55960\n",
      "Epoch 16877: train_loss=432.78629, val_loss=447.55820\n",
      "Epoch 16878: train_loss=432.76047, val_loss=447.50604\n",
      "Epoch 16879: train_loss=432.73911, val_loss=447.52475\n",
      "Epoch 16880: train_loss=432.72363, val_loss=447.47458\n",
      "Epoch 16881: train_loss=432.71436, val_loss=447.51389\n",
      "Epoch 16882: train_loss=432.70874, val_loss=447.46231\n",
      "Epoch 16883: train_loss=432.70764, val_loss=447.51138\n",
      "Epoch 16884: train_loss=432.70123, val_loss=447.44281\n",
      "Epoch 16885: train_loss=432.69162, val_loss=447.47852\n",
      "Epoch 16886: train_loss=432.66675, val_loss=447.37448\n",
      "Epoch 16887: train_loss=432.62683, val_loss=447.36761\n",
      "Epoch 16888: train_loss=432.55969, val_loss=447.22128\n",
      "Epoch 16889: train_loss=432.47345, val_loss=447.16464\n",
      "Epoch 16890: train_loss=432.36581, val_loss=447.00555\n",
      "Epoch 16891: train_loss=432.25458, val_loss=446.92999\n",
      "Epoch 16892: train_loss=432.14771, val_loss=446.81223\n",
      "Epoch 16893: train_loss=432.05740, val_loss=446.75443\n",
      "Epoch 16894: train_loss=431.98907, val_loss=446.70444\n",
      "Epoch 16895: train_loss=431.94147, val_loss=446.66360\n",
      "Epoch 16896: train_loss=431.90964, val_loss=446.65475\n",
      "Epoch 16897: train_loss=431.88678, val_loss=446.60788\n",
      "Epoch 16898: train_loss=431.86578, val_loss=446.60843\n",
      "Epoch 16899: train_loss=431.84045, val_loss=446.54150\n",
      "Epoch 16900: train_loss=431.80640, val_loss=446.52875\n",
      "Epoch 16901: train_loss=431.76245, val_loss=446.44217\n",
      "Epoch 16902: train_loss=431.70959, val_loss=446.41000\n",
      "Epoch 16903: train_loss=431.64957, val_loss=446.31976\n",
      "Epoch 16904: train_loss=431.58713, val_loss=446.27835\n",
      "Epoch 16905: train_loss=431.52487, val_loss=446.20184\n",
      "Epoch 16906: train_loss=431.46576, val_loss=446.15625\n",
      "Epoch 16907: train_loss=431.41135, val_loss=446.09915\n",
      "Epoch 16908: train_loss=431.36188, val_loss=446.05246\n",
      "Epoch 16909: train_loss=431.31717, val_loss=446.01559\n",
      "Epoch 16910: train_loss=431.27606, val_loss=445.96674\n",
      "Epoch 16911: train_loss=431.23654, val_loss=445.93845\n",
      "Epoch 16912: train_loss=431.19730, val_loss=445.88058\n",
      "Epoch 16913: train_loss=431.15787, val_loss=445.85287\n",
      "Epoch 16914: train_loss=431.11703, val_loss=445.79099\n",
      "Epoch 16915: train_loss=431.07474, val_loss=445.76550\n",
      "Epoch 16916: train_loss=431.03064, val_loss=445.70139\n",
      "Epoch 16917: train_loss=430.98523, val_loss=445.67105\n",
      "Epoch 16918: train_loss=430.93845, val_loss=445.60208\n",
      "Epoch 16919: train_loss=430.89047, val_loss=445.56711\n",
      "Epoch 16920: train_loss=430.84198, val_loss=445.50119\n",
      "Epoch 16921: train_loss=430.79288, val_loss=445.46631\n",
      "Epoch 16922: train_loss=430.74384, val_loss=445.40451\n",
      "Epoch 16923: train_loss=430.69464, val_loss=445.36499\n",
      "Epoch 16924: train_loss=430.64575, val_loss=445.30463\n",
      "Epoch 16925: train_loss=430.59698, val_loss=445.26071\n",
      "Epoch 16926: train_loss=430.54898, val_loss=445.20615\n",
      "Epoch 16927: train_loss=430.50165, val_loss=445.16116\n",
      "Epoch 16928: train_loss=430.45471, val_loss=445.11240\n",
      "Epoch 16929: train_loss=430.40839, val_loss=445.06485\n",
      "Epoch 16930: train_loss=430.36237, val_loss=445.01898\n",
      "Epoch 16931: train_loss=430.31656, val_loss=444.96878\n",
      "Epoch 16932: train_loss=430.27103, val_loss=444.92621\n",
      "Epoch 16933: train_loss=430.22543, val_loss=444.87476\n",
      "Epoch 16934: train_loss=430.18018, val_loss=444.83490\n",
      "Epoch 16935: train_loss=430.13525, val_loss=444.78085\n",
      "Epoch 16936: train_loss=430.09061, val_loss=444.74463\n",
      "Epoch 16937: train_loss=430.04684, val_loss=444.68927\n",
      "Epoch 16938: train_loss=430.00354, val_loss=444.65909\n",
      "Epoch 16939: train_loss=429.96149, val_loss=444.60345\n",
      "Epoch 16940: train_loss=429.92084, val_loss=444.58011\n",
      "Epoch 16941: train_loss=429.88162, val_loss=444.52158\n",
      "Epoch 16942: train_loss=429.84427, val_loss=444.50647\n",
      "Epoch 16943: train_loss=429.80795, val_loss=444.44519\n",
      "Epoch 16944: train_loss=429.77438, val_loss=444.44058\n",
      "Epoch 16945: train_loss=429.74225, val_loss=444.37711\n",
      "Epoch 16946: train_loss=429.71307, val_loss=444.38251\n",
      "Epoch 16947: train_loss=429.68494, val_loss=444.31525\n",
      "Epoch 16948: train_loss=429.65848, val_loss=444.33017\n",
      "Epoch 16949: train_loss=429.63205, val_loss=444.25647\n",
      "Epoch 16950: train_loss=429.60510, val_loss=444.27213\n",
      "Epoch 16951: train_loss=429.57343, val_loss=444.18463\n",
      "Epoch 16952: train_loss=429.53738, val_loss=444.18683\n",
      "Epoch 16953: train_loss=429.49100, val_loss=444.08054\n",
      "Epoch 16954: train_loss=429.43701, val_loss=444.06262\n",
      "Epoch 16955: train_loss=429.37180, val_loss=443.94400\n",
      "Epoch 16956: train_loss=429.30045, val_loss=443.90552\n",
      "Epoch 16957: train_loss=429.22183, val_loss=443.78839\n",
      "Epoch 16958: train_loss=429.14343, val_loss=443.73804\n",
      "Epoch 16959: train_loss=429.06622, val_loss=443.64087\n",
      "Epoch 16960: train_loss=428.99496, val_loss=443.59122\n",
      "Epoch 16961: train_loss=428.93051, val_loss=443.52478\n",
      "Epoch 16962: train_loss=428.87399, val_loss=443.47693\n",
      "Epoch 16963: train_loss=428.82471, val_loss=443.43564\n",
      "Epoch 16964: train_loss=428.78128, val_loss=443.38446\n",
      "Epoch 16965: train_loss=428.74146, val_loss=443.35828\n",
      "Epoch 16966: train_loss=428.70328, val_loss=443.30176\n",
      "Epoch 16967: train_loss=428.66565, val_loss=443.28284\n",
      "Epoch 16968: train_loss=428.62674, val_loss=443.21942\n",
      "Epoch 16969: train_loss=428.58676, val_loss=443.20038\n",
      "Epoch 16970: train_loss=428.54480, val_loss=443.13004\n",
      "Epoch 16971: train_loss=428.50156, val_loss=443.10901\n",
      "Epoch 16972: train_loss=428.45572, val_loss=443.03537\n",
      "Epoch 16973: train_loss=428.40857, val_loss=443.01160\n",
      "Epoch 16974: train_loss=428.35941, val_loss=442.93536\n",
      "Epoch 16975: train_loss=428.30951, val_loss=442.90674\n",
      "Epoch 16976: train_loss=428.25845, val_loss=442.83063\n",
      "Epoch 16977: train_loss=428.20734, val_loss=442.80017\n",
      "Epoch 16978: train_loss=428.15564, val_loss=442.72794\n",
      "Epoch 16979: train_loss=428.10428, val_loss=442.69473\n",
      "Epoch 16980: train_loss=428.05270, val_loss=442.62408\n",
      "Epoch 16981: train_loss=428.00189, val_loss=442.58643\n",
      "Epoch 16982: train_loss=427.95084, val_loss=442.51926\n",
      "Epoch 16983: train_loss=427.90085, val_loss=442.48126\n",
      "Epoch 16984: train_loss=427.85071, val_loss=442.41855\n",
      "Epoch 16985: train_loss=427.80136, val_loss=442.37781\n",
      "Epoch 16986: train_loss=427.75220, val_loss=442.31717\n",
      "Epoch 16987: train_loss=427.70352, val_loss=442.27521\n",
      "Epoch 16988: train_loss=427.65500, val_loss=442.21875\n",
      "Epoch 16989: train_loss=427.60712, val_loss=442.17780\n",
      "Epoch 16990: train_loss=427.55920, val_loss=442.12103\n",
      "Epoch 16991: train_loss=427.51166, val_loss=442.07736\n",
      "Epoch 16992: train_loss=427.46442, val_loss=442.01929\n",
      "Epoch 16993: train_loss=427.41760, val_loss=441.97980\n",
      "Epoch 16994: train_loss=427.37094, val_loss=441.92557\n",
      "Epoch 16995: train_loss=427.32486, val_loss=441.89136\n",
      "Epoch 16996: train_loss=427.27969, val_loss=441.83319\n",
      "Epoch 16997: train_loss=427.23544, val_loss=441.80020\n",
      "Epoch 16998: train_loss=427.19275, val_loss=441.73843\n",
      "Epoch 16999: train_loss=427.15219, val_loss=441.71878\n",
      "Epoch 17000: train_loss=427.11423, val_loss=441.66101\n",
      "Epoch 17001: train_loss=427.08008, val_loss=441.66080\n",
      "Epoch 17002: train_loss=427.05179, val_loss=441.60406\n",
      "Epoch 17003: train_loss=427.03024, val_loss=441.62579\n",
      "Epoch 17004: train_loss=427.01590, val_loss=441.57333\n",
      "Epoch 17005: train_loss=427.01160, val_loss=441.62585\n",
      "Epoch 17006: train_loss=427.01306, val_loss=441.57401\n",
      "Epoch 17007: train_loss=427.02109, val_loss=441.64777\n",
      "Epoch 17008: train_loss=427.02835, val_loss=441.57944\n",
      "Epoch 17009: train_loss=427.03278, val_loss=441.63632\n",
      "Epoch 17010: train_loss=427.01532, val_loss=441.51584\n",
      "Epoch 17011: train_loss=426.97610, val_loss=441.51001\n",
      "Epoch 17012: train_loss=426.89523, val_loss=441.32407\n",
      "Epoch 17013: train_loss=426.78525, val_loss=441.24753\n",
      "Epoch 17014: train_loss=426.64685, val_loss=441.04993\n",
      "Epoch 17015: train_loss=426.50635, val_loss=440.95758\n",
      "Epoch 17016: train_loss=426.37958, val_loss=440.83481\n",
      "Epoch 17017: train_loss=426.28375, val_loss=440.77740\n",
      "Epoch 17018: train_loss=426.22208, val_loss=440.75098\n",
      "Epoch 17019: train_loss=426.18918, val_loss=440.71268\n",
      "Epoch 17020: train_loss=426.17358, val_loss=440.72983\n",
      "Epoch 17021: train_loss=426.16162, val_loss=440.66956\n",
      "Epoch 17022: train_loss=426.14191, val_loss=440.67313\n",
      "Epoch 17023: train_loss=426.10568, val_loss=440.57523\n",
      "Epoch 17024: train_loss=426.05222, val_loss=440.54416\n",
      "Epoch 17025: train_loss=425.98279, val_loss=440.43130\n",
      "Epoch 17026: train_loss=425.90634, val_loss=440.37894\n",
      "Epoch 17027: train_loss=425.82977, val_loss=440.28677\n",
      "Epoch 17028: train_loss=425.75986, val_loss=440.23526\n",
      "Epoch 17029: train_loss=425.69913, val_loss=440.18298\n",
      "Epoch 17030: train_loss=425.64911, val_loss=440.13544\n",
      "Epoch 17031: train_loss=425.60730, val_loss=440.10992\n",
      "Epoch 17032: train_loss=425.56970, val_loss=440.05154\n",
      "Epoch 17033: train_loss=425.53250, val_loss=440.02997\n",
      "Epoch 17034: train_loss=425.49289, val_loss=439.95953\n",
      "Epoch 17035: train_loss=425.44958, val_loss=439.93481\n",
      "Epoch 17036: train_loss=425.40118, val_loss=439.85764\n",
      "Epoch 17037: train_loss=425.34915, val_loss=439.82376\n",
      "Epoch 17038: train_loss=425.29416, val_loss=439.74423\n",
      "Epoch 17039: train_loss=425.23813, val_loss=439.70193\n",
      "Epoch 17040: train_loss=425.18222, val_loss=439.63068\n",
      "Epoch 17041: train_loss=425.12704, val_loss=439.58542\n",
      "Epoch 17042: train_loss=425.07361, val_loss=439.52844\n",
      "Epoch 17043: train_loss=425.02234, val_loss=439.47812\n",
      "Epoch 17044: train_loss=424.97348, val_loss=439.43137\n",
      "Epoch 17045: train_loss=424.92630, val_loss=439.37622\n",
      "Epoch 17046: train_loss=424.88004, val_loss=439.33765\n",
      "Epoch 17047: train_loss=424.83408, val_loss=439.27960\n",
      "Epoch 17048: train_loss=424.78802, val_loss=439.24475\n",
      "Epoch 17049: train_loss=424.74142, val_loss=439.18234\n",
      "Epoch 17050: train_loss=424.69476, val_loss=439.14777\n",
      "Epoch 17051: train_loss=424.64758, val_loss=439.08347\n",
      "Epoch 17052: train_loss=424.60019, val_loss=439.05090\n",
      "Epoch 17053: train_loss=424.55228, val_loss=438.98566\n",
      "Epoch 17054: train_loss=424.50403, val_loss=438.95325\n",
      "Epoch 17055: train_loss=424.45535, val_loss=438.88538\n",
      "Epoch 17056: train_loss=424.40613, val_loss=438.85129\n",
      "Epoch 17057: train_loss=424.35693, val_loss=438.78290\n",
      "Epoch 17058: train_loss=424.30731, val_loss=438.74808\n",
      "Epoch 17059: train_loss=424.25711, val_loss=438.68088\n",
      "Epoch 17060: train_loss=424.20697, val_loss=438.64484\n",
      "Epoch 17061: train_loss=424.15659, val_loss=438.57730\n",
      "Epoch 17062: train_loss=424.10617, val_loss=438.53870\n",
      "Epoch 17063: train_loss=424.05548, val_loss=438.47177\n",
      "Epoch 17064: train_loss=424.00494, val_loss=438.43231\n",
      "Epoch 17065: train_loss=423.95401, val_loss=438.36847\n",
      "Epoch 17066: train_loss=423.90323, val_loss=438.32910\n",
      "Epoch 17067: train_loss=423.85263, val_loss=438.26624\n",
      "Epoch 17068: train_loss=423.80203, val_loss=438.22391\n",
      "Epoch 17069: train_loss=423.75131, val_loss=438.16071\n",
      "Epoch 17070: train_loss=423.70065, val_loss=438.11694\n",
      "Epoch 17071: train_loss=423.65005, val_loss=438.05692\n",
      "Epoch 17072: train_loss=423.59946, val_loss=438.01413\n",
      "Epoch 17073: train_loss=423.54904, val_loss=437.95490\n",
      "Epoch 17074: train_loss=423.49847, val_loss=437.90839\n",
      "Epoch 17075: train_loss=423.44821, val_loss=437.84805\n",
      "Epoch 17076: train_loss=423.39786, val_loss=437.80197\n",
      "Epoch 17077: train_loss=423.34763, val_loss=437.74432\n",
      "Epoch 17078: train_loss=423.29770, val_loss=437.70157\n",
      "Epoch 17079: train_loss=423.24786, val_loss=437.64246\n",
      "Epoch 17080: train_loss=423.19824, val_loss=437.59918\n",
      "Epoch 17081: train_loss=423.14963, val_loss=437.53711\n",
      "Epoch 17082: train_loss=423.10199, val_loss=437.50259\n",
      "Epoch 17083: train_loss=423.05560, val_loss=437.44211\n",
      "Epoch 17084: train_loss=423.01141, val_loss=437.42047\n",
      "Epoch 17085: train_loss=422.97031, val_loss=437.35651\n",
      "Epoch 17086: train_loss=422.93329, val_loss=437.35028\n",
      "Epoch 17087: train_loss=422.90088, val_loss=437.28601\n",
      "Epoch 17088: train_loss=422.87512, val_loss=437.30588\n",
      "Epoch 17089: train_loss=422.85489, val_loss=437.24612\n",
      "Epoch 17090: train_loss=422.84293, val_loss=437.29498\n",
      "Epoch 17091: train_loss=422.83609, val_loss=437.23303\n",
      "Epoch 17092: train_loss=422.83777, val_loss=437.30054\n",
      "Epoch 17093: train_loss=422.83734, val_loss=437.22369\n",
      "Epoch 17094: train_loss=422.83783, val_loss=437.28534\n",
      "Epoch 17095: train_loss=422.81891, val_loss=437.16571\n",
      "Epoch 17096: train_loss=422.78293, val_loss=437.17529\n",
      "Epoch 17097: train_loss=422.70840, val_loss=436.99005\n",
      "Epoch 17098: train_loss=422.60507, val_loss=436.92322\n",
      "Epoch 17099: train_loss=422.46896, val_loss=436.71765\n",
      "Epoch 17100: train_loss=422.32709, val_loss=436.62891\n",
      "Epoch 17101: train_loss=422.19299, val_loss=436.48730\n",
      "Epoch 17102: train_loss=422.08322, val_loss=436.42169\n",
      "Epoch 17103: train_loss=422.00372, val_loss=436.37070\n",
      "Epoch 17104: train_loss=421.95297, val_loss=436.32095\n",
      "Epoch 17105: train_loss=421.92282, val_loss=436.32776\n",
      "Epoch 17106: train_loss=421.90341, val_loss=436.26694\n",
      "Epoch 17107: train_loss=421.88342, val_loss=436.28558\n",
      "Epoch 17108: train_loss=421.85422, val_loss=436.19308\n",
      "Epoch 17109: train_loss=421.81094, val_loss=436.18451\n",
      "Epoch 17110: train_loss=421.75266, val_loss=436.06537\n",
      "Epoch 17111: train_loss=421.68311, val_loss=436.02863\n",
      "Epoch 17112: train_loss=421.60709, val_loss=435.91663\n",
      "Epoch 17113: train_loss=421.53018, val_loss=435.87048\n",
      "Epoch 17114: train_loss=421.45749, val_loss=435.79129\n",
      "Epoch 17115: train_loss=421.39249, val_loss=435.74176\n",
      "Epoch 17116: train_loss=421.33566, val_loss=435.69409\n",
      "Epoch 17117: train_loss=421.28613, val_loss=435.63898\n",
      "Epoch 17118: train_loss=421.24146, val_loss=435.61362\n",
      "Epoch 17119: train_loss=421.19928, val_loss=435.55035\n",
      "Epoch 17120: train_loss=421.15710, val_loss=435.53195\n",
      "Epoch 17121: train_loss=421.11328, val_loss=435.45474\n",
      "Epoch 17122: train_loss=421.06622, val_loss=435.43091\n",
      "Epoch 17123: train_loss=421.01584, val_loss=435.34525\n",
      "Epoch 17124: train_loss=420.96207, val_loss=435.31436\n",
      "Epoch 17125: train_loss=420.90536, val_loss=435.23047\n",
      "Epoch 17126: train_loss=420.84723, val_loss=435.19247\n",
      "Epoch 17127: train_loss=420.78830, val_loss=435.11429\n",
      "Epoch 17128: train_loss=420.72998, val_loss=435.06808\n",
      "Epoch 17129: train_loss=420.67288, val_loss=434.99936\n",
      "Epoch 17130: train_loss=420.61749, val_loss=434.94977\n",
      "Epoch 17131: train_loss=420.56363, val_loss=434.89301\n",
      "Epoch 17132: train_loss=420.51083, val_loss=434.83948\n",
      "Epoch 17133: train_loss=420.45901, val_loss=434.78854\n",
      "Epoch 17134: train_loss=420.40793, val_loss=434.72879\n",
      "Epoch 17135: train_loss=420.35733, val_loss=434.68344\n",
      "Epoch 17136: train_loss=420.30701, val_loss=434.62164\n",
      "Epoch 17137: train_loss=420.25702, val_loss=434.58191\n",
      "Epoch 17138: train_loss=420.20700, val_loss=434.51605\n",
      "Epoch 17139: train_loss=420.15695, val_loss=434.47803\n",
      "Epoch 17140: train_loss=420.10733, val_loss=434.40768\n",
      "Epoch 17141: train_loss=420.05768, val_loss=434.37521\n",
      "Epoch 17142: train_loss=420.00824, val_loss=434.30597\n",
      "Epoch 17143: train_loss=419.95880, val_loss=434.27963\n",
      "Epoch 17144: train_loss=419.91046, val_loss=434.20551\n",
      "Epoch 17145: train_loss=419.86169, val_loss=434.17944\n",
      "Epoch 17146: train_loss=419.81406, val_loss=434.10046\n",
      "Epoch 17147: train_loss=419.76578, val_loss=434.08038\n",
      "Epoch 17148: train_loss=419.71817, val_loss=434.00238\n",
      "Epoch 17149: train_loss=419.67035, val_loss=433.98697\n",
      "Epoch 17150: train_loss=419.62241, val_loss=433.90323\n",
      "Epoch 17151: train_loss=419.57352, val_loss=433.88431\n",
      "Epoch 17152: train_loss=419.52408, val_loss=433.79544\n",
      "Epoch 17153: train_loss=419.47385, val_loss=433.77826\n",
      "Epoch 17154: train_loss=419.42282, val_loss=433.68973\n",
      "Epoch 17155: train_loss=419.37048, val_loss=433.67252\n",
      "Epoch 17156: train_loss=419.31750, val_loss=433.57944\n",
      "Epoch 17157: train_loss=419.26337, val_loss=433.55670\n",
      "Epoch 17158: train_loss=419.20901, val_loss=433.46219\n",
      "Epoch 17159: train_loss=419.15384, val_loss=433.43936\n",
      "Epoch 17160: train_loss=419.09808, val_loss=433.34894\n",
      "Epoch 17161: train_loss=419.04144, val_loss=433.32385\n",
      "Epoch 17162: train_loss=418.98425, val_loss=433.23248\n",
      "Epoch 17163: train_loss=418.92639, val_loss=433.19968\n",
      "Epoch 17164: train_loss=418.86780, val_loss=433.11075\n",
      "Epoch 17165: train_loss=418.80936, val_loss=433.07648\n",
      "Epoch 17166: train_loss=418.75092, val_loss=432.99515\n",
      "Epoch 17167: train_loss=418.69330, val_loss=432.95795\n",
      "Epoch 17168: train_loss=418.63583, val_loss=432.87924\n",
      "Epoch 17169: train_loss=418.57895, val_loss=432.83804\n",
      "Epoch 17170: train_loss=418.52280, val_loss=432.76376\n",
      "Epoch 17171: train_loss=418.46710, val_loss=432.72244\n",
      "Epoch 17172: train_loss=418.41177, val_loss=432.65231\n",
      "Epoch 17173: train_loss=418.35696, val_loss=432.60858\n",
      "Epoch 17174: train_loss=418.30212, val_loss=432.53940\n",
      "Epoch 17175: train_loss=418.24817, val_loss=432.49646\n",
      "Epoch 17176: train_loss=418.19418, val_loss=432.42926\n",
      "Epoch 17177: train_loss=418.14041, val_loss=432.38666\n",
      "Epoch 17178: train_loss=418.08731, val_loss=432.31808\n",
      "Epoch 17179: train_loss=418.03470, val_loss=432.27750\n",
      "Epoch 17180: train_loss=417.98267, val_loss=432.20898\n",
      "Epoch 17181: train_loss=417.93124, val_loss=432.17648\n",
      "Epoch 17182: train_loss=417.88110, val_loss=432.10678\n",
      "Epoch 17183: train_loss=417.83221, val_loss=432.08032\n",
      "Epoch 17184: train_loss=417.78473, val_loss=432.00485\n",
      "Epoch 17185: train_loss=417.73938, val_loss=431.98776\n",
      "Epoch 17186: train_loss=417.69699, val_loss=431.91156\n",
      "Epoch 17187: train_loss=417.65720, val_loss=431.91403\n",
      "Epoch 17188: train_loss=417.62134, val_loss=431.83865\n",
      "Epoch 17189: train_loss=417.58932, val_loss=431.85828\n",
      "Epoch 17190: train_loss=417.56226, val_loss=431.77719\n",
      "Epoch 17191: train_loss=417.53864, val_loss=431.81287\n",
      "Epoch 17192: train_loss=417.51825, val_loss=431.72699\n",
      "Epoch 17193: train_loss=417.49921, val_loss=431.77405\n",
      "Epoch 17194: train_loss=417.47522, val_loss=431.67145\n",
      "Epoch 17195: train_loss=417.44699, val_loss=431.70389\n",
      "Epoch 17196: train_loss=417.40289, val_loss=431.56354\n",
      "Epoch 17197: train_loss=417.34390, val_loss=431.55399\n",
      "Epoch 17198: train_loss=417.26315, val_loss=431.38290\n",
      "Epoch 17199: train_loss=417.16724, val_loss=431.33420\n",
      "Epoch 17200: train_loss=417.05707, val_loss=431.16608\n",
      "Epoch 17201: train_loss=416.94464, val_loss=431.09952\n",
      "Epoch 17202: train_loss=416.83768, val_loss=430.97513\n",
      "Epoch 17203: train_loss=416.74551, val_loss=430.91299\n",
      "Epoch 17204: train_loss=416.67130, val_loss=430.84973\n",
      "Epoch 17205: train_loss=416.61353, val_loss=430.79333\n",
      "Epoch 17206: train_loss=416.56833, val_loss=430.77356\n",
      "Epoch 17207: train_loss=416.53146, val_loss=430.70886\n",
      "Epoch 17208: train_loss=416.49646, val_loss=430.70496\n",
      "Epoch 17209: train_loss=416.45908, val_loss=430.62317\n",
      "Epoch 17210: train_loss=416.41559, val_loss=430.61346\n",
      "Epoch 17211: train_loss=416.36462, val_loss=430.51358\n",
      "Epoch 17212: train_loss=416.30615, val_loss=430.48544\n",
      "Epoch 17213: train_loss=416.24176, val_loss=430.37756\n",
      "Epoch 17214: train_loss=416.17252, val_loss=430.33505\n",
      "Epoch 17215: train_loss=416.10226, val_loss=430.23938\n",
      "Epoch 17216: train_loss=416.03302, val_loss=430.19153\n",
      "Epoch 17217: train_loss=415.96652, val_loss=430.11655\n",
      "Epoch 17218: train_loss=415.90350, val_loss=430.06332\n",
      "Epoch 17219: train_loss=415.84436, val_loss=430.00519\n",
      "Epoch 17220: train_loss=415.78885, val_loss=429.94492\n",
      "Epoch 17221: train_loss=415.73566, val_loss=429.89868\n",
      "Epoch 17222: train_loss=415.68411, val_loss=429.83145\n",
      "Epoch 17223: train_loss=415.63330, val_loss=429.79449\n",
      "Epoch 17224: train_loss=415.58270, val_loss=429.72375\n",
      "Epoch 17225: train_loss=415.53189, val_loss=429.69412\n",
      "Epoch 17226: train_loss=415.48083, val_loss=429.61929\n",
      "Epoch 17227: train_loss=415.42923, val_loss=429.58932\n",
      "Epoch 17228: train_loss=415.37680, val_loss=429.50742\n",
      "Epoch 17229: train_loss=415.32361, val_loss=429.47678\n",
      "Epoch 17230: train_loss=415.26959, val_loss=429.39319\n",
      "Epoch 17231: train_loss=415.21478, val_loss=429.36328\n",
      "Epoch 17232: train_loss=415.15930, val_loss=429.27936\n",
      "Epoch 17233: train_loss=415.10364, val_loss=429.24860\n",
      "Epoch 17234: train_loss=415.04745, val_loss=429.16455\n",
      "Epoch 17235: train_loss=414.99161, val_loss=429.13361\n",
      "Epoch 17236: train_loss=414.93530, val_loss=429.04977\n",
      "Epoch 17237: train_loss=414.87943, val_loss=429.01797\n",
      "Epoch 17238: train_loss=414.82397, val_loss=428.93246\n",
      "Epoch 17239: train_loss=414.76886, val_loss=428.90228\n",
      "Epoch 17240: train_loss=414.71387, val_loss=428.81918\n",
      "Epoch 17241: train_loss=414.65967, val_loss=428.79373\n",
      "Epoch 17242: train_loss=414.60568, val_loss=428.71011\n",
      "Epoch 17243: train_loss=414.55197, val_loss=428.68469\n",
      "Epoch 17244: train_loss=414.49823, val_loss=428.59766\n",
      "Epoch 17245: train_loss=414.44464, val_loss=428.57358\n",
      "Epoch 17246: train_loss=414.39050, val_loss=428.48502\n",
      "Epoch 17247: train_loss=414.33606, val_loss=428.46069\n",
      "Epoch 17248: train_loss=414.28061, val_loss=428.36969\n",
      "Epoch 17249: train_loss=414.22446, val_loss=428.34344\n",
      "Epoch 17250: train_loss=414.16727, val_loss=428.25082\n",
      "Epoch 17251: train_loss=414.10895, val_loss=428.22141\n",
      "Epoch 17252: train_loss=414.04990, val_loss=428.13019\n",
      "Epoch 17253: train_loss=413.99014, val_loss=428.09805\n",
      "Epoch 17254: train_loss=413.93045, val_loss=428.00864\n",
      "Epoch 17255: train_loss=413.87042, val_loss=427.97287\n",
      "Epoch 17256: train_loss=413.81061, val_loss=427.88553\n",
      "Epoch 17257: train_loss=413.75095, val_loss=427.84628\n",
      "Epoch 17258: train_loss=413.69095, val_loss=427.76297\n",
      "Epoch 17259: train_loss=413.63110, val_loss=427.72275\n",
      "Epoch 17260: train_loss=413.57141, val_loss=427.64313\n",
      "Epoch 17261: train_loss=413.51202, val_loss=427.59851\n",
      "Epoch 17262: train_loss=413.45264, val_loss=427.52179\n",
      "Epoch 17263: train_loss=413.39398, val_loss=427.47403\n",
      "Epoch 17264: train_loss=413.33557, val_loss=427.40137\n",
      "Epoch 17265: train_loss=413.27768, val_loss=427.35294\n",
      "Epoch 17266: train_loss=413.22015, val_loss=427.28275\n",
      "Epoch 17267: train_loss=413.16266, val_loss=427.23386\n",
      "Epoch 17268: train_loss=413.10547, val_loss=427.16562\n",
      "Epoch 17269: train_loss=413.04852, val_loss=427.11664\n",
      "Epoch 17270: train_loss=412.99155, val_loss=427.04791\n",
      "Epoch 17271: train_loss=412.93484, val_loss=426.99902\n",
      "Epoch 17272: train_loss=412.87851, val_loss=426.92871\n",
      "Epoch 17273: train_loss=412.82214, val_loss=426.88315\n",
      "Epoch 17274: train_loss=412.76633, val_loss=426.81381\n",
      "Epoch 17275: train_loss=412.71158, val_loss=426.77390\n",
      "Epoch 17276: train_loss=412.65765, val_loss=426.70078\n",
      "Epoch 17277: train_loss=412.60516, val_loss=426.66666\n",
      "Epoch 17278: train_loss=412.55414, val_loss=426.59000\n",
      "Epoch 17279: train_loss=412.50528, val_loss=426.57001\n",
      "Epoch 17280: train_loss=412.45853, val_loss=426.49268\n",
      "Epoch 17281: train_loss=412.41519, val_loss=426.48914\n",
      "Epoch 17282: train_loss=412.37509, val_loss=426.40714\n",
      "Epoch 17283: train_loss=412.33972, val_loss=426.42181\n",
      "Epoch 17284: train_loss=412.30804, val_loss=426.33701\n",
      "Epoch 17285: train_loss=412.28189, val_loss=426.37549\n",
      "Epoch 17286: train_loss=412.25815, val_loss=426.28745\n",
      "Epoch 17287: train_loss=412.23932, val_loss=426.34070\n",
      "Epoch 17288: train_loss=412.21777, val_loss=426.23389\n",
      "Epoch 17289: train_loss=412.19550, val_loss=426.28262\n",
      "Epoch 17290: train_loss=412.16171, val_loss=426.14432\n",
      "Epoch 17291: train_loss=412.11523, val_loss=426.16205\n",
      "Epoch 17292: train_loss=412.04526, val_loss=425.98312\n",
      "Epoch 17293: train_loss=411.95514, val_loss=425.94604\n",
      "Epoch 17294: train_loss=411.84125, val_loss=425.74673\n",
      "Epoch 17295: train_loss=411.71783, val_loss=425.67499\n",
      "Epoch 17296: train_loss=411.59329, val_loss=425.51474\n",
      "Epoch 17297: train_loss=411.48056, val_loss=425.44452\n",
      "Epoch 17298: train_loss=411.38663, val_loss=425.35733\n",
      "Epoch 17299: train_loss=411.31415, val_loss=425.29532\n",
      "Epoch 17300: train_loss=411.26007, val_loss=425.26697\n",
      "Epoch 17301: train_loss=411.21866, val_loss=425.19852\n",
      "Epoch 17302: train_loss=411.18265, val_loss=425.19629\n",
      "Epoch 17303: train_loss=411.14590, val_loss=425.10953\n",
      "Epoch 17304: train_loss=411.10403, val_loss=425.10306\n",
      "Epoch 17305: train_loss=411.05377, val_loss=424.99353\n",
      "Epoch 17306: train_loss=410.99518, val_loss=424.97003\n",
      "Epoch 17307: train_loss=410.92828, val_loss=424.85123\n",
      "Epoch 17308: train_loss=410.85602, val_loss=424.81265\n",
      "Epoch 17309: train_loss=410.78024, val_loss=424.70142\n",
      "Epoch 17310: train_loss=410.70383, val_loss=424.65216\n",
      "Epoch 17311: train_loss=410.62964, val_loss=424.55997\n",
      "Epoch 17312: train_loss=410.55920, val_loss=424.50284\n",
      "Epoch 17313: train_loss=410.49316, val_loss=424.43393\n",
      "Epoch 17314: train_loss=410.43155, val_loss=424.37091\n",
      "Epoch 17315: train_loss=410.37366, val_loss=424.32251\n",
      "Epoch 17316: train_loss=410.31818, val_loss=424.25235\n",
      "Epoch 17317: train_loss=410.26395, val_loss=424.21451\n",
      "Epoch 17318: train_loss=410.20984, val_loss=424.13553\n",
      "Epoch 17319: train_loss=410.15570, val_loss=424.10165\n",
      "Epoch 17320: train_loss=410.10040, val_loss=424.01624\n",
      "Epoch 17321: train_loss=410.04446, val_loss=423.98532\n",
      "Epoch 17322: train_loss=409.98746, val_loss=423.89560\n",
      "Epoch 17323: train_loss=409.92981, val_loss=423.86365\n",
      "Epoch 17324: train_loss=409.87030, val_loss=423.76935\n",
      "Epoch 17325: train_loss=409.80975, val_loss=423.73474\n",
      "Epoch 17326: train_loss=409.74786, val_loss=423.64145\n",
      "Epoch 17327: train_loss=409.68494, val_loss=423.60431\n",
      "Epoch 17328: train_loss=409.62088, val_loss=423.51111\n",
      "Epoch 17329: train_loss=409.55649, val_loss=423.46753\n",
      "Epoch 17330: train_loss=409.49191, val_loss=423.37646\n",
      "Epoch 17331: train_loss=409.42719, val_loss=423.32751\n",
      "Epoch 17332: train_loss=409.36194, val_loss=423.24219\n",
      "Epoch 17333: train_loss=409.29691, val_loss=423.19028\n",
      "Epoch 17334: train_loss=409.23199, val_loss=423.11035\n",
      "Epoch 17335: train_loss=409.16736, val_loss=423.05286\n",
      "Epoch 17336: train_loss=409.10306, val_loss=422.97714\n",
      "Epoch 17337: train_loss=409.03934, val_loss=422.91544\n",
      "Epoch 17338: train_loss=408.97568, val_loss=422.84409\n",
      "Epoch 17339: train_loss=408.91226, val_loss=422.78165\n",
      "Epoch 17340: train_loss=408.84915, val_loss=422.71506\n",
      "Epoch 17341: train_loss=408.78598, val_loss=422.65176\n",
      "Epoch 17342: train_loss=408.72290, val_loss=422.58609\n",
      "Epoch 17343: train_loss=408.65982, val_loss=422.52158\n",
      "Epoch 17344: train_loss=408.59644, val_loss=422.45685\n",
      "Epoch 17345: train_loss=408.53290, val_loss=422.39130\n",
      "Epoch 17346: train_loss=408.46933, val_loss=422.32513\n",
      "Epoch 17347: train_loss=408.40561, val_loss=422.26031\n",
      "Epoch 17348: train_loss=408.34210, val_loss=422.19678\n",
      "Epoch 17349: train_loss=408.27835, val_loss=422.13342\n",
      "Epoch 17350: train_loss=408.21451, val_loss=422.07062\n",
      "Epoch 17351: train_loss=408.15033, val_loss=422.00699\n",
      "Epoch 17352: train_loss=408.08588, val_loss=421.94308\n",
      "Epoch 17353: train_loss=408.02139, val_loss=421.87952\n",
      "Epoch 17354: train_loss=407.95773, val_loss=421.81573\n",
      "Epoch 17355: train_loss=407.89404, val_loss=421.75327\n",
      "Epoch 17356: train_loss=407.83026, val_loss=421.68918\n",
      "Epoch 17357: train_loss=407.76669, val_loss=421.62558\n",
      "Epoch 17358: train_loss=407.70300, val_loss=421.56055\n",
      "Epoch 17359: train_loss=407.63898, val_loss=421.49710\n",
      "Epoch 17360: train_loss=407.57495, val_loss=421.43317\n",
      "Epoch 17361: train_loss=407.51129, val_loss=421.37122\n",
      "Epoch 17362: train_loss=407.44757, val_loss=421.30670\n",
      "Epoch 17363: train_loss=407.38403, val_loss=421.24368\n",
      "Epoch 17364: train_loss=407.32034, val_loss=421.17834\n",
      "Epoch 17365: train_loss=407.25650, val_loss=421.11685\n",
      "Epoch 17366: train_loss=407.19293, val_loss=421.05130\n",
      "Epoch 17367: train_loss=407.12946, val_loss=420.99240\n",
      "Epoch 17368: train_loss=407.06616, val_loss=420.92587\n",
      "Epoch 17369: train_loss=407.00330, val_loss=420.86752\n",
      "Epoch 17370: train_loss=406.94009, val_loss=420.79593\n",
      "Epoch 17371: train_loss=406.87695, val_loss=420.74008\n",
      "Epoch 17372: train_loss=406.81412, val_loss=420.66287\n",
      "Epoch 17373: train_loss=406.75192, val_loss=420.61429\n",
      "Epoch 17374: train_loss=406.69104, val_loss=420.53381\n",
      "Epoch 17375: train_loss=406.63181, val_loss=420.50070\n",
      "Epoch 17376: train_loss=406.57574, val_loss=420.41708\n",
      "Epoch 17377: train_loss=406.52487, val_loss=420.41168\n",
      "Epoch 17378: train_loss=406.48169, val_loss=420.33188\n",
      "Epoch 17379: train_loss=406.45105, val_loss=420.38321\n",
      "Epoch 17380: train_loss=406.43826, val_loss=420.32495\n",
      "Epoch 17381: train_loss=406.45544, val_loss=420.48016\n",
      "Epoch 17382: train_loss=406.51205, val_loss=420.47906\n",
      "Epoch 17383: train_loss=406.62790, val_loss=420.79660\n",
      "Epoch 17384: train_loss=406.79727, val_loss=420.85443\n",
      "Epoch 17385: train_loss=407.02136, val_loss=421.22958\n",
      "Epoch 17386: train_loss=407.19580, val_loss=421.08066\n",
      "Epoch 17387: train_loss=407.25504, val_loss=421.05664\n",
      "Epoch 17388: train_loss=407.02405, val_loss=420.40295\n",
      "Epoch 17389: train_loss=406.56485, val_loss=419.97787\n",
      "Epoch 17390: train_loss=406.01212, val_loss=419.52448\n",
      "Epoch 17391: train_loss=405.64026, val_loss=419.45145\n",
      "Epoch 17392: train_loss=405.56567, val_loss=419.66473\n",
      "Epoch 17393: train_loss=405.71347, val_loss=419.73578\n",
      "Epoch 17394: train_loss=405.88953, val_loss=419.88281\n",
      "Epoch 17395: train_loss=405.90060, val_loss=419.55658\n",
      "Epoch 17396: train_loss=405.70676, val_loss=419.34897\n",
      "Epoch 17397: train_loss=405.40607, val_loss=419.06705\n",
      "Epoch 17398: train_loss=405.18253, val_loss=419.00424\n",
      "Epoch 17399: train_loss=405.12332, val_loss=419.11035\n",
      "Epoch 17400: train_loss=405.18060, val_loss=419.07999\n",
      "Epoch 17401: train_loss=405.22980, val_loss=419.11362\n",
      "Epoch 17402: train_loss=405.17145, val_loss=418.86914\n",
      "Epoch 17403: train_loss=405.01324, val_loss=418.74490\n",
      "Epoch 17404: train_loss=404.83707, val_loss=418.61499\n",
      "Epoch 17405: train_loss=404.72916, val_loss=418.57288\n",
      "Epoch 17406: train_loss=404.70471, val_loss=418.62814\n",
      "Epoch 17407: train_loss=404.71072, val_loss=418.53497\n",
      "Epoch 17408: train_loss=404.68106, val_loss=418.50809\n",
      "Epoch 17409: train_loss=404.59033, val_loss=418.33081\n",
      "Epoch 17410: train_loss=404.46692, val_loss=418.24881\n",
      "Epoch 17411: train_loss=404.36084, val_loss=418.18796\n",
      "Epoch 17412: train_loss=404.30005, val_loss=418.13364\n",
      "Epoch 17413: train_loss=404.27084, val_loss=418.14297\n",
      "Epoch 17414: train_loss=404.23672, val_loss=418.03101\n",
      "Epoch 17415: train_loss=404.17319, val_loss=417.98221\n",
      "Epoch 17416: train_loss=404.08359, val_loss=417.85889\n",
      "Epoch 17417: train_loss=403.99094, val_loss=417.79309\n",
      "Epoch 17418: train_loss=403.91653, val_loss=417.75128\n",
      "Epoch 17419: train_loss=403.86429, val_loss=417.68323\n",
      "Epoch 17420: train_loss=403.81998, val_loss=417.66376\n",
      "Epoch 17421: train_loss=403.76596, val_loss=417.55865\n",
      "Epoch 17422: train_loss=403.69632, val_loss=417.50494\n",
      "Epoch 17423: train_loss=403.61685, val_loss=417.41141\n",
      "Epoch 17424: train_loss=403.54123, val_loss=417.34689\n",
      "Epoch 17425: train_loss=403.47635, val_loss=417.30054\n",
      "Epoch 17426: train_loss=403.42023, val_loss=417.22583\n",
      "Epoch 17427: train_loss=403.36569, val_loss=417.18958\n",
      "Epoch 17428: train_loss=403.30475, val_loss=417.09723\n",
      "Epoch 17429: train_loss=403.23721, val_loss=417.04385\n",
      "Epoch 17430: train_loss=403.16571, val_loss=416.96396\n",
      "Epoch 17431: train_loss=403.09668, val_loss=416.90067\n",
      "Epoch 17432: train_loss=403.03256, val_loss=416.84839\n",
      "Epoch 17433: train_loss=402.97253, val_loss=416.77405\n",
      "Epoch 17434: train_loss=402.91309, val_loss=416.72882\n",
      "Epoch 17435: train_loss=402.85086, val_loss=416.64545\n",
      "Epoch 17436: train_loss=402.78561, val_loss=416.59207\n",
      "Epoch 17437: train_loss=402.71826, val_loss=416.51593\n",
      "Epoch 17438: train_loss=402.65161, val_loss=416.45306\n",
      "Epoch 17439: train_loss=402.58707, val_loss=416.39334\n",
      "Epoch 17440: train_loss=402.52469, val_loss=416.32117\n",
      "Epoch 17441: train_loss=402.46320, val_loss=416.26926\n",
      "Epoch 17442: train_loss=402.40100, val_loss=416.19223\n",
      "Epoch 17443: train_loss=402.33707, val_loss=416.13800\n",
      "Epoch 17444: train_loss=402.27179, val_loss=416.06430\n",
      "Epoch 17445: train_loss=402.20633, val_loss=416.00320\n",
      "Epoch 17446: train_loss=402.14148, val_loss=415.93906\n",
      "Epoch 17447: train_loss=402.07776, val_loss=415.87177\n",
      "Epoch 17448: train_loss=402.01489, val_loss=415.81509\n",
      "Epoch 17449: train_loss=401.95200, val_loss=415.74268\n",
      "Epoch 17450: train_loss=401.88858, val_loss=415.68542\n",
      "Epoch 17451: train_loss=401.82440, val_loss=415.61182\n",
      "Epoch 17452: train_loss=401.75967, val_loss=415.55075\n",
      "Epoch 17453: train_loss=401.69507, val_loss=415.48203\n",
      "Epoch 17454: train_loss=401.63055, val_loss=415.41632\n",
      "Epoch 17455: train_loss=401.56653, val_loss=415.35336\n",
      "Epoch 17456: train_loss=401.50266, val_loss=415.28409\n",
      "Epoch 17457: train_loss=401.43896, val_loss=415.22409\n",
      "Epoch 17458: train_loss=401.37509, val_loss=415.15323\n",
      "Epoch 17459: train_loss=401.31100, val_loss=415.09299\n",
      "Epoch 17460: train_loss=401.24652, val_loss=415.02307\n",
      "Epoch 17461: train_loss=401.18204, val_loss=414.95996\n",
      "Epoch 17462: train_loss=401.11761, val_loss=414.89258\n",
      "Epoch 17463: train_loss=401.05316, val_loss=414.82660\n",
      "Epoch 17464: train_loss=400.98892, val_loss=414.76263\n",
      "Epoch 17465: train_loss=400.92465, val_loss=414.69418\n",
      "Epoch 17466: train_loss=400.86041, val_loss=414.63177\n",
      "Epoch 17467: train_loss=400.79605, val_loss=414.56195\n",
      "Epoch 17468: train_loss=400.73160, val_loss=414.49948\n",
      "Epoch 17469: train_loss=400.66693, val_loss=414.42981\n",
      "Epoch 17470: train_loss=400.60217, val_loss=414.36569\n",
      "Epoch 17471: train_loss=400.53741, val_loss=414.29758\n",
      "Epoch 17472: train_loss=400.47278, val_loss=414.23193\n",
      "Epoch 17473: train_loss=400.40802, val_loss=414.16644\n",
      "Epoch 17474: train_loss=400.34335, val_loss=414.09891\n",
      "Epoch 17475: train_loss=400.27869, val_loss=414.03427\n",
      "Epoch 17476: train_loss=400.21384, val_loss=413.96588\n",
      "Epoch 17477: train_loss=400.14902, val_loss=413.90259\n",
      "Epoch 17478: train_loss=400.08405, val_loss=413.83325\n",
      "Epoch 17479: train_loss=400.01920, val_loss=413.76807\n",
      "Epoch 17480: train_loss=399.95392, val_loss=413.69858\n",
      "Epoch 17481: train_loss=399.88876, val_loss=413.63266\n",
      "Epoch 17482: train_loss=399.82346, val_loss=413.56613\n",
      "Epoch 17483: train_loss=399.75833, val_loss=413.49976\n",
      "Epoch 17484: train_loss=399.69299, val_loss=413.43311\n",
      "Epoch 17485: train_loss=399.62759, val_loss=413.36432\n",
      "Epoch 17486: train_loss=399.56216, val_loss=413.29828\n",
      "Epoch 17487: train_loss=399.49661, val_loss=413.23038\n",
      "Epoch 17488: train_loss=399.43100, val_loss=413.16565\n",
      "Epoch 17489: train_loss=399.36533, val_loss=413.09702\n",
      "Epoch 17490: train_loss=399.29959, val_loss=413.02948\n",
      "Epoch 17491: train_loss=399.23380, val_loss=412.95862\n",
      "Epoch 17492: train_loss=399.16788, val_loss=412.89050\n",
      "Epoch 17493: train_loss=399.10193, val_loss=412.82220\n",
      "Epoch 17494: train_loss=399.03592, val_loss=412.75534\n",
      "Epoch 17495: train_loss=398.96976, val_loss=412.68713\n",
      "Epoch 17496: train_loss=398.90366, val_loss=412.61844\n",
      "Epoch 17497: train_loss=398.83752, val_loss=412.54800\n",
      "Epoch 17498: train_loss=398.77124, val_loss=412.47745\n",
      "Epoch 17499: train_loss=398.70496, val_loss=412.40756\n",
      "Epoch 17500: train_loss=398.63864, val_loss=412.33804\n",
      "Epoch 17501: train_loss=398.57224, val_loss=412.26923\n",
      "Epoch 17502: train_loss=398.50589, val_loss=412.19949\n",
      "Epoch 17503: train_loss=398.43927, val_loss=412.13028\n",
      "Epoch 17504: train_loss=398.37265, val_loss=412.05945\n",
      "Epoch 17505: train_loss=398.30603, val_loss=411.98987\n",
      "Epoch 17506: train_loss=398.23914, val_loss=411.91949\n",
      "Epoch 17507: train_loss=398.17242, val_loss=411.85168\n",
      "Epoch 17508: train_loss=398.10559, val_loss=411.78125\n",
      "Epoch 17509: train_loss=398.03867, val_loss=411.71216\n",
      "Epoch 17510: train_loss=397.97180, val_loss=411.63965\n",
      "Epoch 17511: train_loss=397.90475, val_loss=411.57043\n",
      "Epoch 17512: train_loss=397.83780, val_loss=411.49976\n",
      "Epoch 17513: train_loss=397.77075, val_loss=411.43192\n",
      "Epoch 17514: train_loss=397.70370, val_loss=411.36197\n",
      "Epoch 17515: train_loss=397.63647, val_loss=411.29208\n",
      "Epoch 17516: train_loss=397.56943, val_loss=411.22073\n",
      "Epoch 17517: train_loss=397.50220, val_loss=411.15036\n",
      "Epoch 17518: train_loss=397.43491, val_loss=411.08127\n",
      "Epoch 17519: train_loss=397.36758, val_loss=411.01129\n",
      "Epoch 17520: train_loss=397.30017, val_loss=410.94125\n",
      "Epoch 17521: train_loss=397.23282, val_loss=410.86902\n",
      "Epoch 17522: train_loss=397.16531, val_loss=410.79883\n",
      "Epoch 17523: train_loss=397.09778, val_loss=410.72830\n",
      "Epoch 17524: train_loss=397.03018, val_loss=410.66101\n",
      "Epoch 17525: train_loss=396.96255, val_loss=410.58899\n",
      "Epoch 17526: train_loss=396.89487, val_loss=410.52017\n",
      "Epoch 17527: train_loss=396.82706, val_loss=410.44547\n",
      "Epoch 17528: train_loss=396.75943, val_loss=410.37842\n",
      "Epoch 17529: train_loss=396.69171, val_loss=410.30450\n",
      "Epoch 17530: train_loss=396.62399, val_loss=410.24042\n",
      "Epoch 17531: train_loss=396.55634, val_loss=410.16354\n",
      "Epoch 17532: train_loss=396.48874, val_loss=410.10074\n",
      "Epoch 17533: train_loss=396.42130, val_loss=410.02130\n",
      "Epoch 17534: train_loss=396.35370, val_loss=409.96136\n",
      "Epoch 17535: train_loss=396.28625, val_loss=409.88031\n",
      "Epoch 17536: train_loss=396.21881, val_loss=409.82224\n",
      "Epoch 17537: train_loss=396.15134, val_loss=409.73743\n",
      "Epoch 17538: train_loss=396.08395, val_loss=409.68036\n",
      "Epoch 17539: train_loss=396.01636, val_loss=409.59375\n",
      "Epoch 17540: train_loss=395.94882, val_loss=409.54007\n",
      "Epoch 17541: train_loss=395.88138, val_loss=409.45239\n",
      "Epoch 17542: train_loss=395.81390, val_loss=409.40030\n",
      "Epoch 17543: train_loss=395.74655, val_loss=409.30957\n",
      "Epoch 17544: train_loss=395.67938, val_loss=409.25980\n",
      "Epoch 17545: train_loss=395.61237, val_loss=409.16718\n",
      "Epoch 17546: train_loss=395.54590, val_loss=409.12274\n",
      "Epoch 17547: train_loss=395.47943, val_loss=409.02692\n",
      "Epoch 17548: train_loss=395.41348, val_loss=408.98550\n",
      "Epoch 17549: train_loss=395.34799, val_loss=408.88489\n",
      "Epoch 17550: train_loss=395.28290, val_loss=408.85114\n",
      "Epoch 17551: train_loss=395.21869, val_loss=408.74927\n",
      "Epoch 17552: train_loss=395.15546, val_loss=408.72510\n",
      "Epoch 17553: train_loss=395.09323, val_loss=408.61685\n",
      "Epoch 17554: train_loss=395.03217, val_loss=408.60016\n",
      "Epoch 17555: train_loss=394.97247, val_loss=408.48441\n",
      "Epoch 17556: train_loss=394.91370, val_loss=408.48029\n",
      "Epoch 17557: train_loss=394.85638, val_loss=408.36118\n",
      "Epoch 17558: train_loss=394.80142, val_loss=408.37054\n",
      "Epoch 17559: train_loss=394.74728, val_loss=408.24219\n",
      "Epoch 17560: train_loss=394.69464, val_loss=408.25952\n",
      "Epoch 17561: train_loss=394.64053, val_loss=408.11899\n",
      "Epoch 17562: train_loss=394.58572, val_loss=408.14197\n",
      "Epoch 17563: train_loss=394.52698, val_loss=407.99005\n",
      "Epoch 17564: train_loss=394.46552, val_loss=408.00565\n",
      "Epoch 17565: train_loss=394.39651, val_loss=407.83875\n",
      "Epoch 17566: train_loss=394.32306, val_loss=407.83859\n",
      "Epoch 17567: train_loss=394.24017, val_loss=407.66415\n",
      "Epoch 17568: train_loss=394.15292, val_loss=407.64362\n",
      "Epoch 17569: train_loss=394.05835, val_loss=407.47278\n",
      "Epoch 17570: train_loss=393.96158, val_loss=407.42981\n",
      "Epoch 17571: train_loss=393.86359, val_loss=407.27988\n",
      "Epoch 17572: train_loss=393.76874, val_loss=407.22330\n",
      "Epoch 17573: train_loss=393.67883, val_loss=407.11044\n",
      "Epoch 17574: train_loss=393.59543, val_loss=407.04297\n",
      "Epoch 17575: train_loss=393.51880, val_loss=406.96680\n",
      "Epoch 17576: train_loss=393.44824, val_loss=406.88715\n",
      "Epoch 17577: train_loss=393.38226, val_loss=406.83829\n",
      "Epoch 17578: train_loss=393.31934, val_loss=406.74741\n",
      "Epoch 17579: train_loss=393.25754, val_loss=406.71490\n",
      "Epoch 17580: train_loss=393.19604, val_loss=406.61099\n",
      "Epoch 17581: train_loss=393.13379, val_loss=406.58456\n",
      "Epoch 17582: train_loss=393.06970, val_loss=406.47043\n",
      "Epoch 17583: train_loss=393.00415, val_loss=406.44846\n",
      "Epoch 17584: train_loss=392.93686, val_loss=406.32916\n",
      "Epoch 17585: train_loss=392.86789, val_loss=406.30453\n",
      "Epoch 17586: train_loss=392.79709, val_loss=406.18024\n",
      "Epoch 17587: train_loss=392.72528, val_loss=406.15103\n",
      "Epoch 17588: train_loss=392.65179, val_loss=406.02838\n",
      "Epoch 17589: train_loss=392.57770, val_loss=405.99500\n",
      "Epoch 17590: train_loss=392.50290, val_loss=405.87686\n",
      "Epoch 17591: train_loss=392.42828, val_loss=405.83655\n",
      "Epoch 17592: train_loss=392.35339, val_loss=405.72244\n",
      "Epoch 17593: train_loss=392.27902, val_loss=405.67719\n",
      "Epoch 17594: train_loss=392.20480, val_loss=405.57047\n",
      "Epoch 17595: train_loss=392.13104, val_loss=405.52344\n",
      "Epoch 17596: train_loss=392.05765, val_loss=405.42236\n",
      "Epoch 17597: train_loss=391.98468, val_loss=405.36920\n",
      "Epoch 17598: train_loss=391.91211, val_loss=405.27005\n",
      "Epoch 17599: train_loss=391.83981, val_loss=405.21475\n",
      "Epoch 17600: train_loss=391.76758, val_loss=405.12106\n",
      "Epoch 17601: train_loss=391.69574, val_loss=405.06534\n",
      "Epoch 17602: train_loss=391.62405, val_loss=404.97198\n",
      "Epoch 17603: train_loss=391.55286, val_loss=404.91327\n",
      "Epoch 17604: train_loss=391.48181, val_loss=404.81964\n",
      "Epoch 17605: train_loss=391.41095, val_loss=404.76495\n",
      "Epoch 17606: train_loss=391.34064, val_loss=404.67184\n",
      "Epoch 17607: train_loss=391.27063, val_loss=404.62085\n",
      "Epoch 17608: train_loss=391.20139, val_loss=404.52313\n",
      "Epoch 17609: train_loss=391.13254, val_loss=404.47937\n",
      "Epoch 17610: train_loss=391.06497, val_loss=404.37799\n",
      "Epoch 17611: train_loss=390.99850, val_loss=404.34738\n",
      "Epoch 17612: train_loss=390.93423, val_loss=404.24176\n",
      "Epoch 17613: train_loss=390.87238, val_loss=404.22800\n",
      "Epoch 17614: train_loss=390.81424, val_loss=404.11374\n",
      "Epoch 17615: train_loss=390.76035, val_loss=404.12592\n",
      "Epoch 17616: train_loss=390.71194, val_loss=404.00610\n",
      "Epoch 17617: train_loss=390.66980, val_loss=404.05231\n",
      "Epoch 17618: train_loss=390.63364, val_loss=403.92532\n",
      "Epoch 17619: train_loss=390.60516, val_loss=404.00381\n",
      "Epoch 17620: train_loss=390.57996, val_loss=403.86087\n",
      "Epoch 17621: train_loss=390.55817, val_loss=403.95483\n",
      "Epoch 17622: train_loss=390.52750, val_loss=403.77753\n",
      "Epoch 17623: train_loss=390.48862, val_loss=403.84698\n",
      "Epoch 17624: train_loss=390.42255, val_loss=403.61697\n",
      "Epoch 17625: train_loss=390.33569, val_loss=403.62244\n",
      "Epoch 17626: train_loss=390.21375, val_loss=403.35733\n",
      "Epoch 17627: train_loss=390.07376, val_loss=403.30103\n",
      "Epoch 17628: train_loss=389.91965, val_loss=403.07034\n",
      "Epoch 17629: train_loss=389.77350, val_loss=402.99377\n",
      "Epoch 17630: train_loss=389.64554, val_loss=402.85852\n",
      "Epoch 17631: train_loss=389.54349, val_loss=402.78192\n",
      "Epoch 17632: train_loss=389.46802, val_loss=402.74438\n",
      "Epoch 17633: train_loss=389.41272, val_loss=402.65482\n",
      "Epoch 17634: train_loss=389.36703, val_loss=402.66190\n",
      "Epoch 17635: train_loss=389.32037, val_loss=402.53702\n",
      "Epoch 17636: train_loss=389.26471, val_loss=402.53656\n",
      "Epoch 17637: train_loss=389.19638, val_loss=402.38181\n",
      "Epoch 17638: train_loss=389.11539, val_loss=402.35526\n",
      "Epoch 17639: train_loss=389.02451, val_loss=402.19949\n",
      "Epoch 17640: train_loss=388.92868, val_loss=402.14777\n",
      "Epoch 17641: train_loss=388.83276, val_loss=402.01953\n",
      "Epoch 17642: train_loss=388.74112, val_loss=401.95279\n",
      "Epoch 17643: train_loss=388.65594, val_loss=401.86777\n",
      "Epoch 17644: train_loss=388.57828, val_loss=401.78711\n",
      "Epoch 17645: train_loss=388.50635, val_loss=401.73389\n",
      "Epoch 17646: train_loss=388.43768, val_loss=401.63632\n",
      "Epoch 17647: train_loss=388.36987, val_loss=401.59821\n",
      "Epoch 17648: train_loss=388.30136, val_loss=401.48651\n",
      "Epoch 17649: train_loss=388.23163, val_loss=401.45145\n",
      "Epoch 17650: train_loss=388.15851, val_loss=401.33157\n",
      "Epoch 17651: train_loss=388.08340, val_loss=401.29013\n",
      "Epoch 17652: train_loss=388.00552, val_loss=401.16910\n",
      "Epoch 17653: train_loss=387.92654, val_loss=401.11810\n",
      "Epoch 17654: train_loss=387.84631, val_loss=401.00620\n",
      "Epoch 17655: train_loss=387.76675, val_loss=400.94611\n",
      "Epoch 17656: train_loss=387.68747, val_loss=400.84689\n",
      "Epoch 17657: train_loss=387.60971, val_loss=400.77515\n",
      "Epoch 17658: train_loss=387.53281, val_loss=400.68771\n",
      "Epoch 17659: train_loss=387.45712, val_loss=400.60837\n",
      "Epoch 17660: train_loss=387.38232, val_loss=400.53595\n",
      "Epoch 17661: train_loss=387.30838, val_loss=400.44934\n",
      "Epoch 17662: train_loss=387.23468, val_loss=400.38434\n",
      "Epoch 17663: train_loss=387.16159, val_loss=400.28815\n",
      "Epoch 17664: train_loss=387.08850, val_loss=400.22852\n",
      "Epoch 17665: train_loss=387.01566, val_loss=400.12686\n",
      "Epoch 17666: train_loss=386.94284, val_loss=400.07523\n",
      "Epoch 17667: train_loss=386.86990, val_loss=399.96878\n",
      "Epoch 17668: train_loss=386.79712, val_loss=399.91928\n",
      "Epoch 17669: train_loss=386.72394, val_loss=399.80582\n",
      "Epoch 17670: train_loss=386.65048, val_loss=399.76016\n",
      "Epoch 17671: train_loss=386.57666, val_loss=399.64572\n",
      "Epoch 17672: train_loss=386.50287, val_loss=399.60391\n",
      "Epoch 17673: train_loss=386.42841, val_loss=399.48642\n",
      "Epoch 17674: train_loss=386.35349, val_loss=399.44330\n",
      "Epoch 17675: train_loss=386.27792, val_loss=399.32205\n",
      "Epoch 17676: train_loss=386.20230, val_loss=399.27805\n",
      "Epoch 17677: train_loss=386.12616, val_loss=399.15424\n",
      "Epoch 17678: train_loss=386.04962, val_loss=399.10748\n",
      "Epoch 17679: train_loss=385.97235, val_loss=398.98181\n",
      "Epoch 17680: train_loss=385.89505, val_loss=398.93436\n",
      "Epoch 17681: train_loss=385.81744, val_loss=398.81027\n",
      "Epoch 17682: train_loss=385.74023, val_loss=398.76422\n",
      "Epoch 17683: train_loss=385.66315, val_loss=398.64011\n",
      "Epoch 17684: train_loss=385.58646, val_loss=398.59509\n",
      "Epoch 17685: train_loss=385.50964, val_loss=398.47134\n",
      "Epoch 17686: train_loss=385.43283, val_loss=398.42676\n",
      "Epoch 17687: train_loss=385.35587, val_loss=398.30145\n",
      "Epoch 17688: train_loss=385.27853, val_loss=398.25623\n",
      "Epoch 17689: train_loss=385.20102, val_loss=398.13107\n",
      "Epoch 17690: train_loss=385.12314, val_loss=398.08673\n",
      "Epoch 17691: train_loss=385.04587, val_loss=397.96274\n",
      "Epoch 17692: train_loss=384.96851, val_loss=397.91910\n",
      "Epoch 17693: train_loss=384.89160, val_loss=397.79391\n",
      "Epoch 17694: train_loss=384.81470, val_loss=397.75174\n",
      "Epoch 17695: train_loss=384.73834, val_loss=397.62564\n",
      "Epoch 17696: train_loss=384.66205, val_loss=397.58542\n",
      "Epoch 17697: train_loss=384.58630, val_loss=397.45486\n",
      "Epoch 17698: train_loss=384.51102, val_loss=397.41992\n",
      "Epoch 17699: train_loss=384.43668, val_loss=397.28705\n",
      "Epoch 17700: train_loss=384.36337, val_loss=397.26306\n",
      "Epoch 17701: train_loss=384.29208, val_loss=397.12488\n",
      "Epoch 17702: train_loss=384.22263, val_loss=397.11255\n",
      "Epoch 17703: train_loss=384.15506, val_loss=396.96756\n",
      "Epoch 17704: train_loss=384.09055, val_loss=396.97525\n",
      "Epoch 17705: train_loss=384.02832, val_loss=396.82315\n",
      "Epoch 17706: train_loss=383.97003, val_loss=396.85309\n",
      "Epoch 17707: train_loss=383.91376, val_loss=396.68893\n",
      "Epoch 17708: train_loss=383.86197, val_loss=396.73932\n",
      "Epoch 17709: train_loss=383.80951, val_loss=396.56174\n",
      "Epoch 17710: train_loss=383.76025, val_loss=396.62631\n",
      "Epoch 17711: train_loss=383.70477, val_loss=396.42899\n",
      "Epoch 17712: train_loss=383.64786, val_loss=396.48715\n",
      "Epoch 17713: train_loss=383.57648, val_loss=396.25922\n",
      "Epoch 17714: train_loss=383.49625, val_loss=396.28165\n",
      "Epoch 17715: train_loss=383.39474, val_loss=396.03394\n",
      "Epoch 17716: train_loss=383.28223, val_loss=396.01294\n",
      "Epoch 17717: train_loss=383.15662, val_loss=395.78146\n",
      "Epoch 17718: train_loss=383.02969, val_loss=395.72855\n",
      "Epoch 17719: train_loss=382.90759, val_loss=395.55295\n",
      "Epoch 17720: train_loss=382.79645, val_loss=395.48001\n",
      "Epoch 17721: train_loss=382.69812, val_loss=395.37384\n",
      "Epoch 17722: train_loss=382.61325, val_loss=395.28531\n",
      "Epoch 17723: train_loss=382.53973, val_loss=395.23779\n",
      "Epoch 17724: train_loss=382.47372, val_loss=395.12985\n",
      "Epoch 17725: train_loss=382.41080, val_loss=395.11005\n",
      "Epoch 17726: train_loss=382.34662, val_loss=394.97574\n",
      "Epoch 17727: train_loss=382.27853, val_loss=394.95557\n",
      "Epoch 17728: train_loss=382.20477, val_loss=394.80493\n",
      "Epoch 17729: train_loss=382.12589, val_loss=394.77609\n",
      "Epoch 17730: train_loss=382.04239, val_loss=394.62411\n",
      "Epoch 17731: train_loss=381.95554, val_loss=394.57605\n",
      "Epoch 17732: train_loss=381.86722, val_loss=394.43463\n",
      "Epoch 17733: train_loss=381.77878, val_loss=394.37152\n",
      "Epoch 17734: train_loss=381.69162, val_loss=394.25244\n",
      "Epoch 17735: train_loss=381.60632, val_loss=394.17706\n",
      "Epoch 17736: train_loss=381.52350, val_loss=394.07980\n",
      "Epoch 17737: train_loss=381.44318, val_loss=393.98969\n",
      "Epoch 17738: train_loss=381.36456, val_loss=393.91071\n",
      "Epoch 17739: train_loss=381.28754, val_loss=393.81146\n",
      "Epoch 17740: train_loss=381.21121, val_loss=393.74744\n",
      "Epoch 17741: train_loss=381.13501, val_loss=393.63882\n",
      "Epoch 17742: train_loss=381.05865, val_loss=393.57962\n",
      "Epoch 17743: train_loss=380.98169, val_loss=393.46353\n",
      "Epoch 17744: train_loss=380.90399, val_loss=393.40823\n",
      "Epoch 17745: train_loss=380.82590, val_loss=393.29184\n",
      "Epoch 17746: train_loss=380.74680, val_loss=393.23648\n",
      "Epoch 17747: train_loss=380.66742, val_loss=393.11777\n",
      "Epoch 17748: train_loss=380.58780, val_loss=393.05838\n",
      "Epoch 17749: train_loss=380.50806, val_loss=392.94043\n",
      "Epoch 17750: train_loss=380.42838, val_loss=392.88281\n",
      "Epoch 17751: train_loss=380.34879, val_loss=392.76807\n",
      "Epoch 17752: train_loss=380.26913, val_loss=392.70731\n",
      "Epoch 17753: train_loss=380.18954, val_loss=392.59048\n",
      "Epoch 17754: train_loss=380.11008, val_loss=392.52768\n",
      "Epoch 17755: train_loss=380.03043, val_loss=392.41507\n",
      "Epoch 17756: train_loss=379.95071, val_loss=392.35660\n",
      "Epoch 17757: train_loss=379.87115, val_loss=392.24753\n",
      "Epoch 17758: train_loss=379.79181, val_loss=392.18613\n",
      "Epoch 17759: train_loss=379.71228, val_loss=392.07254\n",
      "Epoch 17760: train_loss=379.63303, val_loss=392.01123\n",
      "Epoch 17761: train_loss=379.55383, val_loss=391.89999\n",
      "Epoch 17762: train_loss=379.47482, val_loss=391.84525\n",
      "Epoch 17763: train_loss=379.39594, val_loss=391.73471\n",
      "Epoch 17764: train_loss=379.31757, val_loss=391.68076\n",
      "Epoch 17765: train_loss=379.23938, val_loss=391.56354\n",
      "Epoch 17766: train_loss=379.16150, val_loss=391.51227\n",
      "Epoch 17767: train_loss=379.08423, val_loss=391.39429\n",
      "Epoch 17768: train_loss=379.00809, val_loss=391.35345\n",
      "Epoch 17769: train_loss=378.93280, val_loss=391.23236\n",
      "Epoch 17770: train_loss=378.85928, val_loss=391.20209\n",
      "Epoch 17771: train_loss=378.78726, val_loss=391.07434\n",
      "Epoch 17772: train_loss=378.71875, val_loss=391.06064\n",
      "Epoch 17773: train_loss=378.65247, val_loss=390.92682\n",
      "Epoch 17774: train_loss=378.59125, val_loss=390.93820\n",
      "Epoch 17775: train_loss=378.53400, val_loss=390.79663\n",
      "Epoch 17776: train_loss=378.48312, val_loss=390.84125\n",
      "Epoch 17777: train_loss=378.43854, val_loss=390.69043\n",
      "Epoch 17778: train_loss=378.40054, val_loss=390.76752\n",
      "Epoch 17779: train_loss=378.36490, val_loss=390.59952\n",
      "Epoch 17780: train_loss=378.33209, val_loss=390.69373\n",
      "Epoch 17781: train_loss=378.29288, val_loss=390.49344\n",
      "Epoch 17782: train_loss=378.24515, val_loss=390.56833\n",
      "Epoch 17783: train_loss=378.17618, val_loss=390.31702\n",
      "Epoch 17784: train_loss=378.08194, val_loss=390.32748\n",
      "Epoch 17785: train_loss=377.95630, val_loss=390.03897\n",
      "Epoch 17786: train_loss=377.80679, val_loss=389.97858\n",
      "Epoch 17787: train_loss=377.64267, val_loss=389.72174\n",
      "Epoch 17788: train_loss=377.48257, val_loss=389.63428\n",
      "Epoch 17789: train_loss=377.34180, val_loss=389.48331\n",
      "Epoch 17790: train_loss=377.22980, val_loss=389.39655\n",
      "Epoch 17791: train_loss=377.14590, val_loss=389.34824\n",
      "Epoch 17792: train_loss=377.08334, val_loss=389.24756\n",
      "Epoch 17793: train_loss=377.03268, val_loss=389.25397\n",
      "Epoch 17794: train_loss=376.98407, val_loss=389.12085\n",
      "Epoch 17795: train_loss=376.92963, val_loss=389.12698\n",
      "Epoch 17796: train_loss=376.86148, val_loss=388.95483\n",
      "Epoch 17797: train_loss=376.77911, val_loss=388.93060\n",
      "Epoch 17798: train_loss=376.68347, val_loss=388.74673\n",
      "Epoch 17799: train_loss=376.57864, val_loss=388.69308\n",
      "Epoch 17800: train_loss=376.47046, val_loss=388.53726\n",
      "Epoch 17801: train_loss=376.36606, val_loss=388.46243\n",
      "Epoch 17802: train_loss=376.26913, val_loss=388.35223\n",
      "Epoch 17803: train_loss=376.18137, val_loss=388.26221\n",
      "Epoch 17804: train_loss=376.10159, val_loss=388.19678\n",
      "Epoch 17805: train_loss=376.02762, val_loss=388.09366\n",
      "Epoch 17806: train_loss=375.95639, val_loss=388.05405\n",
      "Epoch 17807: train_loss=375.88550, val_loss=387.93195\n",
      "Epoch 17808: train_loss=375.81226, val_loss=387.89474\n",
      "Epoch 17809: train_loss=375.73605, val_loss=387.76071\n",
      "Epoch 17810: train_loss=375.65622, val_loss=387.72165\n",
      "Epoch 17811: train_loss=375.57324, val_loss=387.58691\n",
      "Epoch 17812: train_loss=375.48743, val_loss=387.53830\n",
      "Epoch 17813: train_loss=375.40039, val_loss=387.40848\n",
      "Epoch 17814: train_loss=375.31259, val_loss=387.34494\n",
      "Epoch 17815: train_loss=375.22522, val_loss=387.22580\n",
      "Epoch 17816: train_loss=375.13870, val_loss=387.15186\n",
      "Epoch 17817: train_loss=375.05368, val_loss=387.04956\n",
      "Epoch 17818: train_loss=374.97018, val_loss=386.96646\n",
      "Epoch 17819: train_loss=374.88806, val_loss=386.87860\n",
      "Epoch 17820: train_loss=374.80679, val_loss=386.78799\n",
      "Epoch 17821: train_loss=374.72629, val_loss=386.71231\n",
      "Epoch 17822: train_loss=374.64639, val_loss=386.61539\n",
      "Epoch 17823: train_loss=374.56659, val_loss=386.54660\n",
      "Epoch 17824: train_loss=374.48709, val_loss=386.44125\n",
      "Epoch 17825: train_loss=374.40759, val_loss=386.37811\n",
      "Epoch 17826: train_loss=374.32843, val_loss=386.26926\n",
      "Epoch 17827: train_loss=374.24908, val_loss=386.21414\n",
      "Epoch 17828: train_loss=374.17026, val_loss=386.10019\n",
      "Epoch 17829: train_loss=374.09134, val_loss=386.04922\n",
      "Epoch 17830: train_loss=374.01321, val_loss=385.92801\n",
      "Epoch 17831: train_loss=373.93518, val_loss=385.88495\n",
      "Epoch 17832: train_loss=373.85797, val_loss=385.76178\n",
      "Epoch 17833: train_loss=373.78094, val_loss=385.72800\n",
      "Epoch 17834: train_loss=373.70407, val_loss=385.59711\n",
      "Epoch 17835: train_loss=373.62738, val_loss=385.56741\n",
      "Epoch 17836: train_loss=373.55081, val_loss=385.42944\n",
      "Epoch 17837: train_loss=373.47452, val_loss=385.40738\n",
      "Epoch 17838: train_loss=373.39780, val_loss=385.26477\n",
      "Epoch 17839: train_loss=373.32123, val_loss=385.24734\n",
      "Epoch 17840: train_loss=373.24402, val_loss=385.09656\n",
      "Epoch 17841: train_loss=373.16672, val_loss=385.08087\n",
      "Epoch 17842: train_loss=373.08804, val_loss=384.92532\n",
      "Epoch 17843: train_loss=373.00974, val_loss=384.91473\n",
      "Epoch 17844: train_loss=372.93011, val_loss=384.75568\n",
      "Epoch 17845: train_loss=372.85062, val_loss=384.74451\n",
      "Epoch 17846: train_loss=372.76926, val_loss=384.57913\n",
      "Epoch 17847: train_loss=372.68713, val_loss=384.56635\n",
      "Epoch 17848: train_loss=372.60324, val_loss=384.40097\n",
      "Epoch 17849: train_loss=372.51868, val_loss=384.38553\n",
      "Epoch 17850: train_loss=372.43237, val_loss=384.22134\n",
      "Epoch 17851: train_loss=372.34564, val_loss=384.20007\n",
      "Epoch 17852: train_loss=372.25735, val_loss=384.03635\n",
      "Epoch 17853: train_loss=372.16846, val_loss=384.00891\n",
      "Epoch 17854: train_loss=372.07907, val_loss=383.85187\n",
      "Epoch 17855: train_loss=371.98969, val_loss=383.82019\n",
      "Epoch 17856: train_loss=371.90097, val_loss=383.67114\n",
      "Epoch 17857: train_loss=371.81235, val_loss=383.63220\n",
      "Epoch 17858: train_loss=371.72388, val_loss=383.48877\n",
      "Epoch 17859: train_loss=371.63611, val_loss=383.44431\n",
      "Epoch 17860: train_loss=371.54913, val_loss=383.30795\n",
      "Epoch 17861: train_loss=371.46280, val_loss=383.26132\n",
      "Epoch 17862: train_loss=371.37726, val_loss=383.13138\n",
      "Epoch 17863: train_loss=371.29248, val_loss=383.08347\n",
      "Epoch 17864: train_loss=371.20810, val_loss=382.95526\n",
      "Epoch 17865: train_loss=371.12430, val_loss=382.90659\n",
      "Epoch 17866: train_loss=371.04123, val_loss=382.77866\n",
      "Epoch 17867: train_loss=370.95926, val_loss=382.73380\n",
      "Epoch 17868: train_loss=370.87720, val_loss=382.60471\n",
      "Epoch 17869: train_loss=370.79651, val_loss=382.56564\n",
      "Epoch 17870: train_loss=370.71579, val_loss=382.43286\n",
      "Epoch 17871: train_loss=370.63666, val_loss=382.40204\n",
      "Epoch 17872: train_loss=370.55801, val_loss=382.26486\n",
      "Epoch 17873: train_loss=370.48087, val_loss=382.24643\n",
      "Epoch 17874: train_loss=370.40405, val_loss=382.10114\n",
      "Epoch 17875: train_loss=370.32916, val_loss=382.09470\n",
      "Epoch 17876: train_loss=370.25659, val_loss=381.93906\n",
      "Epoch 17877: train_loss=370.18649, val_loss=381.95129\n",
      "Epoch 17878: train_loss=370.11945, val_loss=381.78848\n",
      "Epoch 17879: train_loss=370.05536, val_loss=381.82596\n",
      "Epoch 17880: train_loss=369.99380, val_loss=381.65021\n",
      "Epoch 17881: train_loss=369.93292, val_loss=381.70334\n",
      "Epoch 17882: train_loss=369.87067, val_loss=381.50745\n",
      "Epoch 17883: train_loss=369.80664, val_loss=381.56357\n",
      "Epoch 17884: train_loss=369.73523, val_loss=381.34402\n",
      "Epoch 17885: train_loss=369.65729, val_loss=381.38528\n",
      "Epoch 17886: train_loss=369.56677, val_loss=381.14731\n",
      "Epoch 17887: train_loss=369.46619, val_loss=381.15756\n",
      "Epoch 17888: train_loss=369.35318, val_loss=380.91791\n",
      "Epoch 17889: train_loss=369.23456, val_loss=380.89059\n",
      "Epoch 17890: train_loss=369.11041, val_loss=380.67609\n",
      "Epoch 17891: train_loss=368.98816, val_loss=380.61823\n",
      "Epoch 17892: train_loss=368.87097, val_loss=380.46014\n",
      "Epoch 17893: train_loss=368.76389, val_loss=380.38303\n",
      "Epoch 17894: train_loss=368.66714, val_loss=380.28848\n",
      "Epoch 17895: train_loss=368.58078, val_loss=380.18997\n",
      "Epoch 17896: train_loss=368.50214, val_loss=380.14175\n",
      "Epoch 17897: train_loss=368.42792, val_loss=380.01953\n",
      "Epoch 17898: train_loss=368.35507, val_loss=379.99435\n",
      "Epoch 17899: train_loss=368.28149, val_loss=379.85159\n",
      "Epoch 17900: train_loss=368.20544, val_loss=379.83295\n",
      "Epoch 17901: train_loss=368.12537, val_loss=379.67831\n",
      "Epoch 17902: train_loss=368.04239, val_loss=379.65521\n",
      "Epoch 17903: train_loss=367.95517, val_loss=379.49521\n",
      "Epoch 17904: train_loss=367.86594, val_loss=379.46069\n",
      "Epoch 17905: train_loss=367.77377, val_loss=379.30618\n",
      "Epoch 17906: train_loss=367.68103, val_loss=379.26035\n",
      "Epoch 17907: train_loss=367.58755, val_loss=379.11884\n",
      "Epoch 17908: train_loss=367.49469, val_loss=379.06003\n",
      "Epoch 17909: train_loss=367.40259, val_loss=378.93338\n",
      "Epoch 17910: train_loss=367.31168, val_loss=378.86081\n",
      "Epoch 17911: train_loss=367.22205, val_loss=378.75024\n",
      "Epoch 17912: train_loss=367.13382, val_loss=378.66675\n",
      "Epoch 17913: train_loss=367.04660, val_loss=378.57193\n",
      "Epoch 17914: train_loss=366.96057, val_loss=378.47906\n",
      "Epoch 17915: train_loss=366.87497, val_loss=378.39505\n",
      "Epoch 17916: train_loss=366.78986, val_loss=378.29352\n",
      "Epoch 17917: train_loss=366.70532, val_loss=378.21921\n",
      "Epoch 17918: train_loss=366.62085, val_loss=378.11105\n",
      "Epoch 17919: train_loss=366.53671, val_loss=378.04761\n",
      "Epoch 17920: train_loss=366.45288, val_loss=377.93311\n",
      "Epoch 17921: train_loss=366.36984, val_loss=377.87881\n",
      "Epoch 17922: train_loss=366.28729, val_loss=377.75317\n",
      "Epoch 17923: train_loss=366.20535, val_loss=377.70877\n",
      "Epoch 17924: train_loss=366.12460, val_loss=377.57544\n",
      "Epoch 17925: train_loss=366.04486, val_loss=377.54846\n",
      "Epoch 17926: train_loss=365.96631, val_loss=377.40765\n",
      "Epoch 17927: train_loss=365.88885, val_loss=377.39749\n",
      "Epoch 17928: train_loss=365.81256, val_loss=377.24307\n",
      "Epoch 17929: train_loss=365.73883, val_loss=377.24847\n",
      "Epoch 17930: train_loss=365.66571, val_loss=377.08127\n",
      "Epoch 17931: train_loss=365.59656, val_loss=377.10846\n",
      "Epoch 17932: train_loss=365.52826, val_loss=376.92862\n",
      "Epoch 17933: train_loss=365.46338, val_loss=376.97665\n",
      "Epoch 17934: train_loss=365.39670, val_loss=376.78027\n",
      "Epoch 17935: train_loss=365.33173, val_loss=376.84091\n",
      "Epoch 17936: train_loss=365.26208, val_loss=376.62305\n",
      "Epoch 17937: train_loss=365.18991, val_loss=376.67926\n",
      "Epoch 17938: train_loss=365.10889, val_loss=376.43991\n",
      "Epoch 17939: train_loss=365.02121, val_loss=376.47632\n",
      "Epoch 17940: train_loss=364.92221, val_loss=376.22632\n",
      "Epoch 17941: train_loss=364.81522, val_loss=376.23239\n",
      "Epoch 17942: train_loss=364.69827, val_loss=375.99335\n",
      "Epoch 17943: train_loss=364.57837, val_loss=375.96634\n",
      "Epoch 17944: train_loss=364.45615, val_loss=375.76141\n",
      "Epoch 17945: train_loss=364.33850, val_loss=375.70392\n",
      "Epoch 17946: train_loss=364.22620, val_loss=375.55209\n",
      "Epoch 17947: train_loss=364.12259, val_loss=375.47263\n",
      "Epoch 17948: train_loss=364.02740, val_loss=375.37701\n",
      "Epoch 17949: train_loss=363.93958, val_loss=375.27563\n",
      "Epoch 17950: train_loss=363.85727, val_loss=375.22058\n",
      "Epoch 17951: train_loss=363.77878, val_loss=375.09686\n",
      "Epoch 17952: train_loss=363.70248, val_loss=375.06863\n",
      "Epoch 17953: train_loss=363.62631, val_loss=374.92438\n",
      "Epoch 17954: train_loss=363.54959, val_loss=374.90887\n",
      "Epoch 17955: train_loss=363.47021, val_loss=374.74963\n",
      "Epoch 17956: train_loss=363.38907, val_loss=374.73502\n",
      "Epoch 17957: train_loss=363.30414, val_loss=374.56650\n",
      "Epoch 17958: train_loss=363.21805, val_loss=374.54529\n",
      "Epoch 17959: train_loss=363.12833, val_loss=374.37503\n",
      "Epoch 17960: train_loss=363.03839, val_loss=374.34784\n",
      "Epoch 17961: train_loss=362.94647, val_loss=374.18353\n",
      "Epoch 17962: train_loss=362.85507, val_loss=374.15048\n",
      "Epoch 17963: train_loss=362.76248, val_loss=373.99191\n",
      "Epoch 17964: train_loss=362.67062, val_loss=373.94907\n",
      "Epoch 17965: train_loss=362.57834, val_loss=373.79938\n",
      "Epoch 17966: train_loss=362.48718, val_loss=373.75259\n",
      "Epoch 17967: train_loss=362.39566, val_loss=373.61514\n",
      "Epoch 17968: train_loss=362.30502, val_loss=373.56259\n",
      "Epoch 17969: train_loss=362.21426, val_loss=373.43246\n",
      "Epoch 17970: train_loss=362.12451, val_loss=373.37057\n",
      "Epoch 17971: train_loss=362.03464, val_loss=373.24530\n",
      "Epoch 17972: train_loss=361.94556, val_loss=373.17822\n",
      "Epoch 17973: train_loss=361.85660, val_loss=373.06036\n",
      "Epoch 17974: train_loss=361.76828, val_loss=372.99170\n",
      "Epoch 17975: train_loss=361.67999, val_loss=372.87811\n",
      "Epoch 17976: train_loss=361.59235, val_loss=372.81036\n",
      "Epoch 17977: train_loss=361.50507, val_loss=372.69754\n",
      "Epoch 17978: train_loss=361.41803, val_loss=372.63226\n",
      "Epoch 17979: train_loss=361.33182, val_loss=372.51544\n",
      "Epoch 17980: train_loss=361.24649, val_loss=372.45923\n",
      "Epoch 17981: train_loss=361.16214, val_loss=372.33575\n",
      "Epoch 17982: train_loss=361.07965, val_loss=372.29678\n",
      "Epoch 17983: train_loss=360.99890, val_loss=372.16266\n",
      "Epoch 17984: train_loss=360.92084, val_loss=372.14484\n",
      "Epoch 17985: train_loss=360.84537, val_loss=371.99506\n",
      "Epoch 17986: train_loss=360.77396, val_loss=372.00589\n",
      "Epoch 17987: train_loss=360.70660, val_loss=371.84360\n",
      "Epoch 17988: train_loss=360.64551, val_loss=371.89420\n",
      "Epoch 17989: train_loss=360.58847, val_loss=371.71658\n",
      "Epoch 17990: train_loss=360.53833, val_loss=371.80536\n",
      "Epoch 17991: train_loss=360.49017, val_loss=371.60565\n",
      "Epoch 17992: train_loss=360.44720, val_loss=371.71716\n",
      "Epoch 17993: train_loss=360.39670, val_loss=371.48126\n",
      "Epoch 17994: train_loss=360.34213, val_loss=371.58157\n",
      "Epoch 17995: train_loss=360.26501, val_loss=371.30148\n",
      "Epoch 17996: train_loss=360.17218, val_loss=371.35309\n",
      "Epoch 17997: train_loss=360.04965, val_loss=371.04303\n",
      "Epoch 17998: train_loss=359.90985, val_loss=371.02792\n",
      "Epoch 17999: train_loss=359.75351, val_loss=370.74634\n",
      "Epoch 18000: train_loss=359.59839, val_loss=370.68716\n",
      "Epoch 18001: train_loss=359.45276, val_loss=370.49570\n",
      "Epoch 18002: train_loss=359.32635, val_loss=370.41287\n",
      "Epoch 18003: train_loss=359.22137, val_loss=370.32596\n",
      "Epoch 18004: train_loss=359.13568, val_loss=370.22067\n",
      "Epoch 18005: train_loss=359.06424, val_loss=370.20709\n",
      "Epoch 18006: train_loss=358.99966, val_loss=370.06668\n",
      "Epoch 18007: train_loss=358.93704, val_loss=370.08218\n",
      "Epoch 18008: train_loss=358.86908, val_loss=369.90488\n",
      "Epoch 18009: train_loss=358.79349, val_loss=369.91452\n",
      "Epoch 18010: train_loss=358.70691, val_loss=369.71548\n",
      "Epoch 18011: train_loss=358.61099, val_loss=369.69897\n",
      "Epoch 18012: train_loss=358.50717, val_loss=369.50607\n",
      "Epoch 18013: train_loss=358.39999, val_loss=369.46198\n",
      "Epoch 18014: train_loss=358.29263, val_loss=369.30130\n",
      "Epoch 18015: train_loss=358.18890, val_loss=369.23340\n",
      "Epoch 18016: train_loss=358.08939, val_loss=369.11493\n",
      "Epoch 18017: train_loss=357.99561, val_loss=369.02478\n",
      "Epoch 18018: train_loss=357.90695, val_loss=368.94534\n",
      "Epoch 18019: train_loss=357.82202, val_loss=368.83490\n",
      "Epoch 18020: train_loss=357.73969, val_loss=368.78342\n",
      "Epoch 18021: train_loss=357.65817, val_loss=368.65469\n",
      "Epoch 18022: train_loss=357.57672, val_loss=368.61670\n",
      "Epoch 18023: train_loss=357.49347, val_loss=368.47528\n",
      "Epoch 18024: train_loss=357.40866, val_loss=368.43991\n",
      "Epoch 18025: train_loss=357.32169, val_loss=368.29117\n",
      "Epoch 18026: train_loss=357.23267, val_loss=368.24976\n",
      "Epoch 18027: train_loss=357.14215, val_loss=368.10266\n",
      "Epoch 18028: train_loss=357.05060, val_loss=368.05130\n",
      "Epoch 18029: train_loss=356.95853, val_loss=367.91272\n",
      "Epoch 18030: train_loss=356.86624, val_loss=367.85168\n",
      "Epoch 18031: train_loss=356.77435, val_loss=367.72556\n",
      "Epoch 18032: train_loss=356.68314, val_loss=367.65332\n",
      "Epoch 18033: train_loss=356.59225, val_loss=367.54013\n",
      "Epoch 18034: train_loss=356.50220, val_loss=367.45682\n",
      "Epoch 18035: train_loss=356.41272, val_loss=367.35498\n",
      "Epoch 18036: train_loss=356.32379, val_loss=367.26364\n",
      "Epoch 18037: train_loss=356.23526, val_loss=367.17389\n",
      "Epoch 18038: train_loss=356.14697, val_loss=367.07584\n",
      "Epoch 18039: train_loss=356.05881, val_loss=366.99130\n",
      "Epoch 18040: train_loss=355.97064, val_loss=366.88461\n",
      "Epoch 18041: train_loss=355.88269, val_loss=366.80533\n",
      "Epoch 18042: train_loss=355.79483, val_loss=366.69370\n",
      "Epoch 18043: train_loss=355.70706, val_loss=366.62030\n",
      "Epoch 18044: train_loss=355.61905, val_loss=366.50354\n",
      "Epoch 18045: train_loss=355.53131, val_loss=366.43420\n",
      "Epoch 18046: train_loss=355.44376, val_loss=366.31036\n",
      "Epoch 18047: train_loss=355.35641, val_loss=366.24753\n",
      "Epoch 18048: train_loss=355.26981, val_loss=366.11819\n",
      "Epoch 18049: train_loss=355.18381, val_loss=366.06744\n",
      "Epoch 18050: train_loss=355.09857, val_loss=365.93176\n",
      "Epoch 18051: train_loss=355.01422, val_loss=365.89706\n",
      "Epoch 18052: train_loss=354.93173, val_loss=365.75067\n",
      "Epoch 18053: train_loss=354.85126, val_loss=365.73267\n",
      "Epoch 18054: train_loss=354.77325, val_loss=365.57114\n",
      "Epoch 18055: train_loss=354.69733, val_loss=365.57883\n",
      "Epoch 18056: train_loss=354.62552, val_loss=365.40503\n",
      "Epoch 18057: train_loss=354.55634, val_loss=365.44354\n",
      "Epoch 18058: train_loss=354.49121, val_loss=365.25403\n",
      "Epoch 18059: train_loss=354.42789, val_loss=365.31738\n",
      "Epoch 18060: train_loss=354.36429, val_loss=365.10651\n",
      "Epoch 18061: train_loss=354.30148, val_loss=365.18469\n",
      "Epoch 18062: train_loss=354.23502, val_loss=364.95059\n",
      "Epoch 18063: train_loss=354.16467, val_loss=365.02930\n",
      "Epoch 18064: train_loss=354.08536, val_loss=364.77054\n",
      "Epoch 18065: train_loss=353.99600, val_loss=364.82132\n",
      "Epoch 18066: train_loss=353.89099, val_loss=364.54550\n",
      "Epoch 18067: train_loss=353.77478, val_loss=364.55286\n",
      "Epoch 18068: train_loss=353.64655, val_loss=364.28699\n",
      "Epoch 18069: train_loss=353.51315, val_loss=364.25165\n",
      "Epoch 18070: train_loss=353.38016, val_loss=364.03348\n",
      "Epoch 18071: train_loss=353.25272, val_loss=363.96832\n",
      "Epoch 18072: train_loss=353.13586, val_loss=363.82007\n",
      "Epoch 18073: train_loss=353.02982, val_loss=363.73175\n",
      "Epoch 18074: train_loss=352.93469, val_loss=363.65021\n",
      "Epoch 18075: train_loss=352.84885, val_loss=363.53497\n",
      "Epoch 18076: train_loss=352.76920, val_loss=363.49625\n",
      "Epoch 18077: train_loss=352.69315, val_loss=363.35632\n",
      "Epoch 18078: train_loss=352.61804, val_loss=363.34729\n",
      "Epoch 18079: train_loss=352.54166, val_loss=363.18558\n",
      "Epoch 18080: train_loss=352.46289, val_loss=363.18298\n",
      "Epoch 18081: train_loss=352.37949, val_loss=363.00189\n",
      "Epoch 18082: train_loss=352.29175, val_loss=362.99060\n",
      "Epoch 18083: train_loss=352.19870, val_loss=362.80460\n",
      "Epoch 18084: train_loss=352.10278, val_loss=362.78119\n",
      "Epoch 18085: train_loss=352.00290, val_loss=362.60541\n",
      "Epoch 18086: train_loss=351.90265, val_loss=362.56668\n",
      "Epoch 18087: train_loss=351.80167, val_loss=362.40427\n",
      "Epoch 18088: train_loss=351.70099, val_loss=362.34454\n",
      "Epoch 18089: train_loss=351.60120, val_loss=362.20541\n",
      "Epoch 18090: train_loss=351.50327, val_loss=362.12814\n",
      "Epoch 18091: train_loss=351.40781, val_loss=362.01971\n",
      "Epoch 18092: train_loss=351.31519, val_loss=361.92487\n",
      "Epoch 18093: train_loss=351.22498, val_loss=361.84174\n",
      "Epoch 18094: train_loss=351.13644, val_loss=361.73145\n",
      "Epoch 18095: train_loss=351.04910, val_loss=361.66733\n",
      "Epoch 18096: train_loss=350.96210, val_loss=361.54568\n",
      "Epoch 18097: train_loss=350.87506, val_loss=361.49121\n",
      "Epoch 18098: train_loss=350.78754, val_loss=361.35730\n",
      "Epoch 18099: train_loss=350.69980, val_loss=361.30719\n",
      "Epoch 18100: train_loss=350.61151, val_loss=361.16830\n",
      "Epoch 18101: train_loss=350.52252, val_loss=361.12357\n",
      "Epoch 18102: train_loss=350.43304, val_loss=360.98181\n",
      "Epoch 18103: train_loss=350.34299, val_loss=360.93646\n",
      "Epoch 18104: train_loss=350.25272, val_loss=360.79129\n",
      "Epoch 18105: train_loss=350.16232, val_loss=360.74472\n",
      "Epoch 18106: train_loss=350.07184, val_loss=360.59711\n",
      "Epoch 18107: train_loss=349.98117, val_loss=360.55231\n",
      "Epoch 18108: train_loss=349.89059, val_loss=360.40588\n",
      "Epoch 18109: train_loss=349.79944, val_loss=360.36142\n",
      "Epoch 18110: train_loss=349.70880, val_loss=360.21475\n",
      "Epoch 18111: train_loss=349.61765, val_loss=360.17020\n",
      "Epoch 18112: train_loss=349.52731, val_loss=360.01999\n",
      "Epoch 18113: train_loss=349.43646, val_loss=359.97748\n",
      "Epoch 18114: train_loss=349.34717, val_loss=359.82715\n",
      "Epoch 18115: train_loss=349.25760, val_loss=359.79196\n",
      "Epoch 18116: train_loss=349.16998, val_loss=359.64020\n",
      "Epoch 18117: train_loss=349.08252, val_loss=359.61520\n",
      "Epoch 18118: train_loss=348.99677, val_loss=359.45572\n",
      "Epoch 18119: train_loss=348.91147, val_loss=359.44125\n",
      "Epoch 18120: train_loss=348.82843, val_loss=359.27341\n",
      "Epoch 18121: train_loss=348.74741, val_loss=359.27692\n",
      "Epoch 18122: train_loss=348.66901, val_loss=359.10141\n",
      "Epoch 18123: train_loss=348.59302, val_loss=359.13004\n",
      "Epoch 18124: train_loss=348.51956, val_loss=358.94458\n",
      "Epoch 18125: train_loss=348.44983, val_loss=358.99561\n",
      "Epoch 18126: train_loss=348.38080, val_loss=358.78830\n",
      "Epoch 18127: train_loss=348.31161, val_loss=358.84915\n",
      "Epoch 18128: train_loss=348.23825, val_loss=358.62067\n",
      "Epoch 18129: train_loss=348.16031, val_loss=358.67905\n",
      "Epoch 18130: train_loss=348.07214, val_loss=358.43011\n",
      "Epoch 18131: train_loss=347.97491, val_loss=358.46204\n",
      "Epoch 18132: train_loss=347.86609, val_loss=358.20111\n",
      "Epoch 18133: train_loss=347.74844, val_loss=358.19580\n",
      "Epoch 18134: train_loss=347.62305, val_loss=357.95200\n",
      "Epoch 18135: train_loss=347.49518, val_loss=357.91360\n",
      "Epoch 18136: train_loss=347.36884, val_loss=357.71341\n",
      "Epoch 18137: train_loss=347.24750, val_loss=357.64511\n",
      "Epoch 18138: train_loss=347.13336, val_loss=357.50299\n",
      "Epoch 18139: train_loss=347.02820, val_loss=357.40948\n",
      "Epoch 18140: train_loss=346.93253, val_loss=357.32635\n",
      "Epoch 18141: train_loss=346.84454, val_loss=357.20950\n",
      "Epoch 18142: train_loss=346.76126, val_loss=357.16626\n",
      "Epoch 18143: train_loss=346.67993, val_loss=357.02582\n",
      "Epoch 18144: train_loss=346.59805, val_loss=356.99954\n",
      "Epoch 18145: train_loss=346.51416, val_loss=356.84103\n",
      "Epoch 18146: train_loss=346.42740, val_loss=356.81671\n",
      "Epoch 18147: train_loss=346.33789, val_loss=356.64832\n",
      "Epoch 18148: train_loss=346.24512, val_loss=356.61835\n",
      "Epoch 18149: train_loss=346.15018, val_loss=356.45047\n",
      "Epoch 18150: train_loss=346.05276, val_loss=356.40823\n",
      "Epoch 18151: train_loss=345.95410, val_loss=356.24612\n",
      "Epoch 18152: train_loss=345.85516, val_loss=356.19153\n",
      "Epoch 18153: train_loss=345.75568, val_loss=356.04391\n",
      "Epoch 18154: train_loss=345.65680, val_loss=355.97775\n",
      "Epoch 18155: train_loss=345.55905, val_loss=355.84698\n",
      "Epoch 18156: train_loss=345.46222, val_loss=355.76761\n",
      "Epoch 18157: train_loss=345.36639, val_loss=355.65247\n",
      "Epoch 18158: train_loss=345.27185, val_loss=355.56100\n",
      "Epoch 18159: train_loss=345.17825, val_loss=355.46048\n",
      "Epoch 18160: train_loss=345.08536, val_loss=355.36053\n",
      "Epoch 18161: train_loss=344.99295, val_loss=355.27206\n",
      "Epoch 18162: train_loss=344.90094, val_loss=355.16409\n",
      "Epoch 18163: train_loss=344.80933, val_loss=355.08627\n",
      "Epoch 18164: train_loss=344.71826, val_loss=354.96902\n",
      "Epoch 18165: train_loss=344.62778, val_loss=354.90118\n",
      "Epoch 18166: train_loss=344.53796, val_loss=354.77283\n",
      "Epoch 18167: train_loss=344.44867, val_loss=354.71695\n",
      "Epoch 18168: train_loss=344.36060, val_loss=354.57999\n",
      "Epoch 18169: train_loss=344.27411, val_loss=354.54346\n",
      "Epoch 18170: train_loss=344.18875, val_loss=354.39655\n",
      "Epoch 18171: train_loss=344.10516, val_loss=354.37906\n",
      "Epoch 18172: train_loss=344.02344, val_loss=354.22095\n",
      "Epoch 18173: train_loss=343.94669, val_loss=354.23099\n",
      "Epoch 18174: train_loss=343.87219, val_loss=354.05914\n",
      "Epoch 18175: train_loss=343.80450, val_loss=354.10291\n",
      "Epoch 18176: train_loss=343.74109, val_loss=353.91391\n",
      "Epoch 18177: train_loss=343.68433, val_loss=353.99854\n",
      "Epoch 18178: train_loss=343.63110, val_loss=353.78912\n",
      "Epoch 18179: train_loss=343.57928, val_loss=353.90259\n",
      "Epoch 18180: train_loss=343.52417, val_loss=353.65851\n",
      "Epoch 18181: train_loss=343.46002, val_loss=353.75800\n",
      "Epoch 18182: train_loss=343.37787, val_loss=353.46820\n",
      "Epoch 18183: train_loss=343.27759, val_loss=353.51495\n",
      "Epoch 18184: train_loss=343.15018, val_loss=353.20078\n",
      "Epoch 18185: train_loss=343.00635, val_loss=353.18655\n",
      "Epoch 18186: train_loss=342.85016, val_loss=352.90662\n",
      "Epoch 18187: train_loss=342.69427, val_loss=352.84976\n",
      "Epoch 18188: train_loss=342.54883, val_loss=352.65878\n",
      "Epoch 18189: train_loss=342.42062, val_loss=352.57333\n",
      "Epoch 18190: train_loss=342.31216, val_loss=352.48352\n",
      "Epoch 18191: train_loss=342.22205, val_loss=352.37213\n",
      "Epoch 18192: train_loss=342.14462, val_loss=352.35223\n",
      "Epoch 18193: train_loss=342.07190, val_loss=352.20551\n",
      "Epoch 18194: train_loss=341.99884, val_loss=352.20667\n",
      "Epoch 18195: train_loss=341.92041, val_loss=352.02698\n",
      "Epoch 18196: train_loss=341.83472, val_loss=352.01984\n",
      "Epoch 18197: train_loss=341.73898, val_loss=351.82855\n",
      "Epoch 18198: train_loss=341.63678, val_loss=351.79813\n",
      "Epoch 18199: train_loss=341.52927, val_loss=351.61954\n",
      "Epoch 18200: train_loss=341.42133, val_loss=351.56339\n",
      "Epoch 18201: train_loss=341.31433, val_loss=351.41678\n",
      "Epoch 18202: train_loss=341.21088, val_loss=351.33920\n",
      "Epoch 18203: train_loss=341.11111, val_loss=351.23270\n",
      "Epoch 18204: train_loss=341.01593, val_loss=351.13480\n",
      "Epoch 18205: train_loss=340.92422, val_loss=351.05823\n",
      "Epoch 18206: train_loss=340.83490, val_loss=350.93961\n",
      "Epoch 18207: train_loss=340.74716, val_loss=350.88486\n",
      "Epoch 18208: train_loss=340.66019, val_loss=350.75128\n",
      "Epoch 18209: train_loss=340.57373, val_loss=350.71335\n",
      "Epoch 18210: train_loss=340.48660, val_loss=350.56644\n",
      "Epoch 18211: train_loss=340.39920, val_loss=350.53427\n",
      "Epoch 18212: train_loss=340.30991, val_loss=350.37561\n",
      "Epoch 18213: train_loss=340.21970, val_loss=350.34509\n",
      "Epoch 18214: train_loss=340.12738, val_loss=350.18552\n",
      "Epoch 18215: train_loss=340.03464, val_loss=350.15482\n",
      "Epoch 18216: train_loss=339.94077, val_loss=349.99487\n",
      "Epoch 18217: train_loss=339.84784, val_loss=349.96075\n",
      "Epoch 18218: train_loss=339.75412, val_loss=349.80237\n",
      "Epoch 18219: train_loss=339.66162, val_loss=349.77121\n",
      "Epoch 18220: train_loss=339.56952, val_loss=349.61475\n",
      "Epoch 18221: train_loss=339.47836, val_loss=349.58862\n",
      "Epoch 18222: train_loss=339.38782, val_loss=349.42868\n",
      "Epoch 18223: train_loss=339.29837, val_loss=349.40652\n",
      "Epoch 18224: train_loss=339.20963, val_loss=349.24106\n",
      "Epoch 18225: train_loss=339.12192, val_loss=349.22824\n",
      "Epoch 18226: train_loss=339.03439, val_loss=349.05875\n",
      "Epoch 18227: train_loss=338.94821, val_loss=349.05719\n",
      "Epoch 18228: train_loss=338.86197, val_loss=348.87827\n",
      "Epoch 18229: train_loss=338.77701, val_loss=348.88281\n",
      "Epoch 18230: train_loss=338.69077, val_loss=348.69327\n",
      "Epoch 18231: train_loss=338.60468, val_loss=348.70251\n",
      "Epoch 18232: train_loss=338.51550, val_loss=348.50711\n",
      "Epoch 18233: train_loss=338.42523, val_loss=348.51694\n",
      "Epoch 18234: train_loss=338.33112, val_loss=348.31631\n",
      "Epoch 18235: train_loss=338.23590, val_loss=348.31494\n",
      "Epoch 18236: train_loss=338.13651, val_loss=348.11270\n",
      "Epoch 18237: train_loss=338.03607, val_loss=348.09921\n",
      "Epoch 18238: train_loss=337.93243, val_loss=347.90768\n",
      "Epoch 18239: train_loss=337.82840, val_loss=347.88199\n",
      "Epoch 18240: train_loss=337.72284, val_loss=347.70490\n",
      "Epoch 18241: train_loss=337.61807, val_loss=347.66006\n",
      "Epoch 18242: train_loss=337.51364, val_loss=347.50015\n",
      "Epoch 18243: train_loss=337.41010, val_loss=347.43942\n",
      "Epoch 18244: train_loss=337.30936, val_loss=347.30411\n",
      "Epoch 18245: train_loss=337.21021, val_loss=347.23102\n",
      "Epoch 18246: train_loss=337.11282, val_loss=347.11624\n",
      "Epoch 18247: train_loss=337.01666, val_loss=347.02997\n",
      "Epoch 18248: train_loss=336.92188, val_loss=346.92972\n",
      "Epoch 18249: train_loss=336.82779, val_loss=346.83301\n",
      "Epoch 18250: train_loss=336.73410, val_loss=346.74588\n",
      "Epoch 18251: train_loss=336.64120, val_loss=346.63907\n",
      "Epoch 18252: train_loss=336.54865, val_loss=346.56097\n",
      "Epoch 18253: train_loss=336.45651, val_loss=346.44141\n",
      "Epoch 18254: train_loss=336.36490, val_loss=346.37286\n",
      "Epoch 18255: train_loss=336.27332, val_loss=346.24673\n",
      "Epoch 18256: train_loss=336.18213, val_loss=346.19373\n",
      "Epoch 18257: train_loss=336.09137, val_loss=346.06235\n",
      "Epoch 18258: train_loss=336.00174, val_loss=346.02179\n",
      "Epoch 18259: train_loss=335.91324, val_loss=345.87671\n",
      "Epoch 18260: train_loss=335.82599, val_loss=345.85098\n",
      "Epoch 18261: train_loss=335.74094, val_loss=345.69473\n",
      "Epoch 18262: train_loss=335.65829, val_loss=345.69580\n",
      "Epoch 18263: train_loss=335.57916, val_loss=345.52692\n",
      "Epoch 18264: train_loss=335.50314, val_loss=345.55609\n",
      "Epoch 18265: train_loss=335.43002, val_loss=345.36981\n",
      "Epoch 18266: train_loss=335.36331, val_loss=345.43076\n",
      "Epoch 18267: train_loss=335.29843, val_loss=345.22141\n",
      "Epoch 18268: train_loss=335.23715, val_loss=345.30780\n",
      "Epoch 18269: train_loss=335.17200, val_loss=345.07123\n",
      "Epoch 18270: train_loss=335.10257, val_loss=345.15948\n",
      "Epoch 18271: train_loss=335.02029, val_loss=344.89291\n",
      "Epoch 18272: train_loss=334.92682, val_loss=344.95059\n",
      "Epoch 18273: train_loss=334.81348, val_loss=344.66293\n",
      "Epoch 18274: train_loss=334.68796, val_loss=344.66782\n",
      "Epoch 18275: train_loss=334.54861, val_loss=344.39597\n",
      "Epoch 18276: train_loss=334.40857, val_loss=344.35352\n",
      "Epoch 18277: train_loss=334.26904, val_loss=344.14093\n",
      "Epoch 18278: train_loss=334.13962, val_loss=344.06863\n",
      "Epoch 18279: train_loss=334.02188, val_loss=343.94055\n",
      "Epoch 18280: train_loss=333.91803, val_loss=343.84302\n",
      "Epoch 18281: train_loss=333.82648, val_loss=343.78864\n",
      "Epoch 18282: train_loss=333.74365, val_loss=343.65860\n",
      "Epoch 18283: train_loss=333.66409, val_loss=343.63818\n",
      "Epoch 18284: train_loss=333.58316, val_loss=343.47647\n",
      "Epoch 18285: train_loss=333.49866, val_loss=343.46243\n",
      "Epoch 18286: train_loss=333.40884, val_loss=343.28564\n",
      "Epoch 18287: train_loss=333.31421, val_loss=343.26184\n",
      "Epoch 18288: train_loss=333.21460, val_loss=343.08685\n",
      "Epoch 18289: train_loss=333.11255, val_loss=343.04593\n",
      "Epoch 18290: train_loss=333.00873, val_loss=342.88538\n",
      "Epoch 18291: train_loss=332.90466, val_loss=342.82156\n",
      "Epoch 18292: train_loss=332.80261, val_loss=342.68723\n",
      "Epoch 18293: train_loss=332.70236, val_loss=342.60431\n",
      "Epoch 18294: train_loss=332.60449, val_loss=342.50092\n",
      "Epoch 18295: train_loss=332.50903, val_loss=342.40164\n",
      "Epoch 18296: train_loss=332.41574, val_loss=342.32352\n",
      "Epoch 18297: train_loss=332.32361, val_loss=342.20541\n",
      "Epoch 18298: train_loss=332.23196, val_loss=342.14005\n",
      "Epoch 18299: train_loss=332.14056, val_loss=342.01013\n",
      "Epoch 18300: train_loss=332.04895, val_loss=341.95389\n",
      "Epoch 18301: train_loss=331.95645, val_loss=341.81897\n",
      "Epoch 18302: train_loss=331.86380, val_loss=341.76791\n",
      "Epoch 18303: train_loss=331.77057, val_loss=341.62717\n",
      "Epoch 18304: train_loss=331.67719, val_loss=341.57562\n",
      "Epoch 18305: train_loss=331.58344, val_loss=341.43286\n",
      "Epoch 18306: train_loss=331.48993, val_loss=341.38425\n",
      "Epoch 18307: train_loss=331.39615, val_loss=341.24243\n",
      "Epoch 18308: train_loss=331.30331, val_loss=341.19812\n",
      "Epoch 18309: train_loss=331.21045, val_loss=341.05081\n",
      "Epoch 18310: train_loss=331.11768, val_loss=341.00720\n",
      "Epoch 18311: train_loss=331.02557, val_loss=340.85486\n",
      "Epoch 18312: train_loss=330.93378, val_loss=340.81851\n",
      "Epoch 18313: train_loss=330.84225, val_loss=340.66354\n",
      "Epoch 18314: train_loss=330.75107, val_loss=340.63568\n",
      "Epoch 18315: train_loss=330.65976, val_loss=340.47620\n",
      "Epoch 18316: train_loss=330.56943, val_loss=340.45471\n",
      "Epoch 18317: train_loss=330.47888, val_loss=340.28775\n",
      "Epoch 18318: train_loss=330.39005, val_loss=340.27664\n",
      "Epoch 18319: train_loss=330.30096, val_loss=340.10306\n",
      "Epoch 18320: train_loss=330.21442, val_loss=340.10635\n",
      "Epoch 18321: train_loss=330.12778, val_loss=339.92310\n",
      "Epoch 18322: train_loss=330.04340, val_loss=339.94141\n",
      "Epoch 18323: train_loss=329.95914, val_loss=339.74667\n",
      "Epoch 18324: train_loss=329.87717, val_loss=339.77960\n",
      "Epoch 18325: train_loss=329.79376, val_loss=339.57123\n",
      "Epoch 18326: train_loss=329.71048, val_loss=339.61258\n",
      "Epoch 18327: train_loss=329.62457, val_loss=339.38980\n",
      "Epoch 18328: train_loss=329.53622, val_loss=339.43185\n",
      "Epoch 18329: train_loss=329.44458, val_loss=339.19946\n",
      "Epoch 18330: train_loss=329.35019, val_loss=339.23199\n",
      "Epoch 18331: train_loss=329.25092, val_loss=338.99316\n",
      "Epoch 18332: train_loss=329.14764, val_loss=339.00354\n",
      "Epoch 18333: train_loss=329.03888, val_loss=338.77310\n",
      "Epoch 18334: train_loss=328.92816, val_loss=338.76276\n",
      "Epoch 18335: train_loss=328.81519, val_loss=338.55847\n",
      "Epoch 18336: train_loss=328.70386, val_loss=338.52341\n",
      "Epoch 18337: train_loss=328.59308, val_loss=338.34839\n",
      "Epoch 18338: train_loss=328.48520, val_loss=338.28714\n",
      "Epoch 18339: train_loss=328.38058, val_loss=338.14789\n",
      "Epoch 18340: train_loss=328.27966, val_loss=338.06601\n",
      "Epoch 18341: train_loss=328.18182, val_loss=337.95944\n",
      "Epoch 18342: train_loss=328.08646, val_loss=337.86017\n",
      "Epoch 18343: train_loss=327.99283, val_loss=337.77875\n",
      "Epoch 18344: train_loss=327.90063, val_loss=337.66309\n",
      "Epoch 18345: train_loss=327.80988, val_loss=337.60266\n",
      "Epoch 18346: train_loss=327.71988, val_loss=337.46976\n",
      "Epoch 18347: train_loss=327.63107, val_loss=337.42776\n",
      "Epoch 18348: train_loss=327.54260, val_loss=337.27817\n",
      "Epoch 18349: train_loss=327.45480, val_loss=337.25012\n",
      "Epoch 18350: train_loss=327.36658, val_loss=337.08652\n",
      "Epoch 18351: train_loss=327.27893, val_loss=337.07095\n",
      "Epoch 18352: train_loss=327.19073, val_loss=336.89740\n",
      "Epoch 18353: train_loss=327.10391, val_loss=336.89450\n",
      "Epoch 18354: train_loss=327.01532, val_loss=336.71115\n",
      "Epoch 18355: train_loss=326.92825, val_loss=336.71625\n",
      "Epoch 18356: train_loss=326.83899, val_loss=336.52267\n",
      "Epoch 18357: train_loss=326.75159, val_loss=336.53656\n",
      "Epoch 18358: train_loss=326.66257, val_loss=336.33640\n",
      "Epoch 18359: train_loss=326.57568, val_loss=336.36102\n",
      "Epoch 18360: train_loss=326.48810, val_loss=336.15051\n",
      "Epoch 18361: train_loss=326.40192, val_loss=336.18015\n",
      "Epoch 18362: train_loss=326.31268, val_loss=335.96115\n",
      "Epoch 18363: train_loss=326.22491, val_loss=335.99744\n",
      "Epoch 18364: train_loss=326.13364, val_loss=335.77115\n",
      "Epoch 18365: train_loss=326.04245, val_loss=335.80463\n",
      "Epoch 18366: train_loss=325.94623, val_loss=335.57227\n",
      "Epoch 18367: train_loss=325.85052, val_loss=335.59781\n",
      "Epoch 18368: train_loss=325.75031, val_loss=335.36349\n",
      "Epoch 18369: train_loss=325.64813, val_loss=335.37332\n",
      "Epoch 18370: train_loss=325.54025, val_loss=335.14777\n",
      "Epoch 18371: train_loss=325.43063, val_loss=335.13733\n",
      "Epoch 18372: train_loss=325.31998, val_loss=334.93399\n",
      "Epoch 18373: train_loss=325.21014, val_loss=334.89999\n",
      "Epoch 18374: train_loss=325.10168, val_loss=334.72702\n",
      "Epoch 18375: train_loss=324.99545, val_loss=334.67130\n",
      "Epoch 18376: train_loss=324.89178, val_loss=334.53082\n",
      "Epoch 18377: train_loss=324.79117, val_loss=334.45166\n",
      "Epoch 18378: train_loss=324.69305, val_loss=334.33719\n",
      "Epoch 18379: train_loss=324.59662, val_loss=334.24094\n",
      "Epoch 18380: train_loss=324.50186, val_loss=334.15176\n",
      "Epoch 18381: train_loss=324.40781, val_loss=334.04199\n",
      "Epoch 18382: train_loss=324.31479, val_loss=333.97018\n",
      "Epoch 18383: train_loss=324.22293, val_loss=333.84305\n",
      "Epoch 18384: train_loss=324.13168, val_loss=333.78918\n",
      "Epoch 18385: train_loss=324.04163, val_loss=333.64972\n",
      "Epoch 18386: train_loss=323.95227, val_loss=333.61627\n",
      "Epoch 18387: train_loss=323.86407, val_loss=333.46008\n",
      "Epoch 18388: train_loss=323.77750, val_loss=333.44611\n",
      "Epoch 18389: train_loss=323.69226, val_loss=333.27426\n",
      "Epoch 18390: train_loss=323.60910, val_loss=333.28644\n",
      "Epoch 18391: train_loss=323.52658, val_loss=333.10132\n",
      "Epoch 18392: train_loss=323.44717, val_loss=333.13757\n",
      "Epoch 18393: train_loss=323.36755, val_loss=332.93192\n",
      "Epoch 18394: train_loss=323.29056, val_loss=332.98456\n",
      "Epoch 18395: train_loss=323.21097, val_loss=332.75830\n",
      "Epoch 18396: train_loss=323.13254, val_loss=332.82562\n",
      "Epoch 18397: train_loss=323.05023, val_loss=332.58423\n",
      "Epoch 18398: train_loss=322.96741, val_loss=332.65601\n",
      "Epoch 18399: train_loss=322.87820, val_loss=332.39734\n",
      "Epoch 18400: train_loss=322.78482, val_loss=332.45517\n",
      "Epoch 18401: train_loss=322.68262, val_loss=332.18854\n",
      "Epoch 18402: train_loss=322.57541, val_loss=332.22018\n",
      "Epoch 18403: train_loss=322.45935, val_loss=331.96274\n",
      "Epoch 18404: train_loss=322.34155, val_loss=331.95874\n",
      "Epoch 18405: train_loss=322.22000, val_loss=331.72760\n",
      "Epoch 18406: train_loss=322.10040, val_loss=331.69168\n",
      "Epoch 18407: train_loss=321.98309, val_loss=331.50925\n",
      "Epoch 18408: train_loss=321.87152, val_loss=331.44620\n",
      "Epoch 18409: train_loss=321.76489, val_loss=331.31384\n",
      "Epoch 18410: train_loss=321.66321, val_loss=331.22290\n",
      "Epoch 18411: train_loss=321.56595, val_loss=331.13522\n",
      "Epoch 18412: train_loss=321.47205, val_loss=331.02020\n",
      "Epoch 18413: train_loss=321.38055, val_loss=330.96396\n",
      "Epoch 18414: train_loss=321.29004, val_loss=330.82480\n",
      "Epoch 18415: train_loss=321.20004, val_loss=330.78607\n",
      "Epoch 18416: train_loss=321.11011, val_loss=330.62726\n",
      "Epoch 18417: train_loss=321.01947, val_loss=330.60046\n",
      "Epoch 18418: train_loss=320.92755, val_loss=330.43094\n",
      "Epoch 18419: train_loss=320.83545, val_loss=330.41150\n",
      "Epoch 18420: train_loss=320.74240, val_loss=330.23044\n",
      "Epoch 18421: train_loss=320.64859, val_loss=330.21115\n",
      "Epoch 18422: train_loss=320.55399, val_loss=330.02682\n",
      "Epoch 18423: train_loss=320.45892, val_loss=330.01254\n",
      "Epoch 18424: train_loss=320.36255, val_loss=329.83032\n",
      "Epoch 18425: train_loss=320.26630, val_loss=329.81381\n",
      "Epoch 18426: train_loss=320.16898, val_loss=329.62973\n",
      "Epoch 18427: train_loss=320.07132, val_loss=329.60431\n",
      "Epoch 18428: train_loss=319.97198, val_loss=329.42249\n",
      "Epoch 18429: train_loss=319.87308, val_loss=329.39780\n",
      "Epoch 18430: train_loss=319.77460, val_loss=329.22385\n",
      "Epoch 18431: train_loss=319.67712, val_loss=329.19913\n",
      "Epoch 18432: train_loss=319.57852, val_loss=329.02573\n",
      "Epoch 18433: train_loss=319.48096, val_loss=328.99866\n",
      "Epoch 18434: train_loss=319.38330, val_loss=328.82504\n",
      "Epoch 18435: train_loss=319.28610, val_loss=328.79999\n",
      "Epoch 18436: train_loss=319.18799, val_loss=328.62946\n",
      "Epoch 18437: train_loss=319.09100, val_loss=328.60516\n",
      "Epoch 18438: train_loss=318.99341, val_loss=328.43027\n",
      "Epoch 18439: train_loss=318.89694, val_loss=328.40805\n",
      "Epoch 18440: train_loss=318.80090, val_loss=328.23111\n",
      "Epoch 18441: train_loss=318.70667, val_loss=328.22195\n",
      "Epoch 18442: train_loss=318.61273, val_loss=328.04321\n",
      "Epoch 18443: train_loss=318.52194, val_loss=328.05450\n",
      "Epoch 18444: train_loss=318.43427, val_loss=327.86639\n",
      "Epoch 18445: train_loss=318.35101, val_loss=327.90933\n",
      "Epoch 18446: train_loss=318.27246, val_loss=327.70612\n",
      "Epoch 18447: train_loss=318.19778, val_loss=327.78461\n",
      "Epoch 18448: train_loss=318.12686, val_loss=327.55878\n",
      "Epoch 18449: train_loss=318.05917, val_loss=327.66977\n",
      "Epoch 18450: train_loss=317.99469, val_loss=327.41412\n",
      "Epoch 18451: train_loss=317.92828, val_loss=327.54199\n",
      "Epoch 18452: train_loss=317.85782, val_loss=327.25394\n",
      "Epoch 18453: train_loss=317.77783, val_loss=327.36746\n",
      "Epoch 18454: train_loss=317.68143, val_loss=327.04434\n",
      "Epoch 18455: train_loss=317.56689, val_loss=327.10861\n",
      "Epoch 18456: train_loss=317.43323, val_loss=326.77283\n",
      "Epoch 18457: train_loss=317.28433, val_loss=326.77448\n",
      "Epoch 18458: train_loss=317.12930, val_loss=326.48221\n",
      "Epoch 18459: train_loss=316.97418, val_loss=326.43250\n",
      "Epoch 18460: train_loss=316.82852, val_loss=326.23337\n",
      "Epoch 18461: train_loss=316.69846, val_loss=326.14539\n",
      "Epoch 18462: train_loss=316.58673, val_loss=326.04941\n",
      "Epoch 18463: train_loss=316.49216, val_loss=325.92499\n",
      "Epoch 18464: train_loss=316.40955, val_loss=325.90524\n",
      "Epoch 18465: train_loss=316.33319, val_loss=325.74466\n",
      "Epoch 18466: train_loss=316.25757, val_loss=325.75992\n",
      "Epoch 18467: train_loss=316.17905, val_loss=325.56534\n",
      "Epoch 18468: train_loss=316.09424, val_loss=325.57935\n",
      "Epoch 18469: train_loss=316.00308, val_loss=325.36642\n",
      "Epoch 18470: train_loss=315.90466, val_loss=325.36569\n",
      "Epoch 18471: train_loss=315.80109, val_loss=325.15762\n",
      "Epoch 18472: train_loss=315.69308, val_loss=325.13303\n",
      "Epoch 18473: train_loss=315.58359, val_loss=324.94601\n",
      "Epoch 18474: train_loss=315.47345, val_loss=324.88953\n",
      "Epoch 18475: train_loss=315.36597, val_loss=324.73773\n",
      "Epoch 18476: train_loss=315.26221, val_loss=324.65491\n",
      "Epoch 18477: train_loss=315.16275, val_loss=324.54984\n",
      "Epoch 18478: train_loss=315.06778, val_loss=324.44528\n",
      "Epoch 18479: train_loss=314.97650, val_loss=324.37479\n",
      "Epoch 18480: train_loss=314.88757, val_loss=324.24481\n",
      "Epoch 18481: train_loss=314.79974, val_loss=324.19318\n",
      "Epoch 18482: train_loss=314.71262, val_loss=324.04681\n",
      "Epoch 18483: train_loss=314.62558, val_loss=324.01385\n",
      "Epoch 18484: train_loss=314.53818, val_loss=323.85727\n",
      "Epoch 18485: train_loss=314.45029, val_loss=323.83450\n",
      "Epoch 18486: train_loss=314.36182, val_loss=323.66672\n",
      "Epoch 18487: train_loss=314.27237, val_loss=323.64517\n",
      "Epoch 18488: train_loss=314.18173, val_loss=323.47256\n",
      "Epoch 18489: train_loss=314.08978, val_loss=323.45227\n",
      "Epoch 18490: train_loss=313.99582, val_loss=323.27927\n",
      "Epoch 18491: train_loss=313.90094, val_loss=323.25098\n",
      "Epoch 18492: train_loss=313.80511, val_loss=323.07709\n",
      "Epoch 18493: train_loss=313.70810, val_loss=323.03931\n",
      "Epoch 18494: train_loss=313.61090, val_loss=322.87250\n",
      "Epoch 18495: train_loss=313.51337, val_loss=322.82971\n",
      "Epoch 18496: train_loss=313.41589, val_loss=322.67520\n",
      "Epoch 18497: train_loss=313.31857, val_loss=322.62100\n",
      "Epoch 18498: train_loss=313.22128, val_loss=322.47437\n",
      "Epoch 18499: train_loss=313.12448, val_loss=322.40845\n",
      "Epoch 18500: train_loss=313.02780, val_loss=322.27188\n",
      "Epoch 18501: train_loss=312.93164, val_loss=322.20111\n",
      "Epoch 18502: train_loss=312.83603, val_loss=322.07825\n",
      "Epoch 18503: train_loss=312.74161, val_loss=322.00372\n",
      "Epoch 18504: train_loss=312.64749, val_loss=321.88803\n",
      "Epoch 18505: train_loss=312.55356, val_loss=321.80658\n",
      "Epoch 18506: train_loss=312.46036, val_loss=321.69775\n",
      "Epoch 18507: train_loss=312.36768, val_loss=321.61673\n",
      "Epoch 18508: train_loss=312.27530, val_loss=321.51318\n",
      "Epoch 18509: train_loss=312.18280, val_loss=321.43109\n",
      "Epoch 18510: train_loss=312.09061, val_loss=321.32764\n",
      "Epoch 18511: train_loss=311.99875, val_loss=321.24338\n",
      "Epoch 18512: train_loss=311.90677, val_loss=321.13785\n",
      "Epoch 18513: train_loss=311.81500, val_loss=321.05444\n",
      "Epoch 18514: train_loss=311.72333, val_loss=320.94968\n",
      "Epoch 18515: train_loss=311.63174, val_loss=320.86887\n",
      "Epoch 18516: train_loss=311.54013, val_loss=320.76437\n",
      "Epoch 18517: train_loss=311.44879, val_loss=320.68399\n",
      "Epoch 18518: train_loss=311.35757, val_loss=320.57620\n",
      "Epoch 18519: train_loss=311.26639, val_loss=320.49902\n",
      "Epoch 18520: train_loss=311.17566, val_loss=320.38870\n",
      "Epoch 18521: train_loss=311.08505, val_loss=320.31808\n",
      "Epoch 18522: train_loss=310.99469, val_loss=320.20374\n",
      "Epoch 18523: train_loss=310.90509, val_loss=320.14426\n",
      "Epoch 18524: train_loss=310.81653, val_loss=320.01971\n",
      "Epoch 18525: train_loss=310.72900, val_loss=319.97281\n",
      "Epoch 18526: train_loss=310.64337, val_loss=319.83655\n",
      "Epoch 18527: train_loss=310.56155, val_loss=319.81995\n",
      "Epoch 18528: train_loss=310.48355, val_loss=319.67172\n",
      "Epoch 18529: train_loss=310.41205, val_loss=319.70062\n",
      "Epoch 18530: train_loss=310.34854, val_loss=319.53629\n",
      "Epoch 18531: train_loss=310.29706, val_loss=319.62714\n",
      "Epoch 18532: train_loss=310.25711, val_loss=319.44946\n",
      "Epoch 18533: train_loss=310.23755, val_loss=319.62775\n",
      "Epoch 18534: train_loss=310.23138, val_loss=319.43301\n",
      "Epoch 18535: train_loss=310.24689, val_loss=319.68915\n",
      "Epoch 18536: train_loss=310.26328, val_loss=319.43628\n",
      "Epoch 18537: train_loss=310.27383, val_loss=319.66949\n",
      "Epoch 18538: train_loss=310.23077, val_loss=319.27750\n",
      "Epoch 18539: train_loss=310.12308, val_loss=319.33804\n",
      "Epoch 18540: train_loss=309.91971, val_loss=318.84216\n",
      "Epoch 18541: train_loss=309.66272, val_loss=318.74301\n",
      "Epoch 18542: train_loss=309.38550, val_loss=318.38803\n",
      "Epoch 18543: train_loss=309.15540, val_loss=318.28354\n",
      "Epoch 18544: train_loss=309.00436, val_loss=318.23370\n",
      "Epoch 18545: train_loss=308.93848, val_loss=318.14008\n",
      "Epoch 18546: train_loss=308.92770, val_loss=318.26389\n",
      "Epoch 18547: train_loss=308.92294, val_loss=318.07370\n",
      "Epoch 18548: train_loss=308.88837, val_loss=318.14932\n",
      "Epoch 18549: train_loss=308.79788, val_loss=317.85095\n",
      "Epoch 18550: train_loss=308.65869, val_loss=317.81262\n",
      "Epoch 18551: train_loss=308.49216, val_loss=317.56070\n",
      "Epoch 18552: train_loss=308.33487, val_loss=317.47766\n",
      "Epoch 18553: train_loss=308.20786, val_loss=317.39203\n",
      "Epoch 18554: train_loss=308.12131, val_loss=317.28629\n",
      "Epoch 18555: train_loss=308.06271, val_loss=317.30838\n",
      "Epoch 18556: train_loss=308.00821, val_loss=317.14713\n",
      "Epoch 18557: train_loss=307.94351, val_loss=317.16220\n",
      "Epoch 18558: train_loss=307.85446, val_loss=316.95639\n",
      "Epoch 18559: train_loss=307.74789, val_loss=316.91724\n",
      "Epoch 18560: train_loss=307.62894, val_loss=316.74072\n",
      "Epoch 18561: train_loss=307.51422, val_loss=316.66385\n",
      "Epoch 18562: train_loss=307.41064, val_loss=316.57199\n",
      "Epoch 18563: train_loss=307.32196, val_loss=316.46844\n",
      "Epoch 18564: train_loss=307.24423, val_loss=316.44128\n",
      "Epoch 18565: train_loss=307.17026, val_loss=316.30399\n",
      "Epoch 18566: train_loss=307.09430, val_loss=316.28781\n",
      "Epoch 18567: train_loss=307.00931, val_loss=316.12701\n",
      "Epoch 18568: train_loss=306.91772, val_loss=316.08990\n",
      "Epoch 18569: train_loss=306.81891, val_loss=315.93860\n",
      "Epoch 18570: train_loss=306.71933, val_loss=315.87613\n",
      "Epoch 18571: train_loss=306.62109, val_loss=315.76199\n",
      "Epoch 18572: train_loss=306.52731, val_loss=315.67517\n",
      "Epoch 18573: train_loss=306.43832, val_loss=315.60297\n",
      "Epoch 18574: train_loss=306.35345, val_loss=315.49548\n",
      "Epoch 18575: train_loss=306.27054, val_loss=315.44714\n",
      "Epoch 18576: train_loss=306.18753, val_loss=315.32147\n",
      "Epoch 18577: train_loss=306.10376, val_loss=315.27899\n",
      "Epoch 18578: train_loss=306.01733, val_loss=315.14401\n",
      "Epoch 18579: train_loss=305.92953, val_loss=315.09634\n",
      "Epoch 18580: train_loss=305.83939, val_loss=314.96451\n",
      "Epoch 18581: train_loss=305.74896, val_loss=314.90607\n",
      "Epoch 18582: train_loss=305.65790, val_loss=314.78302\n",
      "Epoch 18583: train_loss=305.56723, val_loss=314.71127\n",
      "Epoch 18584: train_loss=305.47699, val_loss=314.60672\n",
      "Epoch 18585: train_loss=305.38770, val_loss=314.52316\n",
      "Epoch 18586: train_loss=305.29932, val_loss=314.43576\n",
      "Epoch 18587: train_loss=305.21216, val_loss=314.33838\n",
      "Epoch 18588: train_loss=305.12555, val_loss=314.26230\n",
      "Epoch 18589: train_loss=305.03937, val_loss=314.15372\n",
      "Epoch 18590: train_loss=304.95364, val_loss=314.08948\n",
      "Epoch 18591: train_loss=304.86813, val_loss=313.97525\n",
      "Epoch 18592: train_loss=304.78275, val_loss=313.91977\n",
      "Epoch 18593: train_loss=304.69742, val_loss=313.79675\n",
      "Epoch 18594: train_loss=304.61209, val_loss=313.74493\n",
      "Epoch 18595: train_loss=304.52618, val_loss=313.61542\n",
      "Epoch 18596: train_loss=304.44006, val_loss=313.56647\n",
      "Epoch 18597: train_loss=304.35287, val_loss=313.43689\n",
      "Epoch 18598: train_loss=304.26559, val_loss=313.38611\n",
      "Epoch 18599: train_loss=304.17743, val_loss=313.25681\n",
      "Epoch 18600: train_loss=304.08911, val_loss=313.20056\n",
      "Epoch 18601: train_loss=304.00003, val_loss=313.07596\n",
      "Epoch 18602: train_loss=303.91101, val_loss=313.01361\n",
      "Epoch 18603: train_loss=303.82184, val_loss=312.89536\n",
      "Epoch 18604: train_loss=303.73334, val_loss=312.82654\n",
      "Epoch 18605: train_loss=303.64462, val_loss=312.71722\n",
      "Epoch 18606: train_loss=303.55621, val_loss=312.64307\n",
      "Epoch 18607: train_loss=303.46823, val_loss=312.54156\n",
      "Epoch 18608: train_loss=303.38052, val_loss=312.46021\n",
      "Epoch 18609: train_loss=303.29312, val_loss=312.36514\n",
      "Epoch 18610: train_loss=303.20578, val_loss=312.27768\n",
      "Epoch 18611: train_loss=303.11871, val_loss=312.18991\n",
      "Epoch 18612: train_loss=303.03174, val_loss=312.09882\n",
      "Epoch 18613: train_loss=302.94495, val_loss=312.01440\n",
      "Epoch 18614: train_loss=302.85806, val_loss=311.91678\n",
      "Epoch 18615: train_loss=302.77158, val_loss=311.83554\n",
      "Epoch 18616: train_loss=302.68521, val_loss=311.73480\n",
      "Epoch 18617: train_loss=302.59885, val_loss=311.66190\n",
      "Epoch 18618: train_loss=302.51294, val_loss=311.55762\n",
      "Epoch 18619: train_loss=302.42773, val_loss=311.49371\n",
      "Epoch 18620: train_loss=302.34280, val_loss=311.37918\n",
      "Epoch 18621: train_loss=302.25900, val_loss=311.32553\n",
      "Epoch 18622: train_loss=302.17664, val_loss=311.19968\n",
      "Epoch 18623: train_loss=302.09641, val_loss=311.16855\n",
      "Epoch 18624: train_loss=302.01801, val_loss=311.03262\n",
      "Epoch 18625: train_loss=301.94235, val_loss=311.02838\n",
      "Epoch 18626: train_loss=301.86887, val_loss=310.87766\n",
      "Epoch 18627: train_loss=301.79922, val_loss=310.89706\n",
      "Epoch 18628: train_loss=301.73050, val_loss=310.72739\n",
      "Epoch 18629: train_loss=301.66577, val_loss=310.77069\n",
      "Epoch 18630: train_loss=301.60007, val_loss=310.58392\n",
      "Epoch 18631: train_loss=301.53644, val_loss=310.64725\n",
      "Epoch 18632: train_loss=301.47055, val_loss=310.44110\n",
      "Epoch 18633: train_loss=301.40366, val_loss=310.51105\n",
      "Epoch 18634: train_loss=301.33057, val_loss=310.28577\n",
      "Epoch 18635: train_loss=301.25409, val_loss=310.34613\n",
      "Epoch 18636: train_loss=301.16675, val_loss=310.10254\n",
      "Epoch 18637: train_loss=301.07169, val_loss=310.13440\n",
      "Epoch 18638: train_loss=300.96545, val_loss=309.88727\n",
      "Epoch 18639: train_loss=300.85312, val_loss=309.88672\n",
      "Epoch 18640: train_loss=300.73471, val_loss=309.66153\n",
      "Epoch 18641: train_loss=300.61511, val_loss=309.62738\n",
      "Epoch 18642: train_loss=300.49738, val_loss=309.44797\n",
      "Epoch 18643: train_loss=300.38586, val_loss=309.38589\n",
      "Epoch 18644: train_loss=300.28299, val_loss=309.26636\n",
      "Epoch 18645: train_loss=300.18912, val_loss=309.18124\n",
      "Epoch 18646: train_loss=300.10223, val_loss=309.10907\n",
      "Epoch 18647: train_loss=300.02045, val_loss=309.00217\n",
      "Epoch 18648: train_loss=299.94220, val_loss=308.96277\n",
      "Epoch 18649: train_loss=299.86563, val_loss=308.83502\n",
      "Epoch 18650: train_loss=299.78967, val_loss=308.81415\n",
      "Epoch 18651: train_loss=299.71286, val_loss=308.66867\n",
      "Epoch 18652: train_loss=299.63528, val_loss=308.65567\n",
      "Epoch 18653: train_loss=299.55597, val_loss=308.49707\n",
      "Epoch 18654: train_loss=299.47559, val_loss=308.48846\n",
      "Epoch 18655: train_loss=299.39380, val_loss=308.32446\n",
      "Epoch 18656: train_loss=299.31064, val_loss=308.31821\n",
      "Epoch 18657: train_loss=299.22690, val_loss=308.15195\n",
      "Epoch 18658: train_loss=299.14160, val_loss=308.14517\n",
      "Epoch 18659: train_loss=299.05612, val_loss=307.97739\n",
      "Epoch 18660: train_loss=298.96927, val_loss=307.96646\n",
      "Epoch 18661: train_loss=298.88162, val_loss=307.80075\n",
      "Epoch 18662: train_loss=298.79337, val_loss=307.78168\n",
      "Epoch 18663: train_loss=298.70425, val_loss=307.61871\n",
      "Epoch 18664: train_loss=298.61475, val_loss=307.59186\n",
      "Epoch 18665: train_loss=298.52560, val_loss=307.43600\n",
      "Epoch 18666: train_loss=298.43616, val_loss=307.40411\n",
      "Epoch 18667: train_loss=298.34689, val_loss=307.25812\n",
      "Epoch 18668: train_loss=298.25790, val_loss=307.21872\n",
      "Epoch 18669: train_loss=298.16873, val_loss=307.08160\n",
      "Epoch 18670: train_loss=298.08014, val_loss=307.03333\n",
      "Epoch 18671: train_loss=297.99170, val_loss=306.90506\n",
      "Epoch 18672: train_loss=297.90424, val_loss=306.84836\n",
      "Epoch 18673: train_loss=297.81686, val_loss=306.72745\n",
      "Epoch 18674: train_loss=297.73032, val_loss=306.66467\n",
      "Epoch 18675: train_loss=297.64413, val_loss=306.55298\n",
      "Epoch 18676: train_loss=297.55823, val_loss=306.48807\n",
      "Epoch 18677: train_loss=297.47269, val_loss=306.38220\n",
      "Epoch 18678: train_loss=297.38760, val_loss=306.31375\n",
      "Epoch 18679: train_loss=297.30258, val_loss=306.20877\n",
      "Epoch 18680: train_loss=297.21799, val_loss=306.13898\n",
      "Epoch 18681: train_loss=297.13354, val_loss=306.03537\n",
      "Epoch 18682: train_loss=297.04941, val_loss=305.96777\n",
      "Epoch 18683: train_loss=296.96561, val_loss=305.86444\n",
      "Epoch 18684: train_loss=296.88226, val_loss=305.80313\n",
      "Epoch 18685: train_loss=296.79947, val_loss=305.69424\n",
      "Epoch 18686: train_loss=296.71777, val_loss=305.64368\n",
      "Epoch 18687: train_loss=296.63708, val_loss=305.52557\n",
      "Epoch 18688: train_loss=296.55820, val_loss=305.49271\n",
      "Epoch 18689: train_loss=296.48132, val_loss=305.36444\n",
      "Epoch 18690: train_loss=296.40686, val_loss=305.35510\n",
      "Epoch 18691: train_loss=296.33539, val_loss=305.21283\n",
      "Epoch 18692: train_loss=296.26764, val_loss=305.23395\n",
      "Epoch 18693: train_loss=296.20425, val_loss=305.07886\n",
      "Epoch 18694: train_loss=296.14587, val_loss=305.13702\n",
      "Epoch 18695: train_loss=296.09314, val_loss=304.96280\n",
      "Epoch 18696: train_loss=296.04422, val_loss=305.05200\n",
      "Epoch 18697: train_loss=295.99710, val_loss=304.85458\n",
      "Epoch 18698: train_loss=295.95071, val_loss=304.96515\n",
      "Epoch 18699: train_loss=295.89871, val_loss=304.73615\n",
      "Epoch 18700: train_loss=295.83789, val_loss=304.83154\n",
      "Epoch 18701: train_loss=295.75897, val_loss=304.56628\n",
      "Epoch 18702: train_loss=295.66653, val_loss=304.61472\n",
      "Epoch 18703: train_loss=295.54996, val_loss=304.32715\n",
      "Epoch 18704: train_loss=295.41791, val_loss=304.31689\n",
      "Epoch 18705: train_loss=295.27524, val_loss=304.06143\n",
      "Epoch 18706: train_loss=295.13330, val_loss=304.01077\n",
      "Epoch 18707: train_loss=295.00235, val_loss=303.83762\n",
      "Epoch 18708: train_loss=294.88730, val_loss=303.76331\n",
      "Epoch 18709: train_loss=294.78967, val_loss=303.67957\n",
      "Epoch 18710: train_loss=294.70697, val_loss=303.58392\n",
      "Epoch 18711: train_loss=294.63470, val_loss=303.56293\n",
      "Epoch 18712: train_loss=294.56900, val_loss=303.43820\n",
      "Epoch 18713: train_loss=294.50613, val_loss=303.44946\n",
      "Epoch 18714: train_loss=294.44272, val_loss=303.29483\n",
      "Epoch 18715: train_loss=294.37518, val_loss=303.31152\n",
      "Epoch 18716: train_loss=294.30072, val_loss=303.13464\n",
      "Epoch 18717: train_loss=294.21930, val_loss=303.13647\n",
      "Epoch 18718: train_loss=294.13052, val_loss=302.95258\n",
      "Epoch 18719: train_loss=294.03644, val_loss=302.93365\n",
      "Epoch 18720: train_loss=293.93915, val_loss=302.76669\n",
      "Epoch 18721: train_loss=293.84213, val_loss=302.72852\n",
      "Epoch 18722: train_loss=293.74588, val_loss=302.58734\n",
      "Epoch 18723: train_loss=293.65283, val_loss=302.53235\n",
      "Epoch 18724: train_loss=293.56244, val_loss=302.41818\n",
      "Epoch 18725: train_loss=293.47519, val_loss=302.34869\n",
      "Epoch 18726: train_loss=293.38998, val_loss=302.25684\n",
      "Epoch 18727: train_loss=293.30676, val_loss=302.17221\n",
      "Epoch 18728: train_loss=293.22482, val_loss=302.09537\n",
      "Epoch 18729: train_loss=293.14392, val_loss=301.99954\n",
      "Epoch 18730: train_loss=293.06396, val_loss=301.93887\n",
      "Epoch 18731: train_loss=292.98462, val_loss=301.83536\n",
      "Epoch 18732: train_loss=292.90616, val_loss=301.78973\n",
      "Epoch 18733: train_loss=292.82858, val_loss=301.67532\n",
      "Epoch 18734: train_loss=292.75275, val_loss=301.64337\n",
      "Epoch 18735: train_loss=292.67746, val_loss=301.51620\n",
      "Epoch 18736: train_loss=292.60400, val_loss=301.49728\n",
      "Epoch 18737: train_loss=292.53012, val_loss=301.35760\n",
      "Epoch 18738: train_loss=292.45758, val_loss=301.35223\n",
      "Epoch 18739: train_loss=292.38406, val_loss=301.20282\n",
      "Epoch 18740: train_loss=292.31113, val_loss=301.20706\n",
      "Epoch 18741: train_loss=292.23618, val_loss=301.04718\n",
      "Epoch 18742: train_loss=292.16092, val_loss=301.05350\n",
      "Epoch 18743: train_loss=292.08331, val_loss=300.88550\n",
      "Epoch 18744: train_loss=292.00507, val_loss=300.89084\n",
      "Epoch 18745: train_loss=291.92343, val_loss=300.71872\n",
      "Epoch 18746: train_loss=291.84036, val_loss=300.71811\n",
      "Epoch 18747: train_loss=291.75394, val_loss=300.54654\n",
      "Epoch 18748: train_loss=291.66586, val_loss=300.53424\n",
      "Epoch 18749: train_loss=291.57483, val_loss=300.36975\n",
      "Epoch 18750: train_loss=291.48389, val_loss=300.34106\n",
      "Epoch 18751: train_loss=291.39078, val_loss=300.18784\n",
      "Epoch 18752: train_loss=291.29919, val_loss=300.14328\n",
      "Epoch 18753: train_loss=291.20813, val_loss=300.00870\n",
      "Epoch 18754: train_loss=291.11844, val_loss=299.95108\n",
      "Epoch 18755: train_loss=291.03012, val_loss=299.84158\n",
      "Epoch 18756: train_loss=290.94409, val_loss=299.77286\n",
      "Epoch 18757: train_loss=290.85983, val_loss=299.68262\n",
      "Epoch 18758: train_loss=290.77737, val_loss=299.60062\n",
      "Epoch 18759: train_loss=290.69598, val_loss=299.52295\n",
      "Epoch 18760: train_loss=290.61548, val_loss=299.43130\n",
      "Epoch 18761: train_loss=290.53558, val_loss=299.36627\n",
      "Epoch 18762: train_loss=290.45639, val_loss=299.26553\n",
      "Epoch 18763: train_loss=290.37781, val_loss=299.21243\n",
      "Epoch 18764: train_loss=290.29974, val_loss=299.10474\n",
      "Epoch 18765: train_loss=290.22336, val_loss=299.06659\n",
      "Epoch 18766: train_loss=290.14755, val_loss=298.94839\n",
      "Epoch 18767: train_loss=290.07318, val_loss=298.92175\n",
      "Epoch 18768: train_loss=289.99902, val_loss=298.79321\n",
      "Epoch 18769: train_loss=289.92682, val_loss=298.78149\n",
      "Epoch 18770: train_loss=289.85455, val_loss=298.64529\n",
      "Epoch 18771: train_loss=289.78497, val_loss=298.64960\n",
      "Epoch 18772: train_loss=289.71552, val_loss=298.50415\n",
      "Epoch 18773: train_loss=289.65063, val_loss=298.52408\n",
      "Epoch 18774: train_loss=289.58395, val_loss=298.36710\n",
      "Epoch 18775: train_loss=289.52179, val_loss=298.40097\n",
      "Epoch 18776: train_loss=289.45590, val_loss=298.22977\n",
      "Epoch 18777: train_loss=289.39145, val_loss=298.26886\n",
      "Epoch 18778: train_loss=289.32001, val_loss=298.08185\n",
      "Epoch 18779: train_loss=289.24625, val_loss=298.11224\n",
      "Epoch 18780: train_loss=289.16296, val_loss=297.91290\n",
      "Epoch 18781: train_loss=289.07587, val_loss=297.92328\n",
      "Epoch 18782: train_loss=288.98035, val_loss=297.72253\n",
      "Epoch 18783: train_loss=288.88327, val_loss=297.71033\n",
      "Epoch 18784: train_loss=288.78036, val_loss=297.52341\n",
      "Epoch 18785: train_loss=288.67868, val_loss=297.48969\n",
      "Epoch 18786: train_loss=288.57623, val_loss=297.32971\n",
      "Epoch 18787: train_loss=288.47720, val_loss=297.27930\n",
      "Epoch 18788: train_loss=288.38147, val_loss=297.15460\n",
      "Epoch 18789: train_loss=288.29056, val_loss=297.09009\n",
      "Epoch 18790: train_loss=288.20413, val_loss=296.99689\n",
      "Epoch 18791: train_loss=288.12146, val_loss=296.91580\n",
      "Epoch 18792: train_loss=288.04196, val_loss=296.84784\n",
      "Epoch 18793: train_loss=287.96497, val_loss=296.75192\n",
      "Epoch 18794: train_loss=287.88947, val_loss=296.70328\n",
      "Epoch 18795: train_loss=287.81500, val_loss=296.59625\n",
      "Epoch 18796: train_loss=287.74078, val_loss=296.56030\n",
      "Epoch 18797: train_loss=287.66632, val_loss=296.44250\n",
      "Epoch 18798: train_loss=287.59180, val_loss=296.41113\n",
      "Epoch 18799: train_loss=287.51642, val_loss=296.28421\n",
      "Epoch 18800: train_loss=287.44073, val_loss=296.25769\n",
      "Epoch 18801: train_loss=287.36386, val_loss=296.12878\n",
      "Epoch 18802: train_loss=287.28687, val_loss=296.10590\n",
      "Epoch 18803: train_loss=287.20837, val_loss=295.97446\n",
      "Epoch 18804: train_loss=287.13019, val_loss=295.94937\n",
      "Epoch 18805: train_loss=287.05054, val_loss=295.81387\n",
      "Epoch 18806: train_loss=286.97137, val_loss=295.78531\n",
      "Epoch 18807: train_loss=286.89157, val_loss=295.65015\n",
      "Epoch 18808: train_loss=286.81180, val_loss=295.62268\n",
      "Epoch 18809: train_loss=286.73135, val_loss=295.49118\n",
      "Epoch 18810: train_loss=286.65021, val_loss=295.46069\n",
      "Epoch 18811: train_loss=286.56888, val_loss=295.32953\n",
      "Epoch 18812: train_loss=286.48721, val_loss=295.29123\n",
      "Epoch 18813: train_loss=286.40512, val_loss=295.16281\n",
      "Epoch 18814: train_loss=286.32361, val_loss=295.12015\n",
      "Epoch 18815: train_loss=286.24191, val_loss=294.99866\n",
      "Epoch 18816: train_loss=286.16077, val_loss=294.95514\n",
      "Epoch 18817: train_loss=286.07962, val_loss=294.83871\n",
      "Epoch 18818: train_loss=285.99899, val_loss=294.79248\n",
      "Epoch 18819: train_loss=285.91888, val_loss=294.67816\n",
      "Epoch 18820: train_loss=285.83908, val_loss=294.62943\n",
      "Epoch 18821: train_loss=285.75967, val_loss=294.51678\n",
      "Epoch 18822: train_loss=285.68073, val_loss=294.46899\n",
      "Epoch 18823: train_loss=285.60193, val_loss=294.35901\n",
      "Epoch 18824: train_loss=285.52402, val_loss=294.31442\n",
      "Epoch 18825: train_loss=285.44635, val_loss=294.20206\n",
      "Epoch 18826: train_loss=285.36963, val_loss=294.16147\n",
      "Epoch 18827: train_loss=285.29349, val_loss=294.04434\n",
      "Epoch 18828: train_loss=285.21832, val_loss=294.01114\n",
      "Epoch 18829: train_loss=285.14447, val_loss=293.89163\n",
      "Epoch 18830: train_loss=285.07245, val_loss=293.87213\n",
      "Epoch 18831: train_loss=285.00226, val_loss=293.74854\n",
      "Epoch 18832: train_loss=284.93552, val_loss=293.74811\n",
      "Epoch 18833: train_loss=284.87100, val_loss=293.61700\n",
      "Epoch 18834: train_loss=284.81079, val_loss=293.63672\n",
      "Epoch 18835: train_loss=284.75217, val_loss=293.49469\n",
      "Epoch 18836: train_loss=284.69797, val_loss=293.53372\n",
      "Epoch 18837: train_loss=284.64322, val_loss=293.37637\n",
      "Epoch 18838: train_loss=284.59119, val_loss=293.42929\n",
      "Epoch 18839: train_loss=284.53479, val_loss=293.25638\n",
      "Epoch 18840: train_loss=284.47742, val_loss=293.31070\n",
      "Epoch 18841: train_loss=284.41003, val_loss=293.11768\n",
      "Epoch 18842: train_loss=284.33887, val_loss=293.15137\n",
      "Epoch 18843: train_loss=284.25085, val_loss=292.93265\n",
      "Epoch 18844: train_loss=284.15372, val_loss=292.92719\n",
      "Epoch 18845: train_loss=284.04144, val_loss=292.70847\n",
      "Epoch 18846: train_loss=283.92368, val_loss=292.66895\n",
      "Epoch 18847: train_loss=283.80179, val_loss=292.48422\n",
      "Epoch 18848: train_loss=283.68454, val_loss=292.42282\n",
      "Epoch 18849: train_loss=283.57745, val_loss=292.30008\n",
      "Epoch 18850: train_loss=283.48288, val_loss=292.22397\n",
      "Epoch 18851: train_loss=283.40125, val_loss=292.16193\n",
      "Epoch 18852: train_loss=283.33047, val_loss=292.07059\n",
      "Epoch 18853: train_loss=283.26654, val_loss=292.04868\n",
      "Epoch 18854: train_loss=283.20544, val_loss=291.93542\n",
      "Epoch 18855: train_loss=283.14328, val_loss=291.92624\n",
      "Epoch 18856: train_loss=283.07797, val_loss=291.79266\n",
      "Epoch 18857: train_loss=283.00772, val_loss=291.77780\n",
      "Epoch 18858: train_loss=282.93161, val_loss=291.63156\n",
      "Epoch 18859: train_loss=282.85025, val_loss=291.60364\n",
      "Epoch 18860: train_loss=282.76532, val_loss=291.46188\n",
      "Epoch 18861: train_loss=282.67807, val_loss=291.42258\n",
      "Epoch 18862: train_loss=282.59082, val_loss=291.29623\n",
      "Epoch 18863: train_loss=282.50372, val_loss=291.24490\n",
      "Epoch 18864: train_loss=282.41818, val_loss=291.13730\n",
      "Epoch 18865: train_loss=282.33514, val_loss=291.07101\n",
      "Epoch 18866: train_loss=282.25439, val_loss=290.98035\n",
      "Epoch 18867: train_loss=282.17578, val_loss=290.90222\n",
      "Epoch 18868: train_loss=282.09933, val_loss=290.83099\n",
      "Epoch 18869: train_loss=282.02444, val_loss=290.74576\n",
      "Epoch 18870: train_loss=281.95053, val_loss=290.68817\n",
      "Epoch 18871: train_loss=281.87732, val_loss=290.59384\n",
      "Epoch 18872: train_loss=281.80438, val_loss=290.54199\n",
      "Epoch 18873: train_loss=281.73105, val_loss=290.43866\n",
      "Epoch 18874: train_loss=281.65768, val_loss=290.39145\n",
      "Epoch 18875: train_loss=281.58386, val_loss=290.28568\n",
      "Epoch 18876: train_loss=281.51007, val_loss=290.24323\n",
      "Epoch 18877: train_loss=281.43607, val_loss=290.13446\n",
      "Epoch 18878: train_loss=281.36182, val_loss=290.09387\n",
      "Epoch 18879: train_loss=281.28751, val_loss=289.98227\n",
      "Epoch 18880: train_loss=281.21338, val_loss=289.94263\n",
      "Epoch 18881: train_loss=281.13925, val_loss=289.82916\n",
      "Epoch 18882: train_loss=281.06467, val_loss=289.79233\n",
      "Epoch 18883: train_loss=280.99023, val_loss=289.67746\n",
      "Epoch 18884: train_loss=280.91605, val_loss=289.64191\n",
      "Epoch 18885: train_loss=280.84219, val_loss=289.52533\n",
      "Epoch 18886: train_loss=280.76849, val_loss=289.49274\n",
      "Epoch 18887: train_loss=280.69507, val_loss=289.37344\n",
      "Epoch 18888: train_loss=280.62189, val_loss=289.34494\n",
      "Epoch 18889: train_loss=280.54953, val_loss=289.22507\n",
      "Epoch 18890: train_loss=280.47754, val_loss=289.20407\n",
      "Epoch 18891: train_loss=280.40698, val_loss=289.08237\n",
      "Epoch 18892: train_loss=280.33740, val_loss=289.06848\n",
      "Epoch 18893: train_loss=280.26886, val_loss=288.93958\n",
      "Epoch 18894: train_loss=280.20099, val_loss=288.93256\n",
      "Epoch 18895: train_loss=280.13406, val_loss=288.79858\n",
      "Epoch 18896: train_loss=280.06750, val_loss=288.80081\n",
      "Epoch 18897: train_loss=280.00101, val_loss=288.66205\n",
      "Epoch 18898: train_loss=279.93451, val_loss=288.66940\n",
      "Epoch 18899: train_loss=279.86728, val_loss=288.52118\n",
      "Epoch 18900: train_loss=279.79840, val_loss=288.52914\n",
      "Epoch 18901: train_loss=279.72882, val_loss=288.37503\n",
      "Epoch 18902: train_loss=279.65628, val_loss=288.38025\n",
      "Epoch 18903: train_loss=279.58115, val_loss=288.22046\n",
      "Epoch 18904: train_loss=279.50165, val_loss=288.21341\n",
      "Epoch 18905: train_loss=279.41803, val_loss=288.04959\n",
      "Epoch 18906: train_loss=279.33014, val_loss=288.02533\n",
      "Epoch 18907: train_loss=279.24042, val_loss=287.87140\n",
      "Epoch 18908: train_loss=279.14859, val_loss=287.83133\n",
      "Epoch 18909: train_loss=279.05731, val_loss=287.69879\n",
      "Epoch 18910: train_loss=278.96783, val_loss=287.64499\n",
      "Epoch 18911: train_loss=278.88165, val_loss=287.53711\n",
      "Epoch 18912: train_loss=278.79913, val_loss=287.46902\n",
      "Epoch 18913: train_loss=278.71994, val_loss=287.38492\n",
      "Epoch 18914: train_loss=278.64383, val_loss=287.30698\n",
      "Epoch 18915: train_loss=278.57010, val_loss=287.24448\n",
      "Epoch 18916: train_loss=278.49786, val_loss=287.15787\n",
      "Epoch 18917: train_loss=278.42685, val_loss=287.10965\n",
      "Epoch 18918: train_loss=278.35669, val_loss=287.01294\n",
      "Epoch 18919: train_loss=278.28735, val_loss=286.97507\n",
      "Epoch 18920: train_loss=278.21848, val_loss=286.86981\n",
      "Epoch 18921: train_loss=278.15051, val_loss=286.84253\n",
      "Epoch 18922: train_loss=278.08307, val_loss=286.72879\n",
      "Epoch 18923: train_loss=278.01715, val_loss=286.71219\n",
      "Epoch 18924: train_loss=277.95120, val_loss=286.59122\n",
      "Epoch 18925: train_loss=277.88559, val_loss=286.58630\n",
      "Epoch 18926: train_loss=277.82040, val_loss=286.45895\n",
      "Epoch 18927: train_loss=277.75623, val_loss=286.46570\n",
      "Epoch 18928: train_loss=277.69424, val_loss=286.33096\n",
      "Epoch 18929: train_loss=277.63324, val_loss=286.34634\n",
      "Epoch 18930: train_loss=277.57315, val_loss=286.20154\n",
      "Epoch 18931: train_loss=277.51312, val_loss=286.22665\n",
      "Epoch 18932: train_loss=277.45331, val_loss=286.07361\n",
      "Epoch 18933: train_loss=277.39066, val_loss=286.10144\n",
      "Epoch 18934: train_loss=277.32535, val_loss=285.93561\n",
      "Epoch 18935: train_loss=277.25351, val_loss=285.95340\n",
      "Epoch 18936: train_loss=277.17639, val_loss=285.77612\n",
      "Epoch 18937: train_loss=277.09216, val_loss=285.77350\n",
      "Epoch 18938: train_loss=277.00284, val_loss=285.59448\n",
      "Epoch 18939: train_loss=276.90796, val_loss=285.57101\n",
      "Epoch 18940: train_loss=276.81116, val_loss=285.40610\n",
      "Epoch 18941: train_loss=276.71347, val_loss=285.36301\n",
      "Epoch 18942: train_loss=276.61777, val_loss=285.22565\n",
      "Epoch 18943: train_loss=276.52545, val_loss=285.16821\n",
      "Epoch 18944: train_loss=276.43875, val_loss=285.06619\n",
      "Epoch 18945: train_loss=276.35773, val_loss=284.99664\n",
      "Epoch 18946: train_loss=276.28183, val_loss=284.92438\n",
      "Epoch 18947: train_loss=276.20978, val_loss=284.84277\n",
      "Epoch 18948: train_loss=276.14078, val_loss=284.79355\n",
      "Epoch 18949: train_loss=276.07339, val_loss=284.70145\n",
      "Epoch 18950: train_loss=276.00677, val_loss=284.66748\n",
      "Epoch 18951: train_loss=275.94067, val_loss=284.56436\n",
      "Epoch 18952: train_loss=275.87357, val_loss=284.53552\n",
      "Epoch 18953: train_loss=275.80579, val_loss=284.42383\n",
      "Epoch 18954: train_loss=275.73639, val_loss=284.39624\n",
      "Epoch 18955: train_loss=275.66571, val_loss=284.27997\n",
      "Epoch 18956: train_loss=275.59323, val_loss=284.24997\n",
      "Epoch 18957: train_loss=275.51965, val_loss=284.13242\n",
      "Epoch 18958: train_loss=275.44461, val_loss=284.09552\n",
      "Epoch 18959: train_loss=275.36935, val_loss=283.98172\n",
      "Epoch 18960: train_loss=275.29379, val_loss=283.94098\n",
      "Epoch 18961: train_loss=275.21814, val_loss=283.83405\n",
      "Epoch 18962: train_loss=275.14273, val_loss=283.78824\n",
      "Epoch 18963: train_loss=275.06784, val_loss=283.68661\n",
      "Epoch 18964: train_loss=274.99341, val_loss=283.63278\n",
      "Epoch 18965: train_loss=274.91916, val_loss=283.53595\n",
      "Epoch 18966: train_loss=274.84528, val_loss=283.47949\n",
      "Epoch 18967: train_loss=274.77200, val_loss=283.39258\n",
      "Epoch 18968: train_loss=274.69925, val_loss=283.33374\n",
      "Epoch 18969: train_loss=274.62668, val_loss=283.25085\n",
      "Epoch 18970: train_loss=274.55447, val_loss=283.18649\n",
      "Epoch 18971: train_loss=274.48279, val_loss=283.10455\n",
      "Epoch 18972: train_loss=274.41116, val_loss=283.03763\n",
      "Epoch 18973: train_loss=274.33975, val_loss=282.95953\n",
      "Epoch 18974: train_loss=274.26840, val_loss=282.89374\n",
      "Epoch 18975: train_loss=274.19730, val_loss=282.81711\n",
      "Epoch 18976: train_loss=274.12622, val_loss=282.75174\n",
      "Epoch 18977: train_loss=274.05518, val_loss=282.67548\n",
      "Epoch 18978: train_loss=273.98410, val_loss=282.61023\n",
      "Epoch 18979: train_loss=273.91342, val_loss=282.53143\n",
      "Epoch 18980: train_loss=273.84293, val_loss=282.46918\n",
      "Epoch 18981: train_loss=273.77274, val_loss=282.38705\n",
      "Epoch 18982: train_loss=273.70322, val_loss=282.33160\n",
      "Epoch 18983: train_loss=273.63431, val_loss=282.24490\n",
      "Epoch 18984: train_loss=273.56638, val_loss=282.20010\n",
      "Epoch 18985: train_loss=273.49957, val_loss=282.10815\n",
      "Epoch 18986: train_loss=273.43478, val_loss=282.07840\n",
      "Epoch 18987: train_loss=273.37244, val_loss=281.98001\n",
      "Epoch 18988: train_loss=273.31369, val_loss=281.97498\n",
      "Epoch 18989: train_loss=273.25903, val_loss=281.86905\n",
      "Epoch 18990: train_loss=273.21017, val_loss=281.89374\n",
      "Epoch 18991: train_loss=273.16754, val_loss=281.78018\n",
      "Epoch 18992: train_loss=273.13345, val_loss=281.84299\n",
      "Epoch 18993: train_loss=273.10623, val_loss=281.72263\n",
      "Epoch 18994: train_loss=273.09021, val_loss=281.83167\n",
      "Epoch 18995: train_loss=273.08127, val_loss=281.69830\n",
      "Epoch 18996: train_loss=273.07791, val_loss=281.83463\n",
      "Epoch 18997: train_loss=273.07013, val_loss=281.66373\n",
      "Epoch 18998: train_loss=273.05273, val_loss=281.77536\n",
      "Epoch 18999: train_loss=273.00443, val_loss=281.53070\n",
      "Epoch 19000: train_loss=272.91959, val_loss=281.54633\n",
      "Epoch 19001: train_loss=272.78165, val_loss=281.23438\n",
      "Epoch 19002: train_loss=272.60834, val_loss=281.15240\n",
      "Epoch 19003: train_loss=272.41644, val_loss=280.89307\n",
      "Epoch 19004: train_loss=272.24176, val_loss=280.80234\n",
      "Epoch 19005: train_loss=272.10825, val_loss=280.70511\n",
      "Epoch 19006: train_loss=272.02420, val_loss=280.64047\n",
      "Epoch 19007: train_loss=271.98102, val_loss=280.66650\n",
      "Epoch 19008: train_loss=271.95999, val_loss=280.57657\n",
      "Epoch 19009: train_loss=271.94025, val_loss=280.62305\n",
      "Epoch 19010: train_loss=271.90475, val_loss=280.47284\n",
      "Epoch 19011: train_loss=271.84393, val_loss=280.47363\n",
      "Epoch 19012: train_loss=271.75729, val_loss=280.28879\n",
      "Epoch 19013: train_loss=271.65140, val_loss=280.23993\n",
      "Epoch 19014: train_loss=271.54031, val_loss=280.08557\n",
      "Epoch 19015: train_loss=271.43481, val_loss=280.01935\n",
      "Epoch 19016: train_loss=271.34433, val_loss=279.94147\n",
      "Epoch 19017: train_loss=271.27127, val_loss=279.87259\n",
      "Epoch 19018: train_loss=271.21262, val_loss=279.85175\n",
      "Epoch 19019: train_loss=271.16171, val_loss=279.76007\n",
      "Epoch 19020: train_loss=271.10986, val_loss=279.74930\n",
      "Epoch 19021: train_loss=271.05228, val_loss=279.63141\n",
      "Epoch 19022: train_loss=270.98514, val_loss=279.60434\n",
      "Epoch 19023: train_loss=270.91019, val_loss=279.48007\n",
      "Epoch 19024: train_loss=270.83026, val_loss=279.43121\n",
      "Epoch 19025: train_loss=270.74893, val_loss=279.32318\n",
      "Epoch 19026: train_loss=270.66940, val_loss=279.26016\n",
      "Epoch 19027: train_loss=270.59479, val_loss=279.18839\n",
      "Epoch 19028: train_loss=270.52582, val_loss=279.11859\n",
      "Epoch 19029: train_loss=270.46118, val_loss=279.07333\n",
      "Epoch 19030: train_loss=270.39905, val_loss=278.98895\n",
      "Epoch 19031: train_loss=270.33755, val_loss=278.95270\n",
      "Epoch 19032: train_loss=270.27505, val_loss=278.85556\n",
      "Epoch 19033: train_loss=270.21021, val_loss=278.81775\n",
      "Epoch 19034: train_loss=270.14258, val_loss=278.71661\n",
      "Epoch 19035: train_loss=270.07266, val_loss=278.67142\n",
      "Epoch 19036: train_loss=270.00153, val_loss=278.57590\n",
      "Epoch 19037: train_loss=269.92963, val_loss=278.52322\n",
      "Epoch 19038: train_loss=269.85831, val_loss=278.44220\n",
      "Epoch 19039: train_loss=269.78818, val_loss=278.38254\n",
      "Epoch 19040: train_loss=269.71936, val_loss=278.31277\n",
      "Epoch 19041: train_loss=269.65179, val_loss=278.24142\n",
      "Epoch 19042: train_loss=269.58533, val_loss=278.17978\n",
      "Epoch 19043: train_loss=269.51959, val_loss=278.10254\n",
      "Epoch 19044: train_loss=269.45428, val_loss=278.05170\n",
      "Epoch 19045: train_loss=269.38910, val_loss=277.97189\n",
      "Epoch 19046: train_loss=269.32358, val_loss=277.92505\n",
      "Epoch 19047: train_loss=269.25812, val_loss=277.83997\n",
      "Epoch 19048: train_loss=269.19238, val_loss=277.79343\n",
      "Epoch 19049: train_loss=269.12656, val_loss=277.70609\n",
      "Epoch 19050: train_loss=269.06039, val_loss=277.66141\n",
      "Epoch 19051: train_loss=268.99417, val_loss=277.57236\n",
      "Epoch 19052: train_loss=268.92743, val_loss=277.52509\n",
      "Epoch 19053: train_loss=268.86047, val_loss=277.43530\n",
      "Epoch 19054: train_loss=268.79315, val_loss=277.38699\n",
      "Epoch 19055: train_loss=268.72595, val_loss=277.30246\n",
      "Epoch 19056: train_loss=268.65891, val_loss=277.25385\n",
      "Epoch 19057: train_loss=268.59201, val_loss=277.17047\n",
      "Epoch 19058: train_loss=268.52527, val_loss=277.11890\n",
      "Epoch 19059: train_loss=268.45883, val_loss=277.03537\n",
      "Epoch 19060: train_loss=268.39273, val_loss=276.98422\n",
      "Epoch 19061: train_loss=268.32678, val_loss=276.90231\n",
      "Epoch 19062: train_loss=268.26114, val_loss=276.85336\n",
      "Epoch 19063: train_loss=268.19577, val_loss=276.77112\n",
      "Epoch 19064: train_loss=268.13077, val_loss=276.72574\n",
      "Epoch 19065: train_loss=268.06674, val_loss=276.64188\n",
      "Epoch 19066: train_loss=268.00333, val_loss=276.60394\n",
      "Epoch 19067: train_loss=267.94107, val_loss=276.51624\n",
      "Epoch 19068: train_loss=267.87985, val_loss=276.48621\n",
      "Epoch 19069: train_loss=267.81998, val_loss=276.39246\n",
      "Epoch 19070: train_loss=267.76160, val_loss=276.37616\n",
      "Epoch 19071: train_loss=267.70499, val_loss=276.27774\n",
      "Epoch 19072: train_loss=267.65005, val_loss=276.27652\n",
      "Epoch 19073: train_loss=267.59726, val_loss=276.16977\n",
      "Epoch 19074: train_loss=267.54565, val_loss=276.18143\n",
      "Epoch 19075: train_loss=267.49557, val_loss=276.06589\n",
      "Epoch 19076: train_loss=267.44611, val_loss=276.08978\n",
      "Epoch 19077: train_loss=267.39618, val_loss=275.96454\n",
      "Epoch 19078: train_loss=267.34650, val_loss=275.99677\n",
      "Epoch 19079: train_loss=267.29651, val_loss=275.85977\n",
      "Epoch 19080: train_loss=267.24533, val_loss=275.89252\n",
      "Epoch 19081: train_loss=267.19000, val_loss=275.74103\n",
      "Epoch 19082: train_loss=267.12839, val_loss=275.76321\n",
      "Epoch 19083: train_loss=267.05942, val_loss=275.59909\n",
      "Epoch 19084: train_loss=266.98181, val_loss=275.59946\n",
      "Epoch 19085: train_loss=266.89783, val_loss=275.43353\n",
      "Epoch 19086: train_loss=266.80841, val_loss=275.41141\n",
      "Epoch 19087: train_loss=266.71759, val_loss=275.26074\n",
      "Epoch 19088: train_loss=266.62561, val_loss=275.22104\n",
      "Epoch 19089: train_loss=266.53833, val_loss=275.10318\n",
      "Epoch 19090: train_loss=266.45596, val_loss=275.05035\n",
      "Epoch 19091: train_loss=266.38080, val_loss=274.96930\n",
      "Epoch 19092: train_loss=266.31155, val_loss=274.90567\n",
      "Epoch 19093: train_loss=266.24750, val_loss=274.85599\n",
      "Epoch 19094: train_loss=266.18719, val_loss=274.78174\n",
      "Epoch 19095: train_loss=266.12939, val_loss=274.75204\n",
      "Epoch 19096: train_loss=266.07327, val_loss=274.66370\n",
      "Epoch 19097: train_loss=266.01752, val_loss=274.64386\n",
      "Epoch 19098: train_loss=265.96225, val_loss=274.54318\n",
      "Epoch 19099: train_loss=265.90582, val_loss=274.52957\n",
      "Epoch 19100: train_loss=265.84717, val_loss=274.42224\n",
      "Epoch 19101: train_loss=265.78625, val_loss=274.40768\n",
      "Epoch 19102: train_loss=265.72247, val_loss=274.29688\n",
      "Epoch 19103: train_loss=265.65802, val_loss=274.27609\n",
      "Epoch 19104: train_loss=265.59167, val_loss=274.16528\n",
      "Epoch 19105: train_loss=265.52524, val_loss=274.14008\n",
      "Epoch 19106: train_loss=265.45767, val_loss=274.03479\n",
      "Epoch 19107: train_loss=265.39096, val_loss=274.00555\n",
      "Epoch 19108: train_loss=265.32391, val_loss=273.90469\n",
      "Epoch 19109: train_loss=265.25745, val_loss=273.86877\n",
      "Epoch 19110: train_loss=265.19095, val_loss=273.77313\n",
      "Epoch 19111: train_loss=265.12570, val_loss=273.73581\n",
      "Epoch 19112: train_loss=265.06067, val_loss=273.64758\n",
      "Epoch 19113: train_loss=264.99643, val_loss=273.61121\n",
      "Epoch 19114: train_loss=264.93265, val_loss=273.52692\n",
      "Epoch 19115: train_loss=264.86963, val_loss=273.49011\n",
      "Epoch 19116: train_loss=264.80692, val_loss=273.40585\n",
      "Epoch 19117: train_loss=264.74466, val_loss=273.37100\n",
      "Epoch 19118: train_loss=264.68301, val_loss=273.28717\n",
      "Epoch 19119: train_loss=264.62195, val_loss=273.25781\n",
      "Epoch 19120: train_loss=264.56152, val_loss=273.17355\n",
      "Epoch 19121: train_loss=264.50195, val_loss=273.15021\n",
      "Epoch 19122: train_loss=264.44327, val_loss=273.06216\n",
      "Epoch 19123: train_loss=264.38623, val_loss=273.04688\n",
      "Epoch 19124: train_loss=264.33075, val_loss=272.95584\n",
      "Epoch 19125: train_loss=264.27872, val_loss=272.95419\n",
      "Epoch 19126: train_loss=264.22842, val_loss=272.85818\n",
      "Epoch 19127: train_loss=264.18256, val_loss=272.87573\n",
      "Epoch 19128: train_loss=264.14029, val_loss=272.77448\n",
      "Epoch 19129: train_loss=264.10196, val_loss=272.81345\n",
      "Epoch 19130: train_loss=264.06732, val_loss=272.70413\n",
      "Epoch 19131: train_loss=264.03488, val_loss=272.75830\n",
      "Epoch 19132: train_loss=264.00104, val_loss=272.63211\n",
      "Epoch 19133: train_loss=263.96414, val_loss=272.68542\n",
      "Epoch 19134: train_loss=263.91992, val_loss=272.53525\n",
      "Epoch 19135: train_loss=263.86627, val_loss=272.56509\n",
      "Epoch 19136: train_loss=263.79764, val_loss=272.38605\n",
      "Epoch 19137: train_loss=263.71439, val_loss=272.37595\n",
      "Epoch 19138: train_loss=263.61789, val_loss=272.19168\n",
      "Epoch 19139: train_loss=263.51361, val_loss=272.15356\n",
      "Epoch 19140: train_loss=263.40817, val_loss=271.99927\n",
      "Epoch 19141: train_loss=263.30655, val_loss=271.94733\n",
      "Epoch 19142: train_loss=263.21341, val_loss=271.84189\n",
      "Epoch 19143: train_loss=263.13257, val_loss=271.78223\n",
      "Epoch 19144: train_loss=263.06366, val_loss=271.72598\n",
      "Epoch 19145: train_loss=263.00534, val_loss=271.65793\n",
      "Epoch 19146: train_loss=262.95416, val_loss=271.63617\n",
      "Epoch 19147: train_loss=262.90692, val_loss=271.55505\n",
      "Epoch 19148: train_loss=262.85904, val_loss=271.54599\n",
      "Epoch 19149: train_loss=262.80923, val_loss=271.45023\n",
      "Epoch 19150: train_loss=262.75589, val_loss=271.43845\n",
      "Epoch 19151: train_loss=262.69812, val_loss=271.33044\n",
      "Epoch 19152: train_loss=262.63599, val_loss=271.30807\n",
      "Epoch 19153: train_loss=262.57001, val_loss=271.19775\n",
      "Epoch 19154: train_loss=262.50192, val_loss=271.16537\n",
      "Epoch 19155: train_loss=262.43265, val_loss=271.06262\n",
      "Epoch 19156: train_loss=262.36356, val_loss=271.02206\n",
      "Epoch 19157: train_loss=262.29489, val_loss=270.93262\n",
      "Epoch 19158: train_loss=262.22775, val_loss=270.88342\n",
      "Epoch 19159: train_loss=262.16235, val_loss=270.80856\n",
      "Epoch 19160: train_loss=262.09906, val_loss=270.75204\n",
      "Epoch 19161: train_loss=262.03754, val_loss=270.68860\n",
      "Epoch 19162: train_loss=261.97726, val_loss=270.62531\n",
      "Epoch 19163: train_loss=261.91806, val_loss=270.57278\n",
      "Epoch 19164: train_loss=261.85938, val_loss=270.50616\n",
      "Epoch 19165: train_loss=261.80130, val_loss=270.46259\n",
      "Epoch 19166: train_loss=261.74359, val_loss=270.39117\n",
      "Epoch 19167: train_loss=261.68634, val_loss=270.35251\n",
      "Epoch 19168: train_loss=261.62939, val_loss=270.27499\n",
      "Epoch 19169: train_loss=261.57278, val_loss=270.24091\n",
      "Epoch 19170: train_loss=261.51648, val_loss=270.15839\n",
      "Epoch 19171: train_loss=261.46021, val_loss=270.12961\n",
      "Epoch 19172: train_loss=261.40384, val_loss=270.04410\n",
      "Epoch 19173: train_loss=261.34793, val_loss=270.02109\n",
      "Epoch 19174: train_loss=261.29254, val_loss=269.93134\n",
      "Epoch 19175: train_loss=261.23724, val_loss=269.91412\n",
      "Epoch 19176: train_loss=261.18341, val_loss=269.82062\n",
      "Epoch 19177: train_loss=261.12936, val_loss=269.80994\n",
      "Epoch 19178: train_loss=261.07626, val_loss=269.71310\n",
      "Epoch 19179: train_loss=261.02362, val_loss=269.70932\n",
      "Epoch 19180: train_loss=260.97214, val_loss=269.60760\n",
      "Epoch 19181: train_loss=260.92050, val_loss=269.61047\n",
      "Epoch 19182: train_loss=260.87006, val_loss=269.50537\n",
      "Epoch 19183: train_loss=260.81964, val_loss=269.51599\n",
      "Epoch 19184: train_loss=260.77029, val_loss=269.40536\n",
      "Epoch 19185: train_loss=260.71945, val_loss=269.41812\n",
      "Epoch 19186: train_loss=260.66818, val_loss=269.29868\n",
      "Epoch 19187: train_loss=260.61407, val_loss=269.30847\n",
      "Epoch 19188: train_loss=260.55844, val_loss=269.18201\n",
      "Epoch 19189: train_loss=260.49908, val_loss=269.18619\n",
      "Epoch 19190: train_loss=260.43668, val_loss=269.05630\n",
      "Epoch 19191: train_loss=260.36993, val_loss=269.05005\n",
      "Epoch 19192: train_loss=260.30078, val_loss=268.91931\n",
      "Epoch 19193: train_loss=260.22836, val_loss=268.89944\n",
      "Epoch 19194: train_loss=260.15533, val_loss=268.77634\n",
      "Epoch 19195: train_loss=260.08209, val_loss=268.74619\n",
      "Epoch 19196: train_loss=260.00885, val_loss=268.63901\n",
      "Epoch 19197: train_loss=259.93762, val_loss=268.60098\n",
      "Epoch 19198: train_loss=259.86896, val_loss=268.51047\n",
      "Epoch 19199: train_loss=259.80249, val_loss=268.46344\n",
      "Epoch 19200: train_loss=259.73843, val_loss=268.38919\n",
      "Epoch 19201: train_loss=259.67657, val_loss=268.33469\n",
      "Epoch 19202: train_loss=259.61682, val_loss=268.27527\n",
      "Epoch 19203: train_loss=259.55829, val_loss=268.21478\n",
      "Epoch 19204: train_loss=259.50101, val_loss=268.16644\n",
      "Epoch 19205: train_loss=259.44446, val_loss=268.09894\n",
      "Epoch 19206: train_loss=259.38858, val_loss=268.05817\n",
      "Epoch 19207: train_loss=259.33304, val_loss=267.98471\n",
      "Epoch 19208: train_loss=259.27777, val_loss=267.95132\n",
      "Epoch 19209: train_loss=259.22302, val_loss=267.87387\n",
      "Epoch 19210: train_loss=259.16888, val_loss=267.84985\n",
      "Epoch 19211: train_loss=259.11664, val_loss=267.76709\n",
      "Epoch 19212: train_loss=259.06586, val_loss=267.75269\n",
      "Epoch 19213: train_loss=259.01675, val_loss=267.66302\n",
      "Epoch 19214: train_loss=258.96933, val_loss=267.66257\n",
      "Epoch 19215: train_loss=258.92401, val_loss=267.56763\n",
      "Epoch 19216: train_loss=258.87943, val_loss=267.58075\n",
      "Epoch 19217: train_loss=258.83588, val_loss=267.47852\n",
      "Epoch 19218: train_loss=258.79193, val_loss=267.49814\n",
      "Epoch 19219: train_loss=258.74875, val_loss=267.38651\n",
      "Epoch 19220: train_loss=258.70441, val_loss=267.40875\n",
      "Epoch 19221: train_loss=258.65878, val_loss=267.28671\n",
      "Epoch 19222: train_loss=258.60941, val_loss=267.30573\n",
      "Epoch 19223: train_loss=258.55579, val_loss=267.17270\n",
      "Epoch 19224: train_loss=258.49570, val_loss=267.17923\n",
      "Epoch 19225: train_loss=258.43045, val_loss=267.03879\n",
      "Epoch 19226: train_loss=258.35886, val_loss=267.02798\n",
      "Epoch 19227: train_loss=258.28394, val_loss=266.89008\n",
      "Epoch 19228: train_loss=258.20596, val_loss=266.86417\n",
      "Epoch 19229: train_loss=258.12817, val_loss=266.74066\n",
      "Epoch 19230: train_loss=258.05124, val_loss=266.70532\n",
      "Epoch 19231: train_loss=257.97794, val_loss=266.60440\n",
      "Epoch 19232: train_loss=257.90790, val_loss=266.56180\n",
      "Epoch 19233: train_loss=257.84097, val_loss=266.48157\n",
      "Epoch 19234: train_loss=257.77756, val_loss=266.43008\n",
      "Epoch 19235: train_loss=257.71680, val_loss=266.36621\n",
      "Epoch 19236: train_loss=257.65845, val_loss=266.30777\n",
      "Epoch 19237: train_loss=257.60175, val_loss=266.25897\n",
      "Epoch 19238: train_loss=257.54620, val_loss=266.19550\n",
      "Epoch 19239: train_loss=257.49167, val_loss=266.15625\n",
      "Epoch 19240: train_loss=257.43750, val_loss=266.08508\n",
      "Epoch 19241: train_loss=257.38464, val_loss=266.05255\n",
      "Epoch 19242: train_loss=257.33212, val_loss=265.97659\n",
      "Epoch 19243: train_loss=257.28079, val_loss=265.95627\n",
      "Epoch 19244: train_loss=257.23105, val_loss=265.87616\n",
      "Epoch 19245: train_loss=257.18298, val_loss=265.86804\n",
      "Epoch 19246: train_loss=257.13663, val_loss=265.78119\n",
      "Epoch 19247: train_loss=257.09216, val_loss=265.78394\n",
      "Epoch 19248: train_loss=257.04929, val_loss=265.69113\n",
      "Epoch 19249: train_loss=257.00858, val_loss=265.70889\n",
      "Epoch 19250: train_loss=256.96933, val_loss=265.60944\n",
      "Epoch 19251: train_loss=256.93073, val_loss=265.63474\n",
      "Epoch 19252: train_loss=256.89023, val_loss=265.52237\n",
      "Epoch 19253: train_loss=256.84756, val_loss=265.54730\n",
      "Epoch 19254: train_loss=256.80133, val_loss=265.42242\n",
      "Epoch 19255: train_loss=256.75031, val_loss=265.43951\n",
      "Epoch 19256: train_loss=256.69238, val_loss=265.30307\n",
      "Epoch 19257: train_loss=256.62823, val_loss=265.30261\n",
      "Epoch 19258: train_loss=256.55719, val_loss=265.15845\n",
      "Epoch 19259: train_loss=256.47998, val_loss=265.13733\n",
      "Epoch 19260: train_loss=256.39987, val_loss=265.00284\n",
      "Epoch 19261: train_loss=256.31918, val_loss=264.96942\n",
      "Epoch 19262: train_loss=256.24161, val_loss=264.85812\n",
      "Epoch 19263: train_loss=256.16760, val_loss=264.81729\n",
      "Epoch 19264: train_loss=256.09802, val_loss=264.72958\n",
      "Epoch 19265: train_loss=256.03250, val_loss=264.68097\n",
      "Epoch 19266: train_loss=255.97078, val_loss=264.61429\n",
      "Epoch 19267: train_loss=255.91229, val_loss=264.55933\n",
      "Epoch 19268: train_loss=255.85620, val_loss=264.50867\n",
      "Epoch 19269: train_loss=255.80177, val_loss=264.44711\n",
      "Epoch 19270: train_loss=255.74889, val_loss=264.40848\n",
      "Epoch 19271: train_loss=255.69690, val_loss=264.33890\n",
      "Epoch 19272: train_loss=255.64589, val_loss=264.31021\n",
      "Epoch 19273: train_loss=255.59624, val_loss=264.23483\n",
      "Epoch 19274: train_loss=255.54793, val_loss=264.21790\n",
      "Epoch 19275: train_loss=255.50064, val_loss=264.13690\n",
      "Epoch 19276: train_loss=255.45444, val_loss=264.13068\n",
      "Epoch 19277: train_loss=255.40935, val_loss=264.04309\n",
      "Epoch 19278: train_loss=255.36531, val_loss=264.04642\n",
      "Epoch 19279: train_loss=255.32253, val_loss=263.95251\n",
      "Epoch 19280: train_loss=255.28023, val_loss=263.96594\n",
      "Epoch 19281: train_loss=255.23824, val_loss=263.86624\n",
      "Epoch 19282: train_loss=255.19559, val_loss=263.88583\n",
      "Epoch 19283: train_loss=255.15140, val_loss=263.77673\n",
      "Epoch 19284: train_loss=255.10539, val_loss=263.79272\n",
      "Epoch 19285: train_loss=255.05524, val_loss=263.67175\n",
      "Epoch 19286: train_loss=255.00177, val_loss=263.67734\n",
      "Epoch 19287: train_loss=254.94267, val_loss=263.54858\n",
      "Epoch 19288: train_loss=254.87950, val_loss=263.54153\n",
      "Epoch 19289: train_loss=254.81174, val_loss=263.41223\n",
      "Epoch 19290: train_loss=254.74034, val_loss=263.39233\n",
      "Epoch 19291: train_loss=254.66788, val_loss=263.27255\n",
      "Epoch 19292: train_loss=254.59438, val_loss=263.24219\n",
      "Epoch 19293: train_loss=254.52309, val_loss=263.14008\n",
      "Epoch 19294: train_loss=254.45406, val_loss=263.10114\n",
      "Epoch 19295: train_loss=254.38844, val_loss=263.01788\n",
      "Epoch 19296: train_loss=254.32581, val_loss=262.97098\n",
      "Epoch 19297: train_loss=254.26680, val_loss=262.90619\n",
      "Epoch 19298: train_loss=254.21013, val_loss=262.85535\n",
      "Epoch 19299: train_loss=254.15491, val_loss=262.80530\n",
      "Epoch 19300: train_loss=254.10104, val_loss=262.74835\n",
      "Epoch 19301: train_loss=254.04817, val_loss=262.70590\n",
      "Epoch 19302: train_loss=253.99619, val_loss=262.63983\n",
      "Epoch 19303: train_loss=253.94466, val_loss=262.60339\n",
      "Epoch 19304: train_loss=253.89432, val_loss=262.53192\n",
      "Epoch 19305: train_loss=253.84477, val_loss=262.50763\n",
      "Epoch 19306: train_loss=253.79652, val_loss=262.43356\n",
      "Epoch 19307: train_loss=253.74861, val_loss=262.42029\n",
      "Epoch 19308: train_loss=253.70192, val_loss=262.33994\n",
      "Epoch 19309: train_loss=253.65526, val_loss=262.33292\n",
      "Epoch 19310: train_loss=253.60968, val_loss=262.24429\n",
      "Epoch 19311: train_loss=253.56433, val_loss=262.24326\n",
      "Epoch 19312: train_loss=253.52014, val_loss=262.14929\n",
      "Epoch 19313: train_loss=253.47610, val_loss=262.15747\n",
      "Epoch 19314: train_loss=253.43369, val_loss=262.06100\n",
      "Epoch 19315: train_loss=253.39157, val_loss=262.07751\n",
      "Epoch 19316: train_loss=253.34933, val_loss=261.97455\n",
      "Epoch 19317: train_loss=253.30721, val_loss=261.99365\n",
      "Epoch 19318: train_loss=253.26340, val_loss=261.88220\n",
      "Epoch 19319: train_loss=253.21927, val_loss=261.89923\n",
      "Epoch 19320: train_loss=253.17033, val_loss=261.77927\n",
      "Epoch 19321: train_loss=253.11966, val_loss=261.79050\n",
      "Epoch 19322: train_loss=253.06261, val_loss=261.66495\n",
      "Epoch 19323: train_loss=253.00276, val_loss=261.66574\n",
      "Epoch 19324: train_loss=252.93726, val_loss=261.53738\n",
      "Epoch 19325: train_loss=252.86934, val_loss=261.52396\n",
      "Epoch 19326: train_loss=252.79848, val_loss=261.39777\n",
      "Epoch 19327: train_loss=252.72531, val_loss=261.36932\n",
      "Epoch 19328: train_loss=252.65219, val_loss=261.25720\n",
      "Epoch 19329: train_loss=252.57988, val_loss=261.21887\n",
      "Epoch 19330: train_loss=252.51204, val_loss=261.13263\n",
      "Epoch 19331: train_loss=252.44757, val_loss=261.08774\n",
      "Epoch 19332: train_loss=252.38731, val_loss=261.02609\n",
      "Epoch 19333: train_loss=252.33130, val_loss=260.97156\n",
      "Epoch 19334: train_loss=252.27901, val_loss=260.92749\n",
      "Epoch 19335: train_loss=252.22926, val_loss=260.86356\n",
      "Epoch 19336: train_loss=252.18095, val_loss=260.83228\n",
      "Epoch 19337: train_loss=252.13324, val_loss=260.76227\n",
      "Epoch 19338: train_loss=252.08493, val_loss=260.73901\n",
      "Epoch 19339: train_loss=252.03668, val_loss=260.66254\n",
      "Epoch 19340: train_loss=251.98686, val_loss=260.64066\n",
      "Epoch 19341: train_loss=251.93753, val_loss=260.55933\n",
      "Epoch 19342: train_loss=251.88634, val_loss=260.53821\n",
      "Epoch 19343: train_loss=251.83554, val_loss=260.45477\n",
      "Epoch 19344: train_loss=251.78322, val_loss=260.43201\n",
      "Epoch 19345: train_loss=251.73039, val_loss=260.34622\n",
      "Epoch 19346: train_loss=251.67601, val_loss=260.31912\n",
      "Epoch 19347: train_loss=251.62160, val_loss=260.23434\n",
      "Epoch 19348: train_loss=251.56625, val_loss=260.20374\n",
      "Epoch 19349: train_loss=251.51070, val_loss=260.12259\n",
      "Epoch 19350: train_loss=251.45474, val_loss=260.08749\n",
      "Epoch 19351: train_loss=251.39870, val_loss=260.01031\n",
      "Epoch 19352: train_loss=251.34259, val_loss=259.96973\n",
      "Epoch 19353: train_loss=251.28703, val_loss=259.89948\n",
      "Epoch 19354: train_loss=251.23151, val_loss=259.85574\n",
      "Epoch 19355: train_loss=251.17680, val_loss=259.79260\n",
      "Epoch 19356: train_loss=251.12265, val_loss=259.74405\n",
      "Epoch 19357: train_loss=251.06914, val_loss=259.68600\n",
      "Epoch 19358: train_loss=251.01588, val_loss=259.63370\n",
      "Epoch 19359: train_loss=250.96300, val_loss=259.58099\n",
      "Epoch 19360: train_loss=250.91054, val_loss=259.52652\n",
      "Epoch 19361: train_loss=250.85820, val_loss=259.47769\n",
      "Epoch 19362: train_loss=250.80608, val_loss=259.41995\n",
      "Epoch 19363: train_loss=250.75397, val_loss=259.37402\n",
      "Epoch 19364: train_loss=250.70218, val_loss=259.31348\n",
      "Epoch 19365: train_loss=250.65065, val_loss=259.27170\n",
      "Epoch 19366: train_loss=250.59973, val_loss=259.20847\n",
      "Epoch 19367: train_loss=250.54936, val_loss=259.17325\n",
      "Epoch 19368: train_loss=250.50011, val_loss=259.10626\n",
      "Epoch 19369: train_loss=250.45192, val_loss=259.08197\n",
      "Epoch 19370: train_loss=250.40662, val_loss=259.01172\n",
      "Epoch 19371: train_loss=250.36359, val_loss=259.00476\n",
      "Epoch 19372: train_loss=250.32542, val_loss=258.93298\n",
      "Epoch 19373: train_loss=250.29185, val_loss=258.95190\n",
      "Epoch 19374: train_loss=250.26465, val_loss=258.87808\n",
      "Epoch 19375: train_loss=250.24471, val_loss=258.92670\n",
      "Epoch 19376: train_loss=250.23180, val_loss=258.85107\n",
      "Epoch 19377: train_loss=250.22778, val_loss=258.92731\n",
      "Epoch 19378: train_loss=250.22440, val_loss=258.83746\n",
      "Epoch 19379: train_loss=250.22166, val_loss=258.91531\n",
      "Epoch 19380: train_loss=250.20338, val_loss=258.78595\n",
      "Epoch 19381: train_loss=250.17064, val_loss=258.82034\n",
      "Epoch 19382: train_loss=250.10660, val_loss=258.63443\n",
      "Epoch 19383: train_loss=250.01741, val_loss=258.60184\n",
      "Epoch 19384: train_loss=249.90054, val_loss=258.39828\n",
      "Epoch 19385: train_loss=249.77452, val_loss=258.33429\n",
      "Epoch 19386: train_loss=249.65105, val_loss=258.18210\n",
      "Epoch 19387: train_loss=249.54330, val_loss=258.12271\n",
      "Epoch 19388: train_loss=249.45813, val_loss=258.04907\n",
      "Epoch 19389: train_loss=249.39491, val_loss=257.99640\n",
      "Epoch 19390: train_loss=249.35066, val_loss=257.98328\n",
      "Epoch 19391: train_loss=249.31839, val_loss=257.92154\n",
      "Epoch 19392: train_loss=249.29044, val_loss=257.93265\n",
      "Epoch 19393: train_loss=249.26050, val_loss=257.84897\n",
      "Epoch 19394: train_loss=249.22348, val_loss=257.85522\n",
      "Epoch 19395: train_loss=249.17899, val_loss=257.74945\n",
      "Epoch 19396: train_loss=249.12399, val_loss=257.73599\n",
      "Epoch 19397: train_loss=249.06226, val_loss=257.62241\n",
      "Epoch 19398: train_loss=248.99330, val_loss=257.59067\n",
      "Epoch 19399: train_loss=248.92276, val_loss=257.49005\n",
      "Epoch 19400: train_loss=248.85313, val_loss=257.44516\n",
      "Epoch 19401: train_loss=248.78757, val_loss=257.37131\n",
      "Epoch 19402: train_loss=248.72827, val_loss=257.31866\n",
      "Epoch 19403: train_loss=248.67574, val_loss=257.27625\n",
      "Epoch 19404: train_loss=248.62863, val_loss=257.21799\n",
      "Epoch 19405: train_loss=248.58476, val_loss=257.19473\n",
      "Epoch 19406: train_loss=248.54185, val_loss=257.12488\n",
      "Epoch 19407: train_loss=248.49779, val_loss=257.10571\n",
      "Epoch 19408: train_loss=248.45369, val_loss=257.02682\n",
      "Epoch 19409: train_loss=248.40742, val_loss=257.00986\n",
      "Epoch 19410: train_loss=248.35966, val_loss=256.92841\n",
      "Epoch 19411: train_loss=248.30949, val_loss=256.90952\n",
      "Epoch 19412: train_loss=248.25844, val_loss=256.82529\n",
      "Epoch 19413: train_loss=248.20529, val_loss=256.79953\n",
      "Epoch 19414: train_loss=248.15193, val_loss=256.71658\n",
      "Epoch 19415: train_loss=248.09703, val_loss=256.68460\n",
      "Epoch 19416: train_loss=248.04155, val_loss=256.60831\n",
      "Epoch 19417: train_loss=247.98610, val_loss=256.56808\n",
      "Epoch 19418: train_loss=247.93152, val_loss=256.50113\n",
      "Epoch 19419: train_loss=247.87807, val_loss=256.45453\n",
      "Epoch 19420: train_loss=247.82635, val_loss=256.40091\n",
      "Epoch 19421: train_loss=247.77594, val_loss=256.35013\n",
      "Epoch 19422: train_loss=247.72719, val_loss=256.30670\n",
      "Epoch 19423: train_loss=247.67911, val_loss=256.25015\n",
      "Epoch 19424: train_loss=247.63158, val_loss=256.21246\n",
      "Epoch 19425: train_loss=247.58443, val_loss=256.15048\n",
      "Epoch 19426: train_loss=247.53700, val_loss=256.11661\n",
      "Epoch 19427: train_loss=247.48952, val_loss=256.05142\n",
      "Epoch 19428: train_loss=247.44130, val_loss=256.01816\n",
      "Epoch 19429: train_loss=247.39328, val_loss=255.95134\n",
      "Epoch 19430: train_loss=247.34476, val_loss=255.91942\n",
      "Epoch 19431: train_loss=247.29636, val_loss=255.85298\n",
      "Epoch 19432: train_loss=247.24785, val_loss=255.82237\n",
      "Epoch 19433: train_loss=247.19951, val_loss=255.75427\n",
      "Epoch 19434: train_loss=247.15141, val_loss=255.72333\n",
      "Epoch 19435: train_loss=247.10355, val_loss=255.65472\n",
      "Epoch 19436: train_loss=247.05609, val_loss=255.62753\n",
      "Epoch 19437: train_loss=247.00894, val_loss=255.55960\n",
      "Epoch 19438: train_loss=246.96219, val_loss=255.53702\n",
      "Epoch 19439: train_loss=246.91649, val_loss=255.46655\n",
      "Epoch 19440: train_loss=246.87132, val_loss=255.44868\n",
      "Epoch 19441: train_loss=246.82822, val_loss=255.37553\n",
      "Epoch 19442: train_loss=246.78595, val_loss=255.36717\n",
      "Epoch 19443: train_loss=246.74582, val_loss=255.29306\n",
      "Epoch 19444: train_loss=246.70758, val_loss=255.29761\n",
      "Epoch 19445: train_loss=246.67166, val_loss=255.21870\n",
      "Epoch 19446: train_loss=246.63760, val_loss=255.23404\n",
      "Epoch 19447: train_loss=246.60576, val_loss=255.14902\n",
      "Epoch 19448: train_loss=246.57509, val_loss=255.17633\n",
      "Epoch 19449: train_loss=246.54550, val_loss=255.08467\n",
      "Epoch 19450: train_loss=246.51503, val_loss=255.11653\n",
      "Epoch 19451: train_loss=246.48180, val_loss=255.01082\n",
      "Epoch 19452: train_loss=246.44427, val_loss=255.03452\n",
      "Epoch 19453: train_loss=246.40059, val_loss=254.91270\n",
      "Epoch 19454: train_loss=246.34930, val_loss=254.92122\n",
      "Epoch 19455: train_loss=246.29114, val_loss=254.79071\n",
      "Epoch 19456: train_loss=246.22453, val_loss=254.78046\n",
      "Epoch 19457: train_loss=246.15376, val_loss=254.65108\n",
      "Epoch 19458: train_loss=246.07918, val_loss=254.62222\n",
      "Epoch 19459: train_loss=246.00465, val_loss=254.50955\n",
      "Epoch 19460: train_loss=245.93306, val_loss=254.47049\n",
      "Epoch 19461: train_loss=245.86588, val_loss=254.38670\n",
      "Epoch 19462: train_loss=245.80502, val_loss=254.34271\n",
      "Epoch 19463: train_loss=245.75009, val_loss=254.28816\n",
      "Epoch 19464: train_loss=245.70055, val_loss=254.23808\n",
      "Epoch 19465: train_loss=245.65501, val_loss=254.20377\n",
      "Epoch 19466: train_loss=245.61215, val_loss=254.14699\n",
      "Epoch 19467: train_loss=245.57100, val_loss=254.12698\n",
      "Epoch 19468: train_loss=245.53044, val_loss=254.06213\n",
      "Epoch 19469: train_loss=245.49036, val_loss=254.04883\n",
      "Epoch 19470: train_loss=245.44972, val_loss=253.97572\n",
      "Epoch 19471: train_loss=245.40816, val_loss=253.96516\n",
      "Epoch 19472: train_loss=245.36613, val_loss=253.88670\n",
      "Epoch 19473: train_loss=245.32285, val_loss=253.87814\n",
      "Epoch 19474: train_loss=245.27991, val_loss=253.79602\n",
      "Epoch 19475: train_loss=245.23557, val_loss=253.78737\n",
      "Epoch 19476: train_loss=245.19096, val_loss=253.70294\n",
      "Epoch 19477: train_loss=245.14503, val_loss=253.69423\n",
      "Epoch 19478: train_loss=245.09875, val_loss=253.60977\n",
      "Epoch 19479: train_loss=245.05132, val_loss=253.59929\n",
      "Epoch 19480: train_loss=245.00369, val_loss=253.51309\n",
      "Epoch 19481: train_loss=244.95515, val_loss=253.49947\n",
      "Epoch 19482: train_loss=244.90671, val_loss=253.41385\n",
      "Epoch 19483: train_loss=244.85753, val_loss=253.39851\n",
      "Epoch 19484: train_loss=244.80820, val_loss=253.31674\n",
      "Epoch 19485: train_loss=244.75890, val_loss=253.29961\n",
      "Epoch 19486: train_loss=244.70981, val_loss=253.21840\n",
      "Epoch 19487: train_loss=244.66037, val_loss=253.19659\n",
      "Epoch 19488: train_loss=244.61116, val_loss=253.11745\n",
      "Epoch 19489: train_loss=244.56181, val_loss=253.09367\n",
      "Epoch 19490: train_loss=244.51250, val_loss=253.02017\n",
      "Epoch 19491: train_loss=244.46391, val_loss=252.99506\n",
      "Epoch 19492: train_loss=244.41534, val_loss=252.92406\n",
      "Epoch 19493: train_loss=244.36761, val_loss=252.89571\n",
      "Epoch 19494: train_loss=244.32007, val_loss=252.82628\n",
      "Epoch 19495: train_loss=244.27312, val_loss=252.79918\n",
      "Epoch 19496: train_loss=244.22647, val_loss=252.73337\n",
      "Epoch 19497: train_loss=244.18019, val_loss=252.70763\n",
      "Epoch 19498: train_loss=244.13414, val_loss=252.64153\n",
      "Epoch 19499: train_loss=244.08867, val_loss=252.61546\n",
      "Epoch 19500: train_loss=244.04361, val_loss=252.54890\n",
      "Epoch 19501: train_loss=243.99939, val_loss=252.52650\n",
      "Epoch 19502: train_loss=243.95586, val_loss=252.46101\n",
      "Epoch 19503: train_loss=243.91373, val_loss=252.44661\n",
      "Epoch 19504: train_loss=243.87274, val_loss=252.37898\n",
      "Epoch 19505: train_loss=243.83391, val_loss=252.37189\n",
      "Epoch 19506: train_loss=243.79706, val_loss=252.30278\n",
      "Epoch 19507: train_loss=243.76401, val_loss=252.31189\n",
      "Epoch 19508: train_loss=243.73427, val_loss=252.24251\n",
      "Epoch 19509: train_loss=243.70982, val_loss=252.27089\n",
      "Epoch 19510: train_loss=243.68755, val_loss=252.19612\n",
      "Epoch 19511: train_loss=243.66942, val_loss=252.23961\n",
      "Epoch 19512: train_loss=243.65213, val_loss=252.15773\n",
      "Epoch 19513: train_loss=243.63771, val_loss=252.20996\n",
      "Epoch 19514: train_loss=243.61768, val_loss=252.10960\n",
      "Epoch 19515: train_loss=243.59285, val_loss=252.14885\n",
      "Epoch 19516: train_loss=243.55396, val_loss=252.01920\n",
      "Epoch 19517: train_loss=243.50389, val_loss=252.02739\n",
      "Epoch 19518: train_loss=243.43657, val_loss=251.87494\n",
      "Epoch 19519: train_loss=243.35646, val_loss=251.85094\n",
      "Epoch 19520: train_loss=243.26674, val_loss=251.70540\n",
      "Epoch 19521: train_loss=243.17587, val_loss=251.66454\n",
      "Epoch 19522: train_loss=243.09116, val_loss=251.55412\n",
      "Epoch 19523: train_loss=243.01558, val_loss=251.51019\n",
      "Epoch 19524: train_loss=242.95132, val_loss=251.44637\n",
      "Epoch 19525: train_loss=242.89806, val_loss=251.40134\n",
      "Epoch 19526: train_loss=242.85399, val_loss=251.37471\n",
      "Epoch 19527: train_loss=242.81685, val_loss=251.32259\n",
      "Epoch 19528: train_loss=242.78413, val_loss=251.31750\n",
      "Epoch 19529: train_loss=242.75343, val_loss=251.25455\n",
      "Epoch 19530: train_loss=242.72197, val_loss=251.25951\n",
      "Epoch 19531: train_loss=242.68930, val_loss=251.18611\n",
      "Epoch 19532: train_loss=242.65369, val_loss=251.18875\n",
      "Epoch 19533: train_loss=242.61397, val_loss=251.10280\n",
      "Epoch 19534: train_loss=242.57045, val_loss=251.09645\n",
      "Epoch 19535: train_loss=242.52293, val_loss=251.00333\n",
      "Epoch 19536: train_loss=242.47166, val_loss=250.98726\n",
      "Epoch 19537: train_loss=242.41905, val_loss=250.89662\n",
      "Epoch 19538: train_loss=242.36453, val_loss=250.87169\n",
      "Epoch 19539: train_loss=242.31035, val_loss=250.78929\n",
      "Epoch 19540: train_loss=242.25629, val_loss=250.75600\n",
      "Epoch 19541: train_loss=242.20406, val_loss=250.68648\n",
      "Epoch 19542: train_loss=242.15346, val_loss=250.64874\n",
      "Epoch 19543: train_loss=242.10493, val_loss=250.59300\n",
      "Epoch 19544: train_loss=242.05840, val_loss=250.55058\n",
      "Epoch 19545: train_loss=242.01315, val_loss=250.50488\n",
      "Epoch 19546: train_loss=241.96930, val_loss=250.45682\n",
      "Epoch 19547: train_loss=241.92632, val_loss=250.41925\n",
      "Epoch 19548: train_loss=241.88414, val_loss=250.36925\n",
      "Epoch 19549: train_loss=241.84233, val_loss=250.34055\n",
      "Epoch 19550: train_loss=241.80125, val_loss=250.28694\n",
      "Epoch 19551: train_loss=241.76054, val_loss=250.26384\n",
      "Epoch 19552: train_loss=241.72066, val_loss=250.20467\n",
      "Epoch 19553: train_loss=241.68114, val_loss=250.18703\n",
      "Epoch 19554: train_loss=241.64258, val_loss=250.12416\n",
      "Epoch 19555: train_loss=241.60384, val_loss=250.11388\n",
      "Epoch 19556: train_loss=241.56598, val_loss=250.04768\n",
      "Epoch 19557: train_loss=241.52789, val_loss=250.04196\n",
      "Epoch 19558: train_loss=241.49051, val_loss=249.97006\n",
      "Epoch 19559: train_loss=241.45262, val_loss=249.96780\n",
      "Epoch 19560: train_loss=241.41524, val_loss=249.89165\n",
      "Epoch 19561: train_loss=241.37712, val_loss=249.89096\n",
      "Epoch 19562: train_loss=241.33876, val_loss=249.81104\n",
      "Epoch 19563: train_loss=241.29976, val_loss=249.81322\n",
      "Epoch 19564: train_loss=241.26025, val_loss=249.73071\n",
      "Epoch 19565: train_loss=241.21965, val_loss=249.73438\n",
      "Epoch 19566: train_loss=241.17853, val_loss=249.64847\n",
      "Epoch 19567: train_loss=241.13640, val_loss=249.64851\n",
      "Epoch 19568: train_loss=241.09326, val_loss=249.55815\n",
      "Epoch 19569: train_loss=241.04860, val_loss=249.55640\n",
      "Epoch 19570: train_loss=241.00343, val_loss=249.46710\n",
      "Epoch 19571: train_loss=240.95610, val_loss=249.46211\n",
      "Epoch 19572: train_loss=240.90781, val_loss=249.37329\n",
      "Epoch 19573: train_loss=240.85725, val_loss=249.35904\n",
      "Epoch 19574: train_loss=240.80676, val_loss=249.27289\n",
      "Epoch 19575: train_loss=240.75534, val_loss=249.25330\n",
      "Epoch 19576: train_loss=240.70526, val_loss=249.17548\n",
      "Epoch 19577: train_loss=240.65453, val_loss=249.14967\n",
      "Epoch 19578: train_loss=240.60527, val_loss=249.07933\n",
      "Epoch 19579: train_loss=240.55635, val_loss=249.04843\n",
      "Epoch 19580: train_loss=240.50911, val_loss=248.98708\n",
      "Epoch 19581: train_loss=240.46266, val_loss=248.95326\n",
      "Epoch 19582: train_loss=240.41739, val_loss=248.90041\n",
      "Epoch 19583: train_loss=240.37283, val_loss=248.86255\n",
      "Epoch 19584: train_loss=240.32890, val_loss=248.81432\n",
      "Epoch 19585: train_loss=240.28560, val_loss=248.77153\n",
      "Epoch 19586: train_loss=240.24283, val_loss=248.72800\n",
      "Epoch 19587: train_loss=240.20023, val_loss=248.68332\n",
      "Epoch 19588: train_loss=240.15796, val_loss=248.64488\n",
      "Epoch 19589: train_loss=240.11595, val_loss=248.59828\n",
      "Epoch 19590: train_loss=240.07404, val_loss=248.56224\n",
      "Epoch 19591: train_loss=240.03229, val_loss=248.51361\n",
      "Epoch 19592: train_loss=239.99092, val_loss=248.48102\n",
      "Epoch 19593: train_loss=239.94994, val_loss=248.42953\n",
      "Epoch 19594: train_loss=239.90952, val_loss=248.40294\n",
      "Epoch 19595: train_loss=239.87016, val_loss=248.34920\n",
      "Epoch 19596: train_loss=239.83176, val_loss=248.33260\n",
      "Epoch 19597: train_loss=239.79546, val_loss=248.27614\n",
      "Epoch 19598: train_loss=239.76122, val_loss=248.27286\n",
      "Epoch 19599: train_loss=239.73087, val_loss=248.21263\n",
      "Epoch 19600: train_loss=239.70395, val_loss=248.23035\n",
      "Epoch 19601: train_loss=239.68291, val_loss=248.16969\n",
      "Epoch 19602: train_loss=239.66740, val_loss=248.21596\n",
      "Epoch 19603: train_loss=239.65903, val_loss=248.15288\n",
      "Epoch 19604: train_loss=239.65660, val_loss=248.22395\n",
      "Epoch 19605: train_loss=239.65787, val_loss=248.15251\n",
      "Epoch 19606: train_loss=239.66333, val_loss=248.23836\n",
      "Epoch 19607: train_loss=239.66414, val_loss=248.14259\n",
      "Epoch 19608: train_loss=239.65755, val_loss=248.20854\n",
      "Epoch 19609: train_loss=239.62863, val_loss=248.06329\n",
      "Epoch 19610: train_loss=239.57681, val_loss=248.07047\n",
      "Epoch 19611: train_loss=239.49480, val_loss=247.88345\n",
      "Epoch 19612: train_loss=239.39186, val_loss=247.83710\n",
      "Epoch 19613: train_loss=239.27588, val_loss=247.66795\n",
      "Epoch 19614: train_loss=239.16402, val_loss=247.61208\n",
      "Epoch 19615: train_loss=239.06947, val_loss=247.51439\n",
      "Epoch 19616: train_loss=238.99640, val_loss=247.46996\n",
      "Epoch 19617: train_loss=238.94582, val_loss=247.44357\n",
      "Epoch 19618: train_loss=238.91324, val_loss=247.40231\n",
      "Epoch 19619: train_loss=238.89249, val_loss=247.41792\n",
      "Epoch 19620: train_loss=238.87701, val_loss=247.36029\n",
      "Epoch 19621: train_loss=238.85909, val_loss=247.38176\n",
      "Epoch 19622: train_loss=238.83482, val_loss=247.29845\n",
      "Epoch 19623: train_loss=238.80035, val_loss=247.30368\n",
      "Epoch 19624: train_loss=238.75607, val_loss=247.20392\n",
      "Epoch 19625: train_loss=238.70239, val_loss=247.18913\n",
      "Epoch 19626: train_loss=238.64381, val_loss=247.09247\n",
      "Epoch 19627: train_loss=238.58276, val_loss=247.06212\n",
      "Epoch 19628: train_loss=238.52364, val_loss=246.98482\n",
      "Epoch 19629: train_loss=238.46875, val_loss=246.94772\n",
      "Epoch 19630: train_loss=238.41910, val_loss=246.89716\n",
      "Epoch 19631: train_loss=238.37482, val_loss=246.85553\n",
      "Epoch 19632: train_loss=238.33514, val_loss=246.82603\n",
      "Epoch 19633: train_loss=238.29840, val_loss=246.77644\n",
      "Epoch 19634: train_loss=238.26398, val_loss=246.75945\n",
      "Epoch 19635: train_loss=238.23016, val_loss=246.70094\n",
      "Epoch 19636: train_loss=238.19572, val_loss=246.69130\n",
      "Epoch 19637: train_loss=238.16045, val_loss=246.62753\n",
      "Epoch 19638: train_loss=238.12329, val_loss=246.61844\n",
      "Epoch 19639: train_loss=238.08432, val_loss=246.55008\n",
      "Epoch 19640: train_loss=238.04384, val_loss=246.53722\n",
      "Epoch 19641: train_loss=238.00233, val_loss=246.46588\n",
      "Epoch 19642: train_loss=237.95935, val_loss=246.44777\n",
      "Epoch 19643: train_loss=237.91592, val_loss=246.37819\n",
      "Epoch 19644: train_loss=237.87178, val_loss=246.35567\n",
      "Epoch 19645: train_loss=237.82785, val_loss=246.29102\n",
      "Epoch 19646: train_loss=237.78380, val_loss=246.26451\n",
      "Epoch 19647: train_loss=237.73985, val_loss=246.20660\n",
      "Epoch 19648: train_loss=237.69675, val_loss=246.17471\n",
      "Epoch 19649: train_loss=237.65395, val_loss=246.12294\n",
      "Epoch 19650: train_loss=237.61197, val_loss=246.08708\n",
      "Epoch 19651: train_loss=237.57069, val_loss=246.04309\n",
      "Epoch 19652: train_loss=237.53001, val_loss=246.00537\n",
      "Epoch 19653: train_loss=237.48979, val_loss=245.96854\n",
      "Epoch 19654: train_loss=237.45013, val_loss=245.92714\n",
      "Epoch 19655: train_loss=237.41075, val_loss=245.89238\n",
      "Epoch 19656: train_loss=237.37144, val_loss=245.84636\n",
      "Epoch 19657: train_loss=237.33252, val_loss=245.81517\n",
      "Epoch 19658: train_loss=237.29395, val_loss=245.76767\n",
      "Epoch 19659: train_loss=237.25571, val_loss=245.74298\n",
      "Epoch 19660: train_loss=237.21808, val_loss=245.69333\n",
      "Epoch 19661: train_loss=237.18120, val_loss=245.67490\n",
      "Epoch 19662: train_loss=237.14555, val_loss=245.62059\n",
      "Epoch 19663: train_loss=237.11084, val_loss=245.61028\n",
      "Epoch 19664: train_loss=237.07809, val_loss=245.55173\n",
      "Epoch 19665: train_loss=237.04663, val_loss=245.55400\n",
      "Epoch 19666: train_loss=237.01782, val_loss=245.49223\n",
      "Epoch 19667: train_loss=236.99059, val_loss=245.50731\n",
      "Epoch 19668: train_loss=236.96587, val_loss=245.43971\n",
      "Epoch 19669: train_loss=236.94270, val_loss=245.46826\n",
      "Epoch 19670: train_loss=236.92188, val_loss=245.39432\n",
      "Epoch 19671: train_loss=236.90152, val_loss=245.43341\n",
      "Epoch 19672: train_loss=236.88130, val_loss=245.34941\n",
      "Epoch 19673: train_loss=236.85893, val_loss=245.38815\n",
      "Epoch 19674: train_loss=236.83253, val_loss=245.28860\n",
      "Epoch 19675: train_loss=236.80077, val_loss=245.31662\n",
      "Epoch 19676: train_loss=236.76118, val_loss=245.20309\n",
      "Epoch 19677: train_loss=236.71361, val_loss=245.21301\n",
      "Epoch 19678: train_loss=236.65807, val_loss=245.09149\n",
      "Epoch 19679: train_loss=236.59566, val_loss=245.07980\n",
      "Epoch 19680: train_loss=236.52986, val_loss=244.96571\n",
      "Epoch 19681: train_loss=236.46339, val_loss=244.94041\n",
      "Epoch 19682: train_loss=236.39908, val_loss=244.84894\n",
      "Epoch 19683: train_loss=236.33943, val_loss=244.81769\n",
      "Epoch 19684: train_loss=236.28554, val_loss=244.75346\n",
      "Epoch 19685: train_loss=236.23740, val_loss=244.71706\n",
      "Epoch 19686: train_loss=236.19417, val_loss=244.67696\n",
      "Epoch 19687: train_loss=236.15533, val_loss=244.63580\n",
      "Epoch 19688: train_loss=236.11978, val_loss=244.61552\n",
      "Epoch 19689: train_loss=236.08626, val_loss=244.56886\n",
      "Epoch 19690: train_loss=236.05432, val_loss=244.55997\n",
      "Epoch 19691: train_loss=236.02351, val_loss=244.50412\n",
      "Epoch 19692: train_loss=235.99292, val_loss=244.50194\n",
      "Epoch 19693: train_loss=235.96217, val_loss=244.44002\n",
      "Epoch 19694: train_loss=235.93098, val_loss=244.44270\n",
      "Epoch 19695: train_loss=235.89877, val_loss=244.37419\n",
      "Epoch 19696: train_loss=235.86542, val_loss=244.37624\n",
      "Epoch 19697: train_loss=235.83054, val_loss=244.30132\n",
      "Epoch 19698: train_loss=235.79469, val_loss=244.30096\n",
      "Epoch 19699: train_loss=235.75731, val_loss=244.22342\n",
      "Epoch 19700: train_loss=235.71875, val_loss=244.22102\n",
      "Epoch 19701: train_loss=235.67882, val_loss=244.14310\n",
      "Epoch 19702: train_loss=235.63814, val_loss=244.13733\n",
      "Epoch 19703: train_loss=235.59644, val_loss=244.06024\n",
      "Epoch 19704: train_loss=235.55441, val_loss=244.05069\n",
      "Epoch 19705: train_loss=235.51169, val_loss=243.97597\n",
      "Epoch 19706: train_loss=235.46851, val_loss=243.96321\n",
      "Epoch 19707: train_loss=235.42557, val_loss=243.89384\n",
      "Epoch 19708: train_loss=235.38283, val_loss=243.87747\n",
      "Epoch 19709: train_loss=235.34050, val_loss=243.81262\n",
      "Epoch 19710: train_loss=235.29851, val_loss=243.79251\n",
      "Epoch 19711: train_loss=235.25703, val_loss=243.73221\n",
      "Epoch 19712: train_loss=235.21611, val_loss=243.70949\n",
      "Epoch 19713: train_loss=235.17607, val_loss=243.65396\n",
      "Epoch 19714: train_loss=235.13649, val_loss=243.62891\n",
      "Epoch 19715: train_loss=235.09723, val_loss=243.57658\n",
      "Epoch 19716: train_loss=235.05835, val_loss=243.54976\n",
      "Epoch 19717: train_loss=235.01965, val_loss=243.50078\n",
      "Epoch 19718: train_loss=234.98134, val_loss=243.47322\n",
      "Epoch 19719: train_loss=234.94327, val_loss=243.42580\n",
      "Epoch 19720: train_loss=234.90552, val_loss=243.39713\n",
      "Epoch 19721: train_loss=234.86790, val_loss=243.34973\n",
      "Epoch 19722: train_loss=234.83080, val_loss=243.32219\n",
      "Epoch 19723: train_loss=234.79385, val_loss=243.27588\n",
      "Epoch 19724: train_loss=234.75740, val_loss=243.25349\n",
      "Epoch 19725: train_loss=234.72134, val_loss=243.20619\n",
      "Epoch 19726: train_loss=234.68607, val_loss=243.18703\n",
      "Epoch 19727: train_loss=234.65175, val_loss=243.13463\n",
      "Epoch 19728: train_loss=234.61862, val_loss=243.12294\n",
      "Epoch 19729: train_loss=234.58725, val_loss=243.06937\n",
      "Epoch 19730: train_loss=234.55817, val_loss=243.07233\n",
      "Epoch 19731: train_loss=234.53210, val_loss=243.01784\n",
      "Epoch 19732: train_loss=234.51018, val_loss=243.03874\n",
      "Epoch 19733: train_loss=234.49200, val_loss=242.98154\n",
      "Epoch 19734: train_loss=234.47946, val_loss=243.02596\n",
      "Epoch 19735: train_loss=234.47243, val_loss=242.96643\n",
      "Epoch 19736: train_loss=234.47261, val_loss=243.03534\n",
      "Epoch 19737: train_loss=234.47548, val_loss=242.96858\n",
      "Epoch 19738: train_loss=234.48300, val_loss=243.05083\n",
      "Epoch 19739: train_loss=234.48531, val_loss=242.96318\n",
      "Epoch 19740: train_loss=234.48280, val_loss=243.03279\n",
      "Epoch 19741: train_loss=234.46162, val_loss=242.90540\n",
      "Epoch 19742: train_loss=234.42261, val_loss=242.92361\n",
      "Epoch 19743: train_loss=234.35373, val_loss=242.75180\n",
      "Epoch 19744: train_loss=234.26550, val_loss=242.71643\n",
      "Epoch 19745: train_loss=234.16064, val_loss=242.55066\n",
      "Epoch 19746: train_loss=234.05687, val_loss=242.49992\n",
      "Epoch 19747: train_loss=233.96231, val_loss=242.39453\n",
      "Epoch 19748: train_loss=233.88634, val_loss=242.35410\n",
      "Epoch 19749: train_loss=233.83119, val_loss=242.31720\n",
      "Epoch 19750: train_loss=233.79424, val_loss=242.28145\n",
      "Epoch 19751: train_loss=233.77074, val_loss=242.28781\n",
      "Epoch 19752: train_loss=233.75453, val_loss=242.24030\n",
      "Epoch 19753: train_loss=233.73981, val_loss=242.26030\n",
      "Epoch 19754: train_loss=233.72139, val_loss=242.19199\n",
      "Epoch 19755: train_loss=233.69644, val_loss=242.20221\n",
      "Epoch 19756: train_loss=233.66200, val_loss=242.11545\n",
      "Epoch 19757: train_loss=233.61945, val_loss=242.10738\n",
      "Epoch 19758: train_loss=233.56998, val_loss=242.01738\n",
      "Epoch 19759: train_loss=233.51659, val_loss=241.99513\n",
      "Epoch 19760: train_loss=233.46326, val_loss=241.91998\n",
      "Epoch 19761: train_loss=233.41240, val_loss=241.88945\n",
      "Epoch 19762: train_loss=233.36574, val_loss=241.83646\n",
      "Epoch 19763: train_loss=233.32367, val_loss=241.80063\n",
      "Epoch 19764: train_loss=233.28589, val_loss=241.76926\n",
      "Epoch 19765: train_loss=233.25186, val_loss=241.72839\n",
      "Epoch 19766: train_loss=233.22008, val_loss=241.71175\n",
      "Epoch 19767: train_loss=233.18932, val_loss=241.66365\n",
      "Epoch 19768: train_loss=233.15892, val_loss=241.65356\n",
      "Epoch 19769: train_loss=233.12816, val_loss=241.59792\n",
      "Epoch 19770: train_loss=233.09669, val_loss=241.58971\n",
      "Epoch 19771: train_loss=233.06384, val_loss=241.52914\n",
      "Epoch 19772: train_loss=233.02979, val_loss=241.52078\n",
      "Epoch 19773: train_loss=232.99455, val_loss=241.45886\n",
      "Epoch 19774: train_loss=232.95805, val_loss=241.44820\n",
      "Epoch 19775: train_loss=232.92067, val_loss=241.38593\n",
      "Epoch 19776: train_loss=232.88258, val_loss=241.37134\n",
      "Epoch 19777: train_loss=232.84416, val_loss=241.31029\n",
      "Epoch 19778: train_loss=232.80571, val_loss=241.29153\n",
      "Epoch 19779: train_loss=232.76701, val_loss=241.23381\n",
      "Epoch 19780: train_loss=232.72832, val_loss=241.21114\n",
      "Epoch 19781: train_loss=232.68954, val_loss=241.15993\n",
      "Epoch 19782: train_loss=232.65132, val_loss=241.13428\n",
      "Epoch 19783: train_loss=232.61336, val_loss=241.08890\n",
      "Epoch 19784: train_loss=232.57614, val_loss=241.05949\n",
      "Epoch 19785: train_loss=232.53947, val_loss=241.01932\n",
      "Epoch 19786: train_loss=232.50342, val_loss=240.98691\n",
      "Epoch 19787: train_loss=232.46770, val_loss=240.95134\n",
      "Epoch 19788: train_loss=232.43231, val_loss=240.91704\n",
      "Epoch 19789: train_loss=232.39713, val_loss=240.88463\n",
      "Epoch 19790: train_loss=232.36209, val_loss=240.84753\n",
      "Epoch 19791: train_loss=232.32716, val_loss=240.81647\n",
      "Epoch 19792: train_loss=232.29237, val_loss=240.77695\n",
      "Epoch 19793: train_loss=232.25766, val_loss=240.74890\n",
      "Epoch 19794: train_loss=232.22310, val_loss=240.70866\n",
      "Epoch 19795: train_loss=232.18855, val_loss=240.68274\n",
      "Epoch 19796: train_loss=232.15404, val_loss=240.63995\n",
      "Epoch 19797: train_loss=232.11980, val_loss=240.61584\n",
      "Epoch 19798: train_loss=232.08566, val_loss=240.57156\n",
      "Epoch 19799: train_loss=232.05203, val_loss=240.55141\n",
      "Epoch 19800: train_loss=232.01874, val_loss=240.50552\n",
      "Epoch 19801: train_loss=231.98633, val_loss=240.49080\n",
      "Epoch 19802: train_loss=231.95486, val_loss=240.44118\n",
      "Epoch 19803: train_loss=231.92502, val_loss=240.43529\n",
      "Epoch 19804: train_loss=231.89671, val_loss=240.38385\n",
      "Epoch 19805: train_loss=231.87079, val_loss=240.39243\n",
      "Epoch 19806: train_loss=231.84769, val_loss=240.33815\n",
      "Epoch 19807: train_loss=231.82793, val_loss=240.36290\n",
      "Epoch 19808: train_loss=231.81172, val_loss=240.30368\n",
      "Epoch 19809: train_loss=231.79926, val_loss=240.34700\n",
      "Epoch 19810: train_loss=231.79012, val_loss=240.28549\n",
      "Epoch 19811: train_loss=231.78630, val_loss=240.35004\n",
      "Epoch 19812: train_loss=231.78484, val_loss=240.28185\n",
      "Epoch 19813: train_loss=231.78716, val_loss=240.35925\n",
      "Epoch 19814: train_loss=231.78690, val_loss=240.27107\n",
      "Epoch 19815: train_loss=231.78159, val_loss=240.33783\n",
      "Epoch 19816: train_loss=231.76262, val_loss=240.21651\n",
      "Epoch 19817: train_loss=231.72870, val_loss=240.24498\n",
      "Epoch 19818: train_loss=231.67238, val_loss=240.08997\n",
      "Epoch 19819: train_loss=231.59888, val_loss=240.07143\n",
      "Epoch 19820: train_loss=231.50800, val_loss=239.91402\n",
      "Epoch 19821: train_loss=231.41405, val_loss=239.87114\n",
      "Epoch 19822: train_loss=231.32317, val_loss=239.75934\n",
      "Epoch 19823: train_loss=231.24658, val_loss=239.72043\n",
      "Epoch 19824: train_loss=231.18848, val_loss=239.67435\n",
      "Epoch 19825: train_loss=231.14806, val_loss=239.64055\n",
      "Epoch 19826: train_loss=231.12184, val_loss=239.64386\n",
      "Epoch 19827: train_loss=231.10472, val_loss=239.60229\n",
      "Epoch 19828: train_loss=231.09221, val_loss=239.62581\n",
      "Epoch 19829: train_loss=231.07820, val_loss=239.56400\n",
      "Epoch 19830: train_loss=231.05997, val_loss=239.58257\n",
      "Epoch 19831: train_loss=231.03314, val_loss=239.50055\n",
      "Epoch 19832: train_loss=230.99855, val_loss=239.50256\n",
      "Epoch 19833: train_loss=230.95480, val_loss=239.41106\n",
      "Epoch 19834: train_loss=230.90628, val_loss=239.39563\n",
      "Epoch 19835: train_loss=230.85477, val_loss=239.31288\n",
      "Epoch 19836: train_loss=230.80452, val_loss=239.28809\n",
      "Epoch 19837: train_loss=230.75677, val_loss=239.22792\n",
      "Epoch 19838: train_loss=230.71349, val_loss=239.19867\n",
      "Epoch 19839: train_loss=230.67471, val_loss=239.16203\n",
      "Epoch 19840: train_loss=230.63989, val_loss=239.12581\n",
      "Epoch 19841: train_loss=230.60823, val_loss=239.10585\n",
      "Epoch 19842: train_loss=230.57846, val_loss=239.06230\n",
      "Epoch 19843: train_loss=230.54980, val_loss=239.05278\n",
      "Epoch 19844: train_loss=230.52136, val_loss=239.00250\n",
      "Epoch 19845: train_loss=230.49217, val_loss=238.99675\n",
      "Epoch 19846: train_loss=230.46173, val_loss=238.94009\n",
      "Epoch 19847: train_loss=230.43015, val_loss=238.93283\n",
      "Epoch 19848: train_loss=230.39696, val_loss=238.87315\n",
      "Epoch 19849: train_loss=230.36269, val_loss=238.86349\n",
      "Epoch 19850: train_loss=230.32747, val_loss=238.80353\n",
      "Epoch 19851: train_loss=230.29167, val_loss=238.78964\n",
      "Epoch 19852: train_loss=230.25562, val_loss=238.73175\n",
      "Epoch 19853: train_loss=230.21912, val_loss=238.71541\n",
      "Epoch 19854: train_loss=230.18274, val_loss=238.66318\n",
      "Epoch 19855: train_loss=230.14667, val_loss=238.64534\n",
      "Epoch 19856: train_loss=230.11096, val_loss=238.59674\n",
      "Epoch 19857: train_loss=230.07556, val_loss=238.57611\n",
      "Epoch 19858: train_loss=230.04071, val_loss=238.53036\n",
      "Epoch 19859: train_loss=230.00607, val_loss=238.50983\n",
      "Epoch 19860: train_loss=229.97182, val_loss=238.46732\n",
      "Epoch 19861: train_loss=229.93756, val_loss=238.44765\n",
      "Epoch 19862: train_loss=229.90373, val_loss=238.40543\n",
      "Epoch 19863: train_loss=229.87003, val_loss=238.38521\n",
      "Epoch 19864: train_loss=229.83665, val_loss=238.34196\n",
      "Epoch 19865: train_loss=229.80345, val_loss=238.32404\n",
      "Epoch 19866: train_loss=229.77080, val_loss=238.28043\n",
      "Epoch 19867: train_loss=229.73883, val_loss=238.26701\n",
      "Epoch 19868: train_loss=229.70766, val_loss=238.21960\n",
      "Epoch 19869: train_loss=229.67784, val_loss=238.21326\n",
      "Epoch 19870: train_loss=229.64922, val_loss=238.16196\n",
      "Epoch 19871: train_loss=229.62216, val_loss=238.16675\n",
      "Epoch 19872: train_loss=229.59648, val_loss=238.11353\n",
      "Epoch 19873: train_loss=229.57378, val_loss=238.13338\n",
      "Epoch 19874: train_loss=229.55258, val_loss=238.07686\n",
      "Epoch 19875: train_loss=229.53479, val_loss=238.11157\n",
      "Epoch 19876: train_loss=229.51901, val_loss=238.04953\n",
      "Epoch 19877: train_loss=229.50682, val_loss=238.10042\n",
      "Epoch 19878: train_loss=229.49631, val_loss=238.03130\n",
      "Epoch 19879: train_loss=229.48695, val_loss=238.09535\n",
      "Epoch 19880: train_loss=229.47836, val_loss=238.01694\n",
      "Epoch 19881: train_loss=229.46852, val_loss=238.08412\n",
      "Epoch 19882: train_loss=229.45422, val_loss=237.98651\n",
      "Epoch 19883: train_loss=229.43259, val_loss=238.03857\n",
      "Epoch 19884: train_loss=229.40021, val_loss=237.91698\n",
      "Epoch 19885: train_loss=229.35628, val_loss=237.93959\n",
      "Epoch 19886: train_loss=229.29945, val_loss=237.80269\n",
      "Epoch 19887: train_loss=229.23254, val_loss=237.79538\n",
      "Epoch 19888: train_loss=229.15878, val_loss=237.66875\n",
      "Epoch 19889: train_loss=229.08417, val_loss=237.64549\n",
      "Epoch 19890: train_loss=229.01468, val_loss=237.55663\n",
      "Epoch 19891: train_loss=228.95439, val_loss=237.52902\n",
      "Epoch 19892: train_loss=228.90518, val_loss=237.48494\n",
      "Epoch 19893: train_loss=228.86668, val_loss=237.45294\n",
      "Epoch 19894: train_loss=228.83669, val_loss=237.44490\n",
      "Epoch 19895: train_loss=228.81273, val_loss=237.40623\n",
      "Epoch 19896: train_loss=228.79259, val_loss=237.42110\n",
      "Epoch 19897: train_loss=228.77361, val_loss=237.36943\n",
      "Epoch 19898: train_loss=228.75372, val_loss=237.38968\n",
      "Epoch 19899: train_loss=228.73111, val_loss=237.32306\n",
      "Epoch 19900: train_loss=228.70500, val_loss=237.33963\n",
      "Epoch 19901: train_loss=228.67461, val_loss=237.26326\n",
      "Epoch 19902: train_loss=228.64020, val_loss=237.27071\n",
      "Epoch 19903: train_loss=228.60220, val_loss=237.19098\n",
      "Epoch 19904: train_loss=228.56157, val_loss=237.18738\n",
      "Epoch 19905: train_loss=228.51915, val_loss=237.11275\n",
      "Epoch 19906: train_loss=228.47621, val_loss=237.10059\n",
      "Epoch 19907: train_loss=228.43408, val_loss=237.03841\n",
      "Epoch 19908: train_loss=228.39334, val_loss=237.01953\n",
      "Epoch 19909: train_loss=228.35466, val_loss=236.97108\n",
      "Epoch 19910: train_loss=228.31801, val_loss=236.94632\n",
      "Epoch 19911: train_loss=228.28310, val_loss=236.91016\n",
      "Epoch 19912: train_loss=228.24971, val_loss=236.88106\n",
      "Epoch 19913: train_loss=228.21727, val_loss=236.85631\n",
      "Epoch 19914: train_loss=228.18582, val_loss=236.82271\n",
      "Epoch 19915: train_loss=228.15512, val_loss=236.80486\n",
      "Epoch 19916: train_loss=228.12506, val_loss=236.76453\n",
      "Epoch 19917: train_loss=228.09537, val_loss=236.75160\n",
      "Epoch 19918: train_loss=228.06609, val_loss=236.70625\n",
      "Epoch 19919: train_loss=228.03720, val_loss=236.69960\n",
      "Epoch 19920: train_loss=228.00850, val_loss=236.65074\n",
      "Epoch 19921: train_loss=227.98021, val_loss=236.64961\n",
      "Epoch 19922: train_loss=227.95209, val_loss=236.59688\n",
      "Epoch 19923: train_loss=227.92397, val_loss=236.59956\n",
      "Epoch 19924: train_loss=227.89622, val_loss=236.54300\n",
      "Epoch 19925: train_loss=227.86896, val_loss=236.55008\n",
      "Epoch 19926: train_loss=227.84195, val_loss=236.49023\n",
      "Epoch 19927: train_loss=227.81516, val_loss=236.50192\n",
      "Epoch 19928: train_loss=227.78848, val_loss=236.43906\n",
      "Epoch 19929: train_loss=227.76181, val_loss=236.45474\n",
      "Epoch 19930: train_loss=227.73570, val_loss=236.38913\n",
      "Epoch 19931: train_loss=227.71016, val_loss=236.40996\n",
      "Epoch 19932: train_loss=227.68472, val_loss=236.34090\n",
      "Epoch 19933: train_loss=227.65955, val_loss=236.36560\n",
      "Epoch 19934: train_loss=227.63412, val_loss=236.29251\n",
      "Epoch 19935: train_loss=227.60896, val_loss=236.31941\n",
      "Epoch 19936: train_loss=227.58299, val_loss=236.24142\n",
      "Epoch 19937: train_loss=227.55640, val_loss=236.26767\n",
      "Epoch 19938: train_loss=227.52747, val_loss=236.18518\n",
      "Epoch 19939: train_loss=227.49753, val_loss=236.20808\n",
      "Epoch 19940: train_loss=227.46501, val_loss=236.12199\n",
      "Epoch 19941: train_loss=227.43068, val_loss=236.13913\n",
      "Epoch 19942: train_loss=227.39380, val_loss=236.05125\n",
      "Epoch 19943: train_loss=227.35492, val_loss=236.05971\n",
      "Epoch 19944: train_loss=227.31377, val_loss=235.97302\n",
      "Epoch 19945: train_loss=227.27104, val_loss=235.97185\n",
      "Epoch 19946: train_loss=227.22710, val_loss=235.89133\n",
      "Epoch 19947: train_loss=227.18286, val_loss=235.88118\n",
      "Epoch 19948: train_loss=227.13931, val_loss=235.81329\n",
      "Epoch 19949: train_loss=227.09766, val_loss=235.79691\n",
      "Epoch 19950: train_loss=227.05782, val_loss=235.74359\n",
      "Epoch 19951: train_loss=227.02046, val_loss=235.72247\n",
      "Epoch 19952: train_loss=226.98488, val_loss=235.68079\n",
      "Epoch 19953: train_loss=226.95102, val_loss=235.65318\n",
      "Epoch 19954: train_loss=226.91833, val_loss=235.62163\n",
      "Epoch 19955: train_loss=226.88667, val_loss=235.59006\n",
      "Epoch 19956: train_loss=226.85585, val_loss=235.56754\n",
      "Epoch 19957: train_loss=226.82559, val_loss=235.53227\n",
      "Epoch 19958: train_loss=226.79593, val_loss=235.51686\n",
      "Epoch 19959: train_loss=226.76683, val_loss=235.47557\n",
      "Epoch 19960: train_loss=226.73813, val_loss=235.46439\n",
      "Epoch 19961: train_loss=226.71002, val_loss=235.41808\n",
      "Epoch 19962: train_loss=226.68240, val_loss=235.41415\n",
      "Epoch 19963: train_loss=226.65559, val_loss=235.36522\n",
      "Epoch 19964: train_loss=226.62996, val_loss=235.37073\n",
      "Epoch 19965: train_loss=226.60574, val_loss=235.31757\n",
      "Epoch 19966: train_loss=226.58305, val_loss=235.33353\n",
      "Epoch 19967: train_loss=226.56264, val_loss=235.27710\n",
      "Epoch 19968: train_loss=226.54521, val_loss=235.30861\n",
      "Epoch 19969: train_loss=226.53050, val_loss=235.24931\n",
      "Epoch 19970: train_loss=226.51958, val_loss=235.29816\n",
      "Epoch 19971: train_loss=226.51128, val_loss=235.23404\n",
      "Epoch 19972: train_loss=226.50615, val_loss=235.29863\n",
      "Epoch 19973: train_loss=226.50276, val_loss=235.22560\n",
      "Epoch 19974: train_loss=226.49936, val_loss=235.29842\n",
      "Epoch 19975: train_loss=226.49324, val_loss=235.20708\n",
      "Epoch 19976: train_loss=226.47995, val_loss=235.26672\n",
      "Epoch 19977: train_loss=226.45589, val_loss=235.14764\n",
      "Epoch 19978: train_loss=226.41849, val_loss=235.17480\n",
      "Epoch 19979: train_loss=226.36580, val_loss=235.03369\n",
      "Epoch 19980: train_loss=226.30060, val_loss=235.02695\n",
      "Epoch 19981: train_loss=226.22635, val_loss=234.89218\n",
      "Epoch 19982: train_loss=226.14935, val_loss=234.86624\n",
      "Epoch 19983: train_loss=226.07504, val_loss=234.76724\n",
      "Epoch 19984: train_loss=226.01067, val_loss=234.73776\n",
      "Epoch 19985: train_loss=225.95810, val_loss=234.68675\n",
      "Epoch 19986: train_loss=225.91721, val_loss=234.65486\n",
      "Epoch 19987: train_loss=225.88692, val_loss=234.64569\n",
      "Epoch 19988: train_loss=225.86398, val_loss=234.60741\n",
      "Epoch 19989: train_loss=225.84502, val_loss=234.62236\n",
      "Epoch 19990: train_loss=225.82750, val_loss=234.57253\n",
      "Epoch 19991: train_loss=225.80991, val_loss=234.59496\n",
      "Epoch 19992: train_loss=225.78883, val_loss=234.52823\n",
      "Epoch 19993: train_loss=225.76410, val_loss=234.54274\n",
      "Epoch 19994: train_loss=225.73402, val_loss=234.46326\n",
      "Epoch 19995: train_loss=225.69945, val_loss=234.46815\n",
      "Epoch 19996: train_loss=225.66037, val_loss=234.38710\n",
      "Epoch 19997: train_loss=225.61887, val_loss=234.38303\n",
      "Epoch 19998: train_loss=225.57524, val_loss=234.30725\n",
      "Epoch 19999: train_loss=225.53197, val_loss=234.29333\n",
      "Epoch 20000: train_loss=225.48907, val_loss=234.22797\n",
      "Epoch 20001: train_loss=225.44766, val_loss=234.20784\n",
      "Epoch 20002: train_loss=225.40805, val_loss=234.15935\n",
      "Epoch 20003: train_loss=225.37027, val_loss=234.13376\n",
      "Epoch 20004: train_loss=225.33501, val_loss=234.10043\n",
      "Epoch 20005: train_loss=225.30174, val_loss=234.06624\n",
      "Epoch 20006: train_loss=225.26996, val_loss=234.04376\n",
      "Epoch 20007: train_loss=225.23920, val_loss=234.00346\n",
      "Epoch 20008: train_loss=225.20883, val_loss=233.99039\n",
      "Epoch 20009: train_loss=225.17874, val_loss=233.94601\n",
      "Epoch 20010: train_loss=225.14882, val_loss=233.93730\n",
      "Epoch 20011: train_loss=225.11893, val_loss=233.88661\n",
      "Epoch 20012: train_loss=225.08917, val_loss=233.88075\n",
      "Epoch 20013: train_loss=225.05963, val_loss=233.82678\n",
      "Epoch 20014: train_loss=225.03070, val_loss=233.82771\n",
      "Epoch 20015: train_loss=225.00211, val_loss=233.77188\n",
      "Epoch 20016: train_loss=224.97421, val_loss=233.77896\n",
      "Epoch 20017: train_loss=224.94698, val_loss=233.71870\n",
      "Epoch 20018: train_loss=224.92072, val_loss=233.73007\n",
      "Epoch 20019: train_loss=224.89435, val_loss=233.66502\n",
      "Epoch 20020: train_loss=224.86929, val_loss=233.68327\n",
      "Epoch 20021: train_loss=224.84392, val_loss=233.61533\n",
      "Epoch 20022: train_loss=224.81923, val_loss=233.63933\n",
      "Epoch 20023: train_loss=224.79413, val_loss=233.56651\n",
      "Epoch 20024: train_loss=224.76949, val_loss=233.59224\n",
      "Epoch 20025: train_loss=224.74268, val_loss=233.51326\n",
      "Epoch 20026: train_loss=224.71622, val_loss=233.53819\n",
      "Epoch 20027: train_loss=224.68666, val_loss=233.45317\n",
      "Epoch 20028: train_loss=224.65645, val_loss=233.47369\n",
      "Epoch 20029: train_loss=224.62288, val_loss=233.38530\n",
      "Epoch 20030: train_loss=224.58817, val_loss=233.40004\n",
      "Epoch 20031: train_loss=224.55003, val_loss=233.31227\n",
      "Epoch 20032: train_loss=224.51111, val_loss=233.32066\n",
      "Epoch 20033: train_loss=224.46989, val_loss=233.23639\n",
      "Epoch 20034: train_loss=224.42853, val_loss=233.23518\n",
      "Epoch 20035: train_loss=224.38669, val_loss=233.15710\n",
      "Epoch 20036: train_loss=224.34579, val_loss=233.15012\n",
      "Epoch 20037: train_loss=224.30566, val_loss=233.08255\n",
      "Epoch 20038: train_loss=224.26666, val_loss=233.07173\n",
      "Epoch 20039: train_loss=224.22922, val_loss=233.01549\n",
      "Epoch 20040: train_loss=224.19321, val_loss=232.99965\n",
      "Epoch 20041: train_loss=224.15843, val_loss=232.95197\n",
      "Epoch 20042: train_loss=224.12454, val_loss=232.93008\n",
      "Epoch 20043: train_loss=224.09158, val_loss=232.89053\n",
      "Epoch 20044: train_loss=224.05957, val_loss=232.86407\n",
      "Epoch 20045: train_loss=224.02823, val_loss=232.83070\n",
      "Epoch 20046: train_loss=223.99736, val_loss=232.80089\n",
      "Epoch 20047: train_loss=223.96692, val_loss=232.77357\n",
      "Epoch 20048: train_loss=223.93669, val_loss=232.74196\n",
      "Epoch 20049: train_loss=223.90651, val_loss=232.71861\n",
      "Epoch 20050: train_loss=223.87675, val_loss=232.68283\n",
      "Epoch 20051: train_loss=223.84726, val_loss=232.66196\n",
      "Epoch 20052: train_loss=223.81795, val_loss=232.62198\n",
      "Epoch 20053: train_loss=223.78917, val_loss=232.60757\n",
      "Epoch 20054: train_loss=223.76103, val_loss=232.56616\n",
      "Epoch 20055: train_loss=223.73349, val_loss=232.56075\n",
      "Epoch 20056: train_loss=223.70734, val_loss=232.51549\n",
      "Epoch 20057: train_loss=223.68256, val_loss=232.51974\n",
      "Epoch 20058: train_loss=223.66005, val_loss=232.46913\n",
      "Epoch 20059: train_loss=223.63972, val_loss=232.48853\n",
      "Epoch 20060: train_loss=223.62222, val_loss=232.43451\n",
      "Epoch 20061: train_loss=223.60820, val_loss=232.47345\n",
      "Epoch 20062: train_loss=223.59715, val_loss=232.41458\n",
      "Epoch 20063: train_loss=223.59097, val_loss=232.47398\n",
      "Epoch 20064: train_loss=223.58720, val_loss=232.40694\n",
      "Epoch 20065: train_loss=223.58736, val_loss=232.48433\n",
      "Epoch 20066: train_loss=223.58786, val_loss=232.40564\n",
      "Epoch 20067: train_loss=223.58748, val_loss=232.48843\n",
      "Epoch 20068: train_loss=223.58089, val_loss=232.38695\n",
      "Epoch 20069: train_loss=223.56679, val_loss=232.44992\n",
      "Epoch 20070: train_loss=223.53822, val_loss=232.31973\n",
      "Epoch 20071: train_loss=223.49586, val_loss=232.34816\n",
      "Epoch 20072: train_loss=223.43556, val_loss=232.20287\n",
      "Epoch 20073: train_loss=223.36372, val_loss=232.19440\n",
      "Epoch 20074: train_loss=223.28406, val_loss=232.06329\n",
      "Epoch 20075: train_loss=223.20694, val_loss=232.03827\n",
      "Epoch 20076: train_loss=223.13702, val_loss=231.95326\n",
      "Epoch 20077: train_loss=223.07935, val_loss=231.92627\n",
      "Epoch 20078: train_loss=223.03577, val_loss=231.89049\n",
      "Epoch 20079: train_loss=223.00330, val_loss=231.85799\n",
      "Epoch 20080: train_loss=222.97923, val_loss=231.85670\n",
      "Epoch 20081: train_loss=222.96059, val_loss=231.81261\n",
      "Epoch 20082: train_loss=222.94414, val_loss=231.82951\n",
      "Epoch 20083: train_loss=222.92813, val_loss=231.77208\n",
      "Epoch 20084: train_loss=222.90938, val_loss=231.79077\n",
      "Epoch 20085: train_loss=222.88681, val_loss=231.71855\n",
      "Epoch 20086: train_loss=222.85880, val_loss=231.72874\n",
      "Epoch 20087: train_loss=222.82616, val_loss=231.65002\n",
      "Epoch 20088: train_loss=222.78955, val_loss=231.64969\n",
      "Epoch 20089: train_loss=222.75076, val_loss=231.57341\n",
      "Epoch 20090: train_loss=222.71092, val_loss=231.56329\n",
      "Epoch 20091: train_loss=222.67151, val_loss=231.49763\n",
      "Epoch 20092: train_loss=222.63263, val_loss=231.48207\n",
      "Epoch 20093: train_loss=222.59595, val_loss=231.43169\n",
      "Epoch 20094: train_loss=222.56099, val_loss=231.40976\n",
      "Epoch 20095: train_loss=222.52791, val_loss=231.37051\n",
      "Epoch 20096: train_loss=222.49649, val_loss=231.34052\n",
      "Epoch 20097: train_loss=222.46635, val_loss=231.31157\n",
      "Epoch 20098: train_loss=222.43732, val_loss=231.27788\n",
      "Epoch 20099: train_loss=222.40923, val_loss=231.25954\n",
      "Epoch 20100: train_loss=222.38156, val_loss=231.22275\n",
      "Epoch 20101: train_loss=222.35417, val_loss=231.21078\n",
      "Epoch 20102: train_loss=222.32724, val_loss=231.16840\n",
      "Epoch 20103: train_loss=222.30066, val_loss=231.16173\n",
      "Epoch 20104: train_loss=222.27484, val_loss=231.11531\n",
      "Epoch 20105: train_loss=222.24934, val_loss=231.11569\n",
      "Epoch 20106: train_loss=222.22485, val_loss=231.06598\n",
      "Epoch 20107: train_loss=222.20128, val_loss=231.07428\n",
      "Epoch 20108: train_loss=222.17842, val_loss=231.01988\n",
      "Epoch 20109: train_loss=222.15605, val_loss=231.03514\n",
      "Epoch 20110: train_loss=222.13367, val_loss=230.97569\n",
      "Epoch 20111: train_loss=222.11142, val_loss=230.99539\n",
      "Epoch 20112: train_loss=222.08919, val_loss=230.92899\n",
      "Epoch 20113: train_loss=222.06647, val_loss=230.95142\n",
      "Epoch 20114: train_loss=222.04366, val_loss=230.88022\n",
      "Epoch 20115: train_loss=222.01965, val_loss=230.90596\n",
      "Epoch 20116: train_loss=221.99530, val_loss=230.83145\n",
      "Epoch 20117: train_loss=221.96901, val_loss=230.85710\n",
      "Epoch 20118: train_loss=221.94179, val_loss=230.77812\n",
      "Epoch 20119: train_loss=221.91216, val_loss=230.79875\n",
      "Epoch 20120: train_loss=221.88144, val_loss=230.71596\n",
      "Epoch 20121: train_loss=221.84856, val_loss=230.73079\n",
      "Epoch 20122: train_loss=221.81485, val_loss=230.64871\n",
      "Epoch 20123: train_loss=221.77930, val_loss=230.65913\n",
      "Epoch 20124: train_loss=221.74338, val_loss=230.58145\n",
      "Epoch 20125: train_loss=221.70648, val_loss=230.58607\n",
      "Epoch 20126: train_loss=221.66978, val_loss=230.51184\n",
      "Epoch 20127: train_loss=221.63239, val_loss=230.50803\n",
      "Epoch 20128: train_loss=221.59572, val_loss=230.43958\n",
      "Epoch 20129: train_loss=221.55904, val_loss=230.43098\n",
      "Epoch 20130: train_loss=221.52342, val_loss=230.37254\n",
      "Epoch 20131: train_loss=221.48836, val_loss=230.36073\n",
      "Epoch 20132: train_loss=221.45461, val_loss=230.31149\n",
      "Epoch 20133: train_loss=221.42130, val_loss=230.29526\n",
      "Epoch 20134: train_loss=221.38928, val_loss=230.25311\n",
      "Epoch 20135: train_loss=221.35774, val_loss=230.23126\n",
      "Epoch 20136: train_loss=221.32648, val_loss=230.19388\n",
      "Epoch 20137: train_loss=221.29573, val_loss=230.16782\n",
      "Epoch 20138: train_loss=221.26540, val_loss=230.13568\n",
      "Epoch 20139: train_loss=221.23528, val_loss=230.10706\n",
      "Epoch 20140: train_loss=221.20544, val_loss=230.08113\n",
      "Epoch 20141: train_loss=221.17590, val_loss=230.04987\n",
      "Epoch 20142: train_loss=221.14658, val_loss=230.02710\n",
      "Epoch 20143: train_loss=221.11731, val_loss=229.99106\n",
      "Epoch 20144: train_loss=221.08824, val_loss=229.97133\n",
      "Epoch 20145: train_loss=221.05949, val_loss=229.93256\n",
      "Epoch 20146: train_loss=221.03108, val_loss=229.91953\n",
      "Epoch 20147: train_loss=221.00320, val_loss=229.87918\n",
      "Epoch 20148: train_loss=220.97629, val_loss=229.87422\n",
      "Epoch 20149: train_loss=220.95085, val_loss=229.82822\n",
      "Epoch 20150: train_loss=220.92735, val_loss=229.83577\n",
      "Epoch 20151: train_loss=220.90742, val_loss=229.78645\n",
      "Epoch 20152: train_loss=220.89130, val_loss=229.81743\n",
      "Epoch 20153: train_loss=220.88083, val_loss=229.76712\n",
      "Epoch 20154: train_loss=220.87601, val_loss=229.82957\n",
      "Epoch 20155: train_loss=220.88007, val_loss=229.77808\n",
      "Epoch 20156: train_loss=220.89174, val_loss=229.87692\n",
      "Epoch 20157: train_loss=220.91393, val_loss=229.82222\n",
      "Epoch 20158: train_loss=220.94217, val_loss=229.95114\n",
      "Epoch 20159: train_loss=220.97298, val_loss=229.87663\n",
      "Epoch 20160: train_loss=220.99968, val_loss=229.99518\n",
      "Epoch 20161: train_loss=221.00647, val_loss=229.86150\n",
      "Epoch 20162: train_loss=220.98618, val_loss=229.91235\n",
      "Epoch 20163: train_loss=220.92567, val_loss=229.70929\n",
      "Epoch 20164: train_loss=220.82976, val_loss=229.67616\n",
      "Epoch 20165: train_loss=220.70479, val_loss=229.46945\n",
      "Epoch 20166: train_loss=220.57449, val_loss=229.40988\n",
      "Epoch 20167: train_loss=220.46207, val_loss=229.29381\n",
      "Epoch 20168: train_loss=220.38077, val_loss=229.25717\n",
      "Epoch 20169: train_loss=220.33629, val_loss=229.25247\n",
      "Epoch 20170: train_loss=220.32211, val_loss=229.22601\n",
      "Epoch 20171: train_loss=220.32570, val_loss=229.27768\n",
      "Epoch 20172: train_loss=220.33426, val_loss=229.22415\n",
      "Epoch 20173: train_loss=220.33438, val_loss=229.27063\n",
      "Epoch 20174: train_loss=220.31964, val_loss=229.17722\n",
      "Epoch 20175: train_loss=220.28545, val_loss=229.18817\n",
      "Epoch 20176: train_loss=220.23637, val_loss=229.07820\n",
      "Epoch 20177: train_loss=220.17679, val_loss=229.05980\n",
      "Epoch 20178: train_loss=220.11720, val_loss=228.97569\n",
      "Epoch 20179: train_loss=220.06323, val_loss=228.94945\n",
      "Epoch 20180: train_loss=220.02023, val_loss=228.91530\n",
      "Epoch 20181: train_loss=219.98866, val_loss=228.88495\n",
      "Epoch 20182: train_loss=219.96623, val_loss=228.88651\n",
      "Epoch 20183: train_loss=219.94875, val_loss=228.84175\n",
      "Epoch 20184: train_loss=219.93195, val_loss=228.85503\n",
      "Epoch 20185: train_loss=219.91307, val_loss=228.79364\n",
      "Epoch 20186: train_loss=219.88885, val_loss=228.80290\n",
      "Epoch 20187: train_loss=219.86028, val_loss=228.73351\n",
      "Epoch 20188: train_loss=219.82597, val_loss=228.73232\n",
      "Epoch 20189: train_loss=219.78973, val_loss=228.66649\n",
      "Epoch 20190: train_loss=219.75151, val_loss=228.65343\n",
      "Epoch 20191: train_loss=219.71422, val_loss=228.60165\n",
      "Epoch 20192: train_loss=219.67845, val_loss=228.57990\n",
      "Epoch 20193: train_loss=219.64560, val_loss=228.54671\n",
      "Epoch 20194: train_loss=219.61551, val_loss=228.51671\n",
      "Epoch 20195: train_loss=219.58791, val_loss=228.49858\n",
      "Epoch 20196: train_loss=219.56197, val_loss=228.46036\n",
      "Epoch 20197: train_loss=219.53683, val_loss=228.45161\n",
      "Epoch 20198: train_loss=219.51173, val_loss=228.40691\n",
      "Epoch 20199: train_loss=219.48590, val_loss=228.40291\n",
      "Epoch 20200: train_loss=219.45932, val_loss=228.35451\n",
      "Epoch 20201: train_loss=219.43141, val_loss=228.35078\n",
      "Epoch 20202: train_loss=219.40324, val_loss=228.30090\n",
      "Epoch 20203: train_loss=219.37424, val_loss=228.29463\n",
      "Epoch 20204: train_loss=219.34494, val_loss=228.24348\n",
      "Epoch 20205: train_loss=219.31499, val_loss=228.23328\n",
      "Epoch 20206: train_loss=219.28474, val_loss=228.18518\n",
      "Epoch 20207: train_loss=219.25438, val_loss=228.17268\n",
      "Epoch 20208: train_loss=219.22386, val_loss=228.12941\n",
      "Epoch 20209: train_loss=219.19377, val_loss=228.11220\n",
      "Epoch 20210: train_loss=219.16388, val_loss=228.07092\n",
      "Epoch 20211: train_loss=219.13420, val_loss=228.04803\n",
      "Epoch 20212: train_loss=219.10487, val_loss=228.01163\n",
      "Epoch 20213: train_loss=219.07593, val_loss=227.98845\n",
      "Epoch 20214: train_loss=219.04724, val_loss=227.95871\n",
      "Epoch 20215: train_loss=219.01871, val_loss=227.93404\n",
      "Epoch 20216: train_loss=218.99030, val_loss=227.90506\n",
      "Epoch 20217: train_loss=218.96207, val_loss=227.87686\n",
      "Epoch 20218: train_loss=218.93376, val_loss=227.84877\n",
      "Epoch 20219: train_loss=218.90561, val_loss=227.82051\n",
      "Epoch 20220: train_loss=218.87747, val_loss=227.79506\n",
      "Epoch 20221: train_loss=218.84952, val_loss=227.76512\n",
      "Epoch 20222: train_loss=218.82153, val_loss=227.74098\n",
      "Epoch 20223: train_loss=218.79370, val_loss=227.70844\n",
      "Epoch 20224: train_loss=218.76614, val_loss=227.68776\n",
      "Epoch 20225: train_loss=218.73898, val_loss=227.65302\n",
      "Epoch 20226: train_loss=218.71239, val_loss=227.63940\n",
      "Epoch 20227: train_loss=218.68648, val_loss=227.60132\n",
      "Epoch 20228: train_loss=218.66144, val_loss=227.59729\n",
      "Epoch 20229: train_loss=218.63809, val_loss=227.55502\n",
      "Epoch 20230: train_loss=218.61615, val_loss=227.56267\n",
      "Epoch 20231: train_loss=218.59647, val_loss=227.51521\n",
      "Epoch 20232: train_loss=218.57875, val_loss=227.53992\n",
      "Epoch 20233: train_loss=218.56544, val_loss=227.48822\n",
      "Epoch 20234: train_loss=218.55489, val_loss=227.53404\n",
      "Epoch 20235: train_loss=218.54961, val_loss=227.47797\n",
      "Epoch 20236: train_loss=218.54819, val_loss=227.54782\n",
      "Epoch 20237: train_loss=218.55240, val_loss=227.48502\n",
      "Epoch 20238: train_loss=218.55957, val_loss=227.57491\n",
      "Epoch 20239: train_loss=218.56822, val_loss=227.49779\n",
      "Epoch 20240: train_loss=218.57520, val_loss=227.58890\n",
      "Epoch 20241: train_loss=218.57291, val_loss=227.48068\n",
      "Epoch 20242: train_loss=218.55847, val_loss=227.54414\n",
      "Epoch 20243: train_loss=218.52560, val_loss=227.40118\n",
      "Epoch 20244: train_loss=218.47502, val_loss=227.41930\n",
      "Epoch 20245: train_loss=218.40456, val_loss=227.26033\n",
      "Epoch 20246: train_loss=218.32327, val_loss=227.24141\n",
      "Epoch 20247: train_loss=218.23874, val_loss=227.11147\n",
      "Epoch 20248: train_loss=218.16002, val_loss=227.08282\n",
      "Epoch 20249: train_loss=218.09625, val_loss=227.01674\n",
      "Epoch 20250: train_loss=218.04878, val_loss=226.99016\n",
      "Epoch 20251: train_loss=218.01721, val_loss=226.98051\n",
      "Epoch 20252: train_loss=217.99767, val_loss=226.94810\n",
      "Epoch 20253: train_loss=217.98579, val_loss=226.97160\n",
      "Epoch 20254: train_loss=217.97725, val_loss=226.92227\n",
      "Epoch 20255: train_loss=217.96667, val_loss=226.95377\n",
      "Epoch 20256: train_loss=217.95256, val_loss=226.88512\n",
      "Epoch 20257: train_loss=217.93037, val_loss=226.90770\n",
      "Epoch 20258: train_loss=217.90277, val_loss=226.82620\n",
      "Epoch 20259: train_loss=217.86745, val_loss=226.83345\n",
      "Epoch 20260: train_loss=217.82938, val_loss=226.75374\n",
      "Epoch 20261: train_loss=217.78809, val_loss=226.74741\n",
      "Epoch 20262: train_loss=217.74760, val_loss=226.68184\n",
      "Epoch 20263: train_loss=217.70842, val_loss=226.66615\n",
      "Epoch 20264: train_loss=217.67198, val_loss=226.62059\n",
      "Epoch 20265: train_loss=217.63904, val_loss=226.59654\n",
      "Epoch 20266: train_loss=217.60953, val_loss=226.56989\n",
      "Epoch 20267: train_loss=217.58266, val_loss=226.53906\n",
      "Epoch 20268: train_loss=217.55774, val_loss=226.52806\n",
      "Epoch 20269: train_loss=217.53403, val_loss=226.49071\n",
      "Epoch 20270: train_loss=217.51077, val_loss=226.48698\n",
      "Epoch 20271: train_loss=217.48730, val_loss=226.44171\n",
      "Epoch 20272: train_loss=217.46353, val_loss=226.44141\n",
      "Epoch 20273: train_loss=217.43910, val_loss=226.39232\n",
      "Epoch 20274: train_loss=217.41441, val_loss=226.39539\n",
      "Epoch 20275: train_loss=217.38904, val_loss=226.34369\n",
      "Epoch 20276: train_loss=217.36348, val_loss=226.34688\n",
      "Epoch 20277: train_loss=217.33781, val_loss=226.29164\n",
      "Epoch 20278: train_loss=217.31175, val_loss=226.29556\n",
      "Epoch 20279: train_loss=217.28564, val_loss=226.24094\n",
      "Epoch 20280: train_loss=217.25940, val_loss=226.24655\n",
      "Epoch 20281: train_loss=217.23343, val_loss=226.19008\n",
      "Epoch 20282: train_loss=217.20711, val_loss=226.19427\n",
      "Epoch 20283: train_loss=217.18105, val_loss=226.13554\n",
      "Epoch 20284: train_loss=217.15456, val_loss=226.14116\n",
      "Epoch 20285: train_loss=217.12849, val_loss=226.08414\n",
      "Epoch 20286: train_loss=217.10204, val_loss=226.09239\n",
      "Epoch 20287: train_loss=217.07622, val_loss=226.03549\n",
      "Epoch 20288: train_loss=217.05011, val_loss=226.04428\n",
      "Epoch 20289: train_loss=217.02477, val_loss=225.98573\n",
      "Epoch 20290: train_loss=216.99913, val_loss=225.99644\n",
      "Epoch 20291: train_loss=216.97452, val_loss=225.93703\n",
      "Epoch 20292: train_loss=216.94974, val_loss=225.95079\n",
      "Epoch 20293: train_loss=216.92627, val_loss=225.88957\n",
      "Epoch 20294: train_loss=216.90240, val_loss=225.90753\n",
      "Epoch 20295: train_loss=216.87962, val_loss=225.84489\n",
      "Epoch 20296: train_loss=216.85696, val_loss=225.86816\n",
      "Epoch 20297: train_loss=216.83601, val_loss=225.80168\n",
      "Epoch 20298: train_loss=216.81516, val_loss=225.82938\n",
      "Epoch 20299: train_loss=216.79556, val_loss=225.75929\n",
      "Epoch 20300: train_loss=216.77628, val_loss=225.79561\n",
      "Epoch 20301: train_loss=216.75873, val_loss=225.72447\n",
      "Epoch 20302: train_loss=216.74127, val_loss=225.76952\n",
      "Epoch 20303: train_loss=216.72408, val_loss=225.69286\n",
      "Epoch 20304: train_loss=216.70624, val_loss=225.73953\n",
      "Epoch 20305: train_loss=216.68704, val_loss=225.65279\n",
      "Epoch 20306: train_loss=216.66571, val_loss=225.69537\n",
      "Epoch 20307: train_loss=216.64087, val_loss=225.59926\n",
      "Epoch 20308: train_loss=216.61217, val_loss=225.63223\n",
      "Epoch 20309: train_loss=216.57922, val_loss=225.53133\n",
      "Epoch 20310: train_loss=216.54225, val_loss=225.55215\n",
      "Epoch 20311: train_loss=216.50261, val_loss=225.45454\n",
      "Epoch 20312: train_loss=216.46094, val_loss=225.46346\n",
      "Epoch 20313: train_loss=216.41743, val_loss=225.37605\n",
      "Epoch 20314: train_loss=216.37425, val_loss=225.37482\n",
      "Epoch 20315: train_loss=216.33255, val_loss=225.30312\n",
      "Epoch 20316: train_loss=216.29280, val_loss=225.29169\n",
      "Epoch 20317: train_loss=216.25537, val_loss=225.23953\n",
      "Epoch 20318: train_loss=216.22090, val_loss=225.21999\n",
      "Epoch 20319: train_loss=216.18958, val_loss=225.19003\n",
      "Epoch 20320: train_loss=216.16144, val_loss=225.16261\n",
      "Epoch 20321: train_loss=216.13556, val_loss=225.14857\n",
      "Epoch 20322: train_loss=216.11133, val_loss=225.11302\n",
      "Epoch 20323: train_loss=216.08794, val_loss=225.10995\n",
      "Epoch 20324: train_loss=216.06500, val_loss=225.06651\n",
      "Epoch 20325: train_loss=216.04213, val_loss=225.06937\n",
      "Epoch 20326: train_loss=216.01945, val_loss=225.01891\n",
      "Epoch 20327: train_loss=215.99643, val_loss=225.02640\n",
      "Epoch 20328: train_loss=215.97388, val_loss=224.97157\n",
      "Epoch 20329: train_loss=215.95119, val_loss=224.98546\n",
      "Epoch 20330: train_loss=215.92909, val_loss=224.92783\n",
      "Epoch 20331: train_loss=215.90727, val_loss=224.94733\n",
      "Epoch 20332: train_loss=215.88647, val_loss=224.88554\n",
      "Epoch 20333: train_loss=215.86584, val_loss=224.91135\n",
      "Epoch 20334: train_loss=215.84616, val_loss=224.84494\n",
      "Epoch 20335: train_loss=215.82660, val_loss=224.87784\n",
      "Epoch 20336: train_loss=215.80814, val_loss=224.80736\n",
      "Epoch 20337: train_loss=215.79034, val_loss=224.84709\n",
      "Epoch 20338: train_loss=215.77315, val_loss=224.77135\n",
      "Epoch 20339: train_loss=215.75520, val_loss=224.81544\n",
      "Epoch 20340: train_loss=215.73637, val_loss=224.73334\n",
      "Epoch 20341: train_loss=215.71602, val_loss=224.77557\n",
      "Epoch 20342: train_loss=215.69266, val_loss=224.68549\n",
      "Epoch 20343: train_loss=215.66669, val_loss=224.71909\n",
      "Epoch 20344: train_loss=215.63611, val_loss=224.62334\n",
      "Epoch 20345: train_loss=215.60295, val_loss=224.64665\n",
      "Epoch 20346: train_loss=215.56612, val_loss=224.55223\n",
      "Epoch 20347: train_loss=215.52748, val_loss=224.56404\n",
      "Epoch 20348: train_loss=215.48715, val_loss=224.47659\n",
      "Epoch 20349: train_loss=215.44670, val_loss=224.47829\n",
      "Epoch 20350: train_loss=215.40704, val_loss=224.40497\n",
      "Epoch 20351: train_loss=215.36876, val_loss=224.39859\n",
      "Epoch 20352: train_loss=215.33279, val_loss=224.34192\n",
      "Epoch 20353: train_loss=215.29893, val_loss=224.32840\n",
      "Epoch 20354: train_loss=215.26750, val_loss=224.28679\n",
      "Epoch 20355: train_loss=215.23772, val_loss=224.26706\n",
      "Epoch 20356: train_loss=215.20978, val_loss=224.23906\n",
      "Epoch 20357: train_loss=215.18311, val_loss=224.21304\n",
      "Epoch 20358: train_loss=215.15756, val_loss=224.19453\n",
      "Epoch 20359: train_loss=215.13293, val_loss=224.16138\n",
      "Epoch 20360: train_loss=215.10898, val_loss=224.15054\n",
      "Epoch 20361: train_loss=215.08569, val_loss=224.11118\n",
      "Epoch 20362: train_loss=215.06308, val_loss=224.10991\n",
      "Epoch 20363: train_loss=215.04146, val_loss=224.06686\n",
      "Epoch 20364: train_loss=215.02048, val_loss=224.07570\n",
      "Epoch 20365: train_loss=215.00063, val_loss=224.02686\n",
      "Epoch 20366: train_loss=214.98169, val_loss=224.04453\n",
      "Epoch 20367: train_loss=214.96400, val_loss=223.98891\n",
      "Epoch 20368: train_loss=214.94745, val_loss=224.01749\n",
      "Epoch 20369: train_loss=214.93219, val_loss=223.95627\n",
      "Epoch 20370: train_loss=214.91861, val_loss=223.99788\n",
      "Epoch 20371: train_loss=214.90674, val_loss=223.93225\n",
      "Epoch 20372: train_loss=214.89655, val_loss=223.98636\n",
      "Epoch 20373: train_loss=214.88672, val_loss=223.91306\n",
      "Epoch 20374: train_loss=214.87772, val_loss=223.97296\n",
      "Epoch 20375: train_loss=214.86601, val_loss=223.88594\n",
      "Epoch 20376: train_loss=214.85281, val_loss=223.94278\n",
      "Epoch 20377: train_loss=214.83424, val_loss=223.84232\n",
      "Epoch 20378: train_loss=214.81149, val_loss=223.88864\n",
      "Epoch 20379: train_loss=214.78058, val_loss=223.77884\n",
      "Epoch 20380: train_loss=214.74420, val_loss=223.80760\n",
      "Epoch 20381: train_loss=214.69997, val_loss=223.69632\n",
      "Epoch 20382: train_loss=214.65263, val_loss=223.70654\n",
      "Epoch 20383: train_loss=214.60254, val_loss=223.60585\n",
      "Epoch 20384: train_loss=214.55333, val_loss=223.60184\n",
      "Epoch 20385: train_loss=214.50690, val_loss=223.52388\n",
      "Epoch 20386: train_loss=214.46411, val_loss=223.51184\n",
      "Epoch 20387: train_loss=214.42642, val_loss=223.46259\n",
      "Epoch 20388: train_loss=214.39294, val_loss=223.44482\n",
      "Epoch 20389: train_loss=214.36363, val_loss=223.41870\n",
      "Epoch 20390: train_loss=214.33733, val_loss=223.39293\n",
      "Epoch 20391: train_loss=214.31339, val_loss=223.38107\n",
      "Epoch 20392: train_loss=214.29115, val_loss=223.34427\n",
      "Epoch 20393: train_loss=214.26982, val_loss=223.34361\n",
      "Epoch 20394: train_loss=214.24954, val_loss=223.30058\n",
      "Epoch 20395: train_loss=214.22926, val_loss=223.31061\n",
      "Epoch 20396: train_loss=214.20943, val_loss=223.26205\n",
      "Epoch 20397: train_loss=214.18944, val_loss=223.27835\n",
      "Epoch 20398: train_loss=214.17006, val_loss=223.22102\n",
      "Epoch 20399: train_loss=214.14983, val_loss=223.23943\n",
      "Epoch 20400: train_loss=214.12965, val_loss=223.17624\n",
      "Epoch 20401: train_loss=214.10855, val_loss=223.19907\n",
      "Epoch 20402: train_loss=214.08742, val_loss=223.13393\n",
      "Epoch 20403: train_loss=214.06555, val_loss=223.16034\n",
      "Epoch 20404: train_loss=214.04385, val_loss=223.09221\n",
      "Epoch 20405: train_loss=214.02133, val_loss=223.11896\n",
      "Epoch 20406: train_loss=213.99867, val_loss=223.04663\n",
      "Epoch 20407: train_loss=213.97514, val_loss=223.07263\n",
      "Epoch 20408: train_loss=213.95108, val_loss=222.99821\n",
      "Epoch 20409: train_loss=213.92654, val_loss=223.02409\n",
      "Epoch 20410: train_loss=213.90172, val_loss=222.94908\n",
      "Epoch 20411: train_loss=213.87604, val_loss=222.97516\n",
      "Epoch 20412: train_loss=213.84995, val_loss=222.90016\n",
      "Epoch 20413: train_loss=213.82304, val_loss=222.92293\n",
      "Epoch 20414: train_loss=213.79547, val_loss=222.84673\n",
      "Epoch 20415: train_loss=213.76678, val_loss=222.86337\n",
      "Epoch 20416: train_loss=213.73784, val_loss=222.78879\n",
      "Epoch 20417: train_loss=213.70790, val_loss=222.80141\n",
      "Epoch 20418: train_loss=213.67784, val_loss=222.73203\n",
      "Epoch 20419: train_loss=213.64719, val_loss=222.73962\n",
      "Epoch 20420: train_loss=213.61710, val_loss=222.67572\n",
      "Epoch 20421: train_loss=213.58719, val_loss=222.67734\n",
      "Epoch 20422: train_loss=213.55765, val_loss=222.61874\n",
      "Epoch 20423: train_loss=213.52844, val_loss=222.61577\n",
      "Epoch 20424: train_loss=213.49979, val_loss=222.56400\n",
      "Epoch 20425: train_loss=213.47137, val_loss=222.55690\n",
      "Epoch 20426: train_loss=213.44345, val_loss=222.51318\n",
      "Epoch 20427: train_loss=213.41618, val_loss=222.50250\n",
      "Epoch 20428: train_loss=213.38940, val_loss=222.46451\n",
      "Epoch 20429: train_loss=213.36296, val_loss=222.45013\n",
      "Epoch 20430: train_loss=213.33687, val_loss=222.41669\n",
      "Epoch 20431: train_loss=213.31113, val_loss=222.39764\n",
      "Epoch 20432: train_loss=213.28564, val_loss=222.36687\n",
      "Epoch 20433: train_loss=213.26028, val_loss=222.34453\n",
      "Epoch 20434: train_loss=213.23515, val_loss=222.31851\n",
      "Epoch 20435: train_loss=213.21008, val_loss=222.29506\n",
      "Epoch 20436: train_loss=213.18506, val_loss=222.27158\n",
      "Epoch 20437: train_loss=213.16016, val_loss=222.24458\n",
      "Epoch 20438: train_loss=213.13524, val_loss=222.22166\n",
      "Epoch 20439: train_loss=213.11034, val_loss=222.19286\n",
      "Epoch 20440: train_loss=213.08569, val_loss=222.17461\n",
      "Epoch 20441: train_loss=213.06108, val_loss=222.14467\n",
      "Epoch 20442: train_loss=213.03667, val_loss=222.13124\n",
      "Epoch 20443: train_loss=213.01266, val_loss=222.09706\n",
      "Epoch 20444: train_loss=212.98915, val_loss=222.08952\n",
      "Epoch 20445: train_loss=212.96643, val_loss=222.05009\n",
      "Epoch 20446: train_loss=212.94505, val_loss=222.05368\n",
      "Epoch 20447: train_loss=212.92584, val_loss=222.00937\n",
      "Epoch 20448: train_loss=212.90936, val_loss=222.03227\n",
      "Epoch 20449: train_loss=212.89667, val_loss=221.98447\n",
      "Epoch 20450: train_loss=212.88924, val_loss=222.03635\n",
      "Epoch 20451: train_loss=212.88895, val_loss=221.98482\n",
      "Epoch 20452: train_loss=212.89667, val_loss=222.07326\n",
      "Epoch 20453: train_loss=212.91350, val_loss=222.01692\n",
      "Epoch 20454: train_loss=212.93916, val_loss=222.14352\n",
      "Epoch 20455: train_loss=212.97134, val_loss=222.07584\n",
      "Epoch 20456: train_loss=213.00832, val_loss=222.22502\n",
      "Epoch 20457: train_loss=213.04085, val_loss=222.12546\n",
      "Epoch 20458: train_loss=213.06297, val_loss=222.24870\n",
      "Epoch 20459: train_loss=213.05682, val_loss=222.08125\n",
      "Epoch 20460: train_loss=213.01740, val_loss=222.12129\n",
      "Epoch 20461: train_loss=212.93517, val_loss=221.89743\n",
      "Epoch 20462: train_loss=212.82310, val_loss=221.86301\n",
      "Epoch 20463: train_loss=212.69640, val_loss=221.67397\n",
      "Epoch 20464: train_loss=212.57887, val_loss=221.63100\n",
      "Epoch 20465: train_loss=212.49080, val_loss=221.55960\n",
      "Epoch 20466: train_loss=212.43910, val_loss=221.53690\n",
      "Epoch 20467: train_loss=212.42050, val_loss=221.56989\n",
      "Epoch 20468: train_loss=212.42509, val_loss=221.53874\n",
      "Epoch 20469: train_loss=212.43861, val_loss=221.60938\n",
      "Epoch 20470: train_loss=212.44844, val_loss=221.53610\n",
      "Epoch 20471: train_loss=212.44360, val_loss=221.58235\n",
      "Epoch 20472: train_loss=212.41843, val_loss=221.46890\n",
      "Epoch 20473: train_loss=212.37498, val_loss=221.47514\n",
      "Epoch 20474: train_loss=212.31992, val_loss=221.36702\n",
      "Epoch 20475: train_loss=212.26167, val_loss=221.35266\n",
      "Epoch 20476: train_loss=212.20940, val_loss=221.29053\n",
      "Epoch 20477: train_loss=212.16772, val_loss=221.26801\n",
      "Epoch 20478: train_loss=212.13820, val_loss=221.25597\n",
      "Epoch 20479: train_loss=212.11856, val_loss=221.22318\n",
      "Epoch 20480: train_loss=212.10477, val_loss=221.24193\n",
      "Epoch 20481: train_loss=212.09277, val_loss=221.19199\n",
      "Epoch 20482: train_loss=212.07858, val_loss=221.21458\n",
      "Epoch 20483: train_loss=212.05943, val_loss=221.14780\n",
      "Epoch 20484: train_loss=212.03464, val_loss=221.15829\n",
      "Epoch 20485: train_loss=212.00455, val_loss=221.08763\n",
      "Epoch 20486: train_loss=211.97096, val_loss=221.08463\n",
      "Epoch 20487: train_loss=211.93648, val_loss=221.02667\n",
      "Epoch 20488: train_loss=211.90302, val_loss=221.01251\n",
      "Epoch 20489: train_loss=211.87204, val_loss=220.97467\n",
      "Epoch 20490: train_loss=211.84399, val_loss=220.95131\n",
      "Epoch 20491: train_loss=211.81876, val_loss=220.93423\n",
      "Epoch 20492: train_loss=211.79585, val_loss=220.90279\n",
      "Epoch 20493: train_loss=211.77432, val_loss=220.89835\n",
      "Epoch 20494: train_loss=211.75308, val_loss=220.85760\n",
      "Epoch 20495: train_loss=211.73134, val_loss=220.85776\n",
      "Epoch 20496: train_loss=211.70920, val_loss=220.81097\n",
      "Epoch 20497: train_loss=211.68594, val_loss=220.81216\n",
      "Epoch 20498: train_loss=211.66196, val_loss=220.76392\n",
      "Epoch 20499: train_loss=211.63702, val_loss=220.76392\n",
      "Epoch 20500: train_loss=211.61182, val_loss=220.71602\n",
      "Epoch 20501: train_loss=211.58606, val_loss=220.71178\n",
      "Epoch 20502: train_loss=211.56020, val_loss=220.66582\n",
      "Epoch 20503: train_loss=211.53423, val_loss=220.65848\n",
      "Epoch 20504: train_loss=211.50824, val_loss=220.61668\n",
      "Epoch 20505: train_loss=211.48251, val_loss=220.60733\n",
      "Epoch 20506: train_loss=211.45708, val_loss=220.56839\n",
      "Epoch 20507: train_loss=211.43178, val_loss=220.55502\n",
      "Epoch 20508: train_loss=211.40649, val_loss=220.51920\n",
      "Epoch 20509: train_loss=211.38147, val_loss=220.50490\n",
      "Epoch 20510: train_loss=211.35640, val_loss=220.47366\n",
      "Epoch 20511: train_loss=211.33156, val_loss=220.45764\n",
      "Epoch 20512: train_loss=211.30678, val_loss=220.42784\n",
      "Epoch 20513: train_loss=211.28220, val_loss=220.40894\n",
      "Epoch 20514: train_loss=211.25758, val_loss=220.38017\n",
      "Epoch 20515: train_loss=211.23308, val_loss=220.36029\n",
      "Epoch 20516: train_loss=211.20863, val_loss=220.33395\n",
      "Epoch 20517: train_loss=211.18430, val_loss=220.31499\n",
      "Epoch 20518: train_loss=211.15996, val_loss=220.28789\n",
      "Epoch 20519: train_loss=211.13582, val_loss=220.26926\n",
      "Epoch 20520: train_loss=211.11180, val_loss=220.23962\n",
      "Epoch 20521: train_loss=211.08784, val_loss=220.22350\n",
      "Epoch 20522: train_loss=211.06427, val_loss=220.19160\n",
      "Epoch 20523: train_loss=211.04121, val_loss=220.18320\n",
      "Epoch 20524: train_loss=211.01875, val_loss=220.14789\n",
      "Epoch 20525: train_loss=210.99731, val_loss=220.14873\n",
      "Epoch 20526: train_loss=210.97694, val_loss=220.10771\n",
      "Epoch 20527: train_loss=210.95802, val_loss=220.11957\n",
      "Epoch 20528: train_loss=210.94064, val_loss=220.07239\n",
      "Epoch 20529: train_loss=210.92543, val_loss=220.09935\n",
      "Epoch 20530: train_loss=210.91235, val_loss=220.04655\n",
      "Epoch 20531: train_loss=210.90259, val_loss=220.09392\n",
      "Epoch 20532: train_loss=210.89688, val_loss=220.03552\n",
      "Epoch 20533: train_loss=210.89519, val_loss=220.10815\n",
      "Epoch 20534: train_loss=210.89868, val_loss=220.04251\n",
      "Epoch 20535: train_loss=210.90640, val_loss=220.13985\n",
      "Epoch 20536: train_loss=210.91785, val_loss=220.06244\n",
      "Epoch 20537: train_loss=210.93079, val_loss=220.17241\n",
      "Epoch 20538: train_loss=210.94002, val_loss=220.07314\n",
      "Epoch 20539: train_loss=210.94398, val_loss=220.17180\n",
      "Epoch 20540: train_loss=210.93137, val_loss=220.03658\n",
      "Epoch 20541: train_loss=210.90359, val_loss=220.09177\n",
      "Epoch 20542: train_loss=210.85088, val_loss=219.92499\n",
      "Epoch 20543: train_loss=210.78264, val_loss=219.93143\n",
      "Epoch 20544: train_loss=210.70120, val_loss=219.77399\n",
      "Epoch 20545: train_loss=210.61717, val_loss=219.75639\n",
      "Epoch 20546: train_loss=210.54248, val_loss=219.65756\n",
      "Epoch 20547: train_loss=210.48148, val_loss=219.63565\n",
      "Epoch 20548: train_loss=210.43872, val_loss=219.60800\n",
      "Epoch 20549: train_loss=210.41281, val_loss=219.58029\n",
      "Epoch 20550: train_loss=210.39964, val_loss=219.60228\n",
      "Epoch 20551: train_loss=210.39372, val_loss=219.55902\n",
      "Epoch 20552: train_loss=210.38884, val_loss=219.60025\n",
      "Epoch 20553: train_loss=210.38118, val_loss=219.53482\n",
      "Epoch 20554: train_loss=210.36627, val_loss=219.57092\n",
      "Epoch 20555: train_loss=210.34499, val_loss=219.48959\n",
      "Epoch 20556: train_loss=210.31520, val_loss=219.50882\n",
      "Epoch 20557: train_loss=210.28091, val_loss=219.42647\n",
      "Epoch 20558: train_loss=210.24278, val_loss=219.42789\n",
      "Epoch 20559: train_loss=210.20442, val_loss=219.36008\n",
      "Epoch 20560: train_loss=210.16742, val_loss=219.34937\n",
      "Epoch 20561: train_loss=210.13361, val_loss=219.30682\n",
      "Epoch 20562: train_loss=210.10376, val_loss=219.28749\n",
      "Epoch 20563: train_loss=210.07787, val_loss=219.26828\n",
      "Epoch 20564: train_loss=210.05495, val_loss=219.23973\n",
      "Epoch 20565: train_loss=210.03384, val_loss=219.23592\n",
      "Epoch 20566: train_loss=210.01414, val_loss=219.19733\n",
      "Epoch 20567: train_loss=209.99451, val_loss=219.20219\n",
      "Epoch 20568: train_loss=209.97470, val_loss=219.15631\n",
      "Epoch 20569: train_loss=209.95389, val_loss=219.16557\n",
      "Epoch 20570: train_loss=209.93256, val_loss=219.11559\n",
      "Epoch 20571: train_loss=209.90987, val_loss=219.12509\n",
      "Epoch 20572: train_loss=209.88661, val_loss=219.07251\n",
      "Epoch 20573: train_loss=209.86205, val_loss=219.07848\n",
      "Epoch 20574: train_loss=209.83717, val_loss=219.02550\n",
      "Epoch 20575: train_loss=209.81149, val_loss=219.02698\n",
      "Epoch 20576: train_loss=209.78586, val_loss=218.97635\n",
      "Epoch 20577: train_loss=209.75993, val_loss=218.97426\n",
      "Epoch 20578: train_loss=209.73389, val_loss=218.92886\n",
      "Epoch 20579: train_loss=209.70810, val_loss=218.92287\n",
      "Epoch 20580: train_loss=209.68237, val_loss=218.88235\n",
      "Epoch 20581: train_loss=209.65712, val_loss=218.87309\n",
      "Epoch 20582: train_loss=209.63206, val_loss=218.83694\n",
      "Epoch 20583: train_loss=209.60738, val_loss=218.82356\n",
      "Epoch 20584: train_loss=209.58289, val_loss=218.79082\n",
      "Epoch 20585: train_loss=209.55865, val_loss=218.77565\n",
      "Epoch 20586: train_loss=209.53468, val_loss=218.74658\n",
      "Epoch 20587: train_loss=209.51074, val_loss=218.73114\n",
      "Epoch 20588: train_loss=209.48698, val_loss=218.70412\n",
      "Epoch 20589: train_loss=209.46333, val_loss=218.68678\n",
      "Epoch 20590: train_loss=209.43971, val_loss=218.65886\n",
      "Epoch 20591: train_loss=209.41620, val_loss=218.64078\n",
      "Epoch 20592: train_loss=209.39272, val_loss=218.61339\n",
      "Epoch 20593: train_loss=209.36929, val_loss=218.59833\n",
      "Epoch 20594: train_loss=209.34605, val_loss=218.57091\n",
      "Epoch 20595: train_loss=209.32280, val_loss=218.55705\n",
      "Epoch 20596: train_loss=209.29985, val_loss=218.52626\n",
      "Epoch 20597: train_loss=209.27722, val_loss=218.51602\n",
      "Epoch 20598: train_loss=209.25519, val_loss=218.48094\n",
      "Epoch 20599: train_loss=209.23390, val_loss=218.47983\n",
      "Epoch 20600: train_loss=209.21390, val_loss=218.43996\n",
      "Epoch 20601: train_loss=209.19531, val_loss=218.45279\n",
      "Epoch 20602: train_loss=209.17928, val_loss=218.40820\n",
      "Epoch 20603: train_loss=209.16608, val_loss=218.44235\n",
      "Epoch 20604: train_loss=209.15724, val_loss=218.39197\n",
      "Epoch 20605: train_loss=209.15361, val_loss=218.45537\n",
      "Epoch 20606: train_loss=209.15704, val_loss=218.39909\n",
      "Epoch 20607: train_loss=209.16867, val_loss=218.50090\n",
      "Epoch 20608: train_loss=209.18956, val_loss=218.44017\n",
      "Epoch 20609: train_loss=209.22035, val_loss=218.58560\n",
      "Epoch 20610: train_loss=209.25894, val_loss=218.51643\n",
      "Epoch 20611: train_loss=209.30466, val_loss=218.69070\n",
      "Epoch 20612: train_loss=209.34651, val_loss=218.58517\n",
      "Epoch 20613: train_loss=209.37784, val_loss=218.72839\n",
      "Epoch 20614: train_loss=209.37448, val_loss=218.54106\n",
      "Epoch 20615: train_loss=209.33144, val_loss=218.58421\n",
      "Epoch 20616: train_loss=209.23648, val_loss=218.33241\n",
      "Epoch 20617: train_loss=209.10750, val_loss=218.28879\n",
      "Epoch 20618: train_loss=208.96381, val_loss=218.09035\n",
      "Epoch 20619: train_loss=208.83864, val_loss=218.04724\n",
      "Epoch 20620: train_loss=208.75447, val_loss=218.00117\n",
      "Epoch 20621: train_loss=208.71748, val_loss=217.98389\n",
      "Epoch 20622: train_loss=208.71887, val_loss=218.05055\n",
      "Epoch 20623: train_loss=208.74106, val_loss=218.00954\n",
      "Epoch 20624: train_loss=208.76424, val_loss=218.09244\n",
      "Epoch 20625: train_loss=208.77060, val_loss=217.99211\n",
      "Epoch 20626: train_loss=208.75189, val_loss=218.02873\n",
      "Epoch 20627: train_loss=208.70795, val_loss=217.90019\n",
      "Epoch 20628: train_loss=208.64807, val_loss=217.89502\n",
      "Epoch 20629: train_loss=208.58473, val_loss=217.80290\n",
      "Epoch 20630: train_loss=208.53000, val_loss=217.78357\n",
      "Epoch 20631: train_loss=208.48997, val_loss=217.75761\n",
      "Epoch 20632: train_loss=208.46579, val_loss=217.73035\n",
      "Epoch 20633: train_loss=208.45355, val_loss=217.75415\n",
      "Epoch 20634: train_loss=208.44710, val_loss=217.70816\n",
      "Epoch 20635: train_loss=208.44006, val_loss=217.74304\n",
      "Epoch 20636: train_loss=208.42648, val_loss=217.67259\n",
      "Epoch 20637: train_loss=208.40475, val_loss=217.69188\n",
      "Epoch 20638: train_loss=208.37512, val_loss=217.61342\n",
      "Epoch 20639: train_loss=208.34055, val_loss=217.61328\n",
      "Epoch 20640: train_loss=208.30424, val_loss=217.55188\n",
      "Epoch 20641: train_loss=208.26990, val_loss=217.53908\n",
      "Epoch 20642: train_loss=208.23938, val_loss=217.50714\n",
      "Epoch 20643: train_loss=208.21349, val_loss=217.48405\n",
      "Epoch 20644: train_loss=208.19177, val_loss=217.47729\n",
      "Epoch 20645: train_loss=208.17278, val_loss=217.44250\n",
      "Epoch 20646: train_loss=208.15518, val_loss=217.44937\n",
      "Epoch 20647: train_loss=208.13741, val_loss=217.40260\n",
      "Epoch 20648: train_loss=208.11874, val_loss=217.41371\n",
      "Epoch 20649: train_loss=208.09804, val_loss=217.36046\n",
      "Epoch 20650: train_loss=208.07533, val_loss=217.36824\n",
      "Epoch 20651: train_loss=208.05069, val_loss=217.31393\n",
      "Epoch 20652: train_loss=208.02496, val_loss=217.31424\n",
      "Epoch 20653: train_loss=207.99850, val_loss=217.26500\n",
      "Epoch 20654: train_loss=207.97218, val_loss=217.25812\n",
      "Epoch 20655: train_loss=207.94614, val_loss=217.21867\n",
      "Epoch 20656: train_loss=207.92085, val_loss=217.20569\n",
      "Epoch 20657: train_loss=207.89609, val_loss=217.17679\n",
      "Epoch 20658: train_loss=207.87241, val_loss=217.15739\n",
      "Epoch 20659: train_loss=207.84926, val_loss=217.13727\n",
      "Epoch 20660: train_loss=207.82674, val_loss=217.11179\n",
      "Epoch 20661: train_loss=207.80452, val_loss=217.09845\n",
      "Epoch 20662: train_loss=207.78264, val_loss=217.06812\n",
      "Epoch 20663: train_loss=207.76089, val_loss=217.06007\n",
      "Epoch 20664: train_loss=207.73946, val_loss=217.02545\n",
      "Epoch 20665: train_loss=207.71805, val_loss=217.02235\n",
      "Epoch 20666: train_loss=207.69667, val_loss=216.98444\n",
      "Epoch 20667: train_loss=207.67567, val_loss=216.98616\n",
      "Epoch 20668: train_loss=207.65482, val_loss=216.94330\n",
      "Epoch 20669: train_loss=207.63425, val_loss=216.94835\n",
      "Epoch 20670: train_loss=207.61371, val_loss=216.90099\n",
      "Epoch 20671: train_loss=207.59341, val_loss=216.91078\n",
      "Epoch 20672: train_loss=207.57297, val_loss=216.86026\n",
      "Epoch 20673: train_loss=207.55305, val_loss=216.87570\n",
      "Epoch 20674: train_loss=207.53293, val_loss=216.82204\n",
      "Epoch 20675: train_loss=207.51352, val_loss=216.84137\n",
      "Epoch 20676: train_loss=207.49396, val_loss=216.78232\n",
      "Epoch 20677: train_loss=207.47507, val_loss=216.80608\n",
      "Epoch 20678: train_loss=207.45575, val_loss=216.74388\n",
      "Epoch 20679: train_loss=207.43739, val_loss=216.77361\n",
      "Epoch 20680: train_loss=207.41872, val_loss=216.70802\n",
      "Epoch 20681: train_loss=207.40041, val_loss=216.74266\n",
      "Epoch 20682: train_loss=207.38170, val_loss=216.67268\n",
      "Epoch 20683: train_loss=207.36340, val_loss=216.70992\n",
      "Epoch 20684: train_loss=207.34431, val_loss=216.63503\n",
      "Epoch 20685: train_loss=207.32581, val_loss=216.67407\n",
      "Epoch 20686: train_loss=207.30602, val_loss=216.59416\n",
      "Epoch 20687: train_loss=207.28555, val_loss=216.63318\n",
      "Epoch 20688: train_loss=207.26360, val_loss=216.55135\n",
      "Epoch 20689: train_loss=207.24107, val_loss=216.58917\n",
      "Epoch 20690: train_loss=207.21724, val_loss=216.50662\n",
      "Epoch 20691: train_loss=207.19267, val_loss=216.54066\n",
      "Epoch 20692: train_loss=207.16689, val_loss=216.45810\n",
      "Epoch 20693: train_loss=207.14012, val_loss=216.48604\n",
      "Epoch 20694: train_loss=207.11263, val_loss=216.40678\n",
      "Epoch 20695: train_loss=207.08455, val_loss=216.42781\n",
      "Epoch 20696: train_loss=207.05632, val_loss=216.35451\n",
      "Epoch 20697: train_loss=207.02826, val_loss=216.36928\n",
      "Epoch 20698: train_loss=207.00027, val_loss=216.30388\n",
      "Epoch 20699: train_loss=206.97302, val_loss=216.31227\n",
      "Epoch 20700: train_loss=206.94611, val_loss=216.25349\n",
      "Epoch 20701: train_loss=206.91991, val_loss=216.25668\n",
      "Epoch 20702: train_loss=206.89401, val_loss=216.20612\n",
      "Epoch 20703: train_loss=206.86897, val_loss=216.20769\n",
      "Epoch 20704: train_loss=206.84450, val_loss=216.16435\n",
      "Epoch 20705: train_loss=206.82056, val_loss=216.16286\n",
      "Epoch 20706: train_loss=206.79691, val_loss=216.12230\n",
      "Epoch 20707: train_loss=206.77370, val_loss=216.11784\n",
      "Epoch 20708: train_loss=206.75081, val_loss=216.07907\n",
      "Epoch 20709: train_loss=206.72832, val_loss=216.07491\n",
      "Epoch 20710: train_loss=206.70598, val_loss=216.03729\n",
      "Epoch 20711: train_loss=206.68396, val_loss=216.03493\n",
      "Epoch 20712: train_loss=206.66214, val_loss=215.99573\n",
      "Epoch 20713: train_loss=206.64061, val_loss=215.99565\n",
      "Epoch 20714: train_loss=206.61949, val_loss=215.95399\n",
      "Epoch 20715: train_loss=206.59892, val_loss=215.95914\n",
      "Epoch 20716: train_loss=206.57896, val_loss=215.91348\n",
      "Epoch 20717: train_loss=206.55986, val_loss=215.92679\n",
      "Epoch 20718: train_loss=206.54158, val_loss=215.87631\n",
      "Epoch 20719: train_loss=206.52464, val_loss=215.90176\n",
      "Epoch 20720: train_loss=206.50943, val_loss=215.84528\n",
      "Epoch 20721: train_loss=206.49648, val_loss=215.88686\n",
      "Epoch 20722: train_loss=206.48601, val_loss=215.82458\n",
      "Epoch 20723: train_loss=206.47971, val_loss=215.88988\n",
      "Epoch 20724: train_loss=206.47760, val_loss=215.82051\n",
      "Epoch 20725: train_loss=206.48126, val_loss=215.91670\n",
      "Epoch 20726: train_loss=206.49126, val_loss=215.83911\n",
      "Epoch 20727: train_loss=206.50845, val_loss=215.96648\n",
      "Epoch 20728: train_loss=206.52766, val_loss=215.87372\n",
      "Epoch 20729: train_loss=206.55063, val_loss=216.01678\n",
      "Epoch 20730: train_loss=206.56618, val_loss=215.89384\n",
      "Epoch 20731: train_loss=206.57538, val_loss=216.01871\n",
      "Epoch 20732: train_loss=206.56143, val_loss=215.84955\n",
      "Epoch 20733: train_loss=206.52795, val_loss=215.91827\n",
      "Epoch 20734: train_loss=206.46376, val_loss=215.71616\n",
      "Epoch 20735: train_loss=206.38133, val_loss=215.72592\n",
      "Epoch 20736: train_loss=206.28596, val_loss=215.55145\n",
      "Epoch 20737: train_loss=206.19496, val_loss=215.53523\n",
      "Epoch 20738: train_loss=206.11937, val_loss=215.44771\n",
      "Epoch 20739: train_loss=206.06638, val_loss=215.42717\n",
      "Epoch 20740: train_loss=206.03587, val_loss=215.42792\n",
      "Epoch 20741: train_loss=206.02385, val_loss=215.39598\n",
      "Epoch 20742: train_loss=206.02339, val_loss=215.45088\n",
      "Epoch 20743: train_loss=206.02684, val_loss=215.39238\n",
      "Epoch 20744: train_loss=206.02792, val_loss=215.45718\n",
      "Epoch 20745: train_loss=206.02037, val_loss=215.36604\n",
      "Epoch 20746: train_loss=206.00269, val_loss=215.41118\n",
      "Epoch 20747: train_loss=205.97354, val_loss=215.30557\n",
      "Epoch 20748: train_loss=205.93687, val_loss=215.32593\n",
      "Epoch 20749: train_loss=205.89508, val_loss=215.23405\n",
      "Epoch 20750: train_loss=205.85329, val_loss=215.23491\n",
      "Epoch 20751: train_loss=205.81389, val_loss=215.17639\n",
      "Epoch 20752: train_loss=205.77986, val_loss=215.16292\n",
      "Epoch 20753: train_loss=205.75200, val_loss=215.14247\n",
      "Epoch 20754: train_loss=205.73015, val_loss=215.11482\n",
      "Epoch 20755: train_loss=205.71269, val_loss=215.12134\n",
      "Epoch 20756: train_loss=205.69743, val_loss=215.07693\n",
      "Epoch 20757: train_loss=205.68231, val_loss=215.09537\n",
      "Epoch 20758: train_loss=205.66597, val_loss=215.03964\n",
      "Epoch 20759: train_loss=205.64760, val_loss=215.06032\n",
      "Epoch 20760: train_loss=205.62675, val_loss=214.99977\n",
      "Epoch 20761: train_loss=205.60374, val_loss=215.01451\n",
      "Epoch 20762: train_loss=205.57866, val_loss=214.95482\n",
      "Epoch 20763: train_loss=205.55252, val_loss=214.95953\n",
      "Epoch 20764: train_loss=205.52576, val_loss=214.90753\n",
      "Epoch 20765: train_loss=205.49951, val_loss=214.90364\n",
      "Epoch 20766: train_loss=205.47382, val_loss=214.86372\n",
      "Epoch 20767: train_loss=205.44920, val_loss=214.85176\n",
      "Epoch 20768: train_loss=205.42552, val_loss=214.82388\n",
      "Epoch 20769: train_loss=205.40262, val_loss=214.80502\n",
      "Epoch 20770: train_loss=205.38052, val_loss=214.78741\n",
      "Epoch 20771: train_loss=205.35892, val_loss=214.76079\n",
      "Epoch 20772: train_loss=205.33780, val_loss=214.75012\n",
      "Epoch 20773: train_loss=205.31682, val_loss=214.71584\n",
      "Epoch 20774: train_loss=205.29601, val_loss=214.71217\n",
      "Epoch 20775: train_loss=205.27541, val_loss=214.67421\n",
      "Epoch 20776: train_loss=205.25497, val_loss=214.67868\n",
      "Epoch 20777: train_loss=205.23465, val_loss=214.63545\n",
      "Epoch 20778: train_loss=205.21449, val_loss=214.64415\n",
      "Epoch 20779: train_loss=205.19429, val_loss=214.59341\n",
      "Epoch 20780: train_loss=205.17432, val_loss=214.60655\n",
      "Epoch 20781: train_loss=205.15437, val_loss=214.55144\n",
      "Epoch 20782: train_loss=205.13467, val_loss=214.57202\n",
      "Epoch 20783: train_loss=205.11473, val_loss=214.51332\n",
      "Epoch 20784: train_loss=205.09528, val_loss=214.53996\n",
      "Epoch 20785: train_loss=205.07584, val_loss=214.47552\n",
      "Epoch 20786: train_loss=205.05685, val_loss=214.50700\n",
      "Epoch 20787: train_loss=205.03810, val_loss=214.43678\n",
      "Epoch 20788: train_loss=205.02026, val_loss=214.47552\n",
      "Epoch 20789: train_loss=205.00253, val_loss=214.40041\n",
      "Epoch 20790: train_loss=204.98579, val_loss=214.44780\n",
      "Epoch 20791: train_loss=204.96867, val_loss=214.36667\n",
      "Epoch 20792: train_loss=204.95227, val_loss=214.42049\n",
      "Epoch 20793: train_loss=204.93501, val_loss=214.33250\n",
      "Epoch 20794: train_loss=204.91774, val_loss=214.38960\n",
      "Epoch 20795: train_loss=204.89880, val_loss=214.29553\n",
      "Epoch 20796: train_loss=204.87958, val_loss=214.35283\n",
      "Epoch 20797: train_loss=204.85782, val_loss=214.25294\n",
      "Epoch 20798: train_loss=204.83493, val_loss=214.30544\n",
      "Epoch 20799: train_loss=204.80832, val_loss=214.20232\n",
      "Epoch 20800: train_loss=204.78027, val_loss=214.24612\n",
      "Epoch 20801: train_loss=204.74861, val_loss=214.14407\n",
      "Epoch 20802: train_loss=204.71597, val_loss=214.17729\n",
      "Epoch 20803: train_loss=204.68137, val_loss=214.08311\n",
      "Epoch 20804: train_loss=204.64711, val_loss=214.10565\n",
      "Epoch 20805: train_loss=204.61307, val_loss=214.02423\n",
      "Epoch 20806: train_loss=204.58017, val_loss=214.03722\n",
      "Epoch 20807: train_loss=204.54857, val_loss=213.97069\n",
      "Epoch 20808: train_loss=204.51857, val_loss=213.97350\n",
      "Epoch 20809: train_loss=204.48969, val_loss=213.92174\n",
      "Epoch 20810: train_loss=204.46233, val_loss=213.91661\n",
      "Epoch 20811: train_loss=204.43642, val_loss=213.87926\n",
      "Epoch 20812: train_loss=204.41165, val_loss=213.86580\n",
      "Epoch 20813: train_loss=204.38815, val_loss=213.83958\n",
      "Epoch 20814: train_loss=204.36536, val_loss=213.81937\n",
      "Epoch 20815: train_loss=204.34317, val_loss=213.80162\n",
      "Epoch 20816: train_loss=204.32137, val_loss=213.77519\n",
      "Epoch 20817: train_loss=204.30002, val_loss=213.76443\n",
      "Epoch 20818: train_loss=204.27898, val_loss=213.73238\n",
      "Epoch 20819: train_loss=204.25829, val_loss=213.72951\n",
      "Epoch 20820: train_loss=204.23807, val_loss=213.69220\n",
      "Epoch 20821: train_loss=204.21831, val_loss=213.69870\n",
      "Epoch 20822: train_loss=204.19910, val_loss=213.65549\n",
      "Epoch 20823: train_loss=204.18071, val_loss=213.67137\n",
      "Epoch 20824: train_loss=204.16316, val_loss=213.62039\n",
      "Epoch 20825: train_loss=204.14677, val_loss=213.64742\n",
      "Epoch 20826: train_loss=204.13156, val_loss=213.58841\n",
      "Epoch 20827: train_loss=204.11865, val_loss=213.63258\n",
      "Epoch 20828: train_loss=204.10808, val_loss=213.56668\n",
      "Epoch 20829: train_loss=204.10132, val_loss=213.63412\n",
      "Epoch 20830: train_loss=204.09811, val_loss=213.55804\n",
      "Epoch 20831: train_loss=204.09933, val_loss=213.65074\n",
      "Epoch 20832: train_loss=204.10344, val_loss=213.56342\n",
      "Epoch 20833: train_loss=204.11256, val_loss=213.68291\n",
      "Epoch 20834: train_loss=204.12311, val_loss=213.58122\n",
      "Epoch 20835: train_loss=204.13654, val_loss=213.71581\n",
      "Epoch 20836: train_loss=204.14374, val_loss=213.58690\n",
      "Epoch 20837: train_loss=204.14590, val_loss=213.70963\n",
      "Epoch 20838: train_loss=204.13179, val_loss=213.54686\n",
      "Epoch 20839: train_loss=204.10448, val_loss=213.63066\n",
      "Epoch 20840: train_loss=204.05476, val_loss=213.44577\n",
      "Epoch 20841: train_loss=203.99138, val_loss=213.47978\n",
      "Epoch 20842: train_loss=203.91422, val_loss=213.31075\n",
      "Epoch 20843: train_loss=203.83684, val_loss=213.31227\n",
      "Epoch 20844: train_loss=203.76616, val_loss=213.20612\n",
      "Epoch 20845: train_loss=203.70897, val_loss=213.19331\n",
      "Epoch 20846: train_loss=203.66835, val_loss=213.16396\n",
      "Epoch 20847: train_loss=203.64323, val_loss=213.13683\n",
      "Epoch 20848: train_loss=203.63011, val_loss=213.16298\n",
      "Epoch 20849: train_loss=203.62411, val_loss=213.11424\n",
      "Epoch 20850: train_loss=203.62044, val_loss=213.16805\n",
      "Epoch 20851: train_loss=203.61542, val_loss=213.09550\n",
      "Epoch 20852: train_loss=203.60577, val_loss=213.15063\n",
      "Epoch 20853: train_loss=203.58951, val_loss=213.05933\n",
      "Epoch 20854: train_loss=203.56656, val_loss=213.09909\n",
      "Epoch 20855: train_loss=203.53746, val_loss=213.00342\n",
      "Epoch 20856: train_loss=203.50447, val_loss=213.02538\n",
      "Epoch 20857: train_loss=203.46945, val_loss=212.94373\n",
      "Epoch 20858: train_loss=203.43440, val_loss=212.95027\n",
      "Epoch 20859: train_loss=203.40088, val_loss=212.89207\n",
      "Epoch 20860: train_loss=203.37019, val_loss=212.88408\n",
      "Epoch 20861: train_loss=203.34265, val_loss=212.85046\n",
      "Epoch 20862: train_loss=203.31821, val_loss=212.82872\n",
      "Epoch 20863: train_loss=203.29646, val_loss=212.81671\n",
      "Epoch 20864: train_loss=203.27678, val_loss=212.78413\n",
      "Epoch 20865: train_loss=203.25839, val_loss=212.78859\n",
      "Epoch 20866: train_loss=203.24089, val_loss=212.74565\n",
      "Epoch 20867: train_loss=203.22366, val_loss=212.76035\n",
      "Epoch 20868: train_loss=203.20619, val_loss=212.70816\n",
      "Epoch 20869: train_loss=203.18835, val_loss=212.72867\n",
      "Epoch 20870: train_loss=203.17006, val_loss=212.66997\n",
      "Epoch 20871: train_loss=203.15102, val_loss=212.69347\n",
      "Epoch 20872: train_loss=203.13129, val_loss=212.63129\n",
      "Epoch 20873: train_loss=203.11118, val_loss=212.65617\n",
      "Epoch 20874: train_loss=203.09030, val_loss=212.59135\n",
      "Epoch 20875: train_loss=203.06938, val_loss=212.61624\n",
      "Epoch 20876: train_loss=203.04811, val_loss=212.54988\n",
      "Epoch 20877: train_loss=203.02684, val_loss=212.57451\n",
      "Epoch 20878: train_loss=203.00540, val_loss=212.50854\n",
      "Epoch 20879: train_loss=202.98427, val_loss=212.53427\n",
      "Epoch 20880: train_loss=202.96275, val_loss=212.46848\n",
      "Epoch 20881: train_loss=202.94138, val_loss=212.49463\n",
      "Epoch 20882: train_loss=202.91991, val_loss=212.42886\n",
      "Epoch 20883: train_loss=202.89877, val_loss=212.45543\n",
      "Epoch 20884: train_loss=202.87776, val_loss=212.38940\n",
      "Epoch 20885: train_loss=202.85732, val_loss=212.41754\n",
      "Epoch 20886: train_loss=202.83693, val_loss=212.35121\n",
      "Epoch 20887: train_loss=202.81708, val_loss=212.38248\n",
      "Epoch 20888: train_loss=202.79739, val_loss=212.31499\n",
      "Epoch 20889: train_loss=202.77888, val_loss=212.35063\n",
      "Epoch 20890: train_loss=202.76047, val_loss=212.27933\n",
      "Epoch 20891: train_loss=202.74297, val_loss=212.32028\n",
      "Epoch 20892: train_loss=202.72565, val_loss=212.24525\n",
      "Epoch 20893: train_loss=202.70934, val_loss=212.29184\n",
      "Epoch 20894: train_loss=202.69264, val_loss=212.21251\n",
      "Epoch 20895: train_loss=202.67725, val_loss=212.26540\n",
      "Epoch 20896: train_loss=202.66133, val_loss=212.18126\n",
      "Epoch 20897: train_loss=202.64627, val_loss=212.24028\n",
      "Epoch 20898: train_loss=202.63049, val_loss=212.15063\n",
      "Epoch 20899: train_loss=202.61504, val_loss=212.21326\n",
      "Epoch 20900: train_loss=202.59853, val_loss=212.11714\n",
      "Epoch 20901: train_loss=202.58118, val_loss=212.18027\n",
      "Epoch 20902: train_loss=202.56215, val_loss=212.07869\n",
      "Epoch 20903: train_loss=202.54167, val_loss=212.13887\n",
      "Epoch 20904: train_loss=202.51872, val_loss=212.03397\n",
      "Epoch 20905: train_loss=202.49409, val_loss=212.08772\n",
      "Epoch 20906: train_loss=202.46707, val_loss=211.98262\n",
      "Epoch 20907: train_loss=202.43839, val_loss=212.02620\n",
      "Epoch 20908: train_loss=202.40791, val_loss=211.92654\n",
      "Epoch 20909: train_loss=202.37689, val_loss=211.95886\n",
      "Epoch 20910: train_loss=202.34492, val_loss=211.86909\n",
      "Epoch 20911: train_loss=202.31290, val_loss=211.89137\n",
      "Epoch 20912: train_loss=202.28188, val_loss=211.81563\n",
      "Epoch 20913: train_loss=202.25156, val_loss=211.82748\n",
      "Epoch 20914: train_loss=202.22241, val_loss=211.76591\n",
      "Epoch 20915: train_loss=202.19472, val_loss=211.76776\n",
      "Epoch 20916: train_loss=202.16838, val_loss=211.72003\n",
      "Epoch 20917: train_loss=202.14323, val_loss=211.71376\n",
      "Epoch 20918: train_loss=202.11923, val_loss=211.67888\n",
      "Epoch 20919: train_loss=202.09618, val_loss=211.66608\n",
      "Epoch 20920: train_loss=202.07388, val_loss=211.64064\n",
      "Epoch 20921: train_loss=202.05206, val_loss=211.62218\n",
      "Epoch 20922: train_loss=202.03055, val_loss=211.60188\n",
      "Epoch 20923: train_loss=202.00919, val_loss=211.57773\n",
      "Epoch 20924: train_loss=201.98804, val_loss=211.56224\n",
      "Epoch 20925: train_loss=201.96713, val_loss=211.53497\n",
      "Epoch 20926: train_loss=201.94630, val_loss=211.52711\n",
      "Epoch 20927: train_loss=201.92580, val_loss=211.49667\n",
      "Epoch 20928: train_loss=201.90579, val_loss=211.49651\n",
      "Epoch 20929: train_loss=201.88623, val_loss=211.45877\n",
      "Epoch 20930: train_loss=201.86740, val_loss=211.46645\n",
      "Epoch 20931: train_loss=201.84932, val_loss=211.42082\n",
      "Epoch 20932: train_loss=201.83287, val_loss=211.44153\n",
      "Epoch 20933: train_loss=201.81766, val_loss=211.38930\n",
      "Epoch 20934: train_loss=201.80507, val_loss=211.43102\n",
      "Epoch 20935: train_loss=201.79489, val_loss=211.37073\n",
      "Epoch 20936: train_loss=201.78897, val_loss=211.43655\n",
      "Epoch 20937: train_loss=201.78661, val_loss=211.36552\n",
      "Epoch 20938: train_loss=201.79010, val_loss=211.46191\n",
      "Epoch 20939: train_loss=201.79819, val_loss=211.38229\n",
      "Epoch 20940: train_loss=201.81535, val_loss=211.51707\n",
      "Epoch 20941: train_loss=201.83611, val_loss=211.42325\n",
      "Epoch 20942: train_loss=201.86415, val_loss=211.58470\n",
      "Epoch 20943: train_loss=201.88643, val_loss=211.46049\n",
      "Epoch 20944: train_loss=201.90662, val_loss=211.61415\n",
      "Epoch 20945: train_loss=201.90431, val_loss=211.44063\n",
      "Epoch 20946: train_loss=201.88466, val_loss=211.53983\n",
      "Epoch 20947: train_loss=201.82986, val_loss=211.32239\n",
      "Epoch 20948: train_loss=201.75401, val_loss=211.35086\n",
      "Epoch 20949: train_loss=201.65630, val_loss=211.15118\n",
      "Epoch 20950: train_loss=201.55905, val_loss=211.14310\n",
      "Epoch 20951: train_loss=201.47287, val_loss=211.03163\n",
      "Epoch 20952: train_loss=201.40919, val_loss=211.01535\n",
      "Epoch 20953: train_loss=201.37039, val_loss=211.00583\n",
      "Epoch 20954: train_loss=201.35361, val_loss=210.97638\n",
      "Epoch 20955: train_loss=201.35211, val_loss=211.03392\n",
      "Epoch 20956: train_loss=201.35800, val_loss=210.97557\n",
      "Epoch 20957: train_loss=201.36319, val_loss=211.05165\n",
      "Epoch 20958: train_loss=201.36029, val_loss=210.95775\n",
      "Epoch 20959: train_loss=201.34669, val_loss=211.01508\n",
      "Epoch 20960: train_loss=201.31944, val_loss=210.90231\n",
      "Epoch 20961: train_loss=201.28287, val_loss=210.92995\n",
      "Epoch 20962: train_loss=201.23975, val_loss=210.83102\n",
      "Epoch 20963: train_loss=201.19653, val_loss=210.83572\n",
      "Epoch 20964: train_loss=201.15627, val_loss=210.77339\n",
      "Epoch 20965: train_loss=201.12189, val_loss=210.76172\n",
      "Epoch 20966: train_loss=201.09435, val_loss=210.74182\n",
      "Epoch 20967: train_loss=201.07285, val_loss=210.71478\n",
      "Epoch 20968: train_loss=201.05586, val_loss=210.72505\n",
      "Epoch 20969: train_loss=201.04126, val_loss=210.68059\n",
      "Epoch 20970: train_loss=201.02731, val_loss=210.70473\n",
      "Epoch 20971: train_loss=201.01228, val_loss=210.64618\n",
      "Epoch 20972: train_loss=200.99538, val_loss=210.67351\n",
      "Epoch 20973: train_loss=200.97580, val_loss=210.60768\n",
      "Epoch 20974: train_loss=200.95395, val_loss=210.63017\n",
      "Epoch 20975: train_loss=200.92975, val_loss=210.56445\n",
      "Epoch 20976: train_loss=200.90431, val_loss=210.57732\n",
      "Epoch 20977: train_loss=200.87823, val_loss=210.51956\n",
      "Epoch 20978: train_loss=200.85201, val_loss=210.52365\n",
      "Epoch 20979: train_loss=200.82626, val_loss=210.47824\n",
      "Epoch 20980: train_loss=200.80141, val_loss=210.47322\n",
      "Epoch 20981: train_loss=200.77737, val_loss=210.43889\n",
      "Epoch 20982: train_loss=200.75410, val_loss=210.42424\n",
      "Epoch 20983: train_loss=200.73178, val_loss=210.40164\n",
      "Epoch 20984: train_loss=200.71021, val_loss=210.38007\n",
      "Epoch 20985: train_loss=200.68919, val_loss=210.36757\n",
      "Epoch 20986: train_loss=200.66849, val_loss=210.34004\n",
      "Epoch 20987: train_loss=200.64799, val_loss=210.33275\n",
      "Epoch 20988: train_loss=200.62758, val_loss=210.29875\n",
      "Epoch 20989: train_loss=200.60735, val_loss=210.29634\n",
      "Epoch 20990: train_loss=200.58720, val_loss=210.25819\n",
      "Epoch 20991: train_loss=200.56735, val_loss=210.26167\n",
      "Epoch 20992: train_loss=200.54762, val_loss=210.21957\n",
      "Epoch 20993: train_loss=200.52837, val_loss=210.22943\n",
      "Epoch 20994: train_loss=200.50938, val_loss=210.18181\n",
      "Epoch 20995: train_loss=200.49071, val_loss=210.19867\n",
      "Epoch 20996: train_loss=200.47266, val_loss=210.14590\n",
      "Epoch 20997: train_loss=200.45502, val_loss=210.17090\n",
      "Epoch 20998: train_loss=200.43776, val_loss=210.11235\n",
      "Epoch 20999: train_loss=200.42099, val_loss=210.14572\n",
      "Epoch 21000: train_loss=200.40462, val_loss=210.08070\n",
      "Epoch 21001: train_loss=200.38866, val_loss=210.12080\n",
      "Epoch 21002: train_loss=200.37288, val_loss=210.04845\n",
      "Epoch 21003: train_loss=200.35767, val_loss=210.09537\n",
      "Epoch 21004: train_loss=200.34245, val_loss=210.01645\n",
      "Epoch 21005: train_loss=200.32730, val_loss=210.07079\n",
      "Epoch 21006: train_loss=200.31212, val_loss=209.98645\n",
      "Epoch 21007: train_loss=200.29689, val_loss=210.04602\n",
      "Epoch 21008: train_loss=200.28119, val_loss=209.95509\n",
      "Epoch 21009: train_loss=200.26518, val_loss=210.01698\n",
      "Epoch 21010: train_loss=200.24800, val_loss=209.91974\n",
      "Epoch 21011: train_loss=200.22984, val_loss=209.98109\n",
      "Epoch 21012: train_loss=200.20973, val_loss=209.88065\n",
      "Epoch 21013: train_loss=200.18832, val_loss=209.93839\n",
      "Epoch 21014: train_loss=200.16490, val_loss=209.83662\n",
      "Epoch 21015: train_loss=200.13969, val_loss=209.88733\n",
      "Epoch 21016: train_loss=200.11272, val_loss=209.78799\n",
      "Epoch 21017: train_loss=200.08449, val_loss=209.82976\n",
      "Epoch 21018: train_loss=200.05606, val_loss=209.73677\n",
      "Epoch 21019: train_loss=200.02707, val_loss=209.76773\n",
      "Epoch 21020: train_loss=199.99817, val_loss=209.68451\n",
      "Epoch 21021: train_loss=199.96925, val_loss=209.70651\n",
      "Epoch 21022: train_loss=199.94133, val_loss=209.63678\n",
      "Epoch 21023: train_loss=199.91396, val_loss=209.65036\n",
      "Epoch 21024: train_loss=199.88776, val_loss=209.59326\n",
      "Epoch 21025: train_loss=199.86247, val_loss=209.59929\n",
      "Epoch 21026: train_loss=199.83832, val_loss=209.55208\n",
      "Epoch 21027: train_loss=199.81490, val_loss=209.55063\n",
      "Epoch 21028: train_loss=199.79202, val_loss=209.51059\n",
      "Epoch 21029: train_loss=199.76953, val_loss=209.50333\n",
      "Epoch 21030: train_loss=199.74751, val_loss=209.46933\n",
      "Epoch 21031: train_loss=199.72571, val_loss=209.45895\n",
      "Epoch 21032: train_loss=199.70407, val_loss=209.42853\n",
      "Epoch 21033: train_loss=199.68246, val_loss=209.41663\n",
      "Epoch 21034: train_loss=199.66090, val_loss=209.38725\n",
      "Epoch 21035: train_loss=199.63931, val_loss=209.37439\n",
      "Epoch 21036: train_loss=199.61772, val_loss=209.34509\n",
      "Epoch 21037: train_loss=199.59601, val_loss=209.33340\n",
      "Epoch 21038: train_loss=199.57428, val_loss=209.30244\n",
      "Epoch 21039: train_loss=199.55263, val_loss=209.29306\n",
      "Epoch 21040: train_loss=199.53098, val_loss=209.25894\n",
      "Epoch 21041: train_loss=199.50958, val_loss=209.25565\n",
      "Epoch 21042: train_loss=199.48854, val_loss=209.21666\n",
      "Epoch 21043: train_loss=199.46803, val_loss=209.22267\n",
      "Epoch 21044: train_loss=199.44852, val_loss=209.17604\n",
      "Epoch 21045: train_loss=199.43027, val_loss=209.19577\n",
      "Epoch 21046: train_loss=199.41400, val_loss=209.13988\n",
      "Epoch 21047: train_loss=199.40079, val_loss=209.18384\n",
      "Epoch 21048: train_loss=199.39114, val_loss=209.11934\n",
      "Epoch 21049: train_loss=199.38698, val_loss=209.19832\n",
      "Epoch 21050: train_loss=199.38928, val_loss=209.12323\n",
      "Epoch 21051: train_loss=199.40063, val_loss=209.24817\n",
      "Epoch 21052: train_loss=199.42039, val_loss=209.16154\n",
      "Epoch 21053: train_loss=199.45216, val_loss=209.33965\n",
      "Epoch 21054: train_loss=199.49066, val_loss=209.23444\n",
      "Epoch 21055: train_loss=199.53865, val_loss=209.44571\n",
      "Epoch 21056: train_loss=199.57658, val_loss=209.29201\n",
      "Epoch 21057: train_loss=199.60507, val_loss=209.47144\n",
      "Epoch 21058: train_loss=199.59367, val_loss=209.23801\n",
      "Epoch 21059: train_loss=199.54834, val_loss=209.31689\n",
      "Epoch 21060: train_loss=199.44972, val_loss=209.03612\n",
      "Epoch 21061: train_loss=199.32642, val_loss=209.02777\n",
      "Epoch 21062: train_loss=199.19113, val_loss=208.82024\n",
      "Epoch 21063: train_loss=199.07680, val_loss=208.79501\n",
      "Epoch 21064: train_loss=198.99886, val_loss=208.74303\n",
      "Epoch 21065: train_loss=198.96155, val_loss=208.71913\n",
      "Epoch 21066: train_loss=198.95668, val_loss=208.78490\n",
      "Epoch 21067: train_loss=198.97040, val_loss=208.72867\n",
      "Epoch 21068: train_loss=198.98813, val_loss=208.82806\n",
      "Epoch 21069: train_loss=198.99522, val_loss=208.71628\n",
      "Epoch 21070: train_loss=198.98322, val_loss=208.78311\n",
      "Epoch 21071: train_loss=198.94965, val_loss=208.64227\n",
      "Epoch 21072: train_loss=198.90024, val_loss=208.66443\n",
      "Epoch 21073: train_loss=198.84354, val_loss=208.55208\n",
      "Epoch 21074: train_loss=198.78993, val_loss=208.54651\n",
      "Epoch 21075: train_loss=198.74583, val_loss=208.49959\n",
      "Epoch 21076: train_loss=198.71460, val_loss=208.47711\n",
      "Epoch 21077: train_loss=198.69461, val_loss=208.48781\n",
      "Epoch 21078: train_loss=198.68245, val_loss=208.44481\n",
      "Epoch 21079: train_loss=198.67397, val_loss=208.48465\n",
      "Epoch 21080: train_loss=198.66438, val_loss=208.41774\n",
      "Epoch 21081: train_loss=198.65108, val_loss=208.45844\n",
      "Epoch 21082: train_loss=198.63211, val_loss=208.37631\n",
      "Epoch 21083: train_loss=198.60759, val_loss=208.40169\n",
      "Epoch 21084: train_loss=198.57896, val_loss=208.32353\n",
      "Epoch 21085: train_loss=198.54819, val_loss=208.33049\n",
      "Epoch 21086: train_loss=198.51744, val_loss=208.27361\n",
      "Epoch 21087: train_loss=198.48860, val_loss=208.26653\n",
      "Epoch 21088: train_loss=198.46225, val_loss=208.23595\n",
      "Epoch 21089: train_loss=198.43883, val_loss=208.21393\n",
      "Epoch 21090: train_loss=198.41800, val_loss=208.20499\n",
      "Epoch 21091: train_loss=198.39874, val_loss=208.17052\n",
      "Epoch 21092: train_loss=198.38060, val_loss=208.17706\n",
      "Epoch 21093: train_loss=198.36264, val_loss=208.13243\n",
      "Epoch 21094: train_loss=198.34451, val_loss=208.14680\n",
      "Epoch 21095: train_loss=198.32570, val_loss=208.09460\n",
      "Epoch 21096: train_loss=198.30597, val_loss=208.10959\n",
      "Epoch 21097: train_loss=198.28513, val_loss=208.05489\n",
      "Epoch 21098: train_loss=198.26335, val_loss=208.06761\n",
      "Epoch 21099: train_loss=198.24098, val_loss=208.01527\n",
      "Epoch 21100: train_loss=198.21808, val_loss=208.02165\n",
      "Epoch 21101: train_loss=198.19516, val_loss=207.97345\n",
      "Epoch 21102: train_loss=198.17232, val_loss=207.97455\n",
      "Epoch 21103: train_loss=198.14978, val_loss=207.93307\n",
      "Epoch 21104: train_loss=198.12730, val_loss=207.93063\n",
      "Epoch 21105: train_loss=198.10532, val_loss=207.89565\n",
      "Epoch 21106: train_loss=198.08340, val_loss=207.88840\n",
      "Epoch 21107: train_loss=198.06183, val_loss=207.85686\n",
      "Epoch 21108: train_loss=198.04047, val_loss=207.84589\n",
      "Epoch 21109: train_loss=198.01926, val_loss=207.81680\n",
      "Epoch 21110: train_loss=197.99803, val_loss=207.80444\n",
      "Epoch 21111: train_loss=197.97696, val_loss=207.77702\n",
      "Epoch 21112: train_loss=197.95601, val_loss=207.76447\n",
      "Epoch 21113: train_loss=197.93512, val_loss=207.73734\n",
      "Epoch 21114: train_loss=197.91425, val_loss=207.72662\n",
      "Epoch 21115: train_loss=197.89351, val_loss=207.69800\n",
      "Epoch 21116: train_loss=197.87294, val_loss=207.69098\n",
      "Epoch 21117: train_loss=197.85255, val_loss=207.65929\n",
      "Epoch 21118: train_loss=197.83244, val_loss=207.65741\n",
      "Epoch 21119: train_loss=197.81264, val_loss=207.61992\n",
      "Epoch 21120: train_loss=197.79327, val_loss=207.62521\n",
      "Epoch 21121: train_loss=197.77470, val_loss=207.58040\n",
      "Epoch 21122: train_loss=197.75693, val_loss=207.59679\n",
      "Epoch 21123: train_loss=197.74005, val_loss=207.54459\n",
      "Epoch 21124: train_loss=197.72475, val_loss=207.57721\n",
      "Epoch 21125: train_loss=197.71126, val_loss=207.51595\n",
      "Epoch 21126: train_loss=197.70003, val_loss=207.56816\n",
      "Epoch 21127: train_loss=197.69109, val_loss=207.49504\n",
      "Epoch 21128: train_loss=197.68451, val_loss=207.56926\n",
      "Epoch 21129: train_loss=197.68050, val_loss=207.48364\n",
      "Epoch 21130: train_loss=197.67940, val_loss=207.58043\n",
      "Epoch 21131: train_loss=197.67937, val_loss=207.47952\n",
      "Epoch 21132: train_loss=197.68121, val_loss=207.59262\n",
      "Epoch 21133: train_loss=197.68040, val_loss=207.47296\n",
      "Epoch 21134: train_loss=197.67883, val_loss=207.59059\n",
      "Epoch 21135: train_loss=197.66997, val_loss=207.45114\n",
      "Epoch 21136: train_loss=197.65718, val_loss=207.55731\n",
      "Epoch 21137: train_loss=197.63272, val_loss=207.39957\n",
      "Epoch 21138: train_loss=197.60146, val_loss=207.47725\n",
      "Epoch 21139: train_loss=197.55843, val_loss=207.31693\n",
      "Epoch 21140: train_loss=197.51031, val_loss=207.36479\n",
      "Epoch 21141: train_loss=197.45717, val_loss=207.22792\n",
      "Epoch 21142: train_loss=197.40527, val_loss=207.25098\n",
      "Epoch 21143: train_loss=197.35686, val_loss=207.15526\n",
      "Epoch 21144: train_loss=197.31419, val_loss=207.15697\n",
      "Epoch 21145: train_loss=197.27927, val_loss=207.10820\n",
      "Epoch 21146: train_loss=197.25092, val_loss=207.09180\n",
      "Epoch 21147: train_loss=197.22839, val_loss=207.08228\n",
      "Epoch 21148: train_loss=197.21028, val_loss=207.04701\n",
      "Epoch 21149: train_loss=197.19530, val_loss=207.06535\n",
      "Epoch 21150: train_loss=197.18243, val_loss=207.01335\n",
      "Epoch 21151: train_loss=197.17021, val_loss=207.05090\n",
      "Epoch 21152: train_loss=197.15807, val_loss=206.98447\n",
      "Epoch 21153: train_loss=197.14462, val_loss=207.03090\n",
      "Epoch 21154: train_loss=197.13020, val_loss=206.95177\n",
      "Epoch 21155: train_loss=197.11353, val_loss=206.99828\n",
      "Epoch 21156: train_loss=197.09528, val_loss=206.91237\n",
      "Epoch 21157: train_loss=197.07484, val_loss=206.95589\n",
      "Epoch 21158: train_loss=197.05284, val_loss=206.86977\n",
      "Epoch 21159: train_loss=197.02911, val_loss=206.90784\n",
      "Epoch 21160: train_loss=197.00455, val_loss=206.82573\n",
      "Epoch 21161: train_loss=196.97887, val_loss=206.85538\n",
      "Epoch 21162: train_loss=196.95351, val_loss=206.77925\n",
      "Epoch 21163: train_loss=196.92769, val_loss=206.80049\n",
      "Epoch 21164: train_loss=196.90250, val_loss=206.73430\n",
      "Epoch 21165: train_loss=196.87758, val_loss=206.74867\n",
      "Epoch 21166: train_loss=196.85352, val_loss=206.69270\n",
      "Epoch 21167: train_loss=196.83008, val_loss=206.70169\n",
      "Epoch 21168: train_loss=196.80731, val_loss=206.65274\n",
      "Epoch 21169: train_loss=196.78479, val_loss=206.65590\n",
      "Epoch 21170: train_loss=196.76285, val_loss=206.61157\n",
      "Epoch 21171: train_loss=196.74113, val_loss=206.61090\n",
      "Epoch 21172: train_loss=196.71991, val_loss=206.57140\n",
      "Epoch 21173: train_loss=196.69882, val_loss=206.56998\n",
      "Epoch 21174: train_loss=196.67796, val_loss=206.53317\n",
      "Epoch 21175: train_loss=196.65730, val_loss=206.53033\n",
      "Epoch 21176: train_loss=196.63678, val_loss=206.49379\n",
      "Epoch 21177: train_loss=196.61642, val_loss=206.49179\n",
      "Epoch 21178: train_loss=196.59630, val_loss=206.45480\n",
      "Epoch 21179: train_loss=196.57640, val_loss=206.45624\n",
      "Epoch 21180: train_loss=196.55679, val_loss=206.41628\n",
      "Epoch 21181: train_loss=196.53760, val_loss=206.42328\n",
      "Epoch 21182: train_loss=196.51895, val_loss=206.37828\n",
      "Epoch 21183: train_loss=196.50075, val_loss=206.39412\n",
      "Epoch 21184: train_loss=196.48381, val_loss=206.34151\n",
      "Epoch 21185: train_loss=196.46768, val_loss=206.37012\n",
      "Epoch 21186: train_loss=196.45383, val_loss=206.30930\n",
      "Epoch 21187: train_loss=196.44182, val_loss=206.35950\n",
      "Epoch 21188: train_loss=196.43332, val_loss=206.28972\n",
      "Epoch 21189: train_loss=196.42838, val_loss=206.36882\n",
      "Epoch 21190: train_loss=196.42804, val_loss=206.28662\n",
      "Epoch 21191: train_loss=196.43307, val_loss=206.39944\n",
      "Epoch 21192: train_loss=196.44312, val_loss=206.30093\n",
      "Epoch 21193: train_loss=196.45924, val_loss=206.44810\n",
      "Epoch 21194: train_loss=196.47778, val_loss=206.32884\n",
      "Epoch 21195: train_loss=196.49911, val_loss=206.49878\n",
      "Epoch 21196: train_loss=196.51505, val_loss=206.34898\n",
      "Epoch 21197: train_loss=196.52574, val_loss=206.50813\n",
      "Epoch 21198: train_loss=196.51648, val_loss=206.31329\n",
      "Epoch 21199: train_loss=196.48973, val_loss=206.42130\n",
      "Epoch 21200: train_loss=196.43500, val_loss=206.19788\n",
      "Epoch 21201: train_loss=196.36336, val_loss=206.24416\n",
      "Epoch 21202: train_loss=196.27698, val_loss=206.04808\n",
      "Epoch 21203: train_loss=196.19139, val_loss=206.05510\n",
      "Epoch 21204: train_loss=196.11655, val_loss=205.94353\n",
      "Epoch 21205: train_loss=196.05920, val_loss=205.93109\n",
      "Epoch 21206: train_loss=196.02313, val_loss=205.91718\n",
      "Epoch 21207: train_loss=196.00507, val_loss=205.88399\n",
      "Epoch 21208: train_loss=195.99971, val_loss=205.93565\n",
      "Epoch 21209: train_loss=196.00119, val_loss=205.87054\n",
      "Epoch 21210: train_loss=196.00247, val_loss=205.94629\n",
      "Epoch 21211: train_loss=195.99991, val_loss=205.84918\n",
      "Epoch 21212: train_loss=195.98853, val_loss=205.91737\n",
      "Epoch 21213: train_loss=195.96829, val_loss=205.80365\n",
      "Epoch 21214: train_loss=195.93904, val_loss=205.84874\n",
      "Epoch 21215: train_loss=195.90440, val_loss=205.74147\n",
      "Epoch 21216: train_loss=195.86639, val_loss=205.76175\n",
      "Epoch 21217: train_loss=195.82951, val_loss=205.68269\n",
      "Epoch 21218: train_loss=195.79495, val_loss=205.68231\n",
      "Epoch 21219: train_loss=195.76501, val_loss=205.64102\n",
      "Epoch 21220: train_loss=195.73979, val_loss=205.62303\n",
      "Epoch 21221: train_loss=195.71867, val_loss=205.61494\n",
      "Epoch 21222: train_loss=195.70079, val_loss=205.58058\n",
      "Epoch 21223: train_loss=195.68484, val_loss=205.59399\n",
      "Epoch 21224: train_loss=195.66989, val_loss=205.54396\n",
      "Epoch 21225: train_loss=195.65479, val_loss=205.56885\n",
      "Epoch 21226: train_loss=195.63913, val_loss=205.50703\n",
      "Epoch 21227: train_loss=195.62250, val_loss=205.53741\n",
      "Epoch 21228: train_loss=195.60460, val_loss=205.46992\n",
      "Epoch 21229: train_loss=195.58528, val_loss=205.49980\n",
      "Epoch 21230: train_loss=195.56479, val_loss=205.42972\n",
      "Epoch 21231: train_loss=195.54312, val_loss=205.45462\n",
      "Epoch 21232: train_loss=195.52083, val_loss=205.38713\n",
      "Epoch 21233: train_loss=195.49797, val_loss=205.40637\n",
      "Epoch 21234: train_loss=195.47491, val_loss=205.34561\n",
      "Epoch 21235: train_loss=195.45192, val_loss=205.35922\n",
      "Epoch 21236: train_loss=195.42906, val_loss=205.30408\n",
      "Epoch 21237: train_loss=195.40666, val_loss=205.31110\n",
      "Epoch 21238: train_loss=195.38464, val_loss=205.26227\n",
      "Epoch 21239: train_loss=195.36287, val_loss=205.26619\n",
      "Epoch 21240: train_loss=195.34151, val_loss=205.22319\n",
      "Epoch 21241: train_loss=195.32034, val_loss=205.22469\n",
      "Epoch 21242: train_loss=195.29942, val_loss=205.18494\n",
      "Epoch 21243: train_loss=195.27875, val_loss=205.18436\n",
      "Epoch 21244: train_loss=195.25829, val_loss=205.14525\n",
      "Epoch 21245: train_loss=195.23811, val_loss=205.14453\n",
      "Epoch 21246: train_loss=195.21803, val_loss=205.10643\n",
      "Epoch 21247: train_loss=195.19821, val_loss=205.10899\n",
      "Epoch 21248: train_loss=195.17865, val_loss=205.06921\n",
      "Epoch 21249: train_loss=195.15944, val_loss=205.07492\n",
      "Epoch 21250: train_loss=195.14059, val_loss=205.03012\n",
      "Epoch 21251: train_loss=195.12244, val_loss=205.04321\n",
      "Epoch 21252: train_loss=195.10497, val_loss=204.99243\n",
      "Epoch 21253: train_loss=195.08838, val_loss=205.01706\n",
      "Epoch 21254: train_loss=195.07310, val_loss=204.95778\n",
      "Epoch 21255: train_loss=195.05911, val_loss=204.99765\n",
      "Epoch 21256: train_loss=195.04700, val_loss=204.92914\n",
      "Epoch 21257: train_loss=195.03659, val_loss=204.98926\n",
      "Epoch 21258: train_loss=195.02853, val_loss=204.91051\n",
      "Epoch 21259: train_loss=195.02296, val_loss=204.99312\n",
      "Epoch 21260: train_loss=195.02032, val_loss=204.90036\n",
      "Epoch 21261: train_loss=195.02013, val_loss=205.00522\n",
      "Epoch 21262: train_loss=195.02213, val_loss=204.89847\n",
      "Epoch 21263: train_loss=195.02673, val_loss=205.02472\n",
      "Epoch 21264: train_loss=195.03081, val_loss=204.90025\n",
      "Epoch 21265: train_loss=195.03444, val_loss=205.03400\n",
      "Epoch 21266: train_loss=195.03123, val_loss=204.88429\n",
      "Epoch 21267: train_loss=195.02174, val_loss=205.00525\n",
      "Epoch 21268: train_loss=195.00066, val_loss=204.83482\n",
      "Epoch 21269: train_loss=194.97003, val_loss=204.92632\n",
      "Epoch 21270: train_loss=194.92603, val_loss=204.74957\n",
      "Epoch 21271: train_loss=194.87428, val_loss=204.80318\n",
      "Epoch 21272: train_loss=194.81531, val_loss=204.64874\n",
      "Epoch 21273: train_loss=194.75693, val_loss=204.67242\n",
      "Epoch 21274: train_loss=194.70279, val_loss=204.56808\n",
      "Epoch 21275: train_loss=194.65587, val_loss=204.56891\n",
      "Epoch 21276: train_loss=194.61858, val_loss=204.52318\n",
      "Epoch 21277: train_loss=194.59061, val_loss=204.50314\n",
      "Epoch 21278: train_loss=194.57037, val_loss=204.50429\n",
      "Epoch 21279: train_loss=194.55594, val_loss=204.46304\n",
      "Epoch 21280: train_loss=194.54517, val_loss=204.49796\n",
      "Epoch 21281: train_loss=194.53613, val_loss=204.43710\n",
      "Epoch 21282: train_loss=194.52670, val_loss=204.48853\n",
      "Epoch 21283: train_loss=194.51585, val_loss=204.40894\n",
      "Epoch 21284: train_loss=194.50237, val_loss=204.46204\n",
      "Epoch 21285: train_loss=194.48598, val_loss=204.37172\n",
      "Epoch 21286: train_loss=194.46678, val_loss=204.42082\n",
      "Epoch 21287: train_loss=194.44495, val_loss=204.32898\n",
      "Epoch 21288: train_loss=194.42073, val_loss=204.36989\n",
      "Epoch 21289: train_loss=194.39493, val_loss=204.28287\n",
      "Epoch 21290: train_loss=194.36771, val_loss=204.31102\n",
      "Epoch 21291: train_loss=194.33997, val_loss=204.23499\n",
      "Epoch 21292: train_loss=194.31270, val_loss=204.25090\n",
      "Epoch 21293: train_loss=194.28625, val_loss=204.19009\n",
      "Epoch 21294: train_loss=194.26082, val_loss=204.19612\n",
      "Epoch 21295: train_loss=194.23666, val_loss=204.15073\n",
      "Epoch 21296: train_loss=194.21344, val_loss=204.14764\n",
      "Epoch 21297: train_loss=194.19124, val_loss=204.11420\n",
      "Epoch 21298: train_loss=194.16971, val_loss=204.10162\n",
      "Epoch 21299: train_loss=194.14882, val_loss=204.07748\n",
      "Epoch 21300: train_loss=194.12834, val_loss=204.05763\n",
      "Epoch 21301: train_loss=194.10835, val_loss=204.04211\n",
      "Epoch 21302: train_loss=194.08862, val_loss=204.01601\n",
      "Epoch 21303: train_loss=194.06911, val_loss=204.00797\n",
      "Epoch 21304: train_loss=194.04974, val_loss=203.97530\n",
      "Epoch 21305: train_loss=194.03069, val_loss=203.97359\n",
      "Epoch 21306: train_loss=194.01190, val_loss=203.93456\n",
      "Epoch 21307: train_loss=193.99374, val_loss=203.94289\n",
      "Epoch 21308: train_loss=193.97623, val_loss=203.89742\n",
      "Epoch 21309: train_loss=193.95959, val_loss=203.91823\n",
      "Epoch 21310: train_loss=193.94415, val_loss=203.86317\n",
      "Epoch 21311: train_loss=193.93007, val_loss=203.90031\n",
      "Epoch 21312: train_loss=193.91780, val_loss=203.83522\n",
      "Epoch 21313: train_loss=193.90762, val_loss=203.89240\n",
      "Epoch 21314: train_loss=193.89957, val_loss=203.81453\n",
      "Epoch 21315: train_loss=193.89427, val_loss=203.89435\n",
      "Epoch 21316: train_loss=193.89182, val_loss=203.80420\n",
      "Epoch 21317: train_loss=193.89282, val_loss=203.91322\n",
      "Epoch 21318: train_loss=193.89722, val_loss=203.81038\n",
      "Epoch 21319: train_loss=193.90472, val_loss=203.94490\n",
      "Epoch 21320: train_loss=193.91264, val_loss=203.82082\n",
      "Epoch 21321: train_loss=193.92041, val_loss=203.96573\n",
      "Epoch 21322: train_loss=193.92259, val_loss=203.81375\n",
      "Epoch 21323: train_loss=193.91808, val_loss=203.94592\n",
      "Epoch 21324: train_loss=193.89966, val_loss=203.76576\n",
      "Epoch 21325: train_loss=193.86845, val_loss=203.86127\n",
      "Epoch 21326: train_loss=193.82066, val_loss=203.67137\n",
      "Epoch 21327: train_loss=193.76358, val_loss=203.72495\n",
      "Epoch 21328: train_loss=193.69940, val_loss=203.56067\n",
      "Epoch 21329: train_loss=193.63583, val_loss=203.58270\n",
      "Epoch 21330: train_loss=193.57782, val_loss=203.47592\n",
      "Epoch 21331: train_loss=193.52934, val_loss=203.47469\n",
      "Epoch 21332: train_loss=193.49174, val_loss=203.43082\n",
      "Epoch 21333: train_loss=193.46454, val_loss=203.40817\n",
      "Epoch 21334: train_loss=193.44609, val_loss=203.41821\n",
      "Epoch 21335: train_loss=193.43404, val_loss=203.37424\n",
      "Epoch 21336: train_loss=193.42570, val_loss=203.41914\n",
      "Epoch 21337: train_loss=193.41820, val_loss=203.35243\n",
      "Epoch 21338: train_loss=193.40993, val_loss=203.41083\n",
      "Epoch 21339: train_loss=193.39902, val_loss=203.32359\n",
      "Epoch 21340: train_loss=193.38483, val_loss=203.38121\n",
      "Epoch 21341: train_loss=193.36714, val_loss=203.28310\n",
      "Epoch 21342: train_loss=193.34586, val_loss=203.33260\n",
      "Epoch 21343: train_loss=193.32159, val_loss=203.23584\n",
      "Epoch 21344: train_loss=193.29491, val_loss=203.27423\n",
      "Epoch 21345: train_loss=193.26646, val_loss=203.18753\n",
      "Epoch 21346: train_loss=193.23735, val_loss=203.21138\n",
      "Epoch 21347: train_loss=193.20827, val_loss=203.13980\n",
      "Epoch 21348: train_loss=193.18051, val_loss=203.14890\n",
      "Epoch 21349: train_loss=193.15411, val_loss=203.09529\n",
      "Epoch 21350: train_loss=193.12935, val_loss=203.09247\n",
      "Epoch 21351: train_loss=193.10603, val_loss=203.05716\n",
      "Epoch 21352: train_loss=193.08383, val_loss=203.04559\n",
      "Epoch 21353: train_loss=193.06259, val_loss=203.02403\n",
      "Epoch 21354: train_loss=193.04210, val_loss=203.00227\n",
      "Epoch 21355: train_loss=193.02214, val_loss=202.98984\n",
      "Epoch 21356: train_loss=193.00258, val_loss=202.95892\n",
      "Epoch 21357: train_loss=192.98328, val_loss=202.95584\n",
      "Epoch 21358: train_loss=192.96437, val_loss=202.91994\n",
      "Epoch 21359: train_loss=192.94582, val_loss=202.92789\n",
      "Epoch 21360: train_loss=192.92749, val_loss=202.88408\n",
      "Epoch 21361: train_loss=192.90999, val_loss=202.90059\n",
      "Epoch 21362: train_loss=192.89297, val_loss=202.84706\n",
      "Epoch 21363: train_loss=192.87700, val_loss=202.87553\n",
      "Epoch 21364: train_loss=192.86200, val_loss=202.81384\n",
      "Epoch 21365: train_loss=192.84808, val_loss=202.85855\n",
      "Epoch 21366: train_loss=192.83536, val_loss=202.78757\n",
      "Epoch 21367: train_loss=192.82434, val_loss=202.84808\n",
      "Epoch 21368: train_loss=192.81430, val_loss=202.76479\n",
      "Epoch 21369: train_loss=192.80638, val_loss=202.84308\n",
      "Epoch 21370: train_loss=192.80000, val_loss=202.74844\n",
      "Epoch 21371: train_loss=192.79572, val_loss=202.84639\n",
      "Epoch 21372: train_loss=192.79245, val_loss=202.73918\n",
      "Epoch 21373: train_loss=192.79015, val_loss=202.85236\n",
      "Epoch 21374: train_loss=192.78687, val_loss=202.72894\n",
      "Epoch 21375: train_loss=192.78207, val_loss=202.84787\n",
      "Epoch 21376: train_loss=192.77342, val_loss=202.70624\n",
      "Epoch 21377: train_loss=192.75908, val_loss=202.81650\n",
      "Epoch 21378: train_loss=192.73802, val_loss=202.66159\n",
      "Epoch 21379: train_loss=192.70924, val_loss=202.74849\n",
      "Epoch 21380: train_loss=192.67174, val_loss=202.59076\n",
      "Epoch 21381: train_loss=192.62852, val_loss=202.64804\n",
      "Epoch 21382: train_loss=192.58008, val_loss=202.50819\n",
      "Epoch 21383: train_loss=192.53136, val_loss=202.53781\n",
      "Epoch 21384: train_loss=192.48383, val_loss=202.43430\n",
      "Epoch 21385: train_loss=192.44119, val_loss=202.44185\n",
      "Epoch 21386: train_loss=192.40405, val_loss=202.38388\n",
      "Epoch 21387: train_loss=192.37344, val_loss=202.37408\n",
      "Epoch 21388: train_loss=192.34857, val_loss=202.35475\n",
      "Epoch 21389: train_loss=192.32782, val_loss=202.32663\n",
      "Epoch 21390: train_loss=192.31013, val_loss=202.33398\n",
      "Epoch 21391: train_loss=192.29472, val_loss=202.28865\n",
      "Epoch 21392: train_loss=192.28056, val_loss=202.31541\n",
      "Epoch 21393: train_loss=192.26680, val_loss=202.25597\n",
      "Epoch 21394: train_loss=192.25316, val_loss=202.29655\n",
      "Epoch 21395: train_loss=192.23897, val_loss=202.22615\n",
      "Epoch 21396: train_loss=192.22389, val_loss=202.27361\n",
      "Epoch 21397: train_loss=192.20758, val_loss=202.19333\n",
      "Epoch 21398: train_loss=192.19003, val_loss=202.24042\n",
      "Epoch 21399: train_loss=192.17102, val_loss=202.15508\n",
      "Epoch 21400: train_loss=192.15108, val_loss=202.20097\n",
      "Epoch 21401: train_loss=192.12978, val_loss=202.11569\n",
      "Epoch 21402: train_loss=192.10751, val_loss=202.15776\n",
      "Epoch 21403: train_loss=192.08426, val_loss=202.07404\n",
      "Epoch 21404: train_loss=192.06091, val_loss=202.11021\n",
      "Epoch 21405: train_loss=192.03683, val_loss=202.03082\n",
      "Epoch 21406: train_loss=192.01300, val_loss=202.06274\n",
      "Epoch 21407: train_loss=191.98886, val_loss=201.98935\n",
      "Epoch 21408: train_loss=191.96509, val_loss=202.01721\n",
      "Epoch 21409: train_loss=191.94122, val_loss=201.94980\n",
      "Epoch 21410: train_loss=191.91792, val_loss=201.97392\n",
      "Epoch 21411: train_loss=191.89468, val_loss=201.91138\n",
      "Epoch 21412: train_loss=191.87183, val_loss=201.93146\n",
      "Epoch 21413: train_loss=191.84947, val_loss=201.87212\n",
      "Epoch 21414: train_loss=191.82741, val_loss=201.88992\n",
      "Epoch 21415: train_loss=191.80571, val_loss=201.83302\n",
      "Epoch 21416: train_loss=191.78445, val_loss=201.85066\n",
      "Epoch 21417: train_loss=191.76352, val_loss=201.79568\n",
      "Epoch 21418: train_loss=191.74290, val_loss=201.81412\n",
      "Epoch 21419: train_loss=191.72269, val_loss=201.75862\n",
      "Epoch 21420: train_loss=191.70297, val_loss=201.77974\n",
      "Epoch 21421: train_loss=191.68390, val_loss=201.72261\n",
      "Epoch 21422: train_loss=191.66586, val_loss=201.75078\n",
      "Epoch 21423: train_loss=191.64861, val_loss=201.68961\n",
      "Epoch 21424: train_loss=191.63268, val_loss=201.72853\n",
      "Epoch 21425: train_loss=191.61781, val_loss=201.66148\n",
      "Epoch 21426: train_loss=191.60484, val_loss=201.71368\n",
      "Epoch 21427: train_loss=191.59309, val_loss=201.63753\n",
      "Epoch 21428: train_loss=191.58371, val_loss=201.70639\n",
      "Epoch 21429: train_loss=191.57597, val_loss=201.62013\n",
      "Epoch 21430: train_loss=191.57091, val_loss=201.70737\n",
      "Epoch 21431: train_loss=191.56731, val_loss=201.60938\n",
      "Epoch 21432: train_loss=191.56598, val_loss=201.71738\n",
      "Epoch 21433: train_loss=191.56572, val_loss=201.60725\n",
      "Epoch 21434: train_loss=191.56593, val_loss=201.72766\n",
      "Epoch 21435: train_loss=191.56406, val_loss=201.59909\n",
      "Epoch 21436: train_loss=191.55975, val_loss=201.71912\n",
      "Epoch 21437: train_loss=191.54903, val_loss=201.57056\n",
      "Epoch 21438: train_loss=191.53105, val_loss=201.67490\n",
      "Epoch 21439: train_loss=191.50305, val_loss=201.51224\n",
      "Epoch 21440: train_loss=191.46535, val_loss=201.58662\n",
      "Epoch 21441: train_loss=191.41878, val_loss=201.42503\n",
      "Epoch 21442: train_loss=191.36584, val_loss=201.46513\n",
      "Epoch 21443: train_loss=191.30988, val_loss=201.33200\n",
      "Epoch 21444: train_loss=191.25656, val_loss=201.34694\n",
      "Epoch 21445: train_loss=191.20854, val_loss=201.26295\n",
      "Epoch 21446: train_loss=191.16853, val_loss=201.25792\n",
      "Epoch 21447: train_loss=191.13667, val_loss=201.22363\n",
      "Epoch 21448: train_loss=191.11234, val_loss=201.19984\n",
      "Epoch 21449: train_loss=191.09412, val_loss=201.20671\n",
      "Epoch 21450: train_loss=191.08002, val_loss=201.16486\n",
      "Epoch 21451: train_loss=191.06859, val_loss=201.19847\n",
      "Epoch 21452: train_loss=191.05775, val_loss=201.13745\n",
      "Epoch 21453: train_loss=191.04662, val_loss=201.18306\n",
      "Epoch 21454: train_loss=191.03380, val_loss=201.10690\n",
      "Epoch 21455: train_loss=191.01918, val_loss=201.15518\n",
      "Epoch 21456: train_loss=191.00230, val_loss=201.07086\n",
      "Epoch 21457: train_loss=190.98370, val_loss=201.11722\n",
      "Epoch 21458: train_loss=190.96266, val_loss=201.02942\n",
      "Epoch 21459: train_loss=190.94003, val_loss=201.06851\n",
      "Epoch 21460: train_loss=190.91585, val_loss=200.98274\n",
      "Epoch 21461: train_loss=190.89072, val_loss=201.01381\n",
      "Epoch 21462: train_loss=190.86472, val_loss=200.93614\n",
      "Epoch 21463: train_loss=190.83852, val_loss=200.95961\n",
      "Epoch 21464: train_loss=190.81219, val_loss=200.89212\n",
      "Epoch 21465: train_loss=190.78635, val_loss=200.90439\n",
      "Epoch 21466: train_loss=190.76109, val_loss=200.84792\n",
      "Epoch 21467: train_loss=190.73663, val_loss=200.85141\n",
      "Epoch 21468: train_loss=190.71297, val_loss=200.80716\n",
      "Epoch 21469: train_loss=190.69022, val_loss=200.80322\n",
      "Epoch 21470: train_loss=190.66806, val_loss=200.76929\n",
      "Epoch 21471: train_loss=190.64656, val_loss=200.75827\n",
      "Epoch 21472: train_loss=190.62552, val_loss=200.73216\n",
      "Epoch 21473: train_loss=190.60484, val_loss=200.71490\n",
      "Epoch 21474: train_loss=190.58449, val_loss=200.69516\n",
      "Epoch 21475: train_loss=190.56435, val_loss=200.67296\n",
      "Epoch 21476: train_loss=190.54434, val_loss=200.65871\n",
      "Epoch 21477: train_loss=190.52455, val_loss=200.63223\n",
      "Epoch 21478: train_loss=190.50499, val_loss=200.62444\n",
      "Epoch 21479: train_loss=190.48555, val_loss=200.59261\n",
      "Epoch 21480: train_loss=190.46645, val_loss=200.59102\n",
      "Epoch 21481: train_loss=190.44766, val_loss=200.55336\n",
      "Epoch 21482: train_loss=190.42949, val_loss=200.56046\n",
      "Epoch 21483: train_loss=190.41223, val_loss=200.51549\n",
      "Epoch 21484: train_loss=190.39600, val_loss=200.53671\n",
      "Epoch 21485: train_loss=190.38133, val_loss=200.48370\n",
      "Epoch 21486: train_loss=190.36865, val_loss=200.52428\n",
      "Epoch 21487: train_loss=190.35899, val_loss=200.46011\n",
      "Epoch 21488: train_loss=190.35289, val_loss=200.52705\n",
      "Epoch 21489: train_loss=190.35120, val_loss=200.45056\n",
      "Epoch 21490: train_loss=190.35469, val_loss=200.55208\n",
      "Epoch 21491: train_loss=190.36420, val_loss=200.46504\n",
      "Epoch 21492: train_loss=190.38148, val_loss=200.60748\n",
      "Epoch 21493: train_loss=190.40352, val_loss=200.50273\n",
      "Epoch 21494: train_loss=190.43083, val_loss=200.67352\n",
      "Epoch 21495: train_loss=190.45494, val_loss=200.53529\n",
      "Epoch 21496: train_loss=190.47345, val_loss=200.69984\n",
      "Epoch 21497: train_loss=190.47333, val_loss=200.51299\n",
      "Epoch 21498: train_loss=190.45284, val_loss=200.62630\n",
      "Epoch 21499: train_loss=190.40303, val_loss=200.40143\n",
      "Epoch 21500: train_loss=190.33098, val_loss=200.44577\n",
      "Epoch 21501: train_loss=190.23984, val_loss=200.24121\n",
      "Epoch 21502: train_loss=190.14783, val_loss=200.24486\n",
      "Epoch 21503: train_loss=190.06670, val_loss=200.12671\n",
      "Epoch 21504: train_loss=190.00497, val_loss=200.11345\n",
      "Epoch 21505: train_loss=189.96594, val_loss=200.09543\n",
      "Epoch 21506: train_loss=189.94719, val_loss=200.06448\n",
      "Epoch 21507: train_loss=189.94292, val_loss=200.11510\n",
      "Epoch 21508: train_loss=189.94609, val_loss=200.05405\n",
      "Epoch 21509: train_loss=189.94936, val_loss=200.12801\n",
      "Epoch 21510: train_loss=189.94734, val_loss=200.03433\n",
      "Epoch 21511: train_loss=189.93626, val_loss=200.09796\n",
      "Epoch 21512: train_loss=189.91522, val_loss=199.98639\n",
      "Epoch 21513: train_loss=189.88499, val_loss=200.02577\n",
      "Epoch 21514: train_loss=189.84901, val_loss=199.92310\n",
      "Epoch 21515: train_loss=189.81038, val_loss=199.93835\n",
      "Epoch 21516: train_loss=189.77309, val_loss=199.86565\n",
      "Epoch 21517: train_loss=189.73943, val_loss=199.86053\n",
      "Epoch 21518: train_loss=189.71091, val_loss=199.82472\n",
      "Epoch 21519: train_loss=189.68739, val_loss=199.80269\n",
      "Epoch 21520: train_loss=189.66808, val_loss=199.79878\n",
      "Epoch 21521: train_loss=189.65196, val_loss=199.76102\n",
      "Epoch 21522: train_loss=189.63756, val_loss=199.77922\n",
      "Epoch 21523: train_loss=189.62407, val_loss=199.72667\n",
      "Epoch 21524: train_loss=189.61021, val_loss=199.75522\n",
      "Epoch 21525: train_loss=189.59544, val_loss=199.69063\n",
      "Epoch 21526: train_loss=189.57893, val_loss=199.72040\n",
      "Epoch 21527: train_loss=189.56075, val_loss=199.64998\n",
      "Epoch 21528: train_loss=189.54105, val_loss=199.67804\n",
      "Epoch 21529: train_loss=189.51991, val_loss=199.60829\n",
      "Epoch 21530: train_loss=189.49750, val_loss=199.63176\n",
      "Epoch 21531: train_loss=189.47438, val_loss=199.56682\n",
      "Epoch 21532: train_loss=189.45082, val_loss=199.58202\n",
      "Epoch 21533: train_loss=189.42728, val_loss=199.52271\n",
      "Epoch 21534: train_loss=189.40376, val_loss=199.52878\n",
      "Epoch 21535: train_loss=189.38080, val_loss=199.47729\n",
      "Epoch 21536: train_loss=189.35823, val_loss=199.47655\n",
      "Epoch 21537: train_loss=189.33641, val_loss=199.43353\n",
      "Epoch 21538: train_loss=189.31482, val_loss=199.42789\n",
      "Epoch 21539: train_loss=189.29372, val_loss=199.39171\n",
      "Epoch 21540: train_loss=189.27296, val_loss=199.38138\n",
      "Epoch 21541: train_loss=189.25246, val_loss=199.34850\n",
      "Epoch 21542: train_loss=189.23216, val_loss=199.33475\n",
      "Epoch 21543: train_loss=189.21213, val_loss=199.30435\n",
      "Epoch 21544: train_loss=189.19211, val_loss=199.29086\n",
      "Epoch 21545: train_loss=189.17221, val_loss=199.26254\n",
      "Epoch 21546: train_loss=189.15237, val_loss=199.25133\n",
      "Epoch 21547: train_loss=189.13269, val_loss=199.22229\n",
      "Epoch 21548: train_loss=189.11304, val_loss=199.21301\n",
      "Epoch 21549: train_loss=189.09355, val_loss=199.18044\n",
      "Epoch 21550: train_loss=189.07426, val_loss=199.17535\n",
      "Epoch 21551: train_loss=189.05528, val_loss=199.13925\n",
      "Epoch 21552: train_loss=189.03683, val_loss=199.14290\n",
      "Epoch 21553: train_loss=189.01889, val_loss=199.10228\n",
      "Epoch 21554: train_loss=189.00209, val_loss=199.11852\n",
      "Epoch 21555: train_loss=188.98640, val_loss=199.06934\n",
      "Epoch 21556: train_loss=188.97249, val_loss=199.10118\n",
      "Epoch 21557: train_loss=188.96092, val_loss=199.04082\n",
      "Epoch 21558: train_loss=188.95207, val_loss=199.09651\n",
      "Epoch 21559: train_loss=188.94684, val_loss=199.02522\n",
      "Epoch 21560: train_loss=188.94533, val_loss=199.10954\n",
      "Epoch 21561: train_loss=188.94781, val_loss=199.02573\n",
      "Epoch 21562: train_loss=188.95453, val_loss=199.14108\n",
      "Epoch 21563: train_loss=188.96509, val_loss=199.04161\n",
      "Epoch 21564: train_loss=188.97891, val_loss=199.18126\n",
      "Epoch 21565: train_loss=188.99162, val_loss=199.05710\n",
      "Epoch 21566: train_loss=189.00209, val_loss=199.20114\n",
      "Epoch 21567: train_loss=189.00235, val_loss=199.04466\n",
      "Epoch 21568: train_loss=188.99164, val_loss=199.16251\n",
      "Epoch 21569: train_loss=188.96178, val_loss=198.97565\n",
      "Epoch 21570: train_loss=188.91670, val_loss=199.04674\n",
      "Epoch 21571: train_loss=188.85506, val_loss=198.85889\n",
      "Epoch 21572: train_loss=188.78568, val_loss=198.88768\n",
      "Epoch 21573: train_loss=188.71547, val_loss=198.74408\n",
      "Epoch 21574: train_loss=188.65123, val_loss=198.74841\n",
      "Epoch 21575: train_loss=188.59953, val_loss=198.67657\n",
      "Epoch 21576: train_loss=188.56085, val_loss=198.66310\n",
      "Epoch 21577: train_loss=188.53479, val_loss=198.65628\n",
      "Epoch 21578: train_loss=188.51857, val_loss=198.62254\n",
      "Epoch 21579: train_loss=188.50879, val_loss=198.65749\n",
      "Epoch 21580: train_loss=188.50266, val_loss=198.60039\n",
      "Epoch 21581: train_loss=188.49667, val_loss=198.65575\n",
      "Epoch 21582: train_loss=188.48921, val_loss=198.57693\n",
      "Epoch 21583: train_loss=188.47726, val_loss=198.63416\n",
      "Epoch 21584: train_loss=188.46181, val_loss=198.54176\n",
      "Epoch 21585: train_loss=188.44096, val_loss=198.58949\n",
      "Epoch 21586: train_loss=188.41737, val_loss=198.49463\n",
      "Epoch 21587: train_loss=188.38974, val_loss=198.52960\n",
      "Epoch 21588: train_loss=188.36119, val_loss=198.44345\n",
      "Epoch 21589: train_loss=188.33089, val_loss=198.46324\n",
      "Epoch 21590: train_loss=188.30113, val_loss=198.39400\n",
      "Epoch 21591: train_loss=188.27202, val_loss=198.39879\n",
      "Epoch 21592: train_loss=188.24484, val_loss=198.35153\n",
      "Epoch 21593: train_loss=188.21973, val_loss=198.34286\n",
      "Epoch 21594: train_loss=188.19688, val_loss=198.31616\n",
      "Epoch 21595: train_loss=188.17575, val_loss=198.29660\n",
      "Epoch 21596: train_loss=188.15596, val_loss=198.28625\n",
      "Epoch 21597: train_loss=188.13701, val_loss=198.25635\n",
      "Epoch 21598: train_loss=188.11894, val_loss=198.25772\n",
      "Epoch 21599: train_loss=188.10156, val_loss=198.21800\n",
      "Epoch 21600: train_loss=188.08456, val_loss=198.23109\n",
      "Epoch 21601: train_loss=188.06825, val_loss=198.18350\n",
      "Epoch 21602: train_loss=188.05208, val_loss=198.20760\n",
      "Epoch 21603: train_loss=188.03650, val_loss=198.15150\n",
      "Epoch 21604: train_loss=188.02084, val_loss=198.18356\n",
      "Epoch 21605: train_loss=188.00587, val_loss=198.11847\n",
      "Epoch 21606: train_loss=187.99081, val_loss=198.15948\n",
      "Epoch 21607: train_loss=187.97653, val_loss=198.08797\n",
      "Epoch 21608: train_loss=187.96190, val_loss=198.13765\n",
      "Epoch 21609: train_loss=187.94786, val_loss=198.05859\n",
      "Epoch 21610: train_loss=187.93341, val_loss=198.11462\n",
      "Epoch 21611: train_loss=187.91948, val_loss=198.02757\n",
      "Epoch 21612: train_loss=187.90465, val_loss=198.08957\n",
      "Epoch 21613: train_loss=187.89024, val_loss=197.99655\n",
      "Epoch 21614: train_loss=187.87465, val_loss=198.06226\n",
      "Epoch 21615: train_loss=187.85884, val_loss=197.96333\n",
      "Epoch 21616: train_loss=187.84138, val_loss=198.03000\n",
      "Epoch 21617: train_loss=187.82343, val_loss=197.92613\n",
      "Epoch 21618: train_loss=187.80292, val_loss=197.99023\n",
      "Epoch 21619: train_loss=187.78209, val_loss=197.88486\n",
      "Epoch 21620: train_loss=187.75887, val_loss=197.94302\n",
      "Epoch 21621: train_loss=187.73553, val_loss=197.83896\n",
      "Epoch 21622: train_loss=187.71025, val_loss=197.88985\n",
      "Epoch 21623: train_loss=187.68494, val_loss=197.79036\n",
      "Epoch 21624: train_loss=187.65775, val_loss=197.83250\n",
      "Epoch 21625: train_loss=187.63083, val_loss=197.74165\n",
      "Epoch 21626: train_loss=187.60321, val_loss=197.77477\n",
      "Epoch 21627: train_loss=187.57643, val_loss=197.69427\n",
      "Epoch 21628: train_loss=187.54985, val_loss=197.71803\n",
      "Epoch 21629: train_loss=187.52400, val_loss=197.64819\n",
      "Epoch 21630: train_loss=187.49870, val_loss=197.66360\n",
      "Epoch 21631: train_loss=187.47441, val_loss=197.60469\n",
      "Epoch 21632: train_loss=187.45068, val_loss=197.61357\n",
      "Epoch 21633: train_loss=187.42787, val_loss=197.56447\n",
      "Epoch 21634: train_loss=187.40544, val_loss=197.56784\n",
      "Epoch 21635: train_loss=187.38385, val_loss=197.52563\n",
      "Epoch 21636: train_loss=187.36249, val_loss=197.52335\n",
      "Epoch 21637: train_loss=187.34172, val_loss=197.48561\n",
      "Epoch 21638: train_loss=187.32115, val_loss=197.48106\n",
      "Epoch 21639: train_loss=187.30093, val_loss=197.44585\n",
      "Epoch 21640: train_loss=187.28093, val_loss=197.44241\n",
      "Epoch 21641: train_loss=187.26125, val_loss=197.40678\n",
      "Epoch 21642: train_loss=187.24182, val_loss=197.40659\n",
      "Epoch 21643: train_loss=187.22279, val_loss=197.36844\n",
      "Epoch 21644: train_loss=187.20416, val_loss=197.37436\n",
      "Epoch 21645: train_loss=187.18616, val_loss=197.33051\n",
      "Epoch 21646: train_loss=187.16901, val_loss=197.34589\n",
      "Epoch 21647: train_loss=187.15309, val_loss=197.29369\n",
      "Epoch 21648: train_loss=187.13864, val_loss=197.32541\n",
      "Epoch 21649: train_loss=187.12610, val_loss=197.26598\n",
      "Epoch 21650: train_loss=187.11624, val_loss=197.32173\n",
      "Epoch 21651: train_loss=187.10991, val_loss=197.25131\n",
      "Epoch 21652: train_loss=187.10759, val_loss=197.33757\n",
      "Epoch 21653: train_loss=187.11104, val_loss=197.25281\n",
      "Epoch 21654: train_loss=187.11995, val_loss=197.37595\n",
      "Epoch 21655: train_loss=187.13568, val_loss=197.27518\n",
      "Epoch 21656: train_loss=187.15663, val_loss=197.43568\n",
      "Epoch 21657: train_loss=187.18123, val_loss=197.31204\n",
      "Epoch 21658: train_loss=187.20522, val_loss=197.49098\n",
      "Epoch 21659: train_loss=187.22231, val_loss=197.32851\n",
      "Epoch 21660: train_loss=187.22533, val_loss=197.48189\n",
      "Epoch 21661: train_loss=187.20622, val_loss=197.27057\n",
      "Epoch 21662: train_loss=187.16153, val_loss=197.35835\n",
      "Epoch 21663: train_loss=187.09090, val_loss=197.13037\n",
      "Epoch 21664: train_loss=187.00449, val_loss=197.15768\n",
      "Epoch 21665: train_loss=186.91353, val_loss=196.98466\n",
      "Epoch 21666: train_loss=186.83177, val_loss=196.98134\n",
      "Epoch 21667: train_loss=186.76854, val_loss=196.90800\n",
      "Epoch 21668: train_loss=186.72719, val_loss=196.88847\n",
      "Epoch 21669: train_loss=186.70657, val_loss=196.90828\n",
      "Epoch 21670: train_loss=186.70129, val_loss=196.86523\n",
      "Epoch 21671: train_loss=186.70389, val_loss=196.93486\n",
      "Epoch 21672: train_loss=186.70723, val_loss=196.85698\n",
      "Epoch 21673: train_loss=186.70476, val_loss=196.92992\n",
      "Epoch 21674: train_loss=186.69426, val_loss=196.82256\n",
      "Epoch 21675: train_loss=186.67250, val_loss=196.87532\n",
      "Epoch 21676: train_loss=186.64316, val_loss=196.76410\n",
      "Epoch 21677: train_loss=186.60692, val_loss=196.79196\n",
      "Epoch 21678: train_loss=186.56892, val_loss=196.70416\n",
      "Epoch 21679: train_loss=186.53195, val_loss=196.70982\n",
      "Epoch 21680: train_loss=186.49910, val_loss=196.66002\n",
      "Epoch 21681: train_loss=186.47156, val_loss=196.64644\n",
      "Epoch 21682: train_loss=186.44910, val_loss=196.63286\n",
      "Epoch 21683: train_loss=186.43074, val_loss=196.60243\n",
      "Epoch 21684: train_loss=186.41512, val_loss=196.61612\n",
      "Epoch 21685: train_loss=186.40121, val_loss=196.56955\n",
      "Epoch 21686: train_loss=186.38783, val_loss=196.59781\n",
      "Epoch 21687: train_loss=186.37416, val_loss=196.53679\n",
      "Epoch 21688: train_loss=186.35872, val_loss=196.56845\n",
      "Epoch 21689: train_loss=186.34198, val_loss=196.49918\n",
      "Epoch 21690: train_loss=186.32317, val_loss=196.53061\n",
      "Epoch 21691: train_loss=186.30284, val_loss=196.46115\n",
      "Epoch 21692: train_loss=186.28099, val_loss=196.48836\n",
      "Epoch 21693: train_loss=186.25856, val_loss=196.42232\n",
      "Epoch 21694: train_loss=186.23520, val_loss=196.44081\n",
      "Epoch 21695: train_loss=186.21165, val_loss=196.38098\n",
      "Epoch 21696: train_loss=186.18791, val_loss=196.39006\n",
      "Epoch 21697: train_loss=186.16481, val_loss=196.34079\n",
      "Epoch 21698: train_loss=186.14214, val_loss=196.34399\n",
      "Epoch 21699: train_loss=186.11998, val_loss=196.30560\n",
      "Epoch 21700: train_loss=186.09845, val_loss=196.30215\n",
      "Epoch 21701: train_loss=186.07744, val_loss=196.27107\n",
      "Epoch 21702: train_loss=186.05678, val_loss=196.26071\n",
      "Epoch 21703: train_loss=186.03638, val_loss=196.23643\n",
      "Epoch 21704: train_loss=186.01631, val_loss=196.21902\n",
      "Epoch 21705: train_loss=185.99648, val_loss=196.19987\n",
      "Epoch 21706: train_loss=185.97682, val_loss=196.17778\n",
      "Epoch 21707: train_loss=185.95734, val_loss=196.16379\n",
      "Epoch 21708: train_loss=185.93784, val_loss=196.13847\n",
      "Epoch 21709: train_loss=185.91856, val_loss=196.12993\n",
      "Epoch 21710: train_loss=185.89935, val_loss=196.10133\n",
      "Epoch 21711: train_loss=185.88029, val_loss=196.09741\n",
      "Epoch 21712: train_loss=185.86147, val_loss=196.06281\n",
      "Epoch 21713: train_loss=185.84305, val_loss=196.06424\n",
      "Epoch 21714: train_loss=185.82506, val_loss=196.02290\n",
      "Epoch 21715: train_loss=185.80777, val_loss=196.03537\n",
      "Epoch 21716: train_loss=185.79135, val_loss=195.98778\n",
      "Epoch 21717: train_loss=185.77589, val_loss=196.01320\n",
      "Epoch 21718: train_loss=185.76176, val_loss=195.95712\n",
      "Epoch 21719: train_loss=185.74939, val_loss=195.99930\n",
      "Epoch 21720: train_loss=185.73907, val_loss=195.93314\n",
      "Epoch 21721: train_loss=185.73134, val_loss=195.99890\n",
      "Epoch 21722: train_loss=185.72800, val_loss=195.92123\n",
      "Epoch 21723: train_loss=185.72845, val_loss=196.01781\n",
      "Epoch 21724: train_loss=185.73441, val_loss=195.92729\n",
      "Epoch 21725: train_loss=185.74409, val_loss=196.05769\n",
      "Epoch 21726: train_loss=185.75902, val_loss=195.95074\n",
      "Epoch 21727: train_loss=185.77702, val_loss=196.10820\n",
      "Epoch 21728: train_loss=185.79524, val_loss=195.97565\n",
      "Epoch 21729: train_loss=185.81001, val_loss=196.13539\n",
      "Epoch 21730: train_loss=185.81325, val_loss=195.96400\n",
      "Epoch 21731: train_loss=185.80121, val_loss=196.08934\n",
      "Epoch 21732: train_loss=185.76665, val_loss=195.88182\n",
      "Epoch 21733: train_loss=185.71147, val_loss=195.94894\n",
      "Epoch 21734: train_loss=185.63817, val_loss=195.74551\n",
      "Epoch 21735: train_loss=185.55656, val_loss=195.76616\n",
      "Epoch 21736: train_loss=185.47755, val_loss=195.62514\n",
      "Epoch 21737: train_loss=185.40935, val_loss=195.61984\n",
      "Epoch 21738: train_loss=185.35938, val_loss=195.57217\n",
      "Epoch 21739: train_loss=185.32884, val_loss=195.54848\n",
      "Epoch 21740: train_loss=185.31456, val_loss=195.57693\n",
      "Epoch 21741: train_loss=185.31123, val_loss=195.52802\n",
      "Epoch 21742: train_loss=185.31236, val_loss=195.59444\n",
      "Epoch 21743: train_loss=185.31262, val_loss=195.51401\n",
      "Epoch 21744: train_loss=185.30698, val_loss=195.58374\n",
      "Epoch 21745: train_loss=185.29501, val_loss=195.48048\n",
      "Epoch 21746: train_loss=185.27379, val_loss=195.53488\n",
      "Epoch 21747: train_loss=185.24680, val_loss=195.42726\n",
      "Epoch 21748: train_loss=185.21355, val_loss=195.45929\n",
      "Epoch 21749: train_loss=185.17885, val_loss=195.36858\n",
      "Epoch 21750: train_loss=185.14377, val_loss=195.37993\n",
      "Epoch 21751: train_loss=185.11084, val_loss=195.32019\n",
      "Epoch 21752: train_loss=185.08156, val_loss=195.31433\n",
      "Epoch 21753: train_loss=185.05658, val_loss=195.28754\n",
      "Epoch 21754: train_loss=185.03525, val_loss=195.26595\n",
      "Epoch 21755: train_loss=185.01677, val_loss=195.26337\n",
      "Epoch 21756: train_loss=185.00000, val_loss=195.22765\n",
      "Epoch 21757: train_loss=184.98447, val_loss=195.24182\n",
      "Epoch 21758: train_loss=184.96933, val_loss=195.19318\n",
      "Epoch 21759: train_loss=184.95377, val_loss=195.21579\n",
      "Epoch 21760: train_loss=184.93764, val_loss=195.15834\n",
      "Epoch 21761: train_loss=184.92050, val_loss=195.18419\n",
      "Epoch 21762: train_loss=184.90259, val_loss=195.12170\n",
      "Epoch 21763: train_loss=184.88307, val_loss=195.14580\n",
      "Epoch 21764: train_loss=184.86314, val_loss=195.08247\n",
      "Epoch 21765: train_loss=184.84206, val_loss=195.10237\n",
      "Epoch 21766: train_loss=184.82068, val_loss=195.04285\n",
      "Epoch 21767: train_loss=184.79883, val_loss=195.05884\n",
      "Epoch 21768: train_loss=184.77696, val_loss=195.00447\n",
      "Epoch 21769: train_loss=184.75511, val_loss=195.01570\n",
      "Epoch 21770: train_loss=184.73369, val_loss=194.96616\n",
      "Epoch 21771: train_loss=184.71245, val_loss=194.97220\n",
      "Epoch 21772: train_loss=184.69159, val_loss=194.92702\n",
      "Epoch 21773: train_loss=184.67082, val_loss=194.93051\n",
      "Epoch 21774: train_loss=184.65048, val_loss=194.89015\n",
      "Epoch 21775: train_loss=184.63039, val_loss=194.89282\n",
      "Epoch 21776: train_loss=184.61040, val_loss=194.85420\n",
      "Epoch 21777: train_loss=184.59050, val_loss=194.85541\n",
      "Epoch 21778: train_loss=184.57076, val_loss=194.81662\n",
      "Epoch 21779: train_loss=184.55110, val_loss=194.81741\n",
      "Epoch 21780: train_loss=184.53177, val_loss=194.77782\n",
      "Epoch 21781: train_loss=184.51242, val_loss=194.78139\n",
      "Epoch 21782: train_loss=184.49387, val_loss=194.74046\n",
      "Epoch 21783: train_loss=184.47559, val_loss=194.75165\n",
      "Epoch 21784: train_loss=184.45842, val_loss=194.70636\n",
      "Epoch 21785: train_loss=184.44217, val_loss=194.72887\n",
      "Epoch 21786: train_loss=184.42743, val_loss=194.67479\n",
      "Epoch 21787: train_loss=184.41422, val_loss=194.71353\n",
      "Epoch 21788: train_loss=184.40372, val_loss=194.64886\n",
      "Epoch 21789: train_loss=184.39558, val_loss=194.71167\n",
      "Epoch 21790: train_loss=184.39182, val_loss=194.63612\n",
      "Epoch 21791: train_loss=184.39140, val_loss=194.73051\n",
      "Epoch 21792: train_loss=184.39577, val_loss=194.64197\n",
      "Epoch 21793: train_loss=184.40396, val_loss=194.76796\n",
      "Epoch 21794: train_loss=184.41736, val_loss=194.66072\n",
      "Epoch 21795: train_loss=184.43311, val_loss=194.81157\n",
      "Epoch 21796: train_loss=184.44803, val_loss=194.67833\n",
      "Epoch 21797: train_loss=184.45844, val_loss=194.83083\n",
      "Epoch 21798: train_loss=184.45755, val_loss=194.66258\n",
      "Epoch 21799: train_loss=184.44319, val_loss=194.78407\n",
      "Epoch 21800: train_loss=184.40948, val_loss=194.58498\n",
      "Epoch 21801: train_loss=184.35797, val_loss=194.65436\n",
      "Epoch 21802: train_loss=184.29155, val_loss=194.46104\n",
      "Epoch 21803: train_loss=184.21803, val_loss=194.48756\n",
      "Epoch 21804: train_loss=184.14674, val_loss=194.34923\n",
      "Epoch 21805: train_loss=184.08362, val_loss=194.34920\n",
      "Epoch 21806: train_loss=184.03514, val_loss=194.29012\n",
      "Epoch 21807: train_loss=184.00134, val_loss=194.27190\n",
      "Epoch 21808: train_loss=183.98100, val_loss=194.28188\n",
      "Epoch 21809: train_loss=183.97073, val_loss=194.24028\n",
      "Epoch 21810: train_loss=183.96591, val_loss=194.29005\n",
      "Epoch 21811: train_loss=183.96266, val_loss=194.22179\n",
      "Epoch 21812: train_loss=183.95752, val_loss=194.28564\n",
      "Epoch 21813: train_loss=183.94891, val_loss=194.19572\n",
      "Epoch 21814: train_loss=183.93439, val_loss=194.25497\n",
      "Epoch 21815: train_loss=183.91513, val_loss=194.15384\n",
      "Epoch 21816: train_loss=183.88992, val_loss=194.19861\n",
      "Epoch 21817: train_loss=183.86192, val_loss=194.10201\n",
      "Epoch 21818: train_loss=183.83105, val_loss=194.12996\n",
      "Epoch 21819: train_loss=183.79977, val_loss=194.05003\n",
      "Epoch 21820: train_loss=183.76894, val_loss=194.06052\n",
      "Epoch 21821: train_loss=183.73997, val_loss=194.00589\n",
      "Epoch 21822: train_loss=183.71335, val_loss=194.00047\n",
      "Epoch 21823: train_loss=183.68951, val_loss=193.97256\n",
      "Epoch 21824: train_loss=183.66817, val_loss=193.95290\n",
      "Epoch 21825: train_loss=183.64894, val_loss=193.94525\n",
      "Epoch 21826: train_loss=183.63126, val_loss=193.91171\n",
      "Epoch 21827: train_loss=183.61447, val_loss=193.91937\n",
      "Epoch 21828: train_loss=183.59840, val_loss=193.87518\n",
      "Epoch 21829: train_loss=183.58250, val_loss=193.89517\n",
      "Epoch 21830: train_loss=183.56682, val_loss=193.84164\n",
      "Epoch 21831: train_loss=183.55084, val_loss=193.86920\n",
      "Epoch 21832: train_loss=183.53499, val_loss=193.80717\n",
      "Epoch 21833: train_loss=183.51872, val_loss=193.83966\n",
      "Epoch 21834: train_loss=183.50246, val_loss=193.77145\n",
      "Epoch 21835: train_loss=183.48590, val_loss=193.80963\n",
      "Epoch 21836: train_loss=183.46964, val_loss=193.73732\n",
      "Epoch 21837: train_loss=183.45296, val_loss=193.77980\n",
      "Epoch 21838: train_loss=183.43622, val_loss=193.70424\n",
      "Epoch 21839: train_loss=183.41925, val_loss=193.75151\n",
      "Epoch 21840: train_loss=183.40240, val_loss=193.67134\n",
      "Epoch 21841: train_loss=183.38535, val_loss=193.72102\n",
      "Epoch 21842: train_loss=183.36847, val_loss=193.63631\n",
      "Epoch 21843: train_loss=183.35158, val_loss=193.68919\n",
      "Epoch 21844: train_loss=183.33479, val_loss=193.60110\n",
      "Epoch 21845: train_loss=183.31775, val_loss=193.65794\n",
      "Epoch 21846: train_loss=183.30090, val_loss=193.56645\n",
      "Epoch 21847: train_loss=183.28369, val_loss=193.62526\n",
      "Epoch 21848: train_loss=183.26675, val_loss=193.53076\n",
      "Epoch 21849: train_loss=183.24919, val_loss=193.59265\n",
      "Epoch 21850: train_loss=183.23232, val_loss=193.49614\n",
      "Epoch 21851: train_loss=183.21428, val_loss=193.56004\n",
      "Epoch 21852: train_loss=183.19675, val_loss=193.45998\n",
      "Epoch 21853: train_loss=183.17752, val_loss=193.52238\n",
      "Epoch 21854: train_loss=183.15820, val_loss=193.42053\n",
      "Epoch 21855: train_loss=183.13675, val_loss=193.47910\n",
      "Epoch 21856: train_loss=183.11491, val_loss=193.37781\n",
      "Epoch 21857: train_loss=183.09076, val_loss=193.42902\n",
      "Epoch 21858: train_loss=183.06590, val_loss=193.33150\n",
      "Epoch 21859: train_loss=183.03946, val_loss=193.37149\n",
      "Epoch 21860: train_loss=183.01263, val_loss=193.28207\n",
      "Epoch 21861: train_loss=182.98534, val_loss=193.31155\n",
      "Epoch 21862: train_loss=182.95860, val_loss=193.23354\n",
      "Epoch 21863: train_loss=182.93210, val_loss=193.25301\n",
      "Epoch 21864: train_loss=182.90683, val_loss=193.18889\n",
      "Epoch 21865: train_loss=182.88234, val_loss=193.20152\n",
      "Epoch 21866: train_loss=182.85892, val_loss=193.15051\n",
      "Epoch 21867: train_loss=182.83615, val_loss=193.15488\n",
      "Epoch 21868: train_loss=182.81400, val_loss=193.11237\n",
      "Epoch 21869: train_loss=182.79248, val_loss=193.10800\n",
      "Epoch 21870: train_loss=182.77150, val_loss=193.07272\n",
      "Epoch 21871: train_loss=182.75096, val_loss=193.06396\n",
      "Epoch 21872: train_loss=182.73076, val_loss=193.03439\n",
      "Epoch 21873: train_loss=182.71069, val_loss=193.02263\n",
      "Epoch 21874: train_loss=182.69080, val_loss=192.99568\n",
      "Epoch 21875: train_loss=182.67105, val_loss=192.98262\n",
      "Epoch 21876: train_loss=182.65141, val_loss=192.95631\n",
      "Epoch 21877: train_loss=182.63184, val_loss=192.94337\n",
      "Epoch 21878: train_loss=182.61230, val_loss=192.91606\n",
      "Epoch 21879: train_loss=182.59293, val_loss=192.90556\n",
      "Epoch 21880: train_loss=182.57353, val_loss=192.87502\n",
      "Epoch 21881: train_loss=182.55444, val_loss=192.86948\n",
      "Epoch 21882: train_loss=182.53564, val_loss=192.83514\n",
      "Epoch 21883: train_loss=182.51736, val_loss=192.83914\n",
      "Epoch 21884: train_loss=182.49976, val_loss=192.79843\n",
      "Epoch 21885: train_loss=182.48305, val_loss=192.81406\n",
      "Epoch 21886: train_loss=182.46771, val_loss=192.76299\n",
      "Epoch 21887: train_loss=182.45470, val_loss=192.79857\n",
      "Epoch 21888: train_loss=182.44449, val_loss=192.73706\n",
      "Epoch 21889: train_loss=182.43837, val_loss=192.80440\n",
      "Epoch 21890: train_loss=182.43802, val_loss=192.73189\n",
      "Epoch 21891: train_loss=182.44398, val_loss=192.84489\n",
      "Epoch 21892: train_loss=182.46056, val_loss=192.76009\n",
      "Epoch 21893: train_loss=182.48669, val_loss=192.93150\n",
      "Epoch 21894: train_loss=182.52519, val_loss=192.82973\n",
      "Epoch 21895: train_loss=182.57257, val_loss=193.05151\n",
      "Epoch 21896: train_loss=182.62340, val_loss=192.91373\n",
      "Epoch 21897: train_loss=182.67094, val_loss=193.13651\n",
      "Epoch 21898: train_loss=182.69353, val_loss=192.92297\n",
      "Epoch 21899: train_loss=182.68358, val_loss=193.06410\n",
      "Epoch 21900: train_loss=182.62358, val_loss=192.77538\n",
      "Epoch 21901: train_loss=182.52260, val_loss=192.80615\n",
      "Epoch 21902: train_loss=182.39209, val_loss=192.54373\n",
      "Epoch 21903: train_loss=182.26138, val_loss=192.52644\n",
      "Epoch 21904: train_loss=182.15628, val_loss=192.41090\n",
      "Epoch 21905: train_loss=182.09035, val_loss=192.39180\n",
      "Epoch 21906: train_loss=182.06487, val_loss=192.42989\n",
      "Epoch 21907: train_loss=182.07071, val_loss=192.38913\n",
      "Epoch 21908: train_loss=182.09241, val_loss=192.49937\n",
      "Epoch 21909: train_loss=182.11421, val_loss=192.40312\n",
      "Epoch 21910: train_loss=182.12198, val_loss=192.50020\n",
      "Epoch 21911: train_loss=182.10864, val_loss=192.35588\n",
      "Epoch 21912: train_loss=182.07312, val_loss=192.40376\n",
      "Epoch 21913: train_loss=182.02165, val_loss=192.26318\n",
      "Epoch 21914: train_loss=181.96393, val_loss=192.27203\n",
      "Epoch 21915: train_loss=181.91083, val_loss=192.19290\n",
      "Epoch 21916: train_loss=181.86922, val_loss=192.17816\n",
      "Epoch 21917: train_loss=181.84181, val_loss=192.17274\n",
      "Epoch 21918: train_loss=181.82651, val_loss=192.13586\n",
      "Epoch 21919: train_loss=181.81911, val_loss=192.17874\n",
      "Epoch 21920: train_loss=181.81389, val_loss=192.11380\n",
      "Epoch 21921: train_loss=181.80542, val_loss=192.16510\n",
      "Epoch 21922: train_loss=181.79137, val_loss=192.07733\n",
      "Epoch 21923: train_loss=181.76997, val_loss=192.11255\n",
      "Epoch 21924: train_loss=181.74280, val_loss=192.02324\n",
      "Epoch 21925: train_loss=181.71161, val_loss=192.03786\n",
      "Epoch 21926: train_loss=181.67941, val_loss=191.97122\n",
      "Epoch 21927: train_loss=181.64862, val_loss=191.96904\n",
      "Epoch 21928: train_loss=181.62100, val_loss=191.93491\n",
      "Epoch 21929: train_loss=181.59700, val_loss=191.91550\n",
      "Epoch 21930: train_loss=181.57617, val_loss=191.90646\n",
      "Epoch 21931: train_loss=181.55751, val_loss=191.86996\n",
      "Epoch 21932: train_loss=181.54034, val_loss=191.87921\n",
      "Epoch 21933: train_loss=181.52356, val_loss=191.83113\n",
      "Epoch 21934: train_loss=181.50624, val_loss=191.84976\n",
      "Epoch 21935: train_loss=181.48801, val_loss=191.79404\n",
      "Epoch 21936: train_loss=181.46863, val_loss=191.81404\n",
      "Epoch 21937: train_loss=181.44791, val_loss=191.75525\n",
      "Epoch 21938: train_loss=181.42618, val_loss=191.77190\n",
      "Epoch 21939: train_loss=181.40379, val_loss=191.71365\n",
      "Epoch 21940: train_loss=181.38068, val_loss=191.72318\n",
      "Epoch 21941: train_loss=181.35730, val_loss=191.67012\n",
      "Epoch 21942: train_loss=181.33400, val_loss=191.67386\n",
      "Epoch 21943: train_loss=181.31062, val_loss=191.62906\n",
      "Epoch 21944: train_loss=181.28752, val_loss=191.62646\n",
      "Epoch 21945: train_loss=181.26457, val_loss=191.58937\n",
      "Epoch 21946: train_loss=181.24194, val_loss=191.57910\n",
      "Epoch 21947: train_loss=181.21970, val_loss=191.54842\n",
      "Epoch 21948: train_loss=181.19789, val_loss=191.53246\n",
      "Epoch 21949: train_loss=181.17619, val_loss=191.50945\n",
      "Epoch 21950: train_loss=181.15489, val_loss=191.48921\n",
      "Epoch 21951: train_loss=181.13374, val_loss=191.47229\n",
      "Epoch 21952: train_loss=181.11290, val_loss=191.44725\n",
      "Epoch 21953: train_loss=181.09241, val_loss=191.43442\n",
      "Epoch 21954: train_loss=181.07208, val_loss=191.40546\n",
      "Epoch 21955: train_loss=181.05202, val_loss=191.39915\n",
      "Epoch 21956: train_loss=181.03214, val_loss=191.36607\n",
      "Epoch 21957: train_loss=181.01279, val_loss=191.36565\n",
      "Epoch 21958: train_loss=180.99373, val_loss=191.32584\n",
      "Epoch 21959: train_loss=180.97531, val_loss=191.33379\n",
      "Epoch 21960: train_loss=180.95758, val_loss=191.28757\n",
      "Epoch 21961: train_loss=180.94080, val_loss=191.30937\n",
      "Epoch 21962: train_loss=180.92557, val_loss=191.25435\n",
      "Epoch 21963: train_loss=180.91176, val_loss=191.29189\n",
      "Epoch 21964: train_loss=180.89963, val_loss=191.22470\n",
      "Epoch 21965: train_loss=180.88901, val_loss=191.27980\n",
      "Epoch 21966: train_loss=180.87991, val_loss=191.20079\n",
      "Epoch 21967: train_loss=180.87236, val_loss=191.27628\n",
      "Epoch 21968: train_loss=180.86668, val_loss=191.18625\n",
      "Epoch 21969: train_loss=180.86247, val_loss=191.27957\n",
      "Epoch 21970: train_loss=180.85902, val_loss=191.17290\n",
      "Epoch 21971: train_loss=180.85515, val_loss=191.27718\n",
      "Epoch 21972: train_loss=180.84996, val_loss=191.15472\n",
      "Epoch 21973: train_loss=180.84261, val_loss=191.26196\n",
      "Epoch 21974: train_loss=180.83051, val_loss=191.12344\n",
      "Epoch 21975: train_loss=180.81270, val_loss=191.21938\n",
      "Epoch 21976: train_loss=180.78757, val_loss=191.07030\n",
      "Epoch 21977: train_loss=180.75606, val_loss=191.14484\n",
      "Epoch 21978: train_loss=180.71812, val_loss=190.99750\n",
      "Epoch 21979: train_loss=180.67587, val_loss=191.04698\n",
      "Epoch 21980: train_loss=180.63130, val_loss=190.92024\n",
      "Epoch 21981: train_loss=180.58725, val_loss=190.94595\n",
      "Epoch 21982: train_loss=180.54503, val_loss=190.85301\n",
      "Epoch 21983: train_loss=180.50676, val_loss=190.85896\n",
      "Epoch 21984: train_loss=180.47366, val_loss=190.80635\n",
      "Epoch 21985: train_loss=180.44540, val_loss=190.79402\n",
      "Epoch 21986: train_loss=180.42197, val_loss=190.77702\n",
      "Epoch 21987: train_loss=180.40240, val_loss=190.74623\n",
      "Epoch 21988: train_loss=180.38545, val_loss=190.75452\n",
      "Epoch 21989: train_loss=180.37068, val_loss=190.70769\n",
      "Epoch 21990: train_loss=180.35690, val_loss=190.73663\n",
      "Epoch 21991: train_loss=180.34398, val_loss=190.67621\n",
      "Epoch 21992: train_loss=180.33073, val_loss=190.71773\n",
      "Epoch 21993: train_loss=180.31686, val_loss=190.64597\n",
      "Epoch 21994: train_loss=180.30266, val_loss=190.69377\n",
      "Epoch 21995: train_loss=180.28740, val_loss=190.61188\n",
      "Epoch 21996: train_loss=180.27121, val_loss=190.66180\n",
      "Epoch 21997: train_loss=180.25417, val_loss=190.57451\n",
      "Epoch 21998: train_loss=180.23630, val_loss=190.62651\n",
      "Epoch 21999: train_loss=180.21779, val_loss=190.53632\n",
      "Epoch 22000: train_loss=180.19879, val_loss=190.58914\n",
      "Epoch 22001: train_loss=180.17937, val_loss=190.49683\n",
      "Epoch 22002: train_loss=180.15942, val_loss=190.54800\n",
      "Epoch 22003: train_loss=180.13869, val_loss=190.45499\n",
      "Epoch 22004: train_loss=180.11772, val_loss=190.50385\n",
      "Epoch 22005: train_loss=180.09575, val_loss=190.41168\n",
      "Epoch 22006: train_loss=180.07367, val_loss=190.45694\n",
      "Epoch 22007: train_loss=180.05070, val_loss=190.36752\n",
      "Epoch 22008: train_loss=180.02733, val_loss=190.40839\n",
      "Epoch 22009: train_loss=180.00360, val_loss=190.32375\n",
      "Epoch 22010: train_loss=179.97963, val_loss=190.35773\n",
      "Epoch 22011: train_loss=179.95549, val_loss=190.27869\n",
      "Epoch 22012: train_loss=179.93150, val_loss=190.30608\n",
      "Epoch 22013: train_loss=179.90747, val_loss=190.23433\n",
      "Epoch 22014: train_loss=179.88364, val_loss=190.25584\n",
      "Epoch 22015: train_loss=179.86006, val_loss=190.19203\n",
      "Epoch 22016: train_loss=179.83665, val_loss=190.20723\n",
      "Epoch 22017: train_loss=179.81358, val_loss=190.14917\n",
      "Epoch 22018: train_loss=179.79100, val_loss=190.15683\n",
      "Epoch 22019: train_loss=179.76865, val_loss=190.10573\n",
      "Epoch 22020: train_loss=179.74660, val_loss=190.10904\n",
      "Epoch 22021: train_loss=179.72493, val_loss=190.06589\n",
      "Epoch 22022: train_loss=179.70354, val_loss=190.06517\n",
      "Epoch 22023: train_loss=179.68245, val_loss=190.02740\n",
      "Epoch 22024: train_loss=179.66151, val_loss=190.02275\n",
      "Epoch 22025: train_loss=179.64082, val_loss=189.98801\n",
      "Epoch 22026: train_loss=179.62036, val_loss=189.98145\n",
      "Epoch 22027: train_loss=179.60013, val_loss=189.94922\n",
      "Epoch 22028: train_loss=179.58002, val_loss=189.94337\n",
      "Epoch 22029: train_loss=179.56009, val_loss=189.91023\n",
      "Epoch 22030: train_loss=179.54034, val_loss=189.90685\n",
      "Epoch 22031: train_loss=179.52086, val_loss=189.86984\n",
      "Epoch 22032: train_loss=179.50151, val_loss=189.87128\n",
      "Epoch 22033: train_loss=179.48277, val_loss=189.82996\n",
      "Epoch 22034: train_loss=179.46465, val_loss=189.84012\n",
      "Epoch 22035: train_loss=179.44760, val_loss=189.79170\n",
      "Epoch 22036: train_loss=179.43213, val_loss=189.81841\n",
      "Epoch 22037: train_loss=179.41901, val_loss=189.76196\n",
      "Epoch 22038: train_loss=179.40935, val_loss=189.81680\n",
      "Epoch 22039: train_loss=179.40396, val_loss=189.74930\n",
      "Epoch 22040: train_loss=179.40451, val_loss=189.84169\n",
      "Epoch 22041: train_loss=179.41286, val_loss=189.76137\n",
      "Epoch 22042: train_loss=179.43112, val_loss=189.90756\n",
      "Epoch 22043: train_loss=179.46059, val_loss=189.81534\n",
      "Epoch 22044: train_loss=179.50185, val_loss=190.02213\n",
      "Epoch 22045: train_loss=179.55151, val_loss=189.90349\n",
      "Epoch 22046: train_loss=179.60381, val_loss=190.13280\n",
      "Epoch 22047: train_loss=179.64200, val_loss=189.94949\n",
      "Epoch 22048: train_loss=179.65811, val_loss=190.12254\n",
      "Epoch 22049: train_loss=179.62868, val_loss=189.85138\n",
      "Epoch 22050: train_loss=179.55592, val_loss=189.91396\n",
      "Epoch 22051: train_loss=179.43980, val_loss=189.62781\n",
      "Epoch 22052: train_loss=179.30663, val_loss=189.61861\n",
      "Epoch 22053: train_loss=179.18150, val_loss=189.44806\n",
      "Epoch 22054: train_loss=179.08804, val_loss=189.42885\n",
      "Epoch 22055: train_loss=179.03514, val_loss=189.41898\n",
      "Epoch 22056: train_loss=179.01993, val_loss=189.38664\n",
      "Epoch 22057: train_loss=179.03125, val_loss=189.48177\n",
      "Epoch 22058: train_loss=179.05405, val_loss=189.40674\n",
      "Epoch 22059: train_loss=179.07219, val_loss=189.51535\n",
      "Epoch 22060: train_loss=179.07256, val_loss=189.38477\n",
      "Epoch 22061: train_loss=179.05191, val_loss=189.45094\n",
      "Epoch 22062: train_loss=179.00938, val_loss=189.30061\n",
      "Epoch 22063: train_loss=178.95433, val_loss=189.32008\n",
      "Epoch 22064: train_loss=178.89590, val_loss=189.21046\n",
      "Epoch 22065: train_loss=178.84395, val_loss=189.20290\n",
      "Epoch 22066: train_loss=178.80443, val_loss=189.16922\n",
      "Epoch 22067: train_loss=178.77843, val_loss=189.14114\n",
      "Epoch 22068: train_loss=178.76324, val_loss=189.16640\n",
      "Epoch 22069: train_loss=178.75417, val_loss=189.11122\n",
      "Epoch 22070: train_loss=178.74687, val_loss=189.15988\n",
      "Epoch 22071: train_loss=178.73668, val_loss=189.07788\n",
      "Epoch 22072: train_loss=178.72063, val_loss=189.12271\n",
      "Epoch 22073: train_loss=178.69847, val_loss=189.03012\n",
      "Epoch 22074: train_loss=178.67052, val_loss=189.05878\n",
      "Epoch 22075: train_loss=178.63901, val_loss=188.97406\n",
      "Epoch 22076: train_loss=178.60585, val_loss=188.98364\n",
      "Epoch 22077: train_loss=178.57289, val_loss=188.92488\n",
      "Epoch 22078: train_loss=178.54257, val_loss=188.91690\n",
      "Epoch 22079: train_loss=178.51530, val_loss=188.88730\n",
      "Epoch 22080: train_loss=178.49109, val_loss=188.86122\n",
      "Epoch 22081: train_loss=178.46945, val_loss=188.85526\n",
      "Epoch 22082: train_loss=178.44942, val_loss=188.81325\n",
      "Epoch 22083: train_loss=178.42990, val_loss=188.82150\n",
      "Epoch 22084: train_loss=178.41008, val_loss=188.76915\n",
      "Epoch 22085: train_loss=178.38989, val_loss=188.78548\n",
      "Epoch 22086: train_loss=178.36890, val_loss=188.72667\n",
      "Epoch 22087: train_loss=178.34686, val_loss=188.74348\n",
      "Epoch 22088: train_loss=178.32352, val_loss=188.68094\n",
      "Epoch 22089: train_loss=178.29942, val_loss=188.69299\n",
      "Epoch 22090: train_loss=178.27440, val_loss=188.63208\n",
      "Epoch 22091: train_loss=178.24881, val_loss=188.63992\n",
      "Epoch 22092: train_loss=178.22299, val_loss=188.58675\n",
      "Epoch 22093: train_loss=178.19717, val_loss=188.58929\n",
      "Epoch 22094: train_loss=178.17140, val_loss=188.54259\n",
      "Epoch 22095: train_loss=178.14586, val_loss=188.53674\n",
      "Epoch 22096: train_loss=178.12050, val_loss=188.49498\n",
      "Epoch 22097: train_loss=178.09546, val_loss=188.48189\n",
      "Epoch 22098: train_loss=178.07062, val_loss=188.44867\n",
      "Epoch 22099: train_loss=178.04602, val_loss=188.43184\n",
      "Epoch 22100: train_loss=178.02167, val_loss=188.40646\n",
      "Epoch 22101: train_loss=177.99747, val_loss=188.38379\n",
      "Epoch 22102: train_loss=177.97350, val_loss=188.36237\n",
      "Epoch 22103: train_loss=177.94952, val_loss=188.33463\n",
      "Epoch 22104: train_loss=177.92577, val_loss=188.31769\n",
      "Epoch 22105: train_loss=177.90193, val_loss=188.28592\n",
      "Epoch 22106: train_loss=177.87834, val_loss=188.27475\n",
      "Epoch 22107: train_loss=177.85492, val_loss=188.23836\n",
      "Epoch 22108: train_loss=177.83185, val_loss=188.23363\n",
      "Epoch 22109: train_loss=177.80910, val_loss=188.19078\n",
      "Epoch 22110: train_loss=177.78699, val_loss=188.19585\n",
      "Epoch 22111: train_loss=177.76535, val_loss=188.14577\n",
      "Epoch 22112: train_loss=177.74443, val_loss=188.16130\n",
      "Epoch 22113: train_loss=177.72501, val_loss=188.10106\n",
      "Epoch 22114: train_loss=177.70667, val_loss=188.13275\n",
      "Epoch 22115: train_loss=177.69023, val_loss=188.06459\n",
      "Epoch 22116: train_loss=177.67545, val_loss=188.11827\n",
      "Epoch 22117: train_loss=177.66313, val_loss=188.03903\n",
      "Epoch 22118: train_loss=177.65320, val_loss=188.11240\n",
      "Epoch 22119: train_loss=177.64545, val_loss=188.01611\n",
      "Epoch 22120: train_loss=177.63945, val_loss=188.10909\n",
      "Epoch 22121: train_loss=177.63498, val_loss=187.99796\n",
      "Epoch 22122: train_loss=177.63129, val_loss=188.10899\n",
      "Epoch 22123: train_loss=177.62627, val_loss=187.98145\n",
      "Epoch 22124: train_loss=177.61902, val_loss=188.09789\n",
      "Epoch 22125: train_loss=177.60651, val_loss=187.95061\n",
      "Epoch 22126: train_loss=177.58810, val_loss=188.05577\n",
      "Epoch 22127: train_loss=177.56151, val_loss=187.89296\n",
      "Epoch 22128: train_loss=177.52696, val_loss=187.97336\n",
      "Epoch 22129: train_loss=177.48442, val_loss=187.80945\n",
      "Epoch 22130: train_loss=177.43593, val_loss=187.86000\n",
      "Epoch 22131: train_loss=177.38316, val_loss=187.71680\n",
      "Epoch 22132: train_loss=177.33005, val_loss=187.74214\n",
      "Epoch 22133: train_loss=177.27998, val_loss=187.63902\n",
      "Epoch 22134: train_loss=177.23485, val_loss=187.64224\n",
      "Epoch 22135: train_loss=177.19615, val_loss=187.58380\n",
      "Epoch 22136: train_loss=177.16362, val_loss=187.56679\n",
      "Epoch 22137: train_loss=177.13669, val_loss=187.54669\n",
      "Epoch 22138: train_loss=177.11400, val_loss=187.51170\n",
      "Epoch 22139: train_loss=177.09448, val_loss=187.52116\n",
      "Epoch 22140: train_loss=177.07709, val_loss=187.46939\n",
      "Epoch 22141: train_loss=177.06053, val_loss=187.49902\n",
      "Epoch 22142: train_loss=177.04446, val_loss=187.43271\n",
      "Epoch 22143: train_loss=177.02818, val_loss=187.47369\n",
      "Epoch 22144: train_loss=177.01111, val_loss=187.39366\n",
      "Epoch 22145: train_loss=176.99272, val_loss=187.43816\n",
      "Epoch 22146: train_loss=176.97318, val_loss=187.34973\n",
      "Epoch 22147: train_loss=176.95276, val_loss=187.39551\n",
      "Epoch 22148: train_loss=176.93077, val_loss=187.30365\n",
      "Epoch 22149: train_loss=176.90764, val_loss=187.34926\n",
      "Epoch 22150: train_loss=176.88344, val_loss=187.25824\n",
      "Epoch 22151: train_loss=176.85889, val_loss=187.30002\n",
      "Epoch 22152: train_loss=176.83391, val_loss=187.21019\n",
      "Epoch 22153: train_loss=176.80861, val_loss=187.24683\n",
      "Epoch 22154: train_loss=176.78343, val_loss=187.16066\n",
      "Epoch 22155: train_loss=176.75783, val_loss=187.19284\n",
      "Epoch 22156: train_loss=176.73259, val_loss=187.11353\n",
      "Epoch 22157: train_loss=176.70724, val_loss=187.14084\n",
      "Epoch 22158: train_loss=176.68201, val_loss=187.06909\n",
      "Epoch 22159: train_loss=176.65714, val_loss=187.09123\n",
      "Epoch 22160: train_loss=176.63286, val_loss=187.02553\n",
      "Epoch 22161: train_loss=176.60872, val_loss=187.04176\n",
      "Epoch 22162: train_loss=176.58501, val_loss=186.98047\n",
      "Epoch 22163: train_loss=176.56151, val_loss=186.99016\n",
      "Epoch 22164: train_loss=176.53831, val_loss=186.93404\n",
      "Epoch 22165: train_loss=176.51537, val_loss=186.94058\n",
      "Epoch 22166: train_loss=176.49286, val_loss=186.89220\n",
      "Epoch 22167: train_loss=176.47061, val_loss=186.89784\n",
      "Epoch 22168: train_loss=176.44876, val_loss=186.85376\n",
      "Epoch 22169: train_loss=176.42699, val_loss=186.85582\n",
      "Epoch 22170: train_loss=176.40569, val_loss=186.81216\n",
      "Epoch 22171: train_loss=176.38441, val_loss=186.81407\n",
      "Epoch 22172: train_loss=176.36349, val_loss=186.77083\n",
      "Epoch 22173: train_loss=176.34268, val_loss=186.77396\n",
      "Epoch 22174: train_loss=176.32216, val_loss=186.72945\n",
      "Epoch 22175: train_loss=176.30185, val_loss=186.73592\n",
      "Epoch 22176: train_loss=176.28224, val_loss=186.68835\n",
      "Epoch 22177: train_loss=176.26302, val_loss=186.70276\n",
      "Epoch 22178: train_loss=176.24467, val_loss=186.64983\n",
      "Epoch 22179: train_loss=176.22731, val_loss=186.67557\n",
      "Epoch 22180: train_loss=176.21161, val_loss=186.61377\n",
      "Epoch 22181: train_loss=176.19809, val_loss=186.65849\n",
      "Epoch 22182: train_loss=176.18790, val_loss=186.58694\n",
      "Epoch 22183: train_loss=176.18205, val_loss=186.66588\n",
      "Epoch 22184: train_loss=176.18240, val_loss=186.58379\n",
      "Epoch 22185: train_loss=176.18979, val_loss=186.70831\n",
      "Epoch 22186: train_loss=176.20619, val_loss=186.61002\n",
      "Epoch 22187: train_loss=176.23102, val_loss=186.78339\n",
      "Epoch 22188: train_loss=176.26270, val_loss=186.66188\n",
      "Epoch 22189: train_loss=176.30084, val_loss=186.87357\n",
      "Epoch 22190: train_loss=176.33617, val_loss=186.71216\n",
      "Epoch 22191: train_loss=176.36339, val_loss=186.91331\n",
      "Epoch 22192: train_loss=176.36482, val_loss=186.68446\n",
      "Epoch 22193: train_loss=176.33620, val_loss=186.80824\n",
      "Epoch 22194: train_loss=176.26651, val_loss=186.53275\n",
      "Epoch 22195: train_loss=176.16966, val_loss=186.56906\n",
      "Epoch 22196: train_loss=176.05441, val_loss=186.33884\n",
      "Epoch 22197: train_loss=175.94574, val_loss=186.33295\n",
      "Epoch 22198: train_loss=175.85921, val_loss=186.23395\n",
      "Epoch 22199: train_loss=175.80460, val_loss=186.21477\n",
      "Epoch 22200: train_loss=175.78036, val_loss=186.24316\n",
      "Epoch 22201: train_loss=175.77873, val_loss=186.19696\n",
      "Epoch 22202: train_loss=175.78894, val_loss=186.28839\n",
      "Epoch 22203: train_loss=175.79971, val_loss=186.19753\n",
      "Epoch 22204: train_loss=175.80334, val_loss=186.28934\n",
      "Epoch 22205: train_loss=175.79193, val_loss=186.15918\n",
      "Epoch 22206: train_loss=175.76633, val_loss=186.21823\n",
      "Epoch 22207: train_loss=175.72710, val_loss=186.08464\n",
      "Epoch 22208: train_loss=175.68106, val_loss=186.10834\n",
      "Epoch 22209: train_loss=175.63402, val_loss=186.01401\n",
      "Epoch 22210: train_loss=175.59236, val_loss=186.01010\n",
      "Epoch 22211: train_loss=175.55890, val_loss=185.97273\n",
      "Epoch 22212: train_loss=175.53427, val_loss=185.94522\n",
      "Epoch 22213: train_loss=175.51732, val_loss=185.95992\n",
      "Epoch 22214: train_loss=175.50488, val_loss=185.90952\n",
      "Epoch 22215: train_loss=175.49358, val_loss=185.94743\n",
      "Epoch 22216: train_loss=175.48100, val_loss=185.87679\n",
      "Epoch 22217: train_loss=175.46521, val_loss=185.91519\n",
      "Epoch 22218: train_loss=175.44589, val_loss=185.83574\n",
      "Epoch 22219: train_loss=175.42308, val_loss=185.86337\n",
      "Epoch 22220: train_loss=175.39780, val_loss=185.78824\n",
      "Epoch 22221: train_loss=175.37073, val_loss=185.80139\n",
      "Epoch 22222: train_loss=175.34361, val_loss=185.74458\n",
      "Epoch 22223: train_loss=175.31746, val_loss=185.74156\n",
      "Epoch 22224: train_loss=175.29297, val_loss=185.70737\n",
      "Epoch 22225: train_loss=175.27052, val_loss=185.68768\n",
      "Epoch 22226: train_loss=175.24986, val_loss=185.67494\n",
      "Epoch 22227: train_loss=175.23079, val_loss=185.64145\n",
      "Epoch 22228: train_loss=175.21254, val_loss=185.64470\n",
      "Epoch 22229: train_loss=175.19463, val_loss=185.60149\n",
      "Epoch 22230: train_loss=175.17659, val_loss=185.61317\n",
      "Epoch 22231: train_loss=175.15823, val_loss=185.56245\n",
      "Epoch 22232: train_loss=175.13922, val_loss=185.57773\n",
      "Epoch 22233: train_loss=175.11987, val_loss=185.52235\n",
      "Epoch 22234: train_loss=175.09981, val_loss=185.53680\n",
      "Epoch 22235: train_loss=175.07938, val_loss=185.48196\n",
      "Epoch 22236: train_loss=175.05840, val_loss=185.49382\n",
      "Epoch 22237: train_loss=175.03729, val_loss=185.44168\n",
      "Epoch 22238: train_loss=175.01584, val_loss=185.45015\n",
      "Epoch 22239: train_loss=174.99449, val_loss=185.40192\n",
      "Epoch 22240: train_loss=174.97308, val_loss=185.40556\n",
      "Epoch 22241: train_loss=174.95183, val_loss=185.36153\n",
      "Epoch 22242: train_loss=174.93057, val_loss=185.36130\n",
      "Epoch 22243: train_loss=174.90962, val_loss=185.32245\n",
      "Epoch 22244: train_loss=174.88857, val_loss=185.31976\n",
      "Epoch 22245: train_loss=174.86765, val_loss=185.28522\n",
      "Epoch 22246: train_loss=174.84692, val_loss=185.27777\n",
      "Epoch 22247: train_loss=174.82623, val_loss=185.24586\n",
      "Epoch 22248: train_loss=174.80563, val_loss=185.23494\n",
      "Epoch 22249: train_loss=174.78522, val_loss=185.20589\n",
      "Epoch 22250: train_loss=174.76494, val_loss=185.19412\n",
      "Epoch 22251: train_loss=174.74461, val_loss=185.16718\n",
      "Epoch 22252: train_loss=174.72424, val_loss=185.15437\n",
      "Epoch 22253: train_loss=174.70398, val_loss=185.12694\n",
      "Epoch 22254: train_loss=174.68372, val_loss=185.11433\n",
      "Epoch 22255: train_loss=174.66357, val_loss=185.08618\n",
      "Epoch 22256: train_loss=174.64346, val_loss=185.07491\n",
      "Epoch 22257: train_loss=174.62341, val_loss=185.04332\n",
      "Epoch 22258: train_loss=174.60359, val_loss=185.03583\n",
      "Epoch 22259: train_loss=174.58406, val_loss=185.00157\n",
      "Epoch 22260: train_loss=174.56482, val_loss=185.00349\n",
      "Epoch 22261: train_loss=174.54642, val_loss=184.96243\n",
      "Epoch 22262: train_loss=174.52879, val_loss=184.97675\n",
      "Epoch 22263: train_loss=174.51241, val_loss=184.92572\n",
      "Epoch 22264: train_loss=174.49770, val_loss=184.95877\n",
      "Epoch 22265: train_loss=174.48514, val_loss=184.89590\n",
      "Epoch 22266: train_loss=174.47572, val_loss=184.95561\n",
      "Epoch 22267: train_loss=174.46994, val_loss=184.88011\n",
      "Epoch 22268: train_loss=174.46971, val_loss=184.97585\n",
      "Epoch 22269: train_loss=174.47525, val_loss=184.88593\n",
      "Epoch 22270: train_loss=174.48877, val_loss=185.03087\n",
      "Epoch 22271: train_loss=174.51118, val_loss=184.92471\n",
      "Epoch 22272: train_loss=174.54282, val_loss=185.12018\n",
      "Epoch 22273: train_loss=174.57990, val_loss=184.98788\n",
      "Epoch 22274: train_loss=174.62149, val_loss=185.21381\n",
      "Epoch 22275: train_loss=174.65591, val_loss=185.03024\n",
      "Epoch 22276: train_loss=174.67451, val_loss=185.22385\n",
      "Epoch 22277: train_loss=174.65831, val_loss=184.96922\n",
      "Epoch 22278: train_loss=174.60800, val_loss=185.07043\n",
      "Epoch 22279: train_loss=174.51584, val_loss=184.78580\n",
      "Epoch 22280: train_loss=174.40161, val_loss=184.80237\n",
      "Epoch 22281: train_loss=174.28214, val_loss=184.60077\n",
      "Epoch 22282: train_loss=174.18176, val_loss=184.58975\n",
      "Epoch 22283: train_loss=174.11316, val_loss=184.53957\n",
      "Epoch 22284: train_loss=174.07991, val_loss=184.51404\n",
      "Epoch 22285: train_loss=174.07565, val_loss=184.58295\n",
      "Epoch 22286: train_loss=174.08815, val_loss=184.52048\n",
      "Epoch 22287: train_loss=174.10489, val_loss=184.62924\n",
      "Epoch 22288: train_loss=174.11270, val_loss=184.51541\n",
      "Epoch 22289: train_loss=174.10555, val_loss=184.59975\n",
      "Epoch 22290: train_loss=174.07858, val_loss=184.45638\n",
      "Epoch 22291: train_loss=174.03764, val_loss=184.49573\n",
      "Epoch 22292: train_loss=173.98772, val_loss=184.37459\n",
      "Epoch 22293: train_loss=173.93855, val_loss=184.38202\n",
      "Epoch 22294: train_loss=173.89590, val_loss=184.32272\n",
      "Epoch 22295: train_loss=173.86353, val_loss=184.30618\n",
      "Epoch 22296: train_loss=173.84171, val_loss=184.30974\n",
      "Epoch 22297: train_loss=173.82794, val_loss=184.26790\n",
      "Epoch 22298: train_loss=173.81857, val_loss=184.30702\n",
      "Epoch 22299: train_loss=173.80949, val_loss=184.23984\n",
      "Epoch 22300: train_loss=173.79829, val_loss=184.28548\n",
      "Epoch 22301: train_loss=173.78198, val_loss=184.20219\n",
      "Epoch 22302: train_loss=173.76160, val_loss=184.23712\n",
      "Epoch 22303: train_loss=173.73659, val_loss=184.15416\n",
      "Epoch 22304: train_loss=173.70924, val_loss=184.17220\n",
      "Epoch 22305: train_loss=173.68057, val_loss=184.10773\n",
      "Epoch 22306: train_loss=173.65276, val_loss=184.10822\n",
      "Epoch 22307: train_loss=173.62691, val_loss=184.07204\n",
      "Epoch 22308: train_loss=173.60387, val_loss=184.05467\n",
      "Epoch 22309: train_loss=173.58350, val_loss=184.04401\n",
      "Epoch 22310: train_loss=173.56517, val_loss=184.01027\n",
      "Epoch 22311: train_loss=173.54790, val_loss=184.01749\n",
      "Epoch 22312: train_loss=173.53098, val_loss=183.97263\n",
      "Epoch 22313: train_loss=173.51349, val_loss=183.98700\n",
      "Epoch 22314: train_loss=173.49521, val_loss=183.93526\n",
      "Epoch 22315: train_loss=173.47609, val_loss=183.94917\n",
      "Epoch 22316: train_loss=173.45599, val_loss=183.89619\n",
      "Epoch 22317: train_loss=173.43507, val_loss=183.90576\n",
      "Epoch 22318: train_loss=173.41374, val_loss=183.85718\n",
      "Epoch 22319: train_loss=173.39218, val_loss=183.86130\n",
      "Epoch 22320: train_loss=173.37062, val_loss=183.82016\n",
      "Epoch 22321: train_loss=173.34920, val_loss=183.81651\n",
      "Epoch 22322: train_loss=173.32814, val_loss=183.78352\n",
      "Epoch 22323: train_loss=173.30739, val_loss=183.77290\n",
      "Epoch 22324: train_loss=173.28693, val_loss=183.74741\n",
      "Epoch 22325: train_loss=173.26682, val_loss=183.73103\n",
      "Epoch 22326: train_loss=173.24681, val_loss=183.71121\n",
      "Epoch 22327: train_loss=173.22694, val_loss=183.69008\n",
      "Epoch 22328: train_loss=173.20731, val_loss=183.67517\n",
      "Epoch 22329: train_loss=173.18765, val_loss=183.65044\n",
      "Epoch 22330: train_loss=173.16811, val_loss=183.63905\n",
      "Epoch 22331: train_loss=173.14867, val_loss=183.60954\n",
      "Epoch 22332: train_loss=173.12946, val_loss=183.60353\n",
      "Epoch 22333: train_loss=173.11026, val_loss=183.56967\n",
      "Epoch 22334: train_loss=173.09154, val_loss=183.57056\n",
      "Epoch 22335: train_loss=173.07310, val_loss=183.53110\n",
      "Epoch 22336: train_loss=173.05539, val_loss=183.54175\n",
      "Epoch 22337: train_loss=173.03830, val_loss=183.49414\n",
      "Epoch 22338: train_loss=173.02261, val_loss=183.51855\n",
      "Epoch 22339: train_loss=173.00793, val_loss=183.45996\n",
      "Epoch 22340: train_loss=172.99504, val_loss=183.50177\n",
      "Epoch 22341: train_loss=172.98344, val_loss=183.43167\n",
      "Epoch 22342: train_loss=172.97412, val_loss=183.49385\n",
      "Epoch 22343: train_loss=172.96648, val_loss=183.41077\n",
      "Epoch 22344: train_loss=172.96155, val_loss=183.49559\n",
      "Epoch 22345: train_loss=172.95886, val_loss=183.39937\n",
      "Epoch 22346: train_loss=172.95959, val_loss=183.51019\n",
      "Epoch 22347: train_loss=172.96245, val_loss=183.39832\n",
      "Epoch 22348: train_loss=172.96751, val_loss=183.53137\n",
      "Epoch 22349: train_loss=172.97240, val_loss=183.39886\n",
      "Epoch 22350: train_loss=172.97617, val_loss=183.54054\n",
      "Epoch 22351: train_loss=172.97430, val_loss=183.38358\n",
      "Epoch 22352: train_loss=172.96581, val_loss=183.51439\n",
      "Epoch 22353: train_loss=172.94589, val_loss=183.33514\n",
      "Epoch 22354: train_loss=172.91534, val_loss=183.43436\n",
      "Epoch 22355: train_loss=172.87129, val_loss=183.24847\n",
      "Epoch 22356: train_loss=172.81877, val_loss=183.30650\n",
      "Epoch 22357: train_loss=172.75919, val_loss=183.14557\n",
      "Epoch 22358: train_loss=172.69995, val_loss=183.17043\n",
      "Epoch 22359: train_loss=172.64526, val_loss=183.06636\n",
      "Epoch 22360: train_loss=172.59988, val_loss=183.06709\n",
      "Epoch 22361: train_loss=172.56410, val_loss=183.02681\n",
      "Epoch 22362: train_loss=172.53819, val_loss=183.00627\n",
      "Epoch 22363: train_loss=172.52032, val_loss=183.01694\n",
      "Epoch 22364: train_loss=172.50803, val_loss=182.97188\n",
      "Epoch 22365: train_loss=172.49904, val_loss=183.01411\n",
      "Epoch 22366: train_loss=172.49055, val_loss=182.94649\n",
      "Epoch 22367: train_loss=172.48155, val_loss=183.00198\n",
      "Epoch 22368: train_loss=172.46962, val_loss=182.91687\n",
      "Epoch 22369: train_loss=172.45518, val_loss=182.97260\n",
      "Epoch 22370: train_loss=172.43709, val_loss=182.87866\n",
      "Epoch 22371: train_loss=172.41626, val_loss=182.92645\n",
      "Epoch 22372: train_loss=172.39244, val_loss=182.83340\n",
      "Epoch 22373: train_loss=172.36717, val_loss=182.87003\n",
      "Epoch 22374: train_loss=172.34007, val_loss=182.78708\n",
      "Epoch 22375: train_loss=172.31322, val_loss=182.81079\n",
      "Epoch 22376: train_loss=172.28592, val_loss=182.74318\n",
      "Epoch 22377: train_loss=172.26001, val_loss=182.75314\n",
      "Epoch 22378: train_loss=172.23485, val_loss=182.70239\n",
      "Epoch 22379: train_loss=172.21109, val_loss=182.69875\n",
      "Epoch 22380: train_loss=172.18846, val_loss=182.66525\n",
      "Epoch 22381: train_loss=172.16718, val_loss=182.64957\n",
      "Epoch 22382: train_loss=172.14696, val_loss=182.63208\n",
      "Epoch 22383: train_loss=172.12752, val_loss=182.60730\n",
      "Epoch 22384: train_loss=172.10878, val_loss=182.60188\n",
      "Epoch 22385: train_loss=172.09042, val_loss=182.56717\n",
      "Epoch 22386: train_loss=172.07251, val_loss=182.57019\n",
      "Epoch 22387: train_loss=172.05479, val_loss=182.52718\n",
      "Epoch 22388: train_loss=172.03735, val_loss=182.53964\n",
      "Epoch 22389: train_loss=172.02017, val_loss=182.49008\n",
      "Epoch 22390: train_loss=172.00377, val_loss=182.51244\n",
      "Epoch 22391: train_loss=171.98758, val_loss=182.45467\n",
      "Epoch 22392: train_loss=171.97231, val_loss=182.48639\n",
      "Epoch 22393: train_loss=171.95726, val_loss=182.41997\n",
      "Epoch 22394: train_loss=171.94383, val_loss=182.46494\n",
      "Epoch 22395: train_loss=171.93047, val_loss=182.39032\n",
      "Epoch 22396: train_loss=171.91910, val_loss=182.44984\n",
      "Epoch 22397: train_loss=171.90851, val_loss=182.36476\n",
      "Epoch 22398: train_loss=171.90027, val_loss=182.44098\n",
      "Epoch 22399: train_loss=171.89330, val_loss=182.34488\n",
      "Epoch 22400: train_loss=171.88913, val_loss=182.43996\n",
      "Epoch 22401: train_loss=171.88531, val_loss=182.33202\n",
      "Epoch 22402: train_loss=171.88380, val_loss=182.44478\n",
      "Epoch 22403: train_loss=171.88173, val_loss=182.32184\n",
      "Epoch 22404: train_loss=171.87993, val_loss=182.44373\n",
      "Epoch 22405: train_loss=171.87419, val_loss=182.30235\n",
      "Epoch 22406: train_loss=171.86534, val_loss=182.42010\n",
      "Epoch 22407: train_loss=171.84880, val_loss=182.26190\n",
      "Epoch 22408: train_loss=171.82597, val_loss=182.36067\n",
      "Epoch 22409: train_loss=171.79358, val_loss=182.19586\n",
      "Epoch 22410: train_loss=171.75510, val_loss=182.26671\n",
      "Epoch 22411: train_loss=171.70946, val_loss=182.11317\n",
      "Epoch 22412: train_loss=171.66202, val_loss=182.15561\n",
      "Epoch 22413: train_loss=171.61392, val_loss=182.03366\n",
      "Epoch 22414: train_loss=171.56943, val_loss=182.05212\n",
      "Epoch 22415: train_loss=171.52942, val_loss=181.97366\n",
      "Epoch 22416: train_loss=171.49525, val_loss=181.97195\n",
      "Epoch 22417: train_loss=171.46674, val_loss=181.93811\n",
      "Epoch 22418: train_loss=171.44373, val_loss=181.91687\n",
      "Epoch 22419: train_loss=171.42523, val_loss=181.91805\n",
      "Epoch 22420: train_loss=171.40965, val_loss=181.87746\n",
      "Epoch 22421: train_loss=171.39597, val_loss=181.90096\n",
      "Epoch 22422: train_loss=171.38287, val_loss=181.84279\n",
      "Epoch 22423: train_loss=171.36980, val_loss=181.87866\n",
      "Epoch 22424: train_loss=171.35594, val_loss=181.80840\n",
      "Epoch 22425: train_loss=171.34129, val_loss=181.85197\n",
      "Epoch 22426: train_loss=171.32547, val_loss=181.77443\n",
      "Epoch 22427: train_loss=171.30869, val_loss=181.81953\n",
      "Epoch 22428: train_loss=171.29080, val_loss=181.73695\n",
      "Epoch 22429: train_loss=171.27257, val_loss=181.78130\n",
      "Epoch 22430: train_loss=171.25308, val_loss=181.69716\n",
      "Epoch 22431: train_loss=171.23341, val_loss=181.74083\n",
      "Epoch 22432: train_loss=171.21313, val_loss=181.65762\n",
      "Epoch 22433: train_loss=171.19287, val_loss=181.69914\n",
      "Epoch 22434: train_loss=171.17241, val_loss=181.61627\n",
      "Epoch 22435: train_loss=171.15192, val_loss=181.65511\n",
      "Epoch 22436: train_loss=171.13118, val_loss=181.57367\n",
      "Epoch 22437: train_loss=171.11028, val_loss=181.61014\n",
      "Epoch 22438: train_loss=171.08929, val_loss=181.53212\n",
      "Epoch 22439: train_loss=171.06859, val_loss=181.56789\n",
      "Epoch 22440: train_loss=171.04793, val_loss=181.49272\n",
      "Epoch 22441: train_loss=171.02734, val_loss=181.52596\n",
      "Epoch 22442: train_loss=171.00684, val_loss=181.45238\n",
      "Epoch 22443: train_loss=170.98642, val_loss=181.48285\n",
      "Epoch 22444: train_loss=170.96605, val_loss=181.41106\n",
      "Epoch 22445: train_loss=170.94583, val_loss=181.44078\n",
      "Epoch 22446: train_loss=170.92580, val_loss=181.37122\n",
      "Epoch 22447: train_loss=170.90593, val_loss=181.40157\n",
      "Epoch 22448: train_loss=170.88638, val_loss=181.33333\n",
      "Epoch 22449: train_loss=170.86722, val_loss=181.36504\n",
      "Epoch 22450: train_loss=170.84874, val_loss=181.29655\n",
      "Epoch 22451: train_loss=170.83109, val_loss=181.33286\n",
      "Epoch 22452: train_loss=170.81416, val_loss=181.26172\n",
      "Epoch 22453: train_loss=170.79857, val_loss=181.30595\n",
      "Epoch 22454: train_loss=170.78407, val_loss=181.23013\n",
      "Epoch 22455: train_loss=170.77136, val_loss=181.28741\n",
      "Epoch 22456: train_loss=170.75999, val_loss=181.20473\n",
      "Epoch 22457: train_loss=170.75110, val_loss=181.27922\n",
      "Epoch 22458: train_loss=170.74409, val_loss=181.18745\n",
      "Epoch 22459: train_loss=170.73996, val_loss=181.28252\n",
      "Epoch 22460: train_loss=170.73761, val_loss=181.17816\n",
      "Epoch 22461: train_loss=170.73802, val_loss=181.29208\n",
      "Epoch 22462: train_loss=170.73813, val_loss=181.17101\n",
      "Epoch 22463: train_loss=170.73822, val_loss=181.29431\n",
      "Epoch 22464: train_loss=170.73380, val_loss=181.15405\n",
      "Epoch 22465: train_loss=170.72592, val_loss=181.27271\n",
      "Epoch 22466: train_loss=170.70998, val_loss=181.11530\n",
      "Epoch 22467: train_loss=170.68715, val_loss=181.21414\n",
      "Epoch 22468: train_loss=170.65457, val_loss=181.04965\n",
      "Epoch 22469: train_loss=170.61533, val_loss=181.11964\n",
      "Epoch 22470: train_loss=170.56842, val_loss=180.96620\n",
      "Epoch 22471: train_loss=170.51987, val_loss=181.00703\n",
      "Epoch 22472: train_loss=170.47108, val_loss=180.88649\n",
      "Epoch 22473: train_loss=170.42638, val_loss=180.90445\n",
      "Epoch 22474: train_loss=170.38574, val_loss=180.82753\n",
      "Epoch 22475: train_loss=170.35135, val_loss=180.82510\n",
      "Epoch 22476: train_loss=170.32278, val_loss=180.79239\n",
      "Epoch 22477: train_loss=170.29993, val_loss=180.77145\n",
      "Epoch 22478: train_loss=170.28191, val_loss=180.77431\n",
      "Epoch 22479: train_loss=170.26721, val_loss=180.73439\n",
      "Epoch 22480: train_loss=170.25421, val_loss=180.75902\n",
      "Epoch 22481: train_loss=170.24161, val_loss=180.70219\n",
      "Epoch 22482: train_loss=170.22873, val_loss=180.73911\n",
      "Epoch 22483: train_loss=170.21506, val_loss=180.67055\n",
      "Epoch 22484: train_loss=170.20117, val_loss=180.71498\n",
      "Epoch 22485: train_loss=170.18584, val_loss=180.63815\n",
      "Epoch 22486: train_loss=170.17004, val_loss=180.68446\n",
      "Epoch 22487: train_loss=170.15247, val_loss=180.60204\n",
      "Epoch 22488: train_loss=170.13419, val_loss=180.64694\n",
      "Epoch 22489: train_loss=170.11444, val_loss=180.56294\n",
      "Epoch 22490: train_loss=170.09439, val_loss=180.60538\n",
      "Epoch 22491: train_loss=170.07330, val_loss=180.52235\n",
      "Epoch 22492: train_loss=170.05243, val_loss=180.56136\n",
      "Epoch 22493: train_loss=170.03098, val_loss=180.48090\n",
      "Epoch 22494: train_loss=170.00946, val_loss=180.51646\n",
      "Epoch 22495: train_loss=169.98790, val_loss=180.43994\n",
      "Epoch 22496: train_loss=169.96628, val_loss=180.47185\n",
      "Epoch 22497: train_loss=169.94473, val_loss=180.39912\n",
      "Epoch 22498: train_loss=169.92345, val_loss=180.42735\n",
      "Epoch 22499: train_loss=169.90222, val_loss=180.35822\n",
      "Epoch 22500: train_loss=169.88141, val_loss=180.38362\n",
      "Epoch 22501: train_loss=169.86086, val_loss=180.31802\n",
      "Epoch 22502: train_loss=169.84055, val_loss=180.34279\n",
      "Epoch 22503: train_loss=169.82018, val_loss=180.28029\n",
      "Epoch 22504: train_loss=169.80038, val_loss=180.30377\n",
      "Epoch 22505: train_loss=169.78087, val_loss=180.24146\n",
      "Epoch 22506: train_loss=169.76161, val_loss=180.26392\n",
      "Epoch 22507: train_loss=169.74257, val_loss=180.20177\n",
      "Epoch 22508: train_loss=169.72397, val_loss=180.22751\n",
      "Epoch 22509: train_loss=169.70570, val_loss=180.16577\n",
      "Epoch 22510: train_loss=169.68823, val_loss=180.19698\n",
      "Epoch 22511: train_loss=169.67139, val_loss=180.13203\n",
      "Epoch 22512: train_loss=169.65572, val_loss=180.17163\n",
      "Epoch 22513: train_loss=169.64110, val_loss=180.10071\n",
      "Epoch 22514: train_loss=169.62868, val_loss=180.15442\n",
      "Epoch 22515: train_loss=169.61801, val_loss=180.07533\n",
      "Epoch 22516: train_loss=169.61046, val_loss=180.14902\n",
      "Epoch 22517: train_loss=169.60486, val_loss=180.05925\n",
      "Epoch 22518: train_loss=169.60338, val_loss=180.15837\n",
      "Epoch 22519: train_loss=169.60381, val_loss=180.05518\n",
      "Epoch 22520: train_loss=169.60800, val_loss=180.17867\n",
      "Epoch 22521: train_loss=169.61293, val_loss=180.05774\n",
      "Epoch 22522: train_loss=169.61908, val_loss=180.19612\n",
      "Epoch 22523: train_loss=169.62144, val_loss=180.05078\n",
      "Epoch 22524: train_loss=169.61916, val_loss=180.18451\n",
      "Epoch 22525: train_loss=169.60654, val_loss=180.01500\n",
      "Epoch 22526: train_loss=169.58427, val_loss=180.12251\n",
      "Epoch 22527: train_loss=169.54840, val_loss=179.94058\n",
      "Epoch 22528: train_loss=169.50288, val_loss=180.01089\n",
      "Epoch 22529: train_loss=169.44861, val_loss=179.84467\n",
      "Epoch 22530: train_loss=169.39287, val_loss=179.88161\n",
      "Epoch 22531: train_loss=169.33705, val_loss=179.75783\n",
      "Epoch 22532: train_loss=169.28754, val_loss=179.76874\n",
      "Epoch 22533: train_loss=169.24490, val_loss=179.70029\n",
      "Epoch 22534: train_loss=169.21118, val_loss=179.68872\n",
      "Epoch 22535: train_loss=169.18617, val_loss=179.67490\n",
      "Epoch 22536: train_loss=169.16838, val_loss=179.64380\n",
      "Epoch 22537: train_loss=169.15570, val_loss=179.66972\n",
      "Epoch 22538: train_loss=169.14597, val_loss=179.61682\n",
      "Epoch 22539: train_loss=169.13733, val_loss=179.66249\n",
      "Epoch 22540: train_loss=169.12775, val_loss=179.58937\n",
      "Epoch 22541: train_loss=169.11694, val_loss=179.64247\n",
      "Epoch 22542: train_loss=169.10320, val_loss=179.55545\n",
      "Epoch 22543: train_loss=169.08690, val_loss=179.60631\n",
      "Epoch 22544: train_loss=169.06705, val_loss=179.51404\n",
      "Epoch 22545: train_loss=169.04514, val_loss=179.55725\n",
      "Epoch 22546: train_loss=169.02086, val_loss=179.46898\n",
      "Epoch 22547: train_loss=168.99561, val_loss=179.50108\n",
      "Epoch 22548: train_loss=168.96977, val_loss=179.42290\n",
      "Epoch 22549: train_loss=168.94432, val_loss=179.44423\n",
      "Epoch 22550: train_loss=168.91919, val_loss=179.37839\n",
      "Epoch 22551: train_loss=168.89461, val_loss=179.38870\n",
      "Epoch 22552: train_loss=168.87094, val_loss=179.33694\n",
      "Epoch 22553: train_loss=168.84816, val_loss=179.33690\n",
      "Epoch 22554: train_loss=168.82626, val_loss=179.29858\n",
      "Epoch 22555: train_loss=168.80516, val_loss=179.29012\n",
      "Epoch 22556: train_loss=168.78474, val_loss=179.26353\n",
      "Epoch 22557: train_loss=168.76480, val_loss=179.24710\n",
      "Epoch 22558: train_loss=168.74544, val_loss=179.22876\n",
      "Epoch 22559: train_loss=168.72629, val_loss=179.20549\n",
      "Epoch 22560: train_loss=168.70747, val_loss=179.19380\n",
      "Epoch 22561: train_loss=168.68874, val_loss=179.16553\n",
      "Epoch 22562: train_loss=168.67018, val_loss=179.16071\n",
      "Epoch 22563: train_loss=168.65175, val_loss=179.12764\n",
      "Epoch 22564: train_loss=168.63359, val_loss=179.12965\n",
      "Epoch 22565: train_loss=168.61598, val_loss=179.08957\n",
      "Epoch 22566: train_loss=168.59853, val_loss=179.10028\n",
      "Epoch 22567: train_loss=168.58199, val_loss=179.05289\n",
      "Epoch 22568: train_loss=168.56631, val_loss=179.07561\n",
      "Epoch 22569: train_loss=168.55179, val_loss=179.01897\n",
      "Epoch 22570: train_loss=168.53911, val_loss=179.05956\n",
      "Epoch 22571: train_loss=168.52876, val_loss=178.99263\n",
      "Epoch 22572: train_loss=168.52115, val_loss=179.05719\n",
      "Epoch 22573: train_loss=168.51669, val_loss=178.97856\n",
      "Epoch 22574: train_loss=168.51700, val_loss=179.07346\n",
      "Epoch 22575: train_loss=168.52122, val_loss=178.98032\n",
      "Epoch 22576: train_loss=168.53102, val_loss=179.11012\n",
      "Epoch 22577: train_loss=168.54468, val_loss=178.99831\n",
      "Epoch 22578: train_loss=168.56226, val_loss=179.15561\n",
      "Epoch 22579: train_loss=168.57846, val_loss=179.01540\n",
      "Epoch 22580: train_loss=168.59157, val_loss=179.17569\n",
      "Epoch 22581: train_loss=168.59348, val_loss=178.99815\n",
      "Epoch 22582: train_loss=168.58255, val_loss=179.12952\n",
      "Epoch 22583: train_loss=168.55212, val_loss=178.92059\n",
      "Epoch 22584: train_loss=168.50386, val_loss=178.99925\n",
      "Epoch 22585: train_loss=168.43863, val_loss=178.79431\n",
      "Epoch 22586: train_loss=168.36517, val_loss=178.82611\n",
      "Epoch 22587: train_loss=168.29100, val_loss=178.67592\n",
      "Epoch 22588: train_loss=168.22562, val_loss=178.68065\n",
      "Epoch 22589: train_loss=168.17329, val_loss=178.61295\n",
      "Epoch 22590: train_loss=168.13667, val_loss=178.59741\n",
      "Epoch 22591: train_loss=168.11443, val_loss=178.60231\n",
      "Epoch 22592: train_loss=168.10275, val_loss=178.56247\n",
      "Epoch 22593: train_loss=168.09738, val_loss=178.61250\n",
      "Epoch 22594: train_loss=168.09445, val_loss=178.54753\n",
      "Epoch 22595: train_loss=168.09030, val_loss=178.61369\n",
      "Epoch 22596: train_loss=168.08197, val_loss=178.52440\n",
      "Epoch 22597: train_loss=168.06876, val_loss=178.58372\n",
      "Epoch 22598: train_loss=168.04950, val_loss=178.48128\n",
      "Epoch 22599: train_loss=168.02550, val_loss=178.52498\n",
      "Epoch 22600: train_loss=167.99731, val_loss=178.42749\n",
      "Epoch 22601: train_loss=167.96732, val_loss=178.45471\n",
      "Epoch 22602: train_loss=167.93645, val_loss=178.37622\n",
      "Epoch 22603: train_loss=167.90652, val_loss=178.38503\n",
      "Epoch 22604: train_loss=167.87862, val_loss=178.33255\n",
      "Epoch 22605: train_loss=167.85333, val_loss=178.32628\n",
      "Epoch 22606: train_loss=167.83070, val_loss=178.30020\n",
      "Epoch 22607: train_loss=167.81049, val_loss=178.27814\n",
      "Epoch 22608: train_loss=167.79214, val_loss=178.27238\n",
      "Epoch 22609: train_loss=167.77515, val_loss=178.23743\n",
      "Epoch 22610: train_loss=167.75882, val_loss=178.24713\n",
      "Epoch 22611: train_loss=167.74272, val_loss=178.20290\n",
      "Epoch 22612: train_loss=167.72655, val_loss=178.22263\n",
      "Epoch 22613: train_loss=167.71027, val_loss=178.16985\n",
      "Epoch 22614: train_loss=167.69397, val_loss=178.19341\n",
      "Epoch 22615: train_loss=167.67735, val_loss=178.13271\n",
      "Epoch 22616: train_loss=167.66039, val_loss=178.15953\n",
      "Epoch 22617: train_loss=167.64319, val_loss=178.09514\n",
      "Epoch 22618: train_loss=167.62547, val_loss=178.12506\n",
      "Epoch 22619: train_loss=167.60757, val_loss=178.05887\n",
      "Epoch 22620: train_loss=167.58968, val_loss=178.09103\n",
      "Epoch 22621: train_loss=167.57172, val_loss=178.02318\n",
      "Epoch 22622: train_loss=167.55354, val_loss=178.05788\n",
      "Epoch 22623: train_loss=167.53545, val_loss=177.98843\n",
      "Epoch 22624: train_loss=167.51738, val_loss=178.02361\n",
      "Epoch 22625: train_loss=167.49918, val_loss=177.95184\n",
      "Epoch 22626: train_loss=167.48114, val_loss=177.98866\n",
      "Epoch 22627: train_loss=167.46344, val_loss=177.91579\n",
      "Epoch 22628: train_loss=167.44583, val_loss=177.95644\n",
      "Epoch 22629: train_loss=167.42854, val_loss=177.88187\n",
      "Epoch 22630: train_loss=167.41151, val_loss=177.92694\n",
      "Epoch 22631: train_loss=167.39502, val_loss=177.84914\n",
      "Epoch 22632: train_loss=167.37880, val_loss=177.89854\n",
      "Epoch 22633: train_loss=167.36322, val_loss=177.81647\n",
      "Epoch 22634: train_loss=167.34824, val_loss=177.87273\n",
      "Epoch 22635: train_loss=167.33391, val_loss=177.78572\n",
      "Epoch 22636: train_loss=167.32021, val_loss=177.85004\n",
      "Epoch 22637: train_loss=167.30705, val_loss=177.75764\n",
      "Epoch 22638: train_loss=167.29453, val_loss=177.83040\n",
      "Epoch 22639: train_loss=167.28186, val_loss=177.73167\n",
      "Epoch 22640: train_loss=167.26944, val_loss=177.81110\n",
      "Epoch 22641: train_loss=167.25671, val_loss=177.70439\n",
      "Epoch 22642: train_loss=167.24355, val_loss=177.78632\n",
      "Epoch 22643: train_loss=167.22900, val_loss=177.67177\n",
      "Epoch 22644: train_loss=167.21342, val_loss=177.75333\n",
      "Epoch 22645: train_loss=167.19594, val_loss=177.63396\n",
      "Epoch 22646: train_loss=167.17638, val_loss=177.71046\n",
      "Epoch 22647: train_loss=167.15372, val_loss=177.59004\n",
      "Epoch 22648: train_loss=167.12874, val_loss=177.65576\n",
      "Epoch 22649: train_loss=167.10052, val_loss=177.54024\n",
      "Epoch 22650: train_loss=167.07060, val_loss=177.59012\n",
      "Epoch 22651: train_loss=167.03891, val_loss=177.48546\n",
      "Epoch 22652: train_loss=167.00728, val_loss=177.51746\n",
      "Epoch 22653: train_loss=166.97585, val_loss=177.43161\n",
      "Epoch 22654: train_loss=166.94611, val_loss=177.44991\n",
      "Epoch 22655: train_loss=166.91821, val_loss=177.38780\n",
      "Epoch 22656: train_loss=166.89217, val_loss=177.39360\n",
      "Epoch 22657: train_loss=166.86835, val_loss=177.35324\n",
      "Epoch 22658: train_loss=166.84605, val_loss=177.34557\n",
      "Epoch 22659: train_loss=166.82539, val_loss=177.32182\n",
      "Epoch 22660: train_loss=166.80592, val_loss=177.30043\n",
      "Epoch 22661: train_loss=166.78746, val_loss=177.29085\n",
      "Epoch 22662: train_loss=166.76973, val_loss=177.25958\n",
      "Epoch 22663: train_loss=166.75246, val_loss=177.26302\n",
      "Epoch 22664: train_loss=166.73578, val_loss=177.22336\n",
      "Epoch 22665: train_loss=166.71945, val_loss=177.23759\n",
      "Epoch 22666: train_loss=166.70374, val_loss=177.18910\n",
      "Epoch 22667: train_loss=166.68852, val_loss=177.21466\n",
      "Epoch 22668: train_loss=166.67432, val_loss=177.15726\n",
      "Epoch 22669: train_loss=166.66100, val_loss=177.19568\n",
      "Epoch 22670: train_loss=166.64876, val_loss=177.12852\n",
      "Epoch 22671: train_loss=166.63828, val_loss=177.18376\n",
      "Epoch 22672: train_loss=166.62938, val_loss=177.10628\n",
      "Epoch 22673: train_loss=166.62248, val_loss=177.18031\n",
      "Epoch 22674: train_loss=166.61667, val_loss=177.09087\n",
      "Epoch 22675: train_loss=166.61264, val_loss=177.18341\n",
      "Epoch 22676: train_loss=166.60995, val_loss=177.08015\n",
      "Epoch 22677: train_loss=166.60834, val_loss=177.18823\n",
      "Epoch 22678: train_loss=166.60645, val_loss=177.06947\n",
      "Epoch 22679: train_loss=166.60330, val_loss=177.18483\n",
      "Epoch 22680: train_loss=166.59615, val_loss=177.04919\n",
      "Epoch 22681: train_loss=166.58563, val_loss=177.15891\n",
      "Epoch 22682: train_loss=166.56760, val_loss=177.00792\n",
      "Epoch 22683: train_loss=166.54433, val_loss=177.09856\n",
      "Epoch 22684: train_loss=166.51225, val_loss=176.94257\n",
      "Epoch 22685: train_loss=166.47444, val_loss=177.00745\n",
      "Epoch 22686: train_loss=166.43164, val_loss=176.86522\n",
      "Epoch 22687: train_loss=166.38684, val_loss=176.90511\n",
      "Epoch 22688: train_loss=166.34273, val_loss=176.79477\n",
      "Epoch 22689: train_loss=166.30200, val_loss=176.81300\n",
      "Epoch 22690: train_loss=166.26579, val_loss=176.74330\n",
      "Epoch 22691: train_loss=166.23480, val_loss=176.74200\n",
      "Epoch 22692: train_loss=166.20857, val_loss=176.71059\n",
      "Epoch 22693: train_loss=166.18700, val_loss=176.68913\n",
      "Epoch 22694: train_loss=166.16901, val_loss=176.68918\n",
      "Epoch 22695: train_loss=166.15353, val_loss=176.65054\n",
      "Epoch 22696: train_loss=166.13979, val_loss=176.67380\n",
      "Epoch 22697: train_loss=166.12712, val_loss=176.61885\n",
      "Epoch 22698: train_loss=166.11510, val_loss=176.65871\n",
      "Epoch 22699: train_loss=166.10364, val_loss=176.59019\n",
      "Epoch 22700: train_loss=166.09212, val_loss=176.64180\n",
      "Epoch 22701: train_loss=166.08034, val_loss=176.56104\n",
      "Epoch 22702: train_loss=166.06783, val_loss=176.62048\n",
      "Epoch 22703: train_loss=166.05414, val_loss=176.53160\n",
      "Epoch 22704: train_loss=166.03893, val_loss=176.59344\n",
      "Epoch 22705: train_loss=166.02277, val_loss=176.49730\n",
      "Epoch 22706: train_loss=166.00522, val_loss=176.55765\n",
      "Epoch 22707: train_loss=165.98691, val_loss=176.45847\n",
      "Epoch 22708: train_loss=165.96696, val_loss=176.51672\n",
      "Epoch 22709: train_loss=165.94698, val_loss=176.41890\n",
      "Epoch 22710: train_loss=165.92601, val_loss=176.47440\n",
      "Epoch 22711: train_loss=165.90504, val_loss=176.37837\n",
      "Epoch 22712: train_loss=165.88293, val_loss=176.42789\n",
      "Epoch 22713: train_loss=165.86064, val_loss=176.33632\n",
      "Epoch 22714: train_loss=165.83749, val_loss=176.37949\n",
      "Epoch 22715: train_loss=165.81448, val_loss=176.29504\n",
      "Epoch 22716: train_loss=165.79132, val_loss=176.33078\n",
      "Epoch 22717: train_loss=165.76839, val_loss=176.25287\n",
      "Epoch 22718: train_loss=165.74583, val_loss=176.28279\n",
      "Epoch 22719: train_loss=165.72394, val_loss=176.21297\n",
      "Epoch 22720: train_loss=165.70251, val_loss=176.23962\n",
      "Epoch 22721: train_loss=165.68173, val_loss=176.17572\n",
      "Epoch 22722: train_loss=165.66144, val_loss=176.19887\n",
      "Epoch 22723: train_loss=165.64127, val_loss=176.13867\n",
      "Epoch 22724: train_loss=165.62155, val_loss=176.15878\n",
      "Epoch 22725: train_loss=165.60190, val_loss=176.10088\n",
      "Epoch 22726: train_loss=165.58276, val_loss=176.12039\n",
      "Epoch 22727: train_loss=165.56367, val_loss=176.06514\n",
      "Epoch 22728: train_loss=165.54510, val_loss=176.08537\n",
      "Epoch 22729: train_loss=165.52670, val_loss=176.02887\n",
      "Epoch 22730: train_loss=165.50864, val_loss=176.05008\n",
      "Epoch 22731: train_loss=165.49091, val_loss=175.99203\n",
      "Epoch 22732: train_loss=165.47372, val_loss=176.01894\n",
      "Epoch 22733: train_loss=165.45752, val_loss=175.95799\n",
      "Epoch 22734: train_loss=165.44225, val_loss=175.99521\n",
      "Epoch 22735: train_loss=165.42830, val_loss=175.92726\n",
      "Epoch 22736: train_loss=165.41580, val_loss=175.97914\n",
      "Epoch 22737: train_loss=165.40591, val_loss=175.90254\n",
      "Epoch 22738: train_loss=165.39842, val_loss=175.97710\n",
      "Epoch 22739: train_loss=165.39426, val_loss=175.88959\n",
      "Epoch 22740: train_loss=165.39322, val_loss=175.99159\n",
      "Epoch 22741: train_loss=165.39679, val_loss=175.88905\n",
      "Epoch 22742: train_loss=165.40419, val_loss=176.02127\n",
      "Epoch 22743: train_loss=165.41502, val_loss=175.90027\n",
      "Epoch 22744: train_loss=165.42778, val_loss=176.05632\n",
      "Epoch 22745: train_loss=165.43811, val_loss=175.91075\n",
      "Epoch 22746: train_loss=165.44504, val_loss=176.06674\n",
      "Epoch 22747: train_loss=165.44031, val_loss=175.88795\n",
      "Epoch 22748: train_loss=165.42392, val_loss=176.01404\n",
      "Epoch 22749: train_loss=165.39029, val_loss=175.81281\n",
      "Epoch 22750: train_loss=165.34299, val_loss=175.89310\n",
      "Epoch 22751: train_loss=165.28282, val_loss=175.70282\n",
      "Epoch 22752: train_loss=165.21736, val_loss=175.74223\n",
      "Epoch 22753: train_loss=165.15359, val_loss=175.60291\n",
      "Epoch 22754: train_loss=165.09612, val_loss=175.61459\n",
      "Epoch 22755: train_loss=165.05031, val_loss=175.54793\n",
      "Epoch 22756: train_loss=165.01646, val_loss=175.53564\n",
      "Epoch 22757: train_loss=164.99380, val_loss=175.53349\n",
      "Epoch 22758: train_loss=164.97981, val_loss=175.49463\n",
      "Epoch 22759: train_loss=164.97136, val_loss=175.53404\n",
      "Epoch 22760: train_loss=164.96512, val_loss=175.46971\n",
      "Epoch 22761: train_loss=164.95853, val_loss=175.52890\n",
      "Epoch 22762: train_loss=164.95023, val_loss=175.44514\n",
      "Epoch 22763: train_loss=164.93854, val_loss=175.50737\n",
      "Epoch 22764: train_loss=164.92372, val_loss=175.41055\n",
      "Epoch 22765: train_loss=164.90479, val_loss=175.46545\n",
      "Epoch 22766: train_loss=164.88312, val_loss=175.36769\n",
      "Epoch 22767: train_loss=164.85852, val_loss=175.41100\n",
      "Epoch 22768: train_loss=164.83276, val_loss=175.32205\n",
      "Epoch 22769: train_loss=164.80566, val_loss=175.35115\n",
      "Epoch 22770: train_loss=164.77892, val_loss=175.27855\n",
      "Epoch 22771: train_loss=164.75288, val_loss=175.29285\n",
      "Epoch 22772: train_loss=164.72786, val_loss=175.23949\n",
      "Epoch 22773: train_loss=164.70445, val_loss=175.23979\n",
      "Epoch 22774: train_loss=164.68253, val_loss=175.20625\n",
      "Epoch 22775: train_loss=164.66203, val_loss=175.19360\n",
      "Epoch 22776: train_loss=164.64276, val_loss=175.17690\n",
      "Epoch 22777: train_loss=164.62437, val_loss=175.15218\n",
      "Epoch 22778: train_loss=164.60674, val_loss=175.14783\n",
      "Epoch 22779: train_loss=164.58954, val_loss=175.11400\n",
      "Epoch 22780: train_loss=164.57268, val_loss=175.12079\n",
      "Epoch 22781: train_loss=164.55617, val_loss=175.07828\n",
      "Epoch 22782: train_loss=164.53992, val_loss=175.09392\n",
      "Epoch 22783: train_loss=164.52376, val_loss=175.04298\n",
      "Epoch 22784: train_loss=164.50763, val_loss=175.06564\n",
      "Epoch 22785: train_loss=164.49174, val_loss=175.00859\n",
      "Epoch 22786: train_loss=164.47643, val_loss=175.03957\n",
      "Epoch 22787: train_loss=164.46152, val_loss=174.97537\n",
      "Epoch 22788: train_loss=164.44714, val_loss=175.01633\n",
      "Epoch 22789: train_loss=164.43407, val_loss=174.94482\n",
      "Epoch 22790: train_loss=164.42168, val_loss=175.00009\n",
      "Epoch 22791: train_loss=164.41100, val_loss=174.92139\n",
      "Epoch 22792: train_loss=164.40169, val_loss=174.99376\n",
      "Epoch 22793: train_loss=164.39426, val_loss=174.90314\n",
      "Epoch 22794: train_loss=164.38779, val_loss=174.99135\n",
      "Epoch 22795: train_loss=164.38303, val_loss=174.88651\n",
      "Epoch 22796: train_loss=164.37794, val_loss=174.98874\n",
      "Epoch 22797: train_loss=164.37335, val_loss=174.87096\n",
      "Epoch 22798: train_loss=164.36694, val_loss=174.98163\n",
      "Epoch 22799: train_loss=164.35887, val_loss=174.85023\n",
      "Epoch 22800: train_loss=164.34682, val_loss=174.95746\n",
      "Epoch 22801: train_loss=164.33083, val_loss=174.81343\n",
      "Epoch 22802: train_loss=164.30945, val_loss=174.90796\n",
      "Epoch 22803: train_loss=164.28340, val_loss=174.76009\n",
      "Epoch 22804: train_loss=164.25223, val_loss=174.83653\n",
      "Epoch 22805: train_loss=164.21783, val_loss=174.69698\n",
      "Epoch 22806: train_loss=164.17996, val_loss=174.75081\n",
      "Epoch 22807: train_loss=164.14114, val_loss=174.63206\n",
      "Epoch 22808: train_loss=164.10278, val_loss=174.66498\n",
      "Epoch 22809: train_loss=164.06670, val_loss=174.57664\n",
      "Epoch 22810: train_loss=164.03374, val_loss=174.59055\n",
      "Epoch 22811: train_loss=164.00450, val_loss=174.53322\n",
      "Epoch 22812: train_loss=163.97862, val_loss=174.53012\n",
      "Epoch 22813: train_loss=163.95544, val_loss=174.50035\n",
      "Epoch 22814: train_loss=163.93480, val_loss=174.48207\n",
      "Epoch 22815: train_loss=163.91606, val_loss=174.47565\n",
      "Epoch 22816: train_loss=163.89873, val_loss=174.44319\n",
      "Epoch 22817: train_loss=163.88237, val_loss=174.45221\n",
      "Epoch 22818: train_loss=163.86646, val_loss=174.40768\n",
      "Epoch 22819: train_loss=163.85089, val_loss=174.42830\n",
      "Epoch 22820: train_loss=163.83568, val_loss=174.37344\n",
      "Epoch 22821: train_loss=163.82042, val_loss=174.40279\n",
      "Epoch 22822: train_loss=163.80542, val_loss=174.33934\n",
      "Epoch 22823: train_loss=163.79056, val_loss=174.37770\n",
      "Epoch 22824: train_loss=163.77611, val_loss=174.30763\n",
      "Epoch 22825: train_loss=163.76219, val_loss=174.35651\n",
      "Epoch 22826: train_loss=163.74889, val_loss=174.27887\n",
      "Epoch 22827: train_loss=163.73654, val_loss=174.33752\n",
      "Epoch 22828: train_loss=163.72487, val_loss=174.25035\n",
      "Epoch 22829: train_loss=163.71394, val_loss=174.32024\n",
      "Epoch 22830: train_loss=163.70361, val_loss=174.22505\n",
      "Epoch 22831: train_loss=163.69409, val_loss=174.30746\n",
      "Epoch 22832: train_loss=163.68477, val_loss=174.20337\n",
      "Epoch 22833: train_loss=163.67574, val_loss=174.29431\n",
      "Epoch 22834: train_loss=163.66615, val_loss=174.17929\n",
      "Epoch 22835: train_loss=163.65625, val_loss=174.27577\n",
      "Epoch 22836: train_loss=163.64452, val_loss=174.15121\n",
      "Epoch 22837: train_loss=163.63081, val_loss=174.24736\n",
      "Epoch 22838: train_loss=163.61378, val_loss=174.11497\n",
      "Epoch 22839: train_loss=163.59384, val_loss=174.20177\n",
      "Epoch 22840: train_loss=163.57024, val_loss=174.06529\n",
      "Epoch 22841: train_loss=163.54301, val_loss=174.13593\n",
      "Epoch 22842: train_loss=163.51198, val_loss=174.00476\n",
      "Epoch 22843: train_loss=163.47815, val_loss=174.05659\n",
      "Epoch 22844: train_loss=163.44258, val_loss=173.94374\n",
      "Epoch 22845: train_loss=163.40680, val_loss=173.97615\n",
      "Epoch 22846: train_loss=163.37265, val_loss=173.88979\n",
      "Epoch 22847: train_loss=163.34067, val_loss=173.90443\n",
      "Epoch 22848: train_loss=163.31183, val_loss=173.84756\n",
      "Epoch 22849: train_loss=163.28583, val_loss=173.84509\n",
      "Epoch 22850: train_loss=163.26277, val_loss=173.81448\n",
      "Epoch 22851: train_loss=163.24220, val_loss=173.79639\n",
      "Epoch 22852: train_loss=163.22342, val_loss=173.78687\n",
      "Epoch 22853: train_loss=163.20610, val_loss=173.75607\n",
      "Epoch 22854: train_loss=163.18968, val_loss=173.76158\n",
      "Epoch 22855: train_loss=163.17389, val_loss=173.71861\n",
      "Epoch 22856: train_loss=163.15840, val_loss=173.73488\n",
      "Epoch 22857: train_loss=163.14273, val_loss=173.68318\n",
      "Epoch 22858: train_loss=163.12708, val_loss=173.70767\n",
      "Epoch 22859: train_loss=163.11143, val_loss=173.64882\n",
      "Epoch 22860: train_loss=163.09541, val_loss=173.67899\n",
      "Epoch 22861: train_loss=163.07964, val_loss=173.61447\n",
      "Epoch 22862: train_loss=163.06386, val_loss=173.65019\n",
      "Epoch 22863: train_loss=163.04857, val_loss=173.58157\n",
      "Epoch 22864: train_loss=163.03372, val_loss=173.62602\n",
      "Epoch 22865: train_loss=163.01953, val_loss=173.55157\n",
      "Epoch 22866: train_loss=163.00554, val_loss=173.60321\n",
      "Epoch 22867: train_loss=162.99226, val_loss=173.52121\n",
      "Epoch 22868: train_loss=162.97900, val_loss=173.58105\n",
      "Epoch 22869: train_loss=162.96695, val_loss=173.49243\n",
      "Epoch 22870: train_loss=162.95485, val_loss=173.56219\n",
      "Epoch 22871: train_loss=162.94379, val_loss=173.46704\n",
      "Epoch 22872: train_loss=162.93304, val_loss=173.54622\n",
      "Epoch 22873: train_loss=162.92285, val_loss=173.44203\n",
      "Epoch 22874: train_loss=162.91240, val_loss=173.52887\n",
      "Epoch 22875: train_loss=162.90181, val_loss=173.41612\n",
      "Epoch 22876: train_loss=162.88995, val_loss=173.50687\n",
      "Epoch 22877: train_loss=162.87633, val_loss=173.38725\n",
      "Epoch 22878: train_loss=162.86162, val_loss=173.47643\n",
      "Epoch 22879: train_loss=162.84412, val_loss=173.35059\n",
      "Epoch 22880: train_loss=162.82530, val_loss=173.43381\n",
      "Epoch 22881: train_loss=162.80351, val_loss=173.30492\n",
      "Epoch 22882: train_loss=162.77914, val_loss=173.37749\n",
      "Epoch 22883: train_loss=162.75191, val_loss=173.25171\n",
      "Epoch 22884: train_loss=162.72121, val_loss=173.30862\n",
      "Epoch 22885: train_loss=162.68880, val_loss=173.19586\n",
      "Epoch 22886: train_loss=162.65479, val_loss=173.23386\n",
      "Epoch 22887: train_loss=162.62190, val_loss=173.14185\n",
      "Epoch 22888: train_loss=162.58998, val_loss=173.16077\n",
      "Epoch 22889: train_loss=162.56049, val_loss=173.09485\n",
      "Epoch 22890: train_loss=162.53331, val_loss=173.09737\n",
      "Epoch 22891: train_loss=162.50879, val_loss=173.05917\n",
      "Epoch 22892: train_loss=162.48686, val_loss=173.04620\n",
      "Epoch 22893: train_loss=162.46727, val_loss=173.03035\n",
      "Epoch 22894: train_loss=162.44934, val_loss=173.00294\n",
      "Epoch 22895: train_loss=162.43269, val_loss=173.00420\n",
      "Epoch 22896: train_loss=162.41687, val_loss=172.96503\n",
      "Epoch 22897: train_loss=162.40147, val_loss=172.97894\n",
      "Epoch 22898: train_loss=162.38634, val_loss=172.92961\n",
      "Epoch 22899: train_loss=162.37114, val_loss=172.95172\n",
      "Epoch 22900: train_loss=162.35574, val_loss=172.89424\n",
      "Epoch 22901: train_loss=162.34030, val_loss=172.92270\n",
      "Epoch 22902: train_loss=162.32483, val_loss=172.86026\n",
      "Epoch 22903: train_loss=162.30949, val_loss=172.89557\n",
      "Epoch 22904: train_loss=162.29417, val_loss=172.82907\n",
      "Epoch 22905: train_loss=162.27927, val_loss=172.87134\n",
      "Epoch 22906: train_loss=162.26488, val_loss=172.79831\n",
      "Epoch 22907: train_loss=162.25075, val_loss=172.84671\n",
      "Epoch 22908: train_loss=162.23743, val_loss=172.76712\n",
      "Epoch 22909: train_loss=162.22453, val_loss=172.82561\n",
      "Epoch 22910: train_loss=162.21295, val_loss=172.74088\n",
      "Epoch 22911: train_loss=162.20198, val_loss=172.81203\n",
      "Epoch 22912: train_loss=162.19295, val_loss=172.72023\n",
      "Epoch 22913: train_loss=162.18465, val_loss=172.80527\n",
      "Epoch 22914: train_loss=162.17859, val_loss=172.70390\n",
      "Epoch 22915: train_loss=162.17365, val_loss=172.80336\n",
      "Epoch 22916: train_loss=162.16957, val_loss=172.69063\n",
      "Epoch 22917: train_loss=162.16634, val_loss=172.80275\n",
      "Epoch 22918: train_loss=162.16267, val_loss=172.67717\n",
      "Epoch 22919: train_loss=162.15843, val_loss=172.79521\n",
      "Epoch 22920: train_loss=162.15073, val_loss=172.65361\n",
      "Epoch 22921: train_loss=162.13867, val_loss=172.76508\n",
      "Epoch 22922: train_loss=162.12006, val_loss=172.61157\n",
      "Epoch 22923: train_loss=162.09518, val_loss=172.70345\n",
      "Epoch 22924: train_loss=162.06236, val_loss=172.54655\n",
      "Epoch 22925: train_loss=162.02373, val_loss=172.61140\n",
      "Epoch 22926: train_loss=161.98051, val_loss=172.46925\n",
      "Epoch 22927: train_loss=161.93529, val_loss=172.50734\n",
      "Epoch 22928: train_loss=161.89073, val_loss=172.39777\n",
      "Epoch 22929: train_loss=161.84883, val_loss=172.41110\n",
      "Epoch 22930: train_loss=161.81233, val_loss=172.34705\n",
      "Epoch 22931: train_loss=161.78204, val_loss=172.33992\n",
      "Epoch 22932: train_loss=161.75813, val_loss=172.32066\n",
      "Epoch 22933: train_loss=161.73965, val_loss=172.29343\n",
      "Epoch 22934: train_loss=161.72533, val_loss=172.30696\n",
      "Epoch 22935: train_loss=161.71349, val_loss=172.25961\n",
      "Epoch 22936: train_loss=161.70264, val_loss=172.29263\n",
      "Epoch 22937: train_loss=161.69151, val_loss=172.22992\n",
      "Epoch 22938: train_loss=161.67949, val_loss=172.27266\n",
      "Epoch 22939: train_loss=161.66615, val_loss=172.19980\n",
      "Epoch 22940: train_loss=161.65120, val_loss=172.24478\n",
      "Epoch 22941: train_loss=161.63477, val_loss=172.16641\n",
      "Epoch 22942: train_loss=161.61700, val_loss=172.20833\n",
      "Epoch 22943: train_loss=161.59782, val_loss=172.12830\n",
      "Epoch 22944: train_loss=161.57761, val_loss=172.16478\n",
      "Epoch 22945: train_loss=161.55687, val_loss=172.08875\n",
      "Epoch 22946: train_loss=161.53549, val_loss=172.12032\n",
      "Epoch 22947: train_loss=161.51408, val_loss=172.05092\n",
      "Epoch 22948: train_loss=161.49243, val_loss=172.07520\n",
      "Epoch 22949: train_loss=161.47076, val_loss=172.01129\n",
      "Epoch 22950: train_loss=161.44905, val_loss=172.02588\n",
      "Epoch 22951: train_loss=161.42772, val_loss=171.97179\n",
      "Epoch 22952: train_loss=161.40651, val_loss=171.98012\n",
      "Epoch 22953: train_loss=161.38589, val_loss=171.93776\n",
      "Epoch 22954: train_loss=161.36580, val_loss=171.93973\n",
      "Epoch 22955: train_loss=161.34622, val_loss=171.90491\n",
      "Epoch 22956: train_loss=161.32706, val_loss=171.89861\n",
      "Epoch 22957: train_loss=161.30830, val_loss=171.86847\n",
      "Epoch 22958: train_loss=161.28986, val_loss=171.85826\n",
      "Epoch 22959: train_loss=161.27148, val_loss=171.83275\n",
      "Epoch 22960: train_loss=161.25331, val_loss=171.82098\n",
      "Epoch 22961: train_loss=161.23524, val_loss=171.79843\n",
      "Epoch 22962: train_loss=161.21719, val_loss=171.78453\n",
      "Epoch 22963: train_loss=161.19926, val_loss=171.76122\n",
      "Epoch 22964: train_loss=161.18138, val_loss=171.74744\n",
      "Epoch 22965: train_loss=161.16347, val_loss=171.72318\n",
      "Epoch 22966: train_loss=161.14572, val_loss=171.71306\n",
      "Epoch 22967: train_loss=161.12796, val_loss=171.68739\n",
      "Epoch 22968: train_loss=161.11047, val_loss=171.68257\n",
      "Epoch 22969: train_loss=161.09332, val_loss=171.65128\n",
      "Epoch 22970: train_loss=161.07648, val_loss=171.65349\n",
      "Epoch 22971: train_loss=161.06041, val_loss=171.61440\n",
      "Epoch 22972: train_loss=161.04530, val_loss=171.63126\n",
      "Epoch 22973: train_loss=161.03194, val_loss=171.58377\n",
      "Epoch 22974: train_loss=161.02061, val_loss=171.62384\n",
      "Epoch 22975: train_loss=161.01276, val_loss=171.56380\n",
      "Epoch 22976: train_loss=161.00932, val_loss=171.63744\n",
      "Epoch 22977: train_loss=161.01242, val_loss=171.56358\n",
      "Epoch 22978: train_loss=161.02408, val_loss=171.68979\n",
      "Epoch 22979: train_loss=161.04712, val_loss=171.60538\n",
      "Epoch 22980: train_loss=161.08484, val_loss=171.80757\n",
      "Epoch 22981: train_loss=161.13873, val_loss=171.71176\n",
      "Epoch 22982: train_loss=161.21028, val_loss=171.98433\n",
      "Epoch 22983: train_loss=161.28632, val_loss=171.84895\n",
      "Epoch 22984: train_loss=161.36580, val_loss=172.12961\n",
      "Epoch 22985: train_loss=161.41156, val_loss=171.89487\n",
      "Epoch 22986: train_loss=161.41939, val_loss=172.06004\n",
      "Epoch 22987: train_loss=161.34566, val_loss=171.70189\n",
      "Epoch 22988: train_loss=161.21175, val_loss=171.70590\n",
      "Epoch 22989: train_loss=161.03009, val_loss=171.38837\n",
      "Epoch 22990: train_loss=160.85788, val_loss=171.35152\n",
      "Epoch 22991: train_loss=160.73631, val_loss=171.26788\n",
      "Epoch 22992: train_loss=160.68309, val_loss=171.25188\n",
      "Epoch 22993: train_loss=160.69102, val_loss=171.36667\n",
      "Epoch 22994: train_loss=160.73470, val_loss=171.30988\n",
      "Epoch 22995: train_loss=160.78285, val_loss=171.46320\n",
      "Epoch 22996: train_loss=160.80695, val_loss=171.31262\n",
      "Epoch 22997: train_loss=160.79256, val_loss=171.38953\n",
      "Epoch 22998: train_loss=160.73869, val_loss=171.20200\n",
      "Epoch 22999: train_loss=160.66405, val_loss=171.20941\n",
      "Epoch 23000: train_loss=160.58992, val_loss=171.10548\n",
      "Epoch 23001: train_loss=160.53522, val_loss=171.09212\n",
      "Epoch 23002: train_loss=160.50815, val_loss=171.11020\n",
      "Epoch 23003: train_loss=160.50441, val_loss=171.07028\n",
      "Epoch 23004: train_loss=160.51212, val_loss=171.14651\n",
      "Epoch 23005: train_loss=160.51843, val_loss=171.06087\n",
      "Epoch 23006: train_loss=160.51326, val_loss=171.12486\n",
      "Epoch 23007: train_loss=160.49283, val_loss=171.01361\n",
      "Epoch 23008: train_loss=160.45967, val_loss=171.04115\n",
      "Epoch 23009: train_loss=160.42091, val_loss=170.95616\n",
      "Epoch 23010: train_loss=160.38353, val_loss=170.95383\n",
      "Epoch 23011: train_loss=160.35378, val_loss=170.92624\n",
      "Epoch 23012: train_loss=160.33340, val_loss=170.90091\n",
      "Epoch 23013: train_loss=160.32092, val_loss=170.92200\n",
      "Epoch 23014: train_loss=160.31250, val_loss=170.87247\n",
      "Epoch 23015: train_loss=160.30334, val_loss=170.90886\n",
      "Epoch 23016: train_loss=160.29077, val_loss=170.84045\n",
      "Epoch 23017: train_loss=160.27325, val_loss=170.86749\n",
      "Epoch 23018: train_loss=160.25179, val_loss=170.80031\n",
      "Epoch 23019: train_loss=160.22745, val_loss=170.81073\n",
      "Epoch 23020: train_loss=160.20320, val_loss=170.76453\n",
      "Epoch 23021: train_loss=160.18021, val_loss=170.75784\n",
      "Epoch 23022: train_loss=160.15967, val_loss=170.73787\n",
      "Epoch 23023: train_loss=160.14180, val_loss=170.71381\n",
      "Epoch 23024: train_loss=160.12592, val_loss=170.71475\n",
      "Epoch 23025: train_loss=160.11111, val_loss=170.67754\n",
      "Epoch 23026: train_loss=160.09642, val_loss=170.69008\n",
      "Epoch 23027: train_loss=160.08125, val_loss=170.64429\n",
      "Epoch 23028: train_loss=160.06509, val_loss=170.65939\n",
      "Epoch 23029: train_loss=160.04819, val_loss=170.60927\n",
      "Epoch 23030: train_loss=160.03011, val_loss=170.61957\n",
      "Epoch 23031: train_loss=160.01163, val_loss=170.57243\n",
      "Epoch 23032: train_loss=159.99251, val_loss=170.57826\n",
      "Epoch 23033: train_loss=159.97346, val_loss=170.53882\n",
      "Epoch 23034: train_loss=159.95438, val_loss=170.53714\n",
      "Epoch 23035: train_loss=159.93567, val_loss=170.50525\n",
      "Epoch 23036: train_loss=159.91721, val_loss=170.49576\n",
      "Epoch 23037: train_loss=159.89914, val_loss=170.47165\n",
      "Epoch 23038: train_loss=159.88139, val_loss=170.45627\n",
      "Epoch 23039: train_loss=159.86394, val_loss=170.43988\n",
      "Epoch 23040: train_loss=159.84659, val_loss=170.42043\n",
      "Epoch 23041: train_loss=159.82941, val_loss=170.40945\n",
      "Epoch 23042: train_loss=159.81235, val_loss=170.38553\n",
      "Epoch 23043: train_loss=159.79543, val_loss=170.37886\n",
      "Epoch 23044: train_loss=159.77864, val_loss=170.34955\n",
      "Epoch 23045: train_loss=159.76202, val_loss=170.34845\n",
      "Epoch 23046: train_loss=159.74577, val_loss=170.31383\n",
      "Epoch 23047: train_loss=159.72972, val_loss=170.32051\n",
      "Epoch 23048: train_loss=159.71408, val_loss=170.27986\n",
      "Epoch 23049: train_loss=159.69858, val_loss=170.29341\n",
      "Epoch 23050: train_loss=159.68352, val_loss=170.24557\n",
      "Epoch 23051: train_loss=159.66844, val_loss=170.26639\n",
      "Epoch 23052: train_loss=159.65387, val_loss=170.21228\n",
      "Epoch 23053: train_loss=159.63931, val_loss=170.24107\n",
      "Epoch 23054: train_loss=159.62531, val_loss=170.18074\n",
      "Epoch 23055: train_loss=159.61116, val_loss=170.21754\n",
      "Epoch 23056: train_loss=159.59724, val_loss=170.15175\n",
      "Epoch 23057: train_loss=159.58289, val_loss=170.19359\n",
      "Epoch 23058: train_loss=159.56866, val_loss=170.12057\n",
      "Epoch 23059: train_loss=159.55388, val_loss=170.16510\n",
      "Epoch 23060: train_loss=159.53929, val_loss=170.08739\n",
      "Epoch 23061: train_loss=159.52423, val_loss=170.13588\n",
      "Epoch 23062: train_loss=159.50906, val_loss=170.05585\n",
      "Epoch 23063: train_loss=159.49310, val_loss=170.10658\n",
      "Epoch 23064: train_loss=159.47707, val_loss=170.02415\n",
      "Epoch 23065: train_loss=159.46045, val_loss=170.07445\n",
      "Epoch 23066: train_loss=159.44363, val_loss=169.98970\n",
      "Epoch 23067: train_loss=159.42616, val_loss=170.03844\n",
      "Epoch 23068: train_loss=159.40855, val_loss=169.95389\n",
      "Epoch 23069: train_loss=159.39047, val_loss=170.00125\n",
      "Epoch 23070: train_loss=159.37206, val_loss=169.91805\n",
      "Epoch 23071: train_loss=159.35326, val_loss=169.96204\n",
      "Epoch 23072: train_loss=159.33415, val_loss=169.88110\n",
      "Epoch 23073: train_loss=159.31490, val_loss=169.92165\n",
      "Epoch 23074: train_loss=159.29556, val_loss=169.84451\n",
      "Epoch 23075: train_loss=159.27631, val_loss=169.88286\n",
      "Epoch 23076: train_loss=159.25746, val_loss=169.80988\n",
      "Epoch 23077: train_loss=159.23863, val_loss=169.84550\n",
      "Epoch 23078: train_loss=159.22031, val_loss=169.77412\n",
      "Epoch 23079: train_loss=159.20195, val_loss=169.80730\n",
      "Epoch 23080: train_loss=159.18405, val_loss=169.73851\n",
      "Epoch 23081: train_loss=159.16631, val_loss=169.77275\n",
      "Epoch 23082: train_loss=159.14934, val_loss=169.70537\n",
      "Epoch 23083: train_loss=159.13254, val_loss=169.74200\n",
      "Epoch 23084: train_loss=159.11674, val_loss=169.67329\n",
      "Epoch 23085: train_loss=159.10107, val_loss=169.71471\n",
      "Epoch 23086: train_loss=159.08652, val_loss=169.64322\n",
      "Epoch 23087: train_loss=159.07246, val_loss=169.69160\n",
      "Epoch 23088: train_loss=159.05963, val_loss=169.61467\n",
      "Epoch 23089: train_loss=159.04755, val_loss=169.67308\n",
      "Epoch 23090: train_loss=159.03691, val_loss=169.59016\n",
      "Epoch 23091: train_loss=159.02739, val_loss=169.66138\n",
      "Epoch 23092: train_loss=159.01955, val_loss=169.56929\n",
      "Epoch 23093: train_loss=159.01256, val_loss=169.65498\n",
      "Epoch 23094: train_loss=159.00749, val_loss=169.55353\n",
      "Epoch 23095: train_loss=159.00351, val_loss=169.65443\n",
      "Epoch 23096: train_loss=159.00032, val_loss=169.54146\n",
      "Epoch 23097: train_loss=158.99695, val_loss=169.65326\n",
      "Epoch 23098: train_loss=158.99239, val_loss=169.52557\n",
      "Epoch 23099: train_loss=158.98518, val_loss=169.63725\n",
      "Epoch 23100: train_loss=158.97351, val_loss=169.49655\n",
      "Epoch 23101: train_loss=158.95778, val_loss=169.59894\n",
      "Epoch 23102: train_loss=158.93600, val_loss=169.45059\n",
      "Epoch 23103: train_loss=158.90889, val_loss=169.53310\n",
      "Epoch 23104: train_loss=158.87576, val_loss=169.38828\n",
      "Epoch 23105: train_loss=158.83942, val_loss=169.44783\n",
      "Epoch 23106: train_loss=158.80077, val_loss=169.32141\n",
      "Epoch 23107: train_loss=158.76189, val_loss=169.35870\n",
      "Epoch 23108: train_loss=158.72470, val_loss=169.26308\n",
      "Epoch 23109: train_loss=158.69034, val_loss=169.27957\n",
      "Epoch 23110: train_loss=158.65970, val_loss=169.21986\n",
      "Epoch 23111: train_loss=158.63327, val_loss=169.21747\n",
      "Epoch 23112: train_loss=158.61079, val_loss=169.19116\n",
      "Epoch 23113: train_loss=158.59190, val_loss=169.17192\n",
      "Epoch 23114: train_loss=158.57559, val_loss=169.17188\n",
      "Epoch 23115: train_loss=158.56123, val_loss=169.13686\n",
      "Epoch 23116: train_loss=158.54808, val_loss=169.15573\n",
      "Epoch 23117: train_loss=158.53577, val_loss=169.10661\n",
      "Epoch 23118: train_loss=158.52379, val_loss=169.13864\n",
      "Epoch 23119: train_loss=158.51199, val_loss=169.07703\n",
      "Epoch 23120: train_loss=158.50037, val_loss=169.11949\n",
      "Epoch 23121: train_loss=158.48853, val_loss=169.04918\n",
      "Epoch 23122: train_loss=158.47659, val_loss=169.10045\n",
      "Epoch 23123: train_loss=158.46439, val_loss=169.02161\n",
      "Epoch 23124: train_loss=158.45207, val_loss=169.07854\n",
      "Epoch 23125: train_loss=158.43942, val_loss=168.99294\n",
      "Epoch 23126: train_loss=158.42656, val_loss=169.05482\n",
      "Epoch 23127: train_loss=158.41290, val_loss=168.96417\n",
      "Epoch 23128: train_loss=158.39880, val_loss=169.02950\n",
      "Epoch 23129: train_loss=158.38445, val_loss=168.93559\n",
      "Epoch 23130: train_loss=158.37001, val_loss=169.00298\n",
      "Epoch 23131: train_loss=158.35521, val_loss=168.90450\n",
      "Epoch 23132: train_loss=158.34053, val_loss=168.97322\n",
      "Epoch 23133: train_loss=158.32550, val_loss=168.87177\n",
      "Epoch 23134: train_loss=158.31004, val_loss=168.94254\n",
      "Epoch 23135: train_loss=158.29417, val_loss=168.84007\n",
      "Epoch 23136: train_loss=158.27757, val_loss=168.91000\n",
      "Epoch 23137: train_loss=158.26053, val_loss=168.80568\n",
      "Epoch 23138: train_loss=158.24261, val_loss=168.87167\n",
      "Epoch 23139: train_loss=158.22386, val_loss=168.76651\n",
      "Epoch 23140: train_loss=158.20401, val_loss=168.82732\n",
      "Epoch 23141: train_loss=158.18320, val_loss=168.72522\n",
      "Epoch 23142: train_loss=158.16132, val_loss=168.77832\n",
      "Epoch 23143: train_loss=158.13844, val_loss=168.68283\n",
      "Epoch 23144: train_loss=158.11523, val_loss=168.72714\n",
      "Epoch 23145: train_loss=158.09196, val_loss=168.64075\n",
      "Epoch 23146: train_loss=158.06857, val_loss=168.67537\n",
      "Epoch 23147: train_loss=158.04547, val_loss=168.60016\n",
      "Epoch 23148: train_loss=158.02299, val_loss=168.62633\n",
      "Epoch 23149: train_loss=158.00104, val_loss=168.56287\n",
      "Epoch 23150: train_loss=157.97983, val_loss=168.58070\n",
      "Epoch 23151: train_loss=157.95930, val_loss=168.52670\n",
      "Epoch 23152: train_loss=157.93956, val_loss=168.53809\n",
      "Epoch 23153: train_loss=157.92050, val_loss=168.49141\n",
      "Epoch 23154: train_loss=157.90192, val_loss=168.49855\n",
      "Epoch 23155: train_loss=157.88385, val_loss=168.45691\n",
      "Epoch 23156: train_loss=157.86606, val_loss=168.46216\n",
      "Epoch 23157: train_loss=157.84865, val_loss=168.42349\n",
      "Epoch 23158: train_loss=157.83147, val_loss=168.42841\n",
      "Epoch 23159: train_loss=157.81451, val_loss=168.38939\n",
      "Epoch 23160: train_loss=157.79799, val_loss=168.39514\n",
      "Epoch 23161: train_loss=157.78171, val_loss=168.35416\n",
      "Epoch 23162: train_loss=157.76607, val_loss=168.36584\n",
      "Epoch 23163: train_loss=157.75098, val_loss=168.32082\n",
      "Epoch 23164: train_loss=157.73683, val_loss=168.34381\n",
      "Epoch 23165: train_loss=157.72400, val_loss=168.29085\n",
      "Epoch 23166: train_loss=157.71294, val_loss=168.33047\n",
      "Epoch 23167: train_loss=157.70398, val_loss=168.26715\n",
      "Epoch 23168: train_loss=157.69803, val_loss=168.33246\n",
      "Epoch 23169: train_loss=157.69641, val_loss=168.25764\n",
      "Epoch 23170: train_loss=157.69986, val_loss=168.36023\n",
      "Epoch 23171: train_loss=157.71028, val_loss=168.27225\n",
      "Epoch 23172: train_loss=157.72800, val_loss=168.41953\n",
      "Epoch 23173: train_loss=157.75371, val_loss=168.31488\n",
      "Epoch 23174: train_loss=157.78711, val_loss=168.50452\n",
      "Epoch 23175: train_loss=157.82300, val_loss=168.37190\n",
      "Epoch 23176: train_loss=157.86049, val_loss=168.57745\n",
      "Epoch 23177: train_loss=157.88451, val_loss=168.39584\n",
      "Epoch 23178: train_loss=157.89368, val_loss=168.56219\n",
      "Epoch 23179: train_loss=157.86765, val_loss=168.32022\n",
      "Epoch 23180: train_loss=157.81274, val_loss=168.40199\n",
      "Epoch 23181: train_loss=157.72353, val_loss=168.14764\n",
      "Epoch 23182: train_loss=157.62051, val_loss=168.16258\n",
      "Epoch 23183: train_loss=157.51874, val_loss=167.99214\n",
      "Epoch 23184: train_loss=157.43608, val_loss=167.98369\n",
      "Epoch 23185: train_loss=157.38144, val_loss=167.94574\n",
      "Epoch 23186: train_loss=157.35555, val_loss=167.92268\n",
      "Epoch 23187: train_loss=157.35306, val_loss=167.98482\n",
      "Epoch 23188: train_loss=157.36453, val_loss=167.92741\n",
      "Epoch 23189: train_loss=157.37949, val_loss=168.02682\n",
      "Epoch 23190: train_loss=157.38914, val_loss=167.92474\n",
      "Epoch 23191: train_loss=157.38713, val_loss=168.01082\n",
      "Epoch 23192: train_loss=157.36967, val_loss=167.88051\n",
      "Epoch 23193: train_loss=157.33900, val_loss=167.93118\n",
      "Epoch 23194: train_loss=157.29916, val_loss=167.81021\n",
      "Epoch 23195: train_loss=157.25633, val_loss=167.82864\n",
      "Epoch 23196: train_loss=157.21600, val_loss=167.75314\n",
      "Epoch 23197: train_loss=157.18214, val_loss=167.74817\n",
      "Epoch 23198: train_loss=157.15657, val_loss=167.72879\n",
      "Epoch 23199: train_loss=157.13905, val_loss=167.70323\n",
      "Epoch 23200: train_loss=157.12753, val_loss=167.72508\n",
      "Epoch 23201: train_loss=157.11946, val_loss=167.67563\n",
      "Epoch 23202: train_loss=157.11215, val_loss=167.71568\n",
      "Epoch 23203: train_loss=157.10315, val_loss=167.64687\n",
      "Epoch 23204: train_loss=157.09138, val_loss=167.68918\n",
      "Epoch 23205: train_loss=157.07581, val_loss=167.61235\n",
      "Epoch 23206: train_loss=157.05710, val_loss=167.64676\n",
      "Epoch 23207: train_loss=157.03574, val_loss=167.57388\n",
      "Epoch 23208: train_loss=157.01302, val_loss=167.59425\n",
      "Epoch 23209: train_loss=156.98958, val_loss=167.53397\n",
      "Epoch 23210: train_loss=156.96683, val_loss=167.54079\n",
      "Epoch 23211: train_loss=156.94518, val_loss=167.49968\n",
      "Epoch 23212: train_loss=156.92496, val_loss=167.49416\n",
      "Epoch 23213: train_loss=156.90619, val_loss=167.47015\n",
      "Epoch 23214: train_loss=156.88863, val_loss=167.45323\n",
      "Epoch 23215: train_loss=156.87189, val_loss=167.44302\n",
      "Epoch 23216: train_loss=156.85596, val_loss=167.41626\n",
      "Epoch 23217: train_loss=156.84065, val_loss=167.41682\n",
      "Epoch 23218: train_loss=156.82578, val_loss=167.38000\n",
      "Epoch 23219: train_loss=156.81125, val_loss=167.39098\n",
      "Epoch 23220: train_loss=156.79704, val_loss=167.34715\n",
      "Epoch 23221: train_loss=156.78299, val_loss=167.36710\n",
      "Epoch 23222: train_loss=156.76903, val_loss=167.31589\n",
      "Epoch 23223: train_loss=156.75537, val_loss=167.34280\n",
      "Epoch 23224: train_loss=156.74158, val_loss=167.28439\n",
      "Epoch 23225: train_loss=156.72789, val_loss=167.31784\n",
      "Epoch 23226: train_loss=156.71445, val_loss=167.25352\n",
      "Epoch 23227: train_loss=156.70117, val_loss=167.29320\n",
      "Epoch 23228: train_loss=156.68791, val_loss=167.22270\n",
      "Epoch 23229: train_loss=156.67418, val_loss=167.26700\n",
      "Epoch 23230: train_loss=156.66045, val_loss=167.19209\n",
      "Epoch 23231: train_loss=156.64664, val_loss=167.24031\n",
      "Epoch 23232: train_loss=156.63261, val_loss=167.16084\n",
      "Epoch 23233: train_loss=156.61868, val_loss=167.21263\n",
      "Epoch 23234: train_loss=156.60446, val_loss=167.13016\n",
      "Epoch 23235: train_loss=156.59009, val_loss=167.18556\n",
      "Epoch 23236: train_loss=156.57553, val_loss=167.10066\n",
      "Epoch 23237: train_loss=156.56113, val_loss=167.15822\n",
      "Epoch 23238: train_loss=156.54649, val_loss=167.06921\n",
      "Epoch 23239: train_loss=156.53183, val_loss=167.12796\n",
      "Epoch 23240: train_loss=156.51697, val_loss=167.03658\n",
      "Epoch 23241: train_loss=156.50217, val_loss=167.09816\n",
      "Epoch 23242: train_loss=156.48694, val_loss=167.00645\n",
      "Epoch 23243: train_loss=156.47162, val_loss=167.06990\n",
      "Epoch 23244: train_loss=156.45598, val_loss=166.97530\n",
      "Epoch 23245: train_loss=156.44014, val_loss=167.03674\n",
      "Epoch 23246: train_loss=156.42374, val_loss=166.93965\n",
      "Epoch 23247: train_loss=156.40717, val_loss=167.00005\n",
      "Epoch 23248: train_loss=156.38997, val_loss=166.90411\n",
      "Epoch 23249: train_loss=156.37224, val_loss=166.96400\n",
      "Epoch 23250: train_loss=156.35373, val_loss=166.87096\n",
      "Epoch 23251: train_loss=156.33502, val_loss=166.92596\n",
      "Epoch 23252: train_loss=156.31506, val_loss=166.83377\n",
      "Epoch 23253: train_loss=156.29501, val_loss=166.88126\n",
      "Epoch 23254: train_loss=156.27403, val_loss=166.79321\n",
      "Epoch 23255: train_loss=156.25307, val_loss=166.83415\n",
      "Epoch 23256: train_loss=156.23190, val_loss=166.75398\n",
      "Epoch 23257: train_loss=156.21078, val_loss=166.78772\n",
      "Epoch 23258: train_loss=156.18948, val_loss=166.71567\n",
      "Epoch 23259: train_loss=156.16861, val_loss=166.74149\n",
      "Epoch 23260: train_loss=156.14771, val_loss=166.67902\n",
      "Epoch 23261: train_loss=156.12747, val_loss=166.69769\n",
      "Epoch 23262: train_loss=156.10783, val_loss=166.64336\n",
      "Epoch 23263: train_loss=156.08879, val_loss=166.65656\n",
      "Epoch 23264: train_loss=156.07030, val_loss=166.60973\n",
      "Epoch 23265: train_loss=156.05235, val_loss=166.61902\n",
      "Epoch 23266: train_loss=156.03485, val_loss=166.57593\n",
      "Epoch 23267: train_loss=156.01778, val_loss=166.58318\n",
      "Epoch 23268: train_loss=156.00104, val_loss=166.54173\n",
      "Epoch 23269: train_loss=155.98468, val_loss=166.55086\n",
      "Epoch 23270: train_loss=155.96870, val_loss=166.50865\n",
      "Epoch 23271: train_loss=155.95323, val_loss=166.52223\n",
      "Epoch 23272: train_loss=155.93825, val_loss=166.47592\n",
      "Epoch 23273: train_loss=155.92380, val_loss=166.49648\n",
      "Epoch 23274: train_loss=155.91031, val_loss=166.44505\n",
      "Epoch 23275: train_loss=155.89809, val_loss=166.47984\n",
      "Epoch 23276: train_loss=155.88744, val_loss=166.42102\n",
      "Epoch 23277: train_loss=155.87878, val_loss=166.47337\n",
      "Epoch 23278: train_loss=155.87254, val_loss=166.40326\n",
      "Epoch 23279: train_loss=155.86996, val_loss=166.48274\n",
      "Epoch 23280: train_loss=155.87248, val_loss=166.40198\n",
      "Epoch 23281: train_loss=155.88013, val_loss=166.51984\n",
      "Epoch 23282: train_loss=155.89464, val_loss=166.42758\n",
      "Epoch 23283: train_loss=155.91550, val_loss=166.58388\n",
      "Epoch 23284: train_loss=155.94089, val_loss=166.46979\n",
      "Epoch 23285: train_loss=155.96948, val_loss=166.65109\n",
      "Epoch 23286: train_loss=155.99463, val_loss=166.50592\n",
      "Epoch 23287: train_loss=156.01608, val_loss=166.68298\n",
      "Epoch 23288: train_loss=156.01784, val_loss=166.49286\n",
      "Epoch 23289: train_loss=156.00299, val_loss=166.61986\n",
      "Epoch 23290: train_loss=155.95682, val_loss=166.38902\n",
      "Epoch 23291: train_loss=155.88983, val_loss=166.44519\n",
      "Epoch 23292: train_loss=155.80383, val_loss=166.23140\n",
      "Epoch 23293: train_loss=155.71405, val_loss=166.24236\n",
      "Epoch 23294: train_loss=155.63438, val_loss=166.12016\n",
      "Epoch 23295: train_loss=155.57458, val_loss=166.11298\n",
      "Epoch 23296: train_loss=155.53717, val_loss=166.09503\n",
      "Epoch 23297: train_loss=155.52051, val_loss=166.06627\n",
      "Epoch 23298: train_loss=155.51903, val_loss=166.12183\n",
      "Epoch 23299: train_loss=155.52554, val_loss=166.06207\n",
      "Epoch 23300: train_loss=155.53378, val_loss=166.14894\n",
      "Epoch 23301: train_loss=155.53813, val_loss=166.05560\n",
      "Epoch 23302: train_loss=155.53380, val_loss=166.13385\n",
      "Epoch 23303: train_loss=155.51862, val_loss=166.01735\n",
      "Epoch 23304: train_loss=155.49365, val_loss=166.06953\n",
      "Epoch 23305: train_loss=155.46143, val_loss=165.95836\n",
      "Epoch 23306: train_loss=155.42604, val_loss=165.98654\n",
      "Epoch 23307: train_loss=155.39119, val_loss=165.90524\n",
      "Epoch 23308: train_loss=155.35918, val_loss=165.91216\n",
      "Epoch 23309: train_loss=155.33151, val_loss=165.86859\n",
      "Epoch 23310: train_loss=155.30882, val_loss=165.85698\n",
      "Epoch 23311: train_loss=155.29048, val_loss=165.84756\n",
      "Epoch 23312: train_loss=155.27571, val_loss=165.81909\n",
      "Epoch 23313: train_loss=155.26329, val_loss=165.83481\n",
      "Epoch 23314: train_loss=155.25223, val_loss=165.79027\n",
      "Epoch 23315: train_loss=155.24164, val_loss=165.82019\n",
      "Epoch 23316: train_loss=155.23065, val_loss=165.76259\n",
      "Epoch 23317: train_loss=155.21893, val_loss=165.79948\n",
      "Epoch 23318: train_loss=155.20605, val_loss=165.73430\n",
      "Epoch 23319: train_loss=155.19205, val_loss=165.77208\n",
      "Epoch 23320: train_loss=155.17651, val_loss=165.70226\n",
      "Epoch 23321: train_loss=155.15987, val_loss=165.73630\n",
      "Epoch 23322: train_loss=155.14227, val_loss=165.66641\n",
      "Epoch 23323: train_loss=155.12375, val_loss=165.69574\n",
      "Epoch 23324: train_loss=155.10489, val_loss=165.63120\n",
      "Epoch 23325: train_loss=155.08571, val_loss=165.65546\n",
      "Epoch 23326: train_loss=155.06651, val_loss=165.59749\n",
      "Epoch 23327: train_loss=155.04761, val_loss=165.61537\n",
      "Epoch 23328: train_loss=155.02898, val_loss=165.56276\n",
      "Epoch 23329: train_loss=155.01057, val_loss=165.57556\n",
      "Epoch 23330: train_loss=154.99269, val_loss=165.52924\n",
      "Epoch 23331: train_loss=154.97517, val_loss=165.54012\n",
      "Epoch 23332: train_loss=154.95796, val_loss=165.49754\n",
      "Epoch 23333: train_loss=154.94099, val_loss=165.50520\n",
      "Epoch 23334: train_loss=154.92412, val_loss=165.46463\n",
      "Epoch 23335: train_loss=154.90755, val_loss=165.47050\n",
      "Epoch 23336: train_loss=154.89116, val_loss=165.43071\n",
      "Epoch 23337: train_loss=154.87494, val_loss=165.43730\n",
      "Epoch 23338: train_loss=154.85880, val_loss=165.39833\n",
      "Epoch 23339: train_loss=154.84306, val_loss=165.40746\n",
      "Epoch 23340: train_loss=154.82751, val_loss=165.36694\n",
      "Epoch 23341: train_loss=154.81235, val_loss=165.37918\n",
      "Epoch 23342: train_loss=154.79761, val_loss=165.33427\n",
      "Epoch 23343: train_loss=154.78348, val_loss=165.35390\n",
      "Epoch 23344: train_loss=154.77040, val_loss=165.30415\n",
      "Epoch 23345: train_loss=154.75842, val_loss=165.33725\n",
      "Epoch 23346: train_loss=154.74806, val_loss=165.28062\n",
      "Epoch 23347: train_loss=154.73958, val_loss=165.33194\n",
      "Epoch 23348: train_loss=154.73392, val_loss=165.26474\n",
      "Epoch 23349: train_loss=154.73073, val_loss=165.33865\n",
      "Epoch 23350: train_loss=154.73112, val_loss=165.25906\n",
      "Epoch 23351: train_loss=154.73463, val_loss=165.35916\n",
      "Epoch 23352: train_loss=154.74095, val_loss=165.26427\n",
      "Epoch 23353: train_loss=154.74937, val_loss=165.38678\n",
      "Epoch 23354: train_loss=154.75752, val_loss=165.27388\n",
      "Epoch 23355: train_loss=154.76570, val_loss=165.40631\n",
      "Epoch 23356: train_loss=154.76768, val_loss=165.26883\n",
      "Epoch 23357: train_loss=154.76468, val_loss=165.39032\n",
      "Epoch 23358: train_loss=154.74979, val_loss=165.22957\n",
      "Epoch 23359: train_loss=154.72571, val_loss=165.32198\n",
      "Epoch 23360: train_loss=154.68784, val_loss=165.15356\n",
      "Epoch 23361: train_loss=154.64185, val_loss=165.21043\n",
      "Epoch 23362: train_loss=154.58893, val_loss=165.06290\n",
      "Epoch 23363: train_loss=154.53569, val_loss=165.08884\n",
      "Epoch 23364: train_loss=154.48637, val_loss=164.98859\n",
      "Epoch 23365: train_loss=154.44482, val_loss=164.99318\n",
      "Epoch 23366: train_loss=154.41180, val_loss=164.94708\n",
      "Epoch 23367: train_loss=154.38702, val_loss=164.93443\n",
      "Epoch 23368: train_loss=154.36922, val_loss=164.93402\n",
      "Epoch 23369: train_loss=154.35669, val_loss=164.90337\n",
      "Epoch 23370: train_loss=154.34784, val_loss=164.93349\n",
      "Epoch 23371: train_loss=154.34088, val_loss=164.88142\n",
      "Epoch 23372: train_loss=154.33459, val_loss=164.92810\n",
      "Epoch 23373: train_loss=154.32811, val_loss=164.85979\n",
      "Epoch 23374: train_loss=154.32074, val_loss=164.91765\n",
      "Epoch 23375: train_loss=154.31161, val_loss=164.83887\n",
      "Epoch 23376: train_loss=154.30099, val_loss=164.89859\n",
      "Epoch 23377: train_loss=154.28778, val_loss=164.81082\n",
      "Epoch 23378: train_loss=154.27304, val_loss=164.86612\n",
      "Epoch 23379: train_loss=154.25589, val_loss=164.77475\n",
      "Epoch 23380: train_loss=154.23729, val_loss=164.82423\n",
      "Epoch 23381: train_loss=154.21642, val_loss=164.73734\n",
      "Epoch 23382: train_loss=154.19518, val_loss=164.77908\n",
      "Epoch 23383: train_loss=154.17265, val_loss=164.69839\n",
      "Epoch 23384: train_loss=154.14989, val_loss=164.72755\n",
      "Epoch 23385: train_loss=154.12669, val_loss=164.65643\n",
      "Epoch 23386: train_loss=154.10414, val_loss=164.67545\n",
      "Epoch 23387: train_loss=154.08223, val_loss=164.61855\n",
      "Epoch 23388: train_loss=154.06114, val_loss=164.62849\n",
      "Epoch 23389: train_loss=154.04074, val_loss=164.58525\n",
      "Epoch 23390: train_loss=154.02139, val_loss=164.58566\n",
      "Epoch 23391: train_loss=154.00281, val_loss=164.55318\n",
      "Epoch 23392: train_loss=153.98502, val_loss=164.54459\n",
      "Epoch 23393: train_loss=153.96793, val_loss=164.52347\n",
      "Epoch 23394: train_loss=153.95142, val_loss=164.50827\n",
      "Epoch 23395: train_loss=153.93529, val_loss=164.49576\n",
      "Epoch 23396: train_loss=153.91960, val_loss=164.47447\n",
      "Epoch 23397: train_loss=153.90402, val_loss=164.46906\n",
      "Epoch 23398: train_loss=153.88882, val_loss=164.44243\n",
      "Epoch 23399: train_loss=153.87381, val_loss=164.44312\n",
      "Epoch 23400: train_loss=153.85889, val_loss=164.41098\n",
      "Epoch 23401: train_loss=153.84439, val_loss=164.41843\n",
      "Epoch 23402: train_loss=153.83035, val_loss=164.37955\n",
      "Epoch 23403: train_loss=153.81686, val_loss=164.39658\n",
      "Epoch 23404: train_loss=153.80444, val_loss=164.35042\n",
      "Epoch 23405: train_loss=153.79292, val_loss=164.38095\n",
      "Epoch 23406: train_loss=153.78349, val_loss=164.32735\n",
      "Epoch 23407: train_loss=153.77661, val_loss=164.37910\n",
      "Epoch 23408: train_loss=153.77301, val_loss=164.31514\n",
      "Epoch 23409: train_loss=153.77335, val_loss=164.39545\n",
      "Epoch 23410: train_loss=153.77800, val_loss=164.31877\n",
      "Epoch 23411: train_loss=153.78795, val_loss=164.43138\n",
      "Epoch 23412: train_loss=153.80234, val_loss=164.34125\n",
      "Epoch 23413: train_loss=153.82269, val_loss=164.48843\n",
      "Epoch 23414: train_loss=153.84467, val_loss=164.37762\n",
      "Epoch 23415: train_loss=153.86731, val_loss=164.53789\n",
      "Epoch 23416: train_loss=153.88123, val_loss=164.39154\n",
      "Epoch 23417: train_loss=153.88695, val_loss=164.53070\n",
      "Epoch 23418: train_loss=153.87183, val_loss=164.34404\n",
      "Epoch 23419: train_loss=153.83995, val_loss=164.43332\n",
      "Epoch 23420: train_loss=153.78508, val_loss=164.23184\n",
      "Epoch 23421: train_loss=153.71758, val_loss=164.26953\n",
      "Epoch 23422: train_loss=153.64233, val_loss=164.10606\n",
      "Epoch 23423: train_loss=153.57205, val_loss=164.11314\n",
      "Epoch 23424: train_loss=153.51242, val_loss=164.02649\n",
      "Epoch 23425: train_loss=153.46931, val_loss=164.01709\n",
      "Epoch 23426: train_loss=153.44255, val_loss=164.00908\n",
      "Epoch 23427: train_loss=153.42944, val_loss=163.98123\n",
      "Epoch 23428: train_loss=153.42593, val_loss=164.02586\n",
      "Epoch 23429: train_loss=153.42744, val_loss=163.97122\n",
      "Epoch 23430: train_loss=153.42999, val_loss=164.03926\n",
      "Epoch 23431: train_loss=153.42987, val_loss=163.95918\n",
      "Epoch 23432: train_loss=153.42505, val_loss=164.02650\n",
      "Epoch 23433: train_loss=153.41286, val_loss=163.92953\n",
      "Epoch 23434: train_loss=153.39476, val_loss=163.98128\n",
      "Epoch 23435: train_loss=153.37015, val_loss=163.88115\n",
      "Epoch 23436: train_loss=153.34209, val_loss=163.91208\n",
      "Epoch 23437: train_loss=153.31207, val_loss=163.82875\n",
      "Epoch 23438: train_loss=153.28262, val_loss=163.84378\n",
      "Epoch 23439: train_loss=153.25502, val_loss=163.78763\n",
      "Epoch 23440: train_loss=153.23018, val_loss=163.78790\n",
      "Epoch 23441: train_loss=153.20851, val_loss=163.75961\n",
      "Epoch 23442: train_loss=153.19011, val_loss=163.74451\n",
      "Epoch 23443: train_loss=153.17410, val_loss=163.73666\n",
      "Epoch 23444: train_loss=153.15977, val_loss=163.70784\n",
      "Epoch 23445: train_loss=153.14682, val_loss=163.71683\n",
      "Epoch 23446: train_loss=153.13461, val_loss=163.67751\n",
      "Epoch 23447: train_loss=153.12280, val_loss=163.69858\n",
      "Epoch 23448: train_loss=153.11101, val_loss=163.65149\n",
      "Epoch 23449: train_loss=153.09882, val_loss=163.68025\n",
      "Epoch 23450: train_loss=153.08640, val_loss=163.62527\n",
      "Epoch 23451: train_loss=153.07333, val_loss=163.65726\n",
      "Epoch 23452: train_loss=153.06030, val_loss=163.59586\n",
      "Epoch 23453: train_loss=153.04701, val_loss=163.63159\n",
      "Epoch 23454: train_loss=153.03392, val_loss=163.56630\n",
      "Epoch 23455: train_loss=153.02061, val_loss=163.60719\n",
      "Epoch 23456: train_loss=153.00758, val_loss=163.53963\n",
      "Epoch 23457: train_loss=152.99432, val_loss=163.58388\n",
      "Epoch 23458: train_loss=152.98126, val_loss=163.51186\n",
      "Epoch 23459: train_loss=152.96793, val_loss=163.55801\n",
      "Epoch 23460: train_loss=152.95462, val_loss=163.48244\n",
      "Epoch 23461: train_loss=152.94122, val_loss=163.53174\n",
      "Epoch 23462: train_loss=152.92715, val_loss=163.45496\n",
      "Epoch 23463: train_loss=152.91333, val_loss=163.50638\n",
      "Epoch 23464: train_loss=152.89882, val_loss=163.42654\n",
      "Epoch 23465: train_loss=152.88435, val_loss=163.47758\n",
      "Epoch 23466: train_loss=152.86943, val_loss=163.39548\n",
      "Epoch 23467: train_loss=152.85474, val_loss=163.44682\n",
      "Epoch 23468: train_loss=152.83937, val_loss=163.36407\n",
      "Epoch 23469: train_loss=152.82391, val_loss=163.41527\n",
      "Epoch 23470: train_loss=152.80748, val_loss=163.33243\n",
      "Epoch 23471: train_loss=152.79079, val_loss=163.38036\n",
      "Epoch 23472: train_loss=152.77295, val_loss=163.29784\n",
      "Epoch 23473: train_loss=152.75485, val_loss=163.34100\n",
      "Epoch 23474: train_loss=152.73596, val_loss=163.26059\n",
      "Epoch 23475: train_loss=152.71651, val_loss=163.29852\n",
      "Epoch 23476: train_loss=152.69711, val_loss=163.22475\n",
      "Epoch 23477: train_loss=152.67764, val_loss=163.25807\n",
      "Epoch 23478: train_loss=152.65842, val_loss=163.18921\n",
      "Epoch 23479: train_loss=152.63919, val_loss=163.21635\n",
      "Epoch 23480: train_loss=152.62047, val_loss=163.15198\n",
      "Epoch 23481: train_loss=152.60170, val_loss=163.17386\n",
      "Epoch 23482: train_loss=152.58339, val_loss=163.11702\n",
      "Epoch 23483: train_loss=152.56512, val_loss=163.13609\n",
      "Epoch 23484: train_loss=152.54764, val_loss=163.08498\n",
      "Epoch 23485: train_loss=152.53047, val_loss=163.10046\n",
      "Epoch 23486: train_loss=152.51389, val_loss=163.05119\n",
      "Epoch 23487: train_loss=152.49745, val_loss=163.06537\n",
      "Epoch 23488: train_loss=152.48174, val_loss=163.01859\n",
      "Epoch 23489: train_loss=152.46635, val_loss=163.03624\n",
      "Epoch 23490: train_loss=152.45166, val_loss=162.98961\n",
      "Epoch 23491: train_loss=152.43744, val_loss=163.01135\n",
      "Epoch 23492: train_loss=152.42424, val_loss=162.96053\n",
      "Epoch 23493: train_loss=152.41171, val_loss=162.99036\n",
      "Epoch 23494: train_loss=152.40047, val_loss=162.93547\n",
      "Epoch 23495: train_loss=152.39046, val_loss=162.97955\n",
      "Epoch 23496: train_loss=152.38280, val_loss=162.91814\n",
      "Epoch 23497: train_loss=152.37766, val_loss=162.98126\n",
      "Epoch 23498: train_loss=152.37587, val_loss=162.91058\n",
      "Epoch 23499: train_loss=152.37849, val_loss=163.00128\n",
      "Epoch 23500: train_loss=152.38547, val_loss=162.91962\n",
      "Epoch 23501: train_loss=152.39716, val_loss=163.03958\n",
      "Epoch 23502: train_loss=152.41100, val_loss=162.94141\n",
      "Epoch 23503: train_loss=152.42805, val_loss=163.08218\n",
      "Epoch 23504: train_loss=152.44246, val_loss=162.95993\n",
      "Epoch 23505: train_loss=152.45526, val_loss=163.10368\n",
      "Epoch 23506: train_loss=152.45676, val_loss=162.95169\n",
      "Epoch 23507: train_loss=152.44887, val_loss=163.06892\n",
      "Epoch 23508: train_loss=152.42151, val_loss=162.88809\n",
      "Epoch 23509: train_loss=152.38120, val_loss=162.95882\n",
      "Epoch 23510: train_loss=152.32457, val_loss=162.77818\n",
      "Epoch 23511: train_loss=152.26213, val_loss=162.80942\n",
      "Epoch 23512: train_loss=152.19749, val_loss=162.67371\n",
      "Epoch 23513: train_loss=152.14015, val_loss=162.68175\n",
      "Epoch 23514: train_loss=152.09303, val_loss=162.61263\n",
      "Epoch 23515: train_loss=152.05859, val_loss=162.60234\n",
      "Epoch 23516: train_loss=152.03635, val_loss=162.59537\n",
      "Epoch 23517: train_loss=152.02390, val_loss=162.56648\n",
      "Epoch 23518: train_loss=152.01807, val_loss=162.60245\n",
      "Epoch 23519: train_loss=152.01553, val_loss=162.55275\n",
      "Epoch 23520: train_loss=152.01370, val_loss=162.60855\n",
      "Epoch 23521: train_loss=152.01030, val_loss=162.53653\n",
      "Epoch 23522: train_loss=152.00378, val_loss=162.59489\n",
      "Epoch 23523: train_loss=151.99355, val_loss=162.50951\n",
      "Epoch 23524: train_loss=151.97940, val_loss=162.56207\n",
      "Epoch 23525: train_loss=151.96107, val_loss=162.47325\n",
      "Epoch 23526: train_loss=151.94003, val_loss=162.51440\n",
      "Epoch 23527: train_loss=151.91664, val_loss=162.43161\n",
      "Epoch 23528: train_loss=151.89200, val_loss=162.45862\n",
      "Epoch 23529: train_loss=151.86728, val_loss=162.38994\n",
      "Epoch 23530: train_loss=151.84311, val_loss=162.40341\n",
      "Epoch 23531: train_loss=151.82021, val_loss=162.35287\n",
      "Epoch 23532: train_loss=151.79909, val_loss=162.35396\n",
      "Epoch 23533: train_loss=151.77956, val_loss=162.32150\n",
      "Epoch 23534: train_loss=151.76172, val_loss=162.31218\n",
      "Epoch 23535: train_loss=151.74509, val_loss=162.29576\n",
      "Epoch 23536: train_loss=151.72954, val_loss=162.27777\n",
      "Epoch 23537: train_loss=151.71483, val_loss=162.27173\n",
      "Epoch 23538: train_loss=151.70058, val_loss=162.24318\n",
      "Epoch 23539: train_loss=151.68677, val_loss=162.24632\n",
      "Epoch 23540: train_loss=151.67340, val_loss=162.21202\n",
      "Epoch 23541: train_loss=151.66014, val_loss=162.22566\n",
      "Epoch 23542: train_loss=151.64722, val_loss=162.18623\n",
      "Epoch 23543: train_loss=151.63463, val_loss=162.20679\n",
      "Epoch 23544: train_loss=151.62225, val_loss=162.15950\n",
      "Epoch 23545: train_loss=151.61063, val_loss=162.18787\n",
      "Epoch 23546: train_loss=151.59949, val_loss=162.13393\n",
      "Epoch 23547: train_loss=151.58914, val_loss=162.17329\n",
      "Epoch 23548: train_loss=151.57941, val_loss=162.11249\n",
      "Epoch 23549: train_loss=151.57040, val_loss=162.16185\n",
      "Epoch 23550: train_loss=151.56262, val_loss=162.09296\n",
      "Epoch 23551: train_loss=151.55623, val_loss=162.15556\n",
      "Epoch 23552: train_loss=151.55128, val_loss=162.07848\n",
      "Epoch 23553: train_loss=151.54764, val_loss=162.15660\n",
      "Epoch 23554: train_loss=151.54518, val_loss=162.07028\n",
      "Epoch 23555: train_loss=151.54387, val_loss=162.16071\n",
      "Epoch 23556: train_loss=151.54192, val_loss=162.06157\n",
      "Epoch 23557: train_loss=151.53987, val_loss=162.15773\n",
      "Epoch 23558: train_loss=151.53435, val_loss=162.04378\n",
      "Epoch 23559: train_loss=151.52594, val_loss=162.13481\n",
      "Epoch 23560: train_loss=151.51129, val_loss=162.00963\n",
      "Epoch 23561: train_loss=151.49240, val_loss=162.08765\n",
      "Epoch 23562: train_loss=151.46712, val_loss=161.96014\n",
      "Epoch 23563: train_loss=151.43825, val_loss=162.01932\n",
      "Epoch 23564: train_loss=151.40515, val_loss=161.89943\n",
      "Epoch 23565: train_loss=151.37073, val_loss=161.93752\n",
      "Epoch 23566: train_loss=151.33571, val_loss=161.83879\n",
      "Epoch 23567: train_loss=151.30301, val_loss=161.86140\n",
      "Epoch 23568: train_loss=151.27229, val_loss=161.79141\n",
      "Epoch 23569: train_loss=151.24481, val_loss=161.79973\n",
      "Epoch 23570: train_loss=151.22064, val_loss=161.75722\n",
      "Epoch 23571: train_loss=151.19975, val_loss=161.75040\n",
      "Epoch 23572: train_loss=151.18170, val_loss=161.73080\n",
      "Epoch 23573: train_loss=151.16595, val_loss=161.71094\n",
      "Epoch 23574: train_loss=151.15199, val_loss=161.71173\n",
      "Epoch 23575: train_loss=151.13934, val_loss=161.68118\n",
      "Epoch 23576: train_loss=151.12753, val_loss=161.69728\n",
      "Epoch 23577: train_loss=151.11620, val_loss=161.65602\n",
      "Epoch 23578: train_loss=151.10532, val_loss=161.68126\n",
      "Epoch 23579: train_loss=151.09435, val_loss=161.63029\n",
      "Epoch 23580: train_loss=151.08377, val_loss=161.66341\n",
      "Epoch 23581: train_loss=151.07274, val_loss=161.60431\n",
      "Epoch 23582: train_loss=151.06206, val_loss=161.64485\n",
      "Epoch 23583: train_loss=151.05139, val_loss=161.58035\n",
      "Epoch 23584: train_loss=151.04073, val_loss=161.62718\n",
      "Epoch 23585: train_loss=151.02992, val_loss=161.55663\n",
      "Epoch 23586: train_loss=151.01979, val_loss=161.60950\n",
      "Epoch 23587: train_loss=151.00963, val_loss=161.53323\n",
      "Epoch 23588: train_loss=151.00032, val_loss=161.59427\n",
      "Epoch 23589: train_loss=150.99112, val_loss=161.51305\n",
      "Epoch 23590: train_loss=150.98248, val_loss=161.58119\n",
      "Epoch 23591: train_loss=150.97391, val_loss=161.49368\n",
      "Epoch 23592: train_loss=150.96577, val_loss=161.56789\n",
      "Epoch 23593: train_loss=150.95773, val_loss=161.47287\n",
      "Epoch 23594: train_loss=150.94916, val_loss=161.55188\n",
      "Epoch 23595: train_loss=150.93954, val_loss=161.45065\n",
      "Epoch 23596: train_loss=150.92856, val_loss=161.53070\n",
      "Epoch 23597: train_loss=150.91563, val_loss=161.42400\n",
      "Epoch 23598: train_loss=150.90068, val_loss=161.49849\n",
      "Epoch 23599: train_loss=150.88300, val_loss=161.38623\n",
      "Epoch 23600: train_loss=150.86234, val_loss=161.44960\n",
      "Epoch 23601: train_loss=150.83940, val_loss=161.34004\n",
      "Epoch 23602: train_loss=150.81444, val_loss=161.39114\n",
      "Epoch 23603: train_loss=150.78712, val_loss=161.29089\n",
      "Epoch 23604: train_loss=150.75934, val_loss=161.32884\n",
      "Epoch 23605: train_loss=150.73102, val_loss=161.24463\n",
      "Epoch 23606: train_loss=150.70380, val_loss=161.26683\n",
      "Epoch 23607: train_loss=150.67715, val_loss=161.19981\n",
      "Epoch 23608: train_loss=150.65215, val_loss=161.20668\n",
      "Epoch 23609: train_loss=150.62938, val_loss=161.16214\n",
      "Epoch 23610: train_loss=150.60881, val_loss=161.15855\n",
      "Epoch 23611: train_loss=150.59035, val_loss=161.13431\n",
      "Epoch 23612: train_loss=150.57339, val_loss=161.12065\n",
      "Epoch 23613: train_loss=150.55760, val_loss=161.11116\n",
      "Epoch 23614: train_loss=150.54291, val_loss=161.08687\n",
      "Epoch 23615: train_loss=150.52881, val_loss=161.08826\n",
      "Epoch 23616: train_loss=150.51509, val_loss=161.05524\n",
      "Epoch 23617: train_loss=150.50183, val_loss=161.06622\n",
      "Epoch 23618: train_loss=150.48894, val_loss=161.02643\n",
      "Epoch 23619: train_loss=150.47644, val_loss=161.04828\n",
      "Epoch 23620: train_loss=150.46434, val_loss=161.00143\n",
      "Epoch 23621: train_loss=150.45267, val_loss=161.03099\n",
      "Epoch 23622: train_loss=150.44150, val_loss=160.97482\n",
      "Epoch 23623: train_loss=150.43077, val_loss=161.01260\n",
      "Epoch 23624: train_loss=150.42096, val_loss=160.95015\n",
      "Epoch 23625: train_loss=150.41197, val_loss=161.00096\n",
      "Epoch 23626: train_loss=150.40392, val_loss=160.93265\n",
      "Epoch 23627: train_loss=150.39763, val_loss=160.99802\n",
      "Epoch 23628: train_loss=150.39299, val_loss=160.92110\n",
      "Epoch 23629: train_loss=150.39049, val_loss=161.00194\n",
      "Epoch 23630: train_loss=150.38995, val_loss=160.91406\n",
      "Epoch 23631: train_loss=150.39081, val_loss=161.01141\n",
      "Epoch 23632: train_loss=150.39319, val_loss=160.91290\n",
      "Epoch 23633: train_loss=150.39648, val_loss=161.02510\n",
      "Epoch 23634: train_loss=150.39926, val_loss=160.91234\n",
      "Epoch 23635: train_loss=150.40054, val_loss=161.02667\n",
      "Epoch 23636: train_loss=150.39630, val_loss=160.89554\n",
      "Epoch 23637: train_loss=150.38634, val_loss=160.99779\n",
      "Epoch 23638: train_loss=150.36731, val_loss=160.85139\n",
      "Epoch 23639: train_loss=150.34047, val_loss=160.92790\n",
      "Epoch 23640: train_loss=150.30400, val_loss=160.77936\n",
      "Epoch 23641: train_loss=150.26233, val_loss=160.82941\n",
      "Epoch 23642: train_loss=150.21701, val_loss=160.70090\n",
      "Epoch 23643: train_loss=150.17189, val_loss=160.72643\n",
      "Epoch 23644: train_loss=150.12921, val_loss=160.63428\n",
      "Epoch 23645: train_loss=150.09186, val_loss=160.63919\n",
      "Epoch 23646: train_loss=150.06047, val_loss=160.58943\n",
      "Epoch 23647: train_loss=150.03583, val_loss=160.57764\n",
      "Epoch 23648: train_loss=150.01736, val_loss=160.56898\n",
      "Epoch 23649: train_loss=150.00398, val_loss=160.54164\n",
      "Epoch 23650: train_loss=149.99376, val_loss=160.56102\n",
      "Epoch 23651: train_loss=149.98547, val_loss=160.51712\n",
      "Epoch 23652: train_loss=149.97733, val_loss=160.54990\n",
      "Epoch 23653: train_loss=149.96825, val_loss=160.49200\n",
      "Epoch 23654: train_loss=149.95757, val_loss=160.52905\n",
      "Epoch 23655: train_loss=149.94533, val_loss=160.46368\n",
      "Epoch 23656: train_loss=149.93141, val_loss=160.50021\n",
      "Epoch 23657: train_loss=149.91611, val_loss=160.43295\n",
      "Epoch 23658: train_loss=149.89923, val_loss=160.46504\n",
      "Epoch 23659: train_loss=149.88133, val_loss=160.39940\n",
      "Epoch 23660: train_loss=149.86275, val_loss=160.42268\n",
      "Epoch 23661: train_loss=149.84340, val_loss=160.36136\n",
      "Epoch 23662: train_loss=149.82391, val_loss=160.37611\n",
      "Epoch 23663: train_loss=149.80473, val_loss=160.32535\n",
      "Epoch 23664: train_loss=149.78593, val_loss=160.33452\n",
      "Epoch 23665: train_loss=149.76770, val_loss=160.29565\n",
      "Epoch 23666: train_loss=149.75005, val_loss=160.29842\n",
      "Epoch 23667: train_loss=149.73306, val_loss=160.26578\n",
      "Epoch 23668: train_loss=149.71643, val_loss=160.26051\n",
      "Epoch 23669: train_loss=149.70026, val_loss=160.23520\n",
      "Epoch 23670: train_loss=149.68439, val_loss=160.22562\n",
      "Epoch 23671: train_loss=149.66881, val_loss=160.20822\n",
      "Epoch 23672: train_loss=149.65349, val_loss=160.19417\n",
      "Epoch 23673: train_loss=149.63834, val_loss=160.18018\n",
      "Epoch 23674: train_loss=149.62328, val_loss=160.16006\n",
      "Epoch 23675: train_loss=149.60841, val_loss=160.14980\n",
      "Epoch 23676: train_loss=149.59360, val_loss=160.12633\n",
      "Epoch 23677: train_loss=149.57893, val_loss=160.12199\n",
      "Epoch 23678: train_loss=149.56438, val_loss=160.09583\n",
      "Epoch 23679: train_loss=149.54991, val_loss=160.09650\n",
      "Epoch 23680: train_loss=149.53590, val_loss=160.06575\n",
      "Epoch 23681: train_loss=149.52220, val_loss=160.07384\n",
      "Epoch 23682: train_loss=149.50938, val_loss=160.03619\n",
      "Epoch 23683: train_loss=149.49733, val_loss=160.05516\n",
      "Epoch 23684: train_loss=149.48698, val_loss=160.01012\n",
      "Epoch 23685: train_loss=149.47911, val_loss=160.04987\n",
      "Epoch 23686: train_loss=149.47443, val_loss=159.99849\n",
      "Epoch 23687: train_loss=149.47464, val_loss=160.07043\n",
      "Epoch 23688: train_loss=149.48003, val_loss=160.00755\n",
      "Epoch 23689: train_loss=149.49283, val_loss=160.11852\n",
      "Epoch 23690: train_loss=149.51318, val_loss=160.04279\n",
      "Epoch 23691: train_loss=149.54298, val_loss=160.20279\n",
      "Epoch 23692: train_loss=149.58052, val_loss=160.11305\n",
      "Epoch 23693: train_loss=149.62717, val_loss=160.31393\n",
      "Epoch 23694: train_loss=149.67233, val_loss=160.19099\n",
      "Epoch 23695: train_loss=149.71326, val_loss=160.38477\n",
      "Epoch 23696: train_loss=149.72939, val_loss=160.19426\n",
      "Epoch 23697: train_loss=149.71854, val_loss=160.31194\n",
      "Epoch 23698: train_loss=149.66144, val_loss=160.05714\n",
      "Epoch 23699: train_loss=149.57272, val_loss=160.08035\n",
      "Epoch 23700: train_loss=149.45769, val_loss=159.85022\n",
      "Epoch 23701: train_loss=149.34547, val_loss=159.83456\n",
      "Epoch 23702: train_loss=149.25436, val_loss=159.73027\n",
      "Epoch 23703: train_loss=149.19672, val_loss=159.71590\n",
      "Epoch 23704: train_loss=149.17262, val_loss=159.74092\n",
      "Epoch 23705: train_loss=149.17503, val_loss=159.71078\n",
      "Epoch 23706: train_loss=149.19307, val_loss=159.80119\n",
      "Epoch 23707: train_loss=149.21370, val_loss=159.72818\n",
      "Epoch 23708: train_loss=149.22659, val_loss=159.81842\n",
      "Epoch 23709: train_loss=149.22408, val_loss=159.70273\n",
      "Epoch 23710: train_loss=149.20399, val_loss=159.75714\n",
      "Epoch 23711: train_loss=149.16890, val_loss=159.63464\n",
      "Epoch 23712: train_loss=149.12535, val_loss=159.65378\n",
      "Epoch 23713: train_loss=149.08067, val_loss=159.56769\n",
      "Epoch 23714: train_loss=149.04190, val_loss=159.56427\n",
      "Epoch 23715: train_loss=149.01247, val_loss=159.53465\n",
      "Epoch 23716: train_loss=148.99316, val_loss=159.51439\n",
      "Epoch 23717: train_loss=148.98218, val_loss=159.53233\n",
      "Epoch 23718: train_loss=148.97632, val_loss=159.49263\n",
      "Epoch 23719: train_loss=148.97215, val_loss=159.53218\n",
      "Epoch 23720: train_loss=148.96649, val_loss=159.47253\n",
      "Epoch 23721: train_loss=148.95787, val_loss=159.51285\n",
      "Epoch 23722: train_loss=148.94472, val_loss=159.44186\n",
      "Epoch 23723: train_loss=148.92749, val_loss=159.47150\n",
      "Epoch 23724: train_loss=148.90692, val_loss=159.40260\n",
      "Epoch 23725: train_loss=148.88475, val_loss=159.41803\n",
      "Epoch 23726: train_loss=148.86189, val_loss=159.36386\n",
      "Epoch 23727: train_loss=148.84004, val_loss=159.36612\n",
      "Epoch 23728: train_loss=148.81985, val_loss=159.33284\n",
      "Epoch 23729: train_loss=148.80157, val_loss=159.32184\n",
      "Epoch 23730: train_loss=148.78545, val_loss=159.30959\n",
      "Epoch 23731: train_loss=148.77118, val_loss=159.28639\n",
      "Epoch 23732: train_loss=148.75803, val_loss=159.28932\n",
      "Epoch 23733: train_loss=148.74556, val_loss=159.25642\n",
      "Epoch 23734: train_loss=148.73314, val_loss=159.26746\n",
      "Epoch 23735: train_loss=148.72031, val_loss=159.22679\n",
      "Epoch 23736: train_loss=148.70695, val_loss=159.24033\n",
      "Epoch 23737: train_loss=148.69295, val_loss=159.19633\n",
      "Epoch 23738: train_loss=148.67845, val_loss=159.21011\n",
      "Epoch 23739: train_loss=148.66345, val_loss=159.16667\n",
      "Epoch 23740: train_loss=148.64821, val_loss=159.17834\n",
      "Epoch 23741: train_loss=148.63258, val_loss=159.13519\n",
      "Epoch 23742: train_loss=148.61699, val_loss=159.14343\n",
      "Epoch 23743: train_loss=148.60114, val_loss=159.10291\n",
      "Epoch 23744: train_loss=148.58540, val_loss=159.10986\n",
      "Epoch 23745: train_loss=148.56969, val_loss=159.07411\n",
      "Epoch 23746: train_loss=148.55402, val_loss=159.07822\n",
      "Epoch 23747: train_loss=148.53835, val_loss=159.04370\n",
      "Epoch 23748: train_loss=148.52287, val_loss=159.04369\n",
      "Epoch 23749: train_loss=148.50742, val_loss=159.01189\n",
      "Epoch 23750: train_loss=148.49216, val_loss=159.01089\n",
      "Epoch 23751: train_loss=148.47691, val_loss=158.98334\n",
      "Epoch 23752: train_loss=148.46187, val_loss=158.98091\n",
      "Epoch 23753: train_loss=148.44693, val_loss=158.95232\n",
      "Epoch 23754: train_loss=148.43208, val_loss=158.94958\n",
      "Epoch 23755: train_loss=148.41740, val_loss=158.92210\n",
      "Epoch 23756: train_loss=148.40303, val_loss=158.92252\n",
      "Epoch 23757: train_loss=148.38893, val_loss=158.89214\n",
      "Epoch 23758: train_loss=148.37526, val_loss=158.89838\n",
      "Epoch 23759: train_loss=148.36232, val_loss=158.86324\n",
      "Epoch 23760: train_loss=148.35019, val_loss=158.87964\n",
      "Epoch 23761: train_loss=148.33931, val_loss=158.83659\n",
      "Epoch 23762: train_loss=148.32954, val_loss=158.86697\n",
      "Epoch 23763: train_loss=148.32184, val_loss=158.81473\n",
      "Epoch 23764: train_loss=148.31532, val_loss=158.86342\n",
      "Epoch 23765: train_loss=148.31178, val_loss=158.80367\n",
      "Epoch 23766: train_loss=148.31047, val_loss=158.87503\n",
      "Epoch 23767: train_loss=148.31285, val_loss=158.80305\n",
      "Epoch 23768: train_loss=148.31799, val_loss=158.89742\n",
      "Epoch 23769: train_loss=148.32668, val_loss=158.81148\n",
      "Epoch 23770: train_loss=148.33791, val_loss=158.92999\n",
      "Epoch 23771: train_loss=148.35056, val_loss=158.82733\n",
      "Epoch 23772: train_loss=148.36206, val_loss=158.95874\n",
      "Epoch 23773: train_loss=148.36942, val_loss=158.83278\n",
      "Epoch 23774: train_loss=148.37094, val_loss=158.95377\n",
      "Epoch 23775: train_loss=148.36084, val_loss=158.80124\n",
      "Epoch 23776: train_loss=148.34030, val_loss=158.89119\n",
      "Epoch 23777: train_loss=148.30490, val_loss=158.72408\n",
      "Epoch 23778: train_loss=148.25887, val_loss=158.77553\n",
      "Epoch 23779: train_loss=148.20448, val_loss=158.62436\n",
      "Epoch 23780: train_loss=148.14847, val_loss=158.64679\n",
      "Epoch 23781: train_loss=148.09608, val_loss=158.54237\n",
      "Epoch 23782: train_loss=148.05119, val_loss=158.54611\n",
      "Epoch 23783: train_loss=148.01598, val_loss=158.49939\n",
      "Epoch 23784: train_loss=147.99086, val_loss=158.48547\n",
      "Epoch 23785: train_loss=147.97459, val_loss=158.48843\n",
      "Epoch 23786: train_loss=147.96535, val_loss=158.45633\n",
      "Epoch 23787: train_loss=147.96019, val_loss=158.49335\n",
      "Epoch 23788: train_loss=147.95688, val_loss=158.44289\n",
      "Epoch 23789: train_loss=147.95312, val_loss=158.49289\n",
      "Epoch 23790: train_loss=147.94769, val_loss=158.42317\n",
      "Epoch 23791: train_loss=147.93889, val_loss=158.47267\n",
      "Epoch 23792: train_loss=147.92755, val_loss=158.39307\n",
      "Epoch 23793: train_loss=147.91234, val_loss=158.43797\n",
      "Epoch 23794: train_loss=147.89508, val_loss=158.35771\n",
      "Epoch 23795: train_loss=147.87445, val_loss=158.39194\n",
      "Epoch 23796: train_loss=147.85307, val_loss=158.31778\n",
      "Epoch 23797: train_loss=147.83032, val_loss=158.33920\n",
      "Epoch 23798: train_loss=147.80786, val_loss=158.27914\n",
      "Epoch 23799: train_loss=147.78595, val_loss=158.29008\n",
      "Epoch 23800: train_loss=147.76530, val_loss=158.24825\n",
      "Epoch 23801: train_loss=147.74612, val_loss=158.24606\n",
      "Epoch 23802: train_loss=147.72842, val_loss=158.22017\n",
      "Epoch 23803: train_loss=147.71216, val_loss=158.20699\n",
      "Epoch 23804: train_loss=147.69711, val_loss=158.19566\n",
      "Epoch 23805: train_loss=147.68306, val_loss=158.17397\n",
      "Epoch 23806: train_loss=147.66965, val_loss=158.17400\n",
      "Epoch 23807: train_loss=147.65669, val_loss=158.14355\n",
      "Epoch 23808: train_loss=147.64407, val_loss=158.15236\n",
      "Epoch 23809: train_loss=147.63159, val_loss=158.11566\n",
      "Epoch 23810: train_loss=147.61934, val_loss=158.13231\n",
      "Epoch 23811: train_loss=147.60732, val_loss=158.08861\n",
      "Epoch 23812: train_loss=147.59549, val_loss=158.11021\n",
      "Epoch 23813: train_loss=147.58414, val_loss=158.06026\n",
      "Epoch 23814: train_loss=147.57315, val_loss=158.09073\n",
      "Epoch 23815: train_loss=147.56261, val_loss=158.03661\n",
      "Epoch 23816: train_loss=147.55255, val_loss=158.07790\n",
      "Epoch 23817: train_loss=147.54398, val_loss=158.01666\n",
      "Epoch 23818: train_loss=147.53593, val_loss=158.06786\n",
      "Epoch 23819: train_loss=147.52985, val_loss=157.99828\n",
      "Epoch 23820: train_loss=147.52435, val_loss=158.06404\n",
      "Epoch 23821: train_loss=147.52124, val_loss=157.98808\n",
      "Epoch 23822: train_loss=147.51904, val_loss=158.06886\n",
      "Epoch 23823: train_loss=147.51834, val_loss=157.98186\n",
      "Epoch 23824: train_loss=147.51807, val_loss=158.07504\n",
      "Epoch 23825: train_loss=147.51888, val_loss=157.97572\n",
      "Epoch 23826: train_loss=147.51877, val_loss=158.07751\n",
      "Epoch 23827: train_loss=147.51659, val_loss=157.96552\n",
      "Epoch 23828: train_loss=147.51089, val_loss=158.06450\n",
      "Epoch 23829: train_loss=147.50015, val_loss=157.93799\n",
      "Epoch 23830: train_loss=147.48396, val_loss=158.02159\n",
      "Epoch 23831: train_loss=147.46165, val_loss=157.88750\n",
      "Epoch 23832: train_loss=147.43382, val_loss=157.95184\n",
      "Epoch 23833: train_loss=147.40092, val_loss=157.82367\n",
      "Epoch 23834: train_loss=147.36409, val_loss=157.86662\n",
      "Epoch 23835: train_loss=147.32675, val_loss=157.75812\n",
      "Epoch 23836: train_loss=147.28952, val_loss=157.78136\n",
      "Epoch 23837: train_loss=147.25555, val_loss=157.70589\n",
      "Epoch 23838: train_loss=147.22511, val_loss=157.71245\n",
      "Epoch 23839: train_loss=147.19928, val_loss=157.67268\n",
      "Epoch 23840: train_loss=147.17842, val_loss=157.66190\n",
      "Epoch 23841: train_loss=147.16199, val_loss=157.65279\n",
      "Epoch 23842: train_loss=147.14905, val_loss=157.62671\n",
      "Epoch 23843: train_loss=147.13834, val_loss=157.64128\n",
      "Epoch 23844: train_loss=147.12897, val_loss=157.60211\n",
      "Epoch 23845: train_loss=147.11989, val_loss=157.62988\n",
      "Epoch 23846: train_loss=147.11060, val_loss=157.57834\n",
      "Epoch 23847: train_loss=147.10072, val_loss=157.61166\n",
      "Epoch 23848: train_loss=147.09052, val_loss=157.55222\n",
      "Epoch 23849: train_loss=147.07928, val_loss=157.59061\n",
      "Epoch 23850: train_loss=147.06744, val_loss=157.52722\n",
      "Epoch 23851: train_loss=147.05467, val_loss=157.56708\n",
      "Epoch 23852: train_loss=147.04167, val_loss=157.49890\n",
      "Epoch 23853: train_loss=147.02774, val_loss=157.53714\n",
      "Epoch 23854: train_loss=147.01396, val_loss=157.46786\n",
      "Epoch 23855: train_loss=146.99947, val_loss=157.50694\n",
      "Epoch 23856: train_loss=146.98535, val_loss=157.43924\n",
      "Epoch 23857: train_loss=146.97083, val_loss=157.47932\n",
      "Epoch 23858: train_loss=146.95670, val_loss=157.41022\n",
      "Epoch 23859: train_loss=146.94220, val_loss=157.44933\n",
      "Epoch 23860: train_loss=146.92821, val_loss=157.38020\n",
      "Epoch 23861: train_loss=146.91383, val_loss=157.42049\n",
      "Epoch 23862: train_loss=146.89990, val_loss=157.35197\n",
      "Epoch 23863: train_loss=146.88564, val_loss=157.39349\n",
      "Epoch 23864: train_loss=146.87233, val_loss=157.32341\n",
      "Epoch 23865: train_loss=146.85867, val_loss=157.36578\n",
      "Epoch 23866: train_loss=146.84607, val_loss=157.29449\n",
      "Epoch 23867: train_loss=146.83299, val_loss=157.34065\n",
      "Epoch 23868: train_loss=146.82108, val_loss=157.26837\n",
      "Epoch 23869: train_loss=146.80862, val_loss=157.31853\n",
      "Epoch 23870: train_loss=146.79735, val_loss=157.24297\n",
      "Epoch 23871: train_loss=146.78566, val_loss=157.29724\n",
      "Epoch 23872: train_loss=146.77539, val_loss=157.21786\n",
      "Epoch 23873: train_loss=146.76459, val_loss=157.27859\n",
      "Epoch 23874: train_loss=146.75552, val_loss=157.19661\n",
      "Epoch 23875: train_loss=146.74634, val_loss=157.26494\n",
      "Epoch 23876: train_loss=146.73886, val_loss=157.17809\n",
      "Epoch 23877: train_loss=146.73076, val_loss=157.25386\n",
      "Epoch 23878: train_loss=146.72443, val_loss=157.16045\n",
      "Epoch 23879: train_loss=146.71748, val_loss=157.24347\n",
      "Epoch 23880: train_loss=146.71179, val_loss=157.14281\n",
      "Epoch 23881: train_loss=146.70459, val_loss=157.23109\n",
      "Epoch 23882: train_loss=146.69746, val_loss=157.12372\n",
      "Epoch 23883: train_loss=146.68759, val_loss=157.21219\n",
      "Epoch 23884: train_loss=146.67642, val_loss=157.09750\n",
      "Epoch 23885: train_loss=146.66190, val_loss=157.17871\n",
      "Epoch 23886: train_loss=146.64491, val_loss=157.05876\n",
      "Epoch 23887: train_loss=146.62366, val_loss=157.12805\n",
      "Epoch 23888: train_loss=146.60001, val_loss=157.01031\n",
      "Epoch 23889: train_loss=146.57230, val_loss=157.06403\n",
      "Epoch 23890: train_loss=146.54349, val_loss=156.95647\n",
      "Epoch 23891: train_loss=146.51221, val_loss=156.99164\n",
      "Epoch 23892: train_loss=146.48199, val_loss=156.90573\n",
      "Epoch 23893: train_loss=146.45268, val_loss=156.92462\n",
      "Epoch 23894: train_loss=146.42580, val_loss=156.86624\n",
      "Epoch 23895: train_loss=146.40158, val_loss=156.86819\n",
      "Epoch 23896: train_loss=146.38066, val_loss=156.83856\n",
      "Epoch 23897: train_loss=146.36322, val_loss=156.82411\n",
      "Epoch 23898: train_loss=146.34874, val_loss=156.81970\n",
      "Epoch 23899: train_loss=146.33649, val_loss=156.79208\n",
      "Epoch 23900: train_loss=146.32558, val_loss=156.80615\n",
      "Epoch 23901: train_loss=146.31528, val_loss=156.76543\n",
      "Epoch 23902: train_loss=146.30501, val_loss=156.78822\n",
      "Epoch 23903: train_loss=146.29449, val_loss=156.73775\n",
      "Epoch 23904: train_loss=146.28340, val_loss=156.76674\n",
      "Epoch 23905: train_loss=146.27202, val_loss=156.71173\n",
      "Epoch 23906: train_loss=146.26012, val_loss=156.74448\n",
      "Epoch 23907: train_loss=146.24802, val_loss=156.68456\n",
      "Epoch 23908: train_loss=146.23570, val_loss=156.71945\n",
      "Epoch 23909: train_loss=146.22331, val_loss=156.65596\n",
      "Epoch 23910: train_loss=146.21078, val_loss=156.69446\n",
      "Epoch 23911: train_loss=146.19841, val_loss=156.62953\n",
      "Epoch 23912: train_loss=146.18607, val_loss=156.67139\n",
      "Epoch 23913: train_loss=146.17430, val_loss=156.60312\n",
      "Epoch 23914: train_loss=146.16273, val_loss=156.64972\n",
      "Epoch 23915: train_loss=146.15263, val_loss=156.57771\n",
      "Epoch 23916: train_loss=146.14259, val_loss=156.63385\n",
      "Epoch 23917: train_loss=146.13455, val_loss=156.55905\n",
      "Epoch 23918: train_loss=146.12724, val_loss=156.62715\n",
      "Epoch 23919: train_loss=146.12267, val_loss=156.54417\n",
      "Epoch 23920: train_loss=146.11868, val_loss=156.62543\n",
      "Epoch 23921: train_loss=146.11755, val_loss=156.53441\n",
      "Epoch 23922: train_loss=146.11737, val_loss=156.63266\n",
      "Epoch 23923: train_loss=146.11923, val_loss=156.53287\n",
      "Epoch 23924: train_loss=146.12088, val_loss=156.64392\n",
      "Epoch 23925: train_loss=146.12265, val_loss=156.53029\n",
      "Epoch 23926: train_loss=146.12242, val_loss=156.64268\n",
      "Epoch 23927: train_loss=146.11870, val_loss=156.51129\n",
      "Epoch 23928: train_loss=146.10907, val_loss=156.61356\n",
      "Epoch 23929: train_loss=146.09224, val_loss=156.46883\n",
      "Epoch 23930: train_loss=146.06732, val_loss=156.54839\n",
      "Epoch 23931: train_loss=146.03458, val_loss=156.40295\n",
      "Epoch 23932: train_loss=145.99550, val_loss=156.45494\n",
      "Epoch 23933: train_loss=145.95372, val_loss=156.32961\n",
      "Epoch 23934: train_loss=145.91130, val_loss=156.35812\n",
      "Epoch 23935: train_loss=145.87265, val_loss=156.26788\n",
      "Epoch 23936: train_loss=145.83763, val_loss=156.27563\n",
      "Epoch 23937: train_loss=145.80858, val_loss=156.22887\n",
      "Epoch 23938: train_loss=145.78558, val_loss=156.22029\n",
      "Epoch 23939: train_loss=145.76855, val_loss=156.21263\n",
      "Epoch 23940: train_loss=145.75592, val_loss=156.18584\n",
      "Epoch 23941: train_loss=145.74658, val_loss=156.20328\n",
      "Epoch 23942: train_loss=145.73904, val_loss=156.15903\n",
      "Epoch 23943: train_loss=145.73206, val_loss=156.19392\n",
      "Epoch 23944: train_loss=145.72476, val_loss=156.13710\n",
      "Epoch 23945: train_loss=145.71576, val_loss=156.17947\n",
      "Epoch 23946: train_loss=145.70590, val_loss=156.11324\n",
      "Epoch 23947: train_loss=145.69389, val_loss=156.15376\n",
      "Epoch 23948: train_loss=145.68088, val_loss=156.08215\n",
      "Epoch 23949: train_loss=145.66583, val_loss=156.12067\n",
      "Epoch 23950: train_loss=145.65053, val_loss=156.05110\n",
      "Epoch 23951: train_loss=145.63365, val_loss=156.08470\n",
      "Epoch 23952: train_loss=145.61641, val_loss=156.01781\n",
      "Epoch 23953: train_loss=145.59811, val_loss=156.04233\n",
      "Epoch 23954: train_loss=145.57990, val_loss=155.98225\n",
      "Epoch 23955: train_loss=145.56137, val_loss=156.00015\n",
      "Epoch 23956: train_loss=145.54349, val_loss=155.95107\n",
      "Epoch 23957: train_loss=145.52577, val_loss=155.96147\n",
      "Epoch 23958: train_loss=145.50883, val_loss=155.92087\n",
      "Epoch 23959: train_loss=145.49223, val_loss=155.92264\n",
      "Epoch 23960: train_loss=145.47627, val_loss=155.88960\n",
      "Epoch 23961: train_loss=145.46075, val_loss=155.88605\n",
      "Epoch 23962: train_loss=145.44576, val_loss=155.86110\n",
      "Epoch 23963: train_loss=145.43103, val_loss=155.85489\n",
      "Epoch 23964: train_loss=145.41661, val_loss=155.83382\n",
      "Epoch 23965: train_loss=145.40231, val_loss=155.82428\n",
      "Epoch 23966: train_loss=145.38812, val_loss=155.80437\n",
      "Epoch 23967: train_loss=145.37398, val_loss=155.79439\n",
      "Epoch 23968: train_loss=145.35995, val_loss=155.77490\n",
      "Epoch 23969: train_loss=145.34586, val_loss=155.76782\n",
      "Epoch 23970: train_loss=145.33185, val_loss=155.74699\n",
      "Epoch 23971: train_loss=145.31798, val_loss=155.74146\n",
      "Epoch 23972: train_loss=145.30428, val_loss=155.71602\n",
      "Epoch 23973: train_loss=145.29076, val_loss=155.71497\n",
      "Epoch 23974: train_loss=145.27771, val_loss=155.68500\n",
      "Epoch 23975: train_loss=145.26518, val_loss=155.69443\n",
      "Epoch 23976: train_loss=145.25351, val_loss=155.65790\n",
      "Epoch 23977: train_loss=145.24294, val_loss=155.68050\n",
      "Epoch 23978: train_loss=145.23444, val_loss=155.63391\n",
      "Epoch 23979: train_loss=145.22800, val_loss=155.67915\n",
      "Epoch 23980: train_loss=145.22591, val_loss=155.62321\n",
      "Epoch 23981: train_loss=145.22812, val_loss=155.70361\n",
      "Epoch 23982: train_loss=145.23747, val_loss=155.63931\n",
      "Epoch 23983: train_loss=145.25598, val_loss=155.76852\n",
      "Epoch 23984: train_loss=145.28453, val_loss=155.69193\n",
      "Epoch 23985: train_loss=145.32616, val_loss=155.87993\n",
      "Epoch 23986: train_loss=145.37791, val_loss=155.78703\n",
      "Epoch 23987: train_loss=145.44096, val_loss=156.02341\n",
      "Epoch 23988: train_loss=145.50145, val_loss=155.89182\n",
      "Epoch 23989: train_loss=145.55762, val_loss=156.11220\n",
      "Epoch 23990: train_loss=145.57631, val_loss=155.89206\n",
      "Epoch 23991: train_loss=145.55865, val_loss=156.00438\n",
      "Epoch 23992: train_loss=145.47682, val_loss=155.70288\n",
      "Epoch 23993: train_loss=145.35648, val_loss=155.70193\n",
      "Epoch 23994: train_loss=145.21095, val_loss=155.45741\n",
      "Epoch 23995: train_loss=145.08069, val_loss=155.43129\n",
      "Epoch 23996: train_loss=144.99078, val_loss=155.36833\n",
      "Epoch 23997: train_loss=144.95174, val_loss=155.35515\n",
      "Epoch 23998: train_loss=144.95726, val_loss=155.44395\n",
      "Epoch 23999: train_loss=144.99002, val_loss=155.39937\n",
      "Epoch 24000: train_loss=145.02783, val_loss=155.52469\n",
      "Epoch 24001: train_loss=145.05093, val_loss=155.40939\n",
      "Epoch 24002: train_loss=145.04906, val_loss=155.48755\n",
      "Epoch 24003: train_loss=145.01765, val_loss=155.33385\n",
      "Epoch 24004: train_loss=144.96616, val_loss=155.35680\n",
      "Epoch 24005: train_loss=144.90712, val_loss=155.24484\n",
      "Epoch 24006: train_loss=144.85471, val_loss=155.24138\n",
      "Epoch 24007: train_loss=144.81821, val_loss=155.21730\n",
      "Epoch 24008: train_loss=144.80025, val_loss=155.19536\n",
      "Epoch 24009: train_loss=144.79681, val_loss=155.23726\n",
      "Epoch 24010: train_loss=144.80092, val_loss=155.18510\n",
      "Epoch 24011: train_loss=144.80446, val_loss=155.24538\n",
      "Epoch 24012: train_loss=144.80220, val_loss=155.16563\n",
      "Epoch 24013: train_loss=144.79036, val_loss=155.21106\n",
      "Epoch 24014: train_loss=144.76976, val_loss=155.12460\n",
      "Epoch 24015: train_loss=144.74289, val_loss=155.14603\n",
      "Epoch 24016: train_loss=144.71454, val_loss=155.08182\n",
      "Epoch 24017: train_loss=144.68755, val_loss=155.08244\n",
      "Epoch 24018: train_loss=144.66530, val_loss=155.05696\n",
      "Epoch 24019: train_loss=144.64838, val_loss=155.03958\n",
      "Epoch 24020: train_loss=144.63632, val_loss=155.04651\n",
      "Epoch 24021: train_loss=144.62729, val_loss=155.01039\n",
      "Epoch 24022: train_loss=144.61932, val_loss=155.03534\n",
      "Epoch 24023: train_loss=144.61076, val_loss=154.98680\n",
      "Epoch 24024: train_loss=144.59998, val_loss=155.01500\n",
      "Epoch 24025: train_loss=144.58682, val_loss=154.96114\n",
      "Epoch 24026: train_loss=144.57143, val_loss=154.98076\n",
      "Epoch 24027: train_loss=144.55441, val_loss=154.92844\n",
      "Epoch 24028: train_loss=144.53641, val_loss=154.93614\n",
      "Epoch 24029: train_loss=144.51840, val_loss=154.89703\n",
      "Epoch 24030: train_loss=144.50110, val_loss=154.89462\n",
      "Epoch 24031: train_loss=144.48497, val_loss=154.87231\n",
      "Epoch 24032: train_loss=144.47000, val_loss=154.85919\n",
      "Epoch 24033: train_loss=144.45612, val_loss=154.85063\n",
      "Epoch 24034: train_loss=144.44295, val_loss=154.82776\n",
      "Epoch 24035: train_loss=144.43030, val_loss=154.83012\n",
      "Epoch 24036: train_loss=144.41795, val_loss=154.79999\n",
      "Epoch 24037: train_loss=144.40570, val_loss=154.80945\n",
      "Epoch 24038: train_loss=144.39342, val_loss=154.77357\n",
      "Epoch 24039: train_loss=144.38084, val_loss=154.78690\n",
      "Epoch 24040: train_loss=144.36816, val_loss=154.74611\n",
      "Epoch 24041: train_loss=144.35515, val_loss=154.76128\n",
      "Epoch 24042: train_loss=144.34206, val_loss=154.71829\n",
      "Epoch 24043: train_loss=144.32863, val_loss=154.73421\n",
      "Epoch 24044: train_loss=144.31532, val_loss=154.68857\n",
      "Epoch 24045: train_loss=144.30165, val_loss=154.70589\n",
      "Epoch 24046: train_loss=144.28810, val_loss=154.66055\n",
      "Epoch 24047: train_loss=144.27446, val_loss=154.67950\n",
      "Epoch 24048: train_loss=144.26102, val_loss=154.63367\n",
      "Epoch 24049: train_loss=144.24731, val_loss=154.65390\n",
      "Epoch 24050: train_loss=144.23386, val_loss=154.60678\n",
      "Epoch 24051: train_loss=144.22040, val_loss=154.62747\n",
      "Epoch 24052: train_loss=144.20735, val_loss=154.57854\n",
      "Epoch 24053: train_loss=144.19417, val_loss=154.60115\n",
      "Epoch 24054: train_loss=144.18167, val_loss=154.55093\n",
      "Epoch 24055: train_loss=144.16949, val_loss=154.57951\n",
      "Epoch 24056: train_loss=144.15834, val_loss=154.52698\n",
      "Epoch 24057: train_loss=144.14760, val_loss=154.56310\n",
      "Epoch 24058: train_loss=144.13782, val_loss=154.50613\n",
      "Epoch 24059: train_loss=144.12860, val_loss=154.55106\n",
      "Epoch 24060: train_loss=144.12079, val_loss=154.48743\n",
      "Epoch 24061: train_loss=144.11308, val_loss=154.54169\n",
      "Epoch 24062: train_loss=144.10674, val_loss=154.47003\n",
      "Epoch 24063: train_loss=144.10138, val_loss=154.53619\n",
      "Epoch 24064: train_loss=144.09702, val_loss=154.45657\n",
      "Epoch 24065: train_loss=144.09341, val_loss=154.53514\n",
      "Epoch 24066: train_loss=144.09039, val_loss=154.44640\n",
      "Epoch 24067: train_loss=144.08739, val_loss=154.53265\n",
      "Epoch 24068: train_loss=144.08339, val_loss=154.43222\n",
      "Epoch 24069: train_loss=144.07814, val_loss=154.52043\n",
      "Epoch 24070: train_loss=144.07013, val_loss=154.40982\n",
      "Epoch 24071: train_loss=144.05962, val_loss=154.49420\n",
      "Epoch 24072: train_loss=144.04453, val_loss=154.37804\n",
      "Epoch 24073: train_loss=144.02586, val_loss=154.45036\n",
      "Epoch 24074: train_loss=144.00259, val_loss=154.33374\n",
      "Epoch 24075: train_loss=143.97644, val_loss=154.38939\n",
      "Epoch 24076: train_loss=143.94824, val_loss=154.28210\n",
      "Epoch 24077: train_loss=143.91925, val_loss=154.32167\n",
      "Epoch 24078: train_loss=143.89072, val_loss=154.23193\n",
      "Epoch 24079: train_loss=143.86292, val_loss=154.25676\n",
      "Epoch 24080: train_loss=143.83698, val_loss=154.19075\n",
      "Epoch 24081: train_loss=143.81322, val_loss=154.20282\n",
      "Epoch 24082: train_loss=143.79184, val_loss=154.16037\n",
      "Epoch 24083: train_loss=143.77284, val_loss=154.15739\n",
      "Epoch 24084: train_loss=143.75598, val_loss=154.13493\n",
      "Epoch 24085: train_loss=143.74106, val_loss=154.12035\n",
      "Epoch 24086: train_loss=143.72758, val_loss=154.11578\n",
      "Epoch 24087: train_loss=143.71510, val_loss=154.09253\n",
      "Epoch 24088: train_loss=143.70337, val_loss=154.10016\n",
      "Epoch 24089: train_loss=143.69218, val_loss=154.06590\n",
      "Epoch 24090: train_loss=143.68147, val_loss=154.08215\n",
      "Epoch 24091: train_loss=143.67119, val_loss=154.03848\n",
      "Epoch 24092: train_loss=143.66127, val_loss=154.06500\n",
      "Epoch 24093: train_loss=143.65149, val_loss=154.01534\n",
      "Epoch 24094: train_loss=143.64215, val_loss=154.05148\n",
      "Epoch 24095: train_loss=143.63354, val_loss=153.99434\n",
      "Epoch 24096: train_loss=143.62567, val_loss=154.04219\n",
      "Epoch 24097: train_loss=143.61919, val_loss=153.97890\n",
      "Epoch 24098: train_loss=143.61407, val_loss=154.04228\n",
      "Epoch 24099: train_loss=143.61060, val_loss=153.97099\n",
      "Epoch 24100: train_loss=143.60915, val_loss=154.04903\n",
      "Epoch 24101: train_loss=143.60974, val_loss=153.96507\n",
      "Epoch 24102: train_loss=143.61189, val_loss=154.05818\n",
      "Epoch 24103: train_loss=143.61455, val_loss=153.96300\n",
      "Epoch 24104: train_loss=143.61861, val_loss=154.06973\n",
      "Epoch 24105: train_loss=143.62000, val_loss=153.96120\n",
      "Epoch 24106: train_loss=143.62050, val_loss=154.06943\n",
      "Epoch 24107: train_loss=143.61487, val_loss=153.94360\n",
      "Epoch 24108: train_loss=143.60519, val_loss=154.04068\n",
      "Epoch 24109: train_loss=143.58798, val_loss=153.90341\n",
      "Epoch 24110: train_loss=143.56505, val_loss=153.98087\n",
      "Epoch 24111: train_loss=143.53400, val_loss=153.84506\n",
      "Epoch 24112: train_loss=143.49915, val_loss=153.89876\n",
      "Epoch 24113: train_loss=143.46028, val_loss=153.77974\n",
      "Epoch 24114: train_loss=143.42192, val_loss=153.81088\n",
      "Epoch 24115: train_loss=143.38567, val_loss=153.72108\n",
      "Epoch 24116: train_loss=143.35243, val_loss=153.73186\n",
      "Epoch 24117: train_loss=143.32405, val_loss=153.67992\n",
      "Epoch 24118: train_loss=143.30081, val_loss=153.67343\n",
      "Epoch 24119: train_loss=143.28305, val_loss=153.65799\n",
      "Epoch 24120: train_loss=143.26932, val_loss=153.63779\n",
      "Epoch 24121: train_loss=143.25868, val_loss=153.65022\n",
      "Epoch 24122: train_loss=143.25034, val_loss=153.61426\n",
      "Epoch 24123: train_loss=143.24330, val_loss=153.64482\n",
      "Epoch 24124: train_loss=143.23662, val_loss=153.59520\n",
      "Epoch 24125: train_loss=143.22949, val_loss=153.63588\n",
      "Epoch 24126: train_loss=143.22174, val_loss=153.57578\n",
      "Epoch 24127: train_loss=143.21271, val_loss=153.62154\n",
      "Epoch 24128: train_loss=143.20285, val_loss=153.55473\n",
      "Epoch 24129: train_loss=143.19159, val_loss=153.60074\n",
      "Epoch 24130: train_loss=143.17966, val_loss=153.52835\n",
      "Epoch 24131: train_loss=143.16702, val_loss=153.57321\n",
      "Epoch 24132: train_loss=143.15395, val_loss=153.49918\n",
      "Epoch 24133: train_loss=143.14050, val_loss=153.54478\n",
      "Epoch 24134: train_loss=143.12711, val_loss=153.47202\n",
      "Epoch 24135: train_loss=143.11386, val_loss=153.51894\n",
      "Epoch 24136: train_loss=143.10078, val_loss=153.44615\n",
      "Epoch 24137: train_loss=143.08740, val_loss=153.49324\n",
      "Epoch 24138: train_loss=143.07426, val_loss=153.41994\n",
      "Epoch 24139: train_loss=143.06105, val_loss=153.46721\n",
      "Epoch 24140: train_loss=143.04768, val_loss=153.39314\n",
      "Epoch 24141: train_loss=143.03435, val_loss=153.44028\n",
      "Epoch 24142: train_loss=143.02087, val_loss=153.36676\n",
      "Epoch 24143: train_loss=143.00723, val_loss=153.41277\n",
      "Epoch 24144: train_loss=142.99336, val_loss=153.33846\n",
      "Epoch 24145: train_loss=142.97961, val_loss=153.38326\n",
      "Epoch 24146: train_loss=142.96565, val_loss=153.30931\n",
      "Epoch 24147: train_loss=142.95132, val_loss=153.35318\n",
      "Epoch 24148: train_loss=142.93687, val_loss=153.28093\n",
      "Epoch 24149: train_loss=142.92235, val_loss=153.32278\n",
      "Epoch 24150: train_loss=142.90752, val_loss=153.25215\n",
      "Epoch 24151: train_loss=142.89268, val_loss=153.29224\n",
      "Epoch 24152: train_loss=142.87782, val_loss=153.22423\n",
      "Epoch 24153: train_loss=142.86255, val_loss=153.26233\n",
      "Epoch 24154: train_loss=142.84755, val_loss=153.19760\n",
      "Epoch 24155: train_loss=142.83211, val_loss=153.23100\n",
      "Epoch 24156: train_loss=142.81721, val_loss=153.16859\n",
      "Epoch 24157: train_loss=142.80217, val_loss=153.19882\n",
      "Epoch 24158: train_loss=142.78758, val_loss=153.13866\n",
      "Epoch 24159: train_loss=142.77315, val_loss=153.16823\n",
      "Epoch 24160: train_loss=142.75903, val_loss=153.11095\n",
      "Epoch 24161: train_loss=142.74506, val_loss=153.14084\n",
      "Epoch 24162: train_loss=142.73152, val_loss=153.08543\n",
      "Epoch 24163: train_loss=142.71822, val_loss=153.11613\n",
      "Epoch 24164: train_loss=142.70543, val_loss=153.06044\n",
      "Epoch 24165: train_loss=142.69313, val_loss=153.09435\n",
      "Epoch 24166: train_loss=142.68170, val_loss=153.03743\n",
      "Epoch 24167: train_loss=142.67117, val_loss=153.07910\n",
      "Epoch 24168: train_loss=142.66191, val_loss=153.01836\n",
      "Epoch 24169: train_loss=142.65439, val_loss=153.07228\n",
      "Epoch 24170: train_loss=142.64922, val_loss=153.00349\n",
      "Epoch 24171: train_loss=142.64668, val_loss=153.07689\n",
      "Epoch 24172: train_loss=142.64786, val_loss=152.99908\n",
      "Epoch 24173: train_loss=142.65247, val_loss=153.10065\n",
      "Epoch 24174: train_loss=142.66176, val_loss=153.01381\n",
      "Epoch 24175: train_loss=142.67590, val_loss=153.14772\n",
      "Epoch 24176: train_loss=142.69405, val_loss=153.04642\n",
      "Epoch 24177: train_loss=142.71681, val_loss=153.20660\n",
      "Epoch 24178: train_loss=142.73860, val_loss=153.08054\n",
      "Epoch 24179: train_loss=142.75923, val_loss=153.24580\n",
      "Epoch 24180: train_loss=142.76881, val_loss=153.08469\n",
      "Epoch 24181: train_loss=142.76753, val_loss=153.22205\n",
      "Epoch 24182: train_loss=142.74431, val_loss=153.02615\n",
      "Epoch 24183: train_loss=142.70366, val_loss=153.10876\n",
      "Epoch 24184: train_loss=142.64238, val_loss=152.90886\n",
      "Epoch 24185: train_loss=142.57219, val_loss=152.94217\n",
      "Epoch 24186: train_loss=142.50069, val_loss=152.79333\n",
      "Epoch 24187: train_loss=142.43755, val_loss=152.79965\n",
      "Epoch 24188: train_loss=142.38873, val_loss=152.73738\n",
      "Epoch 24189: train_loss=142.35690, val_loss=152.72667\n",
      "Epoch 24190: train_loss=142.34171, val_loss=152.74507\n",
      "Epoch 24191: train_loss=142.33907, val_loss=152.71045\n",
      "Epoch 24192: train_loss=142.34370, val_loss=152.77443\n",
      "Epoch 24193: train_loss=142.35011, val_loss=152.70854\n",
      "Epoch 24194: train_loss=142.35376, val_loss=152.78441\n",
      "Epoch 24195: train_loss=142.35225, val_loss=152.69449\n",
      "Epoch 24196: train_loss=142.34428, val_loss=152.76236\n",
      "Epoch 24197: train_loss=142.32939, val_loss=152.66124\n",
      "Epoch 24198: train_loss=142.30858, val_loss=152.71031\n",
      "Epoch 24199: train_loss=142.28352, val_loss=152.61565\n",
      "Epoch 24200: train_loss=142.25578, val_loss=152.64453\n",
      "Epoch 24201: train_loss=142.22841, val_loss=152.57332\n",
      "Epoch 24202: train_loss=142.20274, val_loss=152.58295\n",
      "Epoch 24203: train_loss=142.17999, val_loss=152.54376\n",
      "Epoch 24204: train_loss=142.16103, val_loss=152.53737\n",
      "Epoch 24205: train_loss=142.14568, val_loss=152.52766\n",
      "Epoch 24206: train_loss=142.13324, val_loss=152.50577\n",
      "Epoch 24207: train_loss=142.12311, val_loss=152.51886\n",
      "Epoch 24208: train_loss=142.11401, val_loss=152.48288\n",
      "Epoch 24209: train_loss=142.10561, val_loss=152.50853\n",
      "Epoch 24210: train_loss=142.09694, val_loss=152.46010\n",
      "Epoch 24211: train_loss=142.08771, val_loss=152.49132\n",
      "Epoch 24212: train_loss=142.07761, val_loss=152.43541\n",
      "Epoch 24213: train_loss=142.06648, val_loss=152.46950\n",
      "Epoch 24214: train_loss=142.05490, val_loss=152.41017\n",
      "Epoch 24215: train_loss=142.04253, val_loss=152.44440\n",
      "Epoch 24216: train_loss=142.02998, val_loss=152.38409\n",
      "Epoch 24217: train_loss=142.01714, val_loss=152.41792\n",
      "Epoch 24218: train_loss=142.00397, val_loss=152.35754\n",
      "Epoch 24219: train_loss=141.99095, val_loss=152.39169\n",
      "Epoch 24220: train_loss=141.97810, val_loss=152.33138\n",
      "Epoch 24221: train_loss=141.96526, val_loss=152.36598\n",
      "Epoch 24222: train_loss=141.95250, val_loss=152.30582\n",
      "Epoch 24223: train_loss=141.93968, val_loss=152.34200\n",
      "Epoch 24224: train_loss=141.92720, val_loss=152.28159\n",
      "Epoch 24225: train_loss=141.91472, val_loss=152.31775\n",
      "Epoch 24226: train_loss=141.90247, val_loss=152.25500\n",
      "Epoch 24227: train_loss=141.89043, val_loss=152.29230\n",
      "Epoch 24228: train_loss=141.87854, val_loss=152.22945\n",
      "Epoch 24229: train_loss=141.86668, val_loss=152.27052\n",
      "Epoch 24230: train_loss=141.85515, val_loss=152.20705\n",
      "Epoch 24231: train_loss=141.84366, val_loss=152.25111\n",
      "Epoch 24232: train_loss=141.83276, val_loss=152.18456\n",
      "Epoch 24233: train_loss=141.82211, val_loss=152.23172\n",
      "Epoch 24234: train_loss=141.81233, val_loss=152.16148\n",
      "Epoch 24235: train_loss=141.80298, val_loss=152.21638\n",
      "Epoch 24236: train_loss=141.79489, val_loss=152.14333\n",
      "Epoch 24237: train_loss=141.78720, val_loss=152.20769\n",
      "Epoch 24238: train_loss=141.78159, val_loss=152.12831\n",
      "Epoch 24239: train_loss=141.77672, val_loss=152.20285\n",
      "Epoch 24240: train_loss=141.77344, val_loss=152.11595\n",
      "Epoch 24241: train_loss=141.77052, val_loss=152.20305\n",
      "Epoch 24242: train_loss=141.76860, val_loss=152.10855\n",
      "Epoch 24243: train_loss=141.76628, val_loss=152.20441\n",
      "Epoch 24244: train_loss=141.76352, val_loss=152.09987\n",
      "Epoch 24245: train_loss=141.75919, val_loss=152.19664\n",
      "Epoch 24246: train_loss=141.75211, val_loss=152.07953\n",
      "Epoch 24247: train_loss=141.74136, val_loss=152.16884\n",
      "Epoch 24248: train_loss=141.72690, val_loss=152.04469\n",
      "Epoch 24249: train_loss=141.70799, val_loss=152.12181\n",
      "Epoch 24250: train_loss=141.68465, val_loss=151.99895\n",
      "Epoch 24251: train_loss=141.65669, val_loss=152.05739\n",
      "Epoch 24252: train_loss=141.62625, val_loss=151.94640\n",
      "Epoch 24253: train_loss=141.59425, val_loss=151.98352\n",
      "Epoch 24254: train_loss=141.56268, val_loss=151.89481\n",
      "Epoch 24255: train_loss=141.53288, val_loss=151.91202\n",
      "Epoch 24256: train_loss=141.50581, val_loss=151.85400\n",
      "Epoch 24257: train_loss=141.48286, val_loss=151.85547\n",
      "Epoch 24258: train_loss=141.46371, val_loss=151.82903\n",
      "Epoch 24259: train_loss=141.44797, val_loss=151.81673\n",
      "Epoch 24260: train_loss=141.43506, val_loss=151.81624\n",
      "Epoch 24261: train_loss=141.42429, val_loss=151.78995\n",
      "Epoch 24262: train_loss=141.41492, val_loss=151.80635\n",
      "Epoch 24263: train_loss=141.40646, val_loss=151.76649\n",
      "Epoch 24264: train_loss=141.39822, val_loss=151.79459\n",
      "Epoch 24265: train_loss=141.38995, val_loss=151.74524\n",
      "Epoch 24266: train_loss=141.38220, val_loss=151.78320\n",
      "Epoch 24267: train_loss=141.37370, val_loss=151.72554\n",
      "Epoch 24268: train_loss=141.36542, val_loss=151.76950\n",
      "Epoch 24269: train_loss=141.35643, val_loss=151.70482\n",
      "Epoch 24270: train_loss=141.34779, val_loss=151.75461\n",
      "Epoch 24271: train_loss=141.33896, val_loss=151.68465\n",
      "Epoch 24272: train_loss=141.33028, val_loss=151.73978\n",
      "Epoch 24273: train_loss=141.32111, val_loss=151.66533\n",
      "Epoch 24274: train_loss=141.31169, val_loss=151.72374\n",
      "Epoch 24275: train_loss=141.30190, val_loss=151.64433\n",
      "Epoch 24276: train_loss=141.29195, val_loss=151.70493\n",
      "Epoch 24277: train_loss=141.28152, val_loss=151.62268\n",
      "Epoch 24278: train_loss=141.27066, val_loss=151.68414\n",
      "Epoch 24279: train_loss=141.25905, val_loss=151.59911\n",
      "Epoch 24280: train_loss=141.24722, val_loss=151.66000\n",
      "Epoch 24281: train_loss=141.23474, val_loss=151.57335\n",
      "Epoch 24282: train_loss=141.22171, val_loss=151.63350\n",
      "Epoch 24283: train_loss=141.20822, val_loss=151.54646\n",
      "Epoch 24284: train_loss=141.19423, val_loss=151.60359\n",
      "Epoch 24285: train_loss=141.17960, val_loss=151.51669\n",
      "Epoch 24286: train_loss=141.16435, val_loss=151.56920\n",
      "Epoch 24287: train_loss=141.14861, val_loss=151.48470\n",
      "Epoch 24288: train_loss=141.13248, val_loss=151.53345\n",
      "Epoch 24289: train_loss=141.11588, val_loss=151.45378\n",
      "Epoch 24290: train_loss=141.09921, val_loss=151.49698\n",
      "Epoch 24291: train_loss=141.08217, val_loss=151.42201\n",
      "Epoch 24292: train_loss=141.06560, val_loss=151.45959\n",
      "Epoch 24293: train_loss=141.04865, val_loss=151.39018\n",
      "Epoch 24294: train_loss=141.03233, val_loss=151.42212\n",
      "Epoch 24295: train_loss=141.01566, val_loss=151.35966\n",
      "Epoch 24296: train_loss=140.99985, val_loss=151.38754\n",
      "Epoch 24297: train_loss=140.98378, val_loss=151.33180\n",
      "Epoch 24298: train_loss=140.96860, val_loss=151.35516\n",
      "Epoch 24299: train_loss=140.95322, val_loss=151.30429\n",
      "Epoch 24300: train_loss=140.93872, val_loss=151.32372\n",
      "Epoch 24301: train_loss=140.92424, val_loss=151.27631\n",
      "Epoch 24302: train_loss=140.91042, val_loss=151.29395\n",
      "Epoch 24303: train_loss=140.89674, val_loss=151.24968\n",
      "Epoch 24304: train_loss=140.88336, val_loss=151.26804\n",
      "Epoch 24305: train_loss=140.87029, val_loss=151.22498\n",
      "Epoch 24306: train_loss=140.85771, val_loss=151.24397\n",
      "Epoch 24307: train_loss=140.84552, val_loss=151.19925\n",
      "Epoch 24308: train_loss=140.83395, val_loss=151.22174\n",
      "Epoch 24309: train_loss=140.82291, val_loss=151.17468\n",
      "Epoch 24310: train_loss=140.81306, val_loss=151.20709\n",
      "Epoch 24311: train_loss=140.80415, val_loss=151.15584\n",
      "Epoch 24312: train_loss=140.79755, val_loss=151.20248\n",
      "Epoch 24313: train_loss=140.79323, val_loss=151.14267\n",
      "Epoch 24314: train_loss=140.79218, val_loss=151.21130\n",
      "Epoch 24315: train_loss=140.79442, val_loss=151.14301\n",
      "Epoch 24316: train_loss=140.80206, val_loss=151.24463\n",
      "Epoch 24317: train_loss=140.81496, val_loss=151.16705\n",
      "Epoch 24318: train_loss=140.83548, val_loss=151.30743\n",
      "Epoch 24319: train_loss=140.86212, val_loss=151.21326\n",
      "Epoch 24320: train_loss=140.89363, val_loss=151.38338\n",
      "Epoch 24321: train_loss=140.92444, val_loss=151.26003\n",
      "Epoch 24322: train_loss=140.95047, val_loss=151.42957\n",
      "Epoch 24323: train_loss=140.96132, val_loss=151.26123\n",
      "Epoch 24324: train_loss=140.95438, val_loss=151.38539\n",
      "Epoch 24325: train_loss=140.91960, val_loss=151.17665\n",
      "Epoch 24326: train_loss=140.86244, val_loss=151.23463\n",
      "Epoch 24327: train_loss=140.78600, val_loss=151.03484\n",
      "Epoch 24328: train_loss=140.70433, val_loss=151.04924\n",
      "Epoch 24329: train_loss=140.62961, val_loss=150.92441\n",
      "Epoch 24330: train_loss=140.57079, val_loss=150.92097\n",
      "Epoch 24331: train_loss=140.53146, val_loss=150.89235\n",
      "Epoch 24332: train_loss=140.51205, val_loss=150.87381\n",
      "Epoch 24333: train_loss=140.50826, val_loss=150.91525\n",
      "Epoch 24334: train_loss=140.51393, val_loss=150.87030\n",
      "Epoch 24335: train_loss=140.52242, val_loss=150.94218\n",
      "Epoch 24336: train_loss=140.52815, val_loss=150.86742\n",
      "Epoch 24337: train_loss=140.52814, val_loss=150.93895\n",
      "Epoch 24338: train_loss=140.51959, val_loss=150.84471\n",
      "Epoch 24339: train_loss=140.50340, val_loss=150.89758\n",
      "Epoch 24340: train_loss=140.47983, val_loss=150.80107\n",
      "Epoch 24341: train_loss=140.45215, val_loss=150.82976\n",
      "Epoch 24342: train_loss=140.42253, val_loss=150.75281\n",
      "Epoch 24343: train_loss=140.39430, val_loss=150.76123\n",
      "Epoch 24344: train_loss=140.36906, val_loss=150.72018\n",
      "Epoch 24345: train_loss=140.34880, val_loss=150.71332\n",
      "Epoch 24346: train_loss=140.33322, val_loss=150.70540\n",
      "Epoch 24347: train_loss=140.32161, val_loss=150.68217\n",
      "Epoch 24348: train_loss=140.31284, val_loss=150.69931\n",
      "Epoch 24349: train_loss=140.30545, val_loss=150.66174\n",
      "Epoch 24350: train_loss=140.29851, val_loss=150.69208\n",
      "Epoch 24351: train_loss=140.29080, val_loss=150.64238\n",
      "Epoch 24352: train_loss=140.28218, val_loss=150.67606\n",
      "Epoch 24353: train_loss=140.27151, val_loss=150.61810\n",
      "Epoch 24354: train_loss=140.25966, val_loss=150.65115\n",
      "Epoch 24355: train_loss=140.24629, val_loss=150.59189\n",
      "Epoch 24356: train_loss=140.23199, val_loss=150.62032\n",
      "Epoch 24357: train_loss=140.21655, val_loss=150.56403\n",
      "Epoch 24358: train_loss=140.20119, val_loss=150.58594\n",
      "Epoch 24359: train_loss=140.18513, val_loss=150.53516\n",
      "Epoch 24360: train_loss=140.16928, val_loss=150.55089\n",
      "Epoch 24361: train_loss=140.15327, val_loss=150.50778\n",
      "Epoch 24362: train_loss=140.13800, val_loss=150.51721\n",
      "Epoch 24363: train_loss=140.12289, val_loss=150.48068\n",
      "Epoch 24364: train_loss=140.10822, val_loss=150.48447\n",
      "Epoch 24365: train_loss=140.09381, val_loss=150.45560\n",
      "Epoch 24366: train_loss=140.07997, val_loss=150.45459\n",
      "Epoch 24367: train_loss=140.06644, val_loss=150.43181\n",
      "Epoch 24368: train_loss=140.05313, val_loss=150.42618\n",
      "Epoch 24369: train_loss=140.04016, val_loss=150.40752\n",
      "Epoch 24370: train_loss=140.02727, val_loss=150.39944\n",
      "Epoch 24371: train_loss=140.01448, val_loss=150.38483\n",
      "Epoch 24372: train_loss=140.00183, val_loss=150.37495\n",
      "Epoch 24373: train_loss=139.98912, val_loss=150.36032\n",
      "Epoch 24374: train_loss=139.97647, val_loss=150.34924\n",
      "Epoch 24375: train_loss=139.96390, val_loss=150.33646\n",
      "Epoch 24376: train_loss=139.95126, val_loss=150.32611\n",
      "Epoch 24377: train_loss=139.93872, val_loss=150.31371\n",
      "Epoch 24378: train_loss=139.92615, val_loss=150.30272\n",
      "Epoch 24379: train_loss=139.91362, val_loss=150.28796\n",
      "Epoch 24380: train_loss=139.90097, val_loss=150.27692\n",
      "Epoch 24381: train_loss=139.88849, val_loss=150.26273\n",
      "Epoch 24382: train_loss=139.87604, val_loss=150.25504\n",
      "Epoch 24383: train_loss=139.86365, val_loss=150.23863\n",
      "Epoch 24384: train_loss=139.85147, val_loss=150.23553\n",
      "Epoch 24385: train_loss=139.83971, val_loss=150.21255\n",
      "Epoch 24386: train_loss=139.82857, val_loss=150.22015\n",
      "Epoch 24387: train_loss=139.81883, val_loss=150.18959\n",
      "Epoch 24388: train_loss=139.81084, val_loss=150.21532\n",
      "Epoch 24389: train_loss=139.80569, val_loss=150.17526\n",
      "Epoch 24390: train_loss=139.80457, val_loss=150.23145\n",
      "Epoch 24391: train_loss=139.80875, val_loss=150.18155\n",
      "Epoch 24392: train_loss=139.82097, val_loss=150.28288\n",
      "Epoch 24393: train_loss=139.84261, val_loss=150.22385\n",
      "Epoch 24394: train_loss=139.87682, val_loss=150.38365\n",
      "Epoch 24395: train_loss=139.92253, val_loss=150.31155\n",
      "Epoch 24396: train_loss=139.98026, val_loss=150.52676\n",
      "Epoch 24397: train_loss=140.04350, val_loss=150.42439\n",
      "Epoch 24398: train_loss=140.10640, val_loss=150.64948\n",
      "Epoch 24399: train_loss=140.14845, val_loss=150.47469\n",
      "Epoch 24400: train_loss=140.16110, val_loss=150.62416\n",
      "Epoch 24401: train_loss=140.12184, val_loss=150.35899\n",
      "Epoch 24402: train_loss=140.03629, val_loss=150.38835\n",
      "Epoch 24403: train_loss=139.90948, val_loss=150.12354\n",
      "Epoch 24404: train_loss=139.77536, val_loss=150.10017\n",
      "Epoch 24405: train_loss=139.66243, val_loss=149.97568\n",
      "Epoch 24406: train_loss=139.59200, val_loss=149.96140\n",
      "Epoch 24407: train_loss=139.56537, val_loss=149.99141\n",
      "Epoch 24408: train_loss=139.57365, val_loss=149.96779\n",
      "Epoch 24409: train_loss=139.60172, val_loss=150.07542\n",
      "Epoch 24410: train_loss=139.63303, val_loss=150.00694\n",
      "Epoch 24411: train_loss=139.65489, val_loss=150.10977\n",
      "Epoch 24412: train_loss=139.65503, val_loss=149.98679\n",
      "Epoch 24413: train_loss=139.63206, val_loss=150.03912\n",
      "Epoch 24414: train_loss=139.58977, val_loss=149.91035\n",
      "Epoch 24415: train_loss=139.54016, val_loss=149.92386\n",
      "Epoch 24416: train_loss=139.49184, val_loss=149.84528\n",
      "Epoch 24417: train_loss=139.45377, val_loss=149.83916\n",
      "Epoch 24418: train_loss=139.43002, val_loss=149.83295\n",
      "Epoch 24419: train_loss=139.41975, val_loss=149.81068\n",
      "Epoch 24420: train_loss=139.41878, val_loss=149.85257\n",
      "Epoch 24421: train_loss=139.42139, val_loss=149.80476\n",
      "Epoch 24422: train_loss=139.42180, val_loss=149.85579\n",
      "Epoch 24423: train_loss=139.41661, val_loss=149.78558\n",
      "Epoch 24424: train_loss=139.40459, val_loss=149.82449\n",
      "Epoch 24425: train_loss=139.38625, val_loss=149.75230\n",
      "Epoch 24426: train_loss=139.36363, val_loss=149.77339\n",
      "Epoch 24427: train_loss=139.33981, val_loss=149.71910\n",
      "Epoch 24428: train_loss=139.31712, val_loss=149.72179\n",
      "Epoch 24429: train_loss=139.29758, val_loss=149.69417\n",
      "Epoch 24430: train_loss=139.28166, val_loss=149.68135\n",
      "Epoch 24431: train_loss=139.26917, val_loss=149.68082\n",
      "Epoch 24432: train_loss=139.25920, val_loss=149.65669\n",
      "Epoch 24433: train_loss=139.25069, val_loss=149.67477\n",
      "Epoch 24434: train_loss=139.24242, val_loss=149.63991\n",
      "Epoch 24435: train_loss=139.23375, val_loss=149.66243\n",
      "Epoch 24436: train_loss=139.22377, val_loss=149.61755\n",
      "Epoch 24437: train_loss=139.21245, val_loss=149.63826\n",
      "Epoch 24438: train_loss=139.19998, val_loss=149.59169\n",
      "Epoch 24439: train_loss=139.18636, val_loss=149.60902\n",
      "Epoch 24440: train_loss=139.17192, val_loss=149.56717\n",
      "Epoch 24441: train_loss=139.15710, val_loss=149.57793\n",
      "Epoch 24442: train_loss=139.14223, val_loss=149.54260\n",
      "Epoch 24443: train_loss=139.12746, val_loss=149.54515\n",
      "Epoch 24444: train_loss=139.11325, val_loss=149.51884\n",
      "Epoch 24445: train_loss=139.09953, val_loss=149.51480\n",
      "Epoch 24446: train_loss=139.08638, val_loss=149.49747\n",
      "Epoch 24447: train_loss=139.07373, val_loss=149.48756\n",
      "Epoch 24448: train_loss=139.06131, val_loss=149.47662\n",
      "Epoch 24449: train_loss=139.04918, val_loss=149.46277\n",
      "Epoch 24450: train_loss=139.03726, val_loss=149.45789\n",
      "Epoch 24451: train_loss=139.02554, val_loss=149.43935\n",
      "Epoch 24452: train_loss=139.01384, val_loss=149.43776\n",
      "Epoch 24453: train_loss=139.00243, val_loss=149.41405\n",
      "Epoch 24454: train_loss=138.99110, val_loss=149.41650\n",
      "Epoch 24455: train_loss=138.98001, val_loss=149.38873\n",
      "Epoch 24456: train_loss=138.96913, val_loss=149.39870\n",
      "Epoch 24457: train_loss=138.95879, val_loss=149.36838\n",
      "Epoch 24458: train_loss=138.94890, val_loss=149.38670\n",
      "Epoch 24459: train_loss=138.93971, val_loss=149.34874\n",
      "Epoch 24460: train_loss=138.93126, val_loss=149.37518\n",
      "Epoch 24461: train_loss=138.92383, val_loss=149.32967\n",
      "Epoch 24462: train_loss=138.91733, val_loss=149.36906\n",
      "Epoch 24463: train_loss=138.91187, val_loss=149.31689\n",
      "Epoch 24464: train_loss=138.90776, val_loss=149.36963\n",
      "Epoch 24465: train_loss=138.90489, val_loss=149.30801\n",
      "Epoch 24466: train_loss=138.90349, val_loss=149.37376\n",
      "Epoch 24467: train_loss=138.90263, val_loss=149.30258\n",
      "Epoch 24468: train_loss=138.90286, val_loss=149.37970\n",
      "Epoch 24469: train_loss=138.90211, val_loss=149.29750\n",
      "Epoch 24470: train_loss=138.90160, val_loss=149.38145\n",
      "Epoch 24471: train_loss=138.89909, val_loss=149.28755\n",
      "Epoch 24472: train_loss=138.89497, val_loss=149.37164\n",
      "Epoch 24473: train_loss=138.88704, val_loss=149.26744\n",
      "Epoch 24474: train_loss=138.87556, val_loss=149.34409\n",
      "Epoch 24475: train_loss=138.85934, val_loss=149.23451\n",
      "Epoch 24476: train_loss=138.83922, val_loss=149.29688\n",
      "Epoch 24477: train_loss=138.81523, val_loss=149.18959\n",
      "Epoch 24478: train_loss=138.78888, val_loss=149.23544\n",
      "Epoch 24479: train_loss=138.76080, val_loss=149.14128\n",
      "Epoch 24480: train_loss=138.73317, val_loss=149.17232\n",
      "Epoch 24481: train_loss=138.70564, val_loss=149.09747\n",
      "Epoch 24482: train_loss=138.68040, val_loss=149.11487\n",
      "Epoch 24483: train_loss=138.65726, val_loss=149.06236\n",
      "Epoch 24484: train_loss=138.63669, val_loss=149.06720\n",
      "Epoch 24485: train_loss=138.61858, val_loss=149.03827\n",
      "Epoch 24486: train_loss=138.60283, val_loss=149.03235\n",
      "Epoch 24487: train_loss=138.58942, val_loss=149.02177\n",
      "Epoch 24488: train_loss=138.57748, val_loss=149.00414\n",
      "Epoch 24489: train_loss=138.56673, val_loss=149.00676\n",
      "Epoch 24490: train_loss=138.55670, val_loss=148.98067\n",
      "Epoch 24491: train_loss=138.54726, val_loss=148.99496\n",
      "Epoch 24492: train_loss=138.53828, val_loss=148.96147\n",
      "Epoch 24493: train_loss=138.52962, val_loss=148.98409\n",
      "Epoch 24494: train_loss=138.52119, val_loss=148.94168\n",
      "Epoch 24495: train_loss=138.51271, val_loss=148.96994\n",
      "Epoch 24496: train_loss=138.50436, val_loss=148.92113\n",
      "Epoch 24497: train_loss=138.49641, val_loss=148.95723\n",
      "Epoch 24498: train_loss=138.48859, val_loss=148.90416\n",
      "Epoch 24499: train_loss=138.48143, val_loss=148.94923\n",
      "Epoch 24500: train_loss=138.47513, val_loss=148.88998\n",
      "Epoch 24501: train_loss=138.47008, val_loss=148.94415\n",
      "Epoch 24502: train_loss=138.46555, val_loss=148.87770\n",
      "Epoch 24503: train_loss=138.46233, val_loss=148.94298\n",
      "Epoch 24504: train_loss=138.45934, val_loss=148.87003\n",
      "Epoch 24505: train_loss=138.45747, val_loss=148.94615\n",
      "Epoch 24506: train_loss=138.45587, val_loss=148.86517\n",
      "Epoch 24507: train_loss=138.45573, val_loss=148.95079\n",
      "Epoch 24508: train_loss=138.45566, val_loss=148.86092\n",
      "Epoch 24509: train_loss=138.45627, val_loss=148.95345\n",
      "Epoch 24510: train_loss=138.45412, val_loss=148.85312\n",
      "Epoch 24511: train_loss=138.45082, val_loss=148.94550\n",
      "Epoch 24512: train_loss=138.44234, val_loss=148.83450\n",
      "Epoch 24513: train_loss=138.43065, val_loss=148.91556\n",
      "Epoch 24514: train_loss=138.41243, val_loss=148.79723\n",
      "Epoch 24515: train_loss=138.39034, val_loss=148.86075\n",
      "Epoch 24516: train_loss=138.36247, val_loss=148.74525\n",
      "Epoch 24517: train_loss=138.33264, val_loss=148.78885\n",
      "Epoch 24518: train_loss=138.30037, val_loss=148.68852\n",
      "Epoch 24519: train_loss=138.26875, val_loss=148.71519\n",
      "Epoch 24520: train_loss=138.23805, val_loss=148.64156\n",
      "Epoch 24521: train_loss=138.21127, val_loss=148.65364\n",
      "Epoch 24522: train_loss=138.18726, val_loss=148.60757\n",
      "Epoch 24523: train_loss=138.16701, val_loss=148.60579\n",
      "Epoch 24524: train_loss=138.15039, val_loss=148.58763\n",
      "Epoch 24525: train_loss=138.13715, val_loss=148.57397\n",
      "Epoch 24526: train_loss=138.12634, val_loss=148.57735\n",
      "Epoch 24527: train_loss=138.11723, val_loss=148.55135\n",
      "Epoch 24528: train_loss=138.10919, val_loss=148.56810\n",
      "Epoch 24529: train_loss=138.10152, val_loss=148.53140\n",
      "Epoch 24530: train_loss=138.09416, val_loss=148.55856\n",
      "Epoch 24531: train_loss=138.08670, val_loss=148.51373\n",
      "Epoch 24532: train_loss=138.07913, val_loss=148.54691\n",
      "Epoch 24533: train_loss=138.07115, val_loss=148.49477\n",
      "Epoch 24534: train_loss=138.06313, val_loss=148.53146\n",
      "Epoch 24535: train_loss=138.05441, val_loss=148.47377\n",
      "Epoch 24536: train_loss=138.04564, val_loss=148.51433\n",
      "Epoch 24537: train_loss=138.03598, val_loss=148.45390\n",
      "Epoch 24538: train_loss=138.02669, val_loss=148.49699\n",
      "Epoch 24539: train_loss=138.01668, val_loss=148.43414\n",
      "Epoch 24540: train_loss=138.00737, val_loss=148.47902\n",
      "Epoch 24541: train_loss=137.99718, val_loss=148.41283\n",
      "Epoch 24542: train_loss=137.98758, val_loss=148.45940\n",
      "Epoch 24543: train_loss=137.97728, val_loss=148.39156\n",
      "Epoch 24544: train_loss=137.96738, val_loss=148.44000\n",
      "Epoch 24545: train_loss=137.95662, val_loss=148.37082\n",
      "Epoch 24546: train_loss=137.94650, val_loss=148.42067\n",
      "Epoch 24547: train_loss=137.93597, val_loss=148.34952\n",
      "Epoch 24548: train_loss=137.92618, val_loss=148.40079\n",
      "Epoch 24549: train_loss=137.91594, val_loss=148.32858\n",
      "Epoch 24550: train_loss=137.90671, val_loss=148.38344\n",
      "Epoch 24551: train_loss=137.89696, val_loss=148.31027\n",
      "Epoch 24552: train_loss=137.88809, val_loss=148.36812\n",
      "Epoch 24553: train_loss=137.87869, val_loss=148.29216\n",
      "Epoch 24554: train_loss=137.86987, val_loss=148.35097\n",
      "Epoch 24555: train_loss=137.86018, val_loss=148.27077\n",
      "Epoch 24556: train_loss=137.85092, val_loss=148.33061\n",
      "Epoch 24557: train_loss=137.84079, val_loss=148.24823\n",
      "Epoch 24558: train_loss=137.83089, val_loss=148.30946\n",
      "Epoch 24559: train_loss=137.81987, val_loss=148.22630\n",
      "Epoch 24560: train_loss=137.80849, val_loss=148.28542\n",
      "Epoch 24561: train_loss=137.79555, val_loss=148.20020\n",
      "Epoch 24562: train_loss=137.78192, val_loss=148.25410\n",
      "Epoch 24563: train_loss=137.76657, val_loss=148.16945\n",
      "Epoch 24564: train_loss=137.75044, val_loss=148.21786\n",
      "Epoch 24565: train_loss=137.73296, val_loss=148.13829\n",
      "Epoch 24566: train_loss=137.71527, val_loss=148.17918\n",
      "Epoch 24567: train_loss=137.69659, val_loss=148.10521\n",
      "Epoch 24568: train_loss=137.67778, val_loss=148.13570\n",
      "Epoch 24569: train_loss=137.65836, val_loss=148.07089\n",
      "Epoch 24570: train_loss=137.63982, val_loss=148.09145\n",
      "Epoch 24571: train_loss=137.62114, val_loss=148.03958\n",
      "Epoch 24572: train_loss=137.60352, val_loss=148.05121\n",
      "Epoch 24573: train_loss=137.58667, val_loss=148.01430\n",
      "Epoch 24574: train_loss=137.57120, val_loss=148.01666\n",
      "Epoch 24575: train_loss=137.55666, val_loss=147.99211\n",
      "Epoch 24576: train_loss=137.54321, val_loss=147.98590\n",
      "Epoch 24577: train_loss=137.53065, val_loss=147.97198\n",
      "Epoch 24578: train_loss=137.51886, val_loss=147.95920\n",
      "Epoch 24579: train_loss=137.50740, val_loss=147.95508\n",
      "Epoch 24580: train_loss=137.49649, val_loss=147.93570\n",
      "Epoch 24581: train_loss=137.48592, val_loss=147.93733\n",
      "Epoch 24582: train_loss=137.47543, val_loss=147.91170\n",
      "Epoch 24583: train_loss=137.46536, val_loss=147.92033\n",
      "Epoch 24584: train_loss=137.45564, val_loss=147.88960\n",
      "Epoch 24585: train_loss=137.44661, val_loss=147.90770\n",
      "Epoch 24586: train_loss=137.43806, val_loss=147.87148\n",
      "Epoch 24587: train_loss=137.43063, val_loss=147.89999\n",
      "Epoch 24588: train_loss=137.42450, val_loss=147.85571\n",
      "Epoch 24589: train_loss=137.42111, val_loss=147.90218\n",
      "Epoch 24590: train_loss=137.42055, val_loss=147.85033\n",
      "Epoch 24591: train_loss=137.42397, val_loss=147.92279\n",
      "Epoch 24592: train_loss=137.43175, val_loss=147.86407\n",
      "Epoch 24593: train_loss=137.44650, val_loss=147.97195\n",
      "Epoch 24594: train_loss=137.46710, val_loss=147.90305\n",
      "Epoch 24595: train_loss=137.49640, val_loss=148.05063\n",
      "Epoch 24596: train_loss=137.53133, val_loss=147.96567\n",
      "Epoch 24597: train_loss=137.57188, val_loss=148.14105\n",
      "Epoch 24598: train_loss=137.60779, val_loss=148.02168\n",
      "Epoch 24599: train_loss=137.63605, val_loss=148.18246\n",
      "Epoch 24600: train_loss=137.64172, val_loss=148.00723\n",
      "Epoch 24601: train_loss=137.62268, val_loss=148.10455\n",
      "Epoch 24602: train_loss=137.57033, val_loss=147.88884\n",
      "Epoch 24603: train_loss=137.49464, val_loss=147.91574\n",
      "Epoch 24604: train_loss=137.40329, val_loss=147.72920\n",
      "Epoch 24605: train_loss=137.31529, val_loss=147.72310\n",
      "Epoch 24606: train_loss=137.24323, val_loss=147.63272\n",
      "Epoch 24607: train_loss=137.19571, val_loss=147.62271\n",
      "Epoch 24608: train_loss=137.17313, val_loss=147.63342\n",
      "Epoch 24609: train_loss=137.17105, val_loss=147.61250\n",
      "Epoch 24610: train_loss=137.18372, val_loss=147.68631\n",
      "Epoch 24611: train_loss=137.20161, val_loss=147.63417\n",
      "Epoch 24612: train_loss=137.21814, val_loss=147.72139\n",
      "Epoch 24613: train_loss=137.22469, val_loss=147.63330\n",
      "Epoch 24614: train_loss=137.21985, val_loss=147.69882\n",
      "Epoch 24615: train_loss=137.20045, val_loss=147.58989\n",
      "Epoch 24616: train_loss=137.17148, val_loss=147.62334\n",
      "Epoch 24617: train_loss=137.13559, val_loss=147.52888\n",
      "Epoch 24618: train_loss=137.10040, val_loss=147.54118\n",
      "Epoch 24619: train_loss=137.06836, val_loss=147.48846\n",
      "Epoch 24620: train_loss=137.04366, val_loss=147.48595\n",
      "Epoch 24621: train_loss=137.02574, val_loss=147.47479\n",
      "Epoch 24622: train_loss=137.01439, val_loss=147.45515\n",
      "Epoch 24623: train_loss=137.00784, val_loss=147.47557\n",
      "Epoch 24624: train_loss=137.00401, val_loss=147.44072\n",
      "Epoch 24625: train_loss=137.00162, val_loss=147.47990\n",
      "Epoch 24626: train_loss=136.99837, val_loss=147.42892\n",
      "Epoch 24627: train_loss=136.99327, val_loss=147.47075\n",
      "Epoch 24628: train_loss=136.98509, val_loss=147.40816\n",
      "Epoch 24629: train_loss=136.97392, val_loss=147.44398\n",
      "Epoch 24630: train_loss=136.95985, val_loss=147.38072\n",
      "Epoch 24631: train_loss=136.94400, val_loss=147.40755\n",
      "Epoch 24632: train_loss=136.92676, val_loss=147.35138\n",
      "Epoch 24633: train_loss=136.90962, val_loss=147.36861\n",
      "Epoch 24634: train_loss=136.89253, val_loss=147.32315\n",
      "Epoch 24635: train_loss=136.87642, val_loss=147.33141\n",
      "Epoch 24636: train_loss=136.86107, val_loss=147.29974\n",
      "Epoch 24637: train_loss=136.84694, val_loss=147.29935\n",
      "Epoch 24638: train_loss=136.83377, val_loss=147.27705\n",
      "Epoch 24639: train_loss=136.82141, val_loss=147.26880\n",
      "Epoch 24640: train_loss=136.80943, val_loss=147.25446\n",
      "Epoch 24641: train_loss=136.79790, val_loss=147.24307\n",
      "Epoch 24642: train_loss=136.78651, val_loss=147.23528\n",
      "Epoch 24643: train_loss=136.77525, val_loss=147.21988\n",
      "Epoch 24644: train_loss=136.76425, val_loss=147.21704\n",
      "Epoch 24645: train_loss=136.75342, val_loss=147.19667\n",
      "Epoch 24646: train_loss=136.74286, val_loss=147.19893\n",
      "Epoch 24647: train_loss=136.73271, val_loss=147.17207\n",
      "Epoch 24648: train_loss=136.72314, val_loss=147.18269\n",
      "Epoch 24649: train_loss=136.71417, val_loss=147.15005\n",
      "Epoch 24650: train_loss=136.70624, val_loss=147.17282\n",
      "Epoch 24651: train_loss=136.69933, val_loss=147.13318\n",
      "Epoch 24652: train_loss=136.69379, val_loss=147.16904\n",
      "Epoch 24653: train_loss=136.68974, val_loss=147.11996\n",
      "Epoch 24654: train_loss=136.68726, val_loss=147.17136\n",
      "Epoch 24655: train_loss=136.68640, val_loss=147.11229\n",
      "Epoch 24656: train_loss=136.68658, val_loss=147.17970\n",
      "Epoch 24657: train_loss=136.68771, val_loss=147.11055\n",
      "Epoch 24658: train_loss=136.68881, val_loss=147.18974\n",
      "Epoch 24659: train_loss=136.68979, val_loss=147.10863\n",
      "Epoch 24660: train_loss=136.68941, val_loss=147.19147\n",
      "Epoch 24661: train_loss=136.68709, val_loss=147.09625\n",
      "Epoch 24662: train_loss=136.68114, val_loss=147.17606\n",
      "Epoch 24663: train_loss=136.67166, val_loss=147.07224\n",
      "Epoch 24664: train_loss=136.65756, val_loss=147.14224\n",
      "Epoch 24665: train_loss=136.63982, val_loss=147.03574\n",
      "Epoch 24666: train_loss=136.61827, val_loss=147.09131\n",
      "Epoch 24667: train_loss=136.59431, val_loss=146.99031\n",
      "Epoch 24668: train_loss=136.56804, val_loss=147.03111\n",
      "Epoch 24669: train_loss=136.54207, val_loss=146.94588\n",
      "Epoch 24670: train_loss=136.51628, val_loss=146.97289\n",
      "Epoch 24671: train_loss=136.49208, val_loss=146.90727\n",
      "Epoch 24672: train_loss=136.47014, val_loss=146.92226\n",
      "Epoch 24673: train_loss=136.45070, val_loss=146.87555\n",
      "Epoch 24674: train_loss=136.43350, val_loss=146.88196\n",
      "Epoch 24675: train_loss=136.41826, val_loss=146.85231\n",
      "Epoch 24676: train_loss=136.40451, val_loss=146.85303\n",
      "Epoch 24677: train_loss=136.39175, val_loss=146.83340\n",
      "Epoch 24678: train_loss=136.37975, val_loss=146.82693\n",
      "Epoch 24679: train_loss=136.36797, val_loss=146.81364\n",
      "Epoch 24680: train_loss=136.35661, val_loss=146.80190\n",
      "Epoch 24681: train_loss=136.34529, val_loss=146.79347\n",
      "Epoch 24682: train_loss=136.33427, val_loss=146.77791\n",
      "Epoch 24683: train_loss=136.32350, val_loss=146.77359\n",
      "Epoch 24684: train_loss=136.31274, val_loss=146.75406\n",
      "Epoch 24685: train_loss=136.30238, val_loss=146.75687\n",
      "Epoch 24686: train_loss=136.29228, val_loss=146.73277\n",
      "Epoch 24687: train_loss=136.28284, val_loss=146.74396\n",
      "Epoch 24688: train_loss=136.27419, val_loss=146.71272\n",
      "Epoch 24689: train_loss=136.26701, val_loss=146.73698\n",
      "Epoch 24690: train_loss=136.26155, val_loss=146.69701\n",
      "Epoch 24691: train_loss=136.25809, val_loss=146.73991\n",
      "Epoch 24692: train_loss=136.25723, val_loss=146.69028\n",
      "Epoch 24693: train_loss=136.25928, val_loss=146.75714\n",
      "Epoch 24694: train_loss=136.26506, val_loss=146.69675\n",
      "Epoch 24695: train_loss=136.27415, val_loss=146.78963\n",
      "Epoch 24696: train_loss=136.28633, val_loss=146.71564\n",
      "Epoch 24697: train_loss=136.30116, val_loss=146.83168\n",
      "Epoch 24698: train_loss=136.31708, val_loss=146.74118\n",
      "Epoch 24699: train_loss=136.33331, val_loss=146.87108\n",
      "Epoch 24700: train_loss=136.34743, val_loss=146.75775\n",
      "Epoch 24701: train_loss=136.35602, val_loss=146.88225\n",
      "Epoch 24702: train_loss=136.35527, val_loss=146.74153\n",
      "Epoch 24703: train_loss=136.34230, val_loss=146.83821\n",
      "Epoch 24704: train_loss=136.31502, val_loss=146.67816\n",
      "Epoch 24705: train_loss=136.27469, val_loss=146.73373\n",
      "Epoch 24706: train_loss=136.22360, val_loss=146.58459\n",
      "Epoch 24707: train_loss=136.16954, val_loss=146.60953\n",
      "Epoch 24708: train_loss=136.11749, val_loss=146.50415\n",
      "Epoch 24709: train_loss=136.07263, val_loss=146.50958\n",
      "Epoch 24710: train_loss=136.03806, val_loss=146.46162\n",
      "Epoch 24711: train_loss=136.01460, val_loss=146.45329\n",
      "Epoch 24712: train_loss=136.00018, val_loss=146.45348\n",
      "Epoch 24713: train_loss=135.99261, val_loss=146.43059\n",
      "Epoch 24714: train_loss=135.98984, val_loss=146.46503\n",
      "Epoch 24715: train_loss=135.98997, val_loss=146.42476\n",
      "Epoch 24716: train_loss=135.99136, val_loss=146.47766\n",
      "Epoch 24717: train_loss=135.99165, val_loss=146.41888\n",
      "Epoch 24718: train_loss=135.99045, val_loss=146.47722\n",
      "Epoch 24719: train_loss=135.98586, val_loss=146.40457\n",
      "Epoch 24720: train_loss=135.97821, val_loss=146.45901\n",
      "Epoch 24721: train_loss=135.96638, val_loss=146.38004\n",
      "Epoch 24722: train_loss=135.95161, val_loss=146.42416\n",
      "Epoch 24723: train_loss=135.93387, val_loss=146.34723\n",
      "Epoch 24724: train_loss=135.91525, val_loss=146.37965\n",
      "Epoch 24725: train_loss=135.89543, val_loss=146.31183\n",
      "Epoch 24726: train_loss=135.87569, val_loss=146.33319\n",
      "Epoch 24727: train_loss=135.85660, val_loss=146.28076\n",
      "Epoch 24728: train_loss=135.83900, val_loss=146.29259\n",
      "Epoch 24729: train_loss=135.82283, val_loss=146.25455\n",
      "Epoch 24730: train_loss=135.80803, val_loss=146.25708\n",
      "Epoch 24731: train_loss=135.79427, val_loss=146.23209\n",
      "Epoch 24732: train_loss=135.78169, val_loss=146.22969\n",
      "Epoch 24733: train_loss=135.76970, val_loss=146.21448\n",
      "Epoch 24734: train_loss=135.75809, val_loss=146.20636\n",
      "Epoch 24735: train_loss=135.74701, val_loss=146.19653\n",
      "Epoch 24736: train_loss=135.73610, val_loss=146.18146\n",
      "Epoch 24737: train_loss=135.72539, val_loss=146.17645\n",
      "Epoch 24738: train_loss=135.71489, val_loss=146.15755\n",
      "Epoch 24739: train_loss=135.70468, val_loss=146.16034\n",
      "Epoch 24740: train_loss=135.69484, val_loss=146.13637\n",
      "Epoch 24741: train_loss=135.68562, val_loss=146.14644\n",
      "Epoch 24742: train_loss=135.67731, val_loss=146.11366\n",
      "Epoch 24743: train_loss=135.67035, val_loss=146.13722\n",
      "Epoch 24744: train_loss=135.66499, val_loss=146.09766\n",
      "Epoch 24745: train_loss=135.66148, val_loss=146.14197\n",
      "Epoch 24746: train_loss=135.66057, val_loss=146.09377\n",
      "Epoch 24747: train_loss=135.66275, val_loss=146.15894\n",
      "Epoch 24748: train_loss=135.66743, val_loss=146.09708\n",
      "Epoch 24749: train_loss=135.67580, val_loss=146.18471\n",
      "Epoch 24750: train_loss=135.68599, val_loss=146.11084\n",
      "Epoch 24751: train_loss=135.69899, val_loss=146.22176\n",
      "Epoch 24752: train_loss=135.71304, val_loss=146.13330\n",
      "Epoch 24753: train_loss=135.72789, val_loss=146.25761\n",
      "Epoch 24754: train_loss=135.73929, val_loss=146.14828\n",
      "Epoch 24755: train_loss=135.74629, val_loss=146.26720\n",
      "Epoch 24756: train_loss=135.74315, val_loss=146.13278\n",
      "Epoch 24757: train_loss=135.73080, val_loss=146.22469\n",
      "Epoch 24758: train_loss=135.70442, val_loss=146.07312\n",
      "Epoch 24759: train_loss=135.66869, val_loss=146.12929\n",
      "Epoch 24760: train_loss=135.62292, val_loss=145.98755\n",
      "Epoch 24761: train_loss=135.57484, val_loss=146.01700\n",
      "Epoch 24762: train_loss=135.52670, val_loss=145.91568\n",
      "Epoch 24763: train_loss=135.48521, val_loss=145.92726\n",
      "Epoch 24764: train_loss=135.45203, val_loss=145.87344\n",
      "Epoch 24765: train_loss=135.42752, val_loss=145.86858\n",
      "Epoch 24766: train_loss=135.41058, val_loss=145.85680\n",
      "Epoch 24767: train_loss=135.39980, val_loss=145.83740\n",
      "Epoch 24768: train_loss=135.39359, val_loss=145.85834\n",
      "Epoch 24769: train_loss=135.39026, val_loss=145.82515\n",
      "Epoch 24770: train_loss=135.38893, val_loss=145.86848\n",
      "Epoch 24771: train_loss=135.38828, val_loss=145.82022\n",
      "Epoch 24772: train_loss=135.38809, val_loss=145.87450\n",
      "Epoch 24773: train_loss=135.38634, val_loss=145.80988\n",
      "Epoch 24774: train_loss=135.38342, val_loss=145.86676\n",
      "Epoch 24775: train_loss=135.37769, val_loss=145.79230\n",
      "Epoch 24776: train_loss=135.36995, val_loss=145.84801\n",
      "Epoch 24777: train_loss=135.35852, val_loss=145.77020\n",
      "Epoch 24778: train_loss=135.34517, val_loss=145.82011\n",
      "Epoch 24779: train_loss=135.32909, val_loss=145.74451\n",
      "Epoch 24780: train_loss=135.31226, val_loss=145.78397\n",
      "Epoch 24781: train_loss=135.29414, val_loss=145.71283\n",
      "Epoch 24782: train_loss=135.27632, val_loss=145.74193\n",
      "Epoch 24783: train_loss=135.25867, val_loss=145.68044\n",
      "Epoch 24784: train_loss=135.24138, val_loss=145.70163\n",
      "Epoch 24785: train_loss=135.22508, val_loss=145.65266\n",
      "Epoch 24786: train_loss=135.20988, val_loss=145.66893\n",
      "Epoch 24787: train_loss=135.19534, val_loss=145.63135\n",
      "Epoch 24788: train_loss=135.18181, val_loss=145.64235\n",
      "Epoch 24789: train_loss=135.16893, val_loss=145.61162\n",
      "Epoch 24790: train_loss=135.15672, val_loss=145.61690\n",
      "Epoch 24791: train_loss=135.14487, val_loss=145.58952\n",
      "Epoch 24792: train_loss=135.13345, val_loss=145.59102\n",
      "Epoch 24793: train_loss=135.12219, val_loss=145.56554\n",
      "Epoch 24794: train_loss=135.11125, val_loss=145.56740\n",
      "Epoch 24795: train_loss=135.10052, val_loss=145.54422\n",
      "Epoch 24796: train_loss=135.09003, val_loss=145.54829\n",
      "Epoch 24797: train_loss=135.07959, val_loss=145.52464\n",
      "Epoch 24798: train_loss=135.06975, val_loss=145.53267\n",
      "Epoch 24799: train_loss=135.06010, val_loss=145.50476\n",
      "Epoch 24800: train_loss=135.05125, val_loss=145.51859\n",
      "Epoch 24801: train_loss=135.04308, val_loss=145.48421\n",
      "Epoch 24802: train_loss=135.03600, val_loss=145.50897\n",
      "Epoch 24803: train_loss=135.03014, val_loss=145.46890\n",
      "Epoch 24804: train_loss=135.02602, val_loss=145.51067\n",
      "Epoch 24805: train_loss=135.02354, val_loss=145.46333\n",
      "Epoch 24806: train_loss=135.02396, val_loss=145.52499\n",
      "Epoch 24807: train_loss=135.02667, val_loss=145.46713\n",
      "Epoch 24808: train_loss=135.03249, val_loss=145.54910\n",
      "Epoch 24809: train_loss=135.04033, val_loss=145.47812\n",
      "Epoch 24810: train_loss=135.05190, val_loss=145.58098\n",
      "Epoch 24811: train_loss=135.06433, val_loss=145.49699\n",
      "Epoch 24812: train_loss=135.08002, val_loss=145.61984\n",
      "Epoch 24813: train_loss=135.09555, val_loss=145.52007\n",
      "Epoch 24814: train_loss=135.10989, val_loss=145.64851\n",
      "Epoch 24815: train_loss=135.11595, val_loss=145.52426\n",
      "Epoch 24816: train_loss=135.11476, val_loss=145.63486\n",
      "Epoch 24817: train_loss=135.09947, val_loss=145.48553\n",
      "Epoch 24818: train_loss=135.07297, val_loss=145.56056\n",
      "Epoch 24819: train_loss=135.03308, val_loss=145.40524\n",
      "Epoch 24820: train_loss=134.98575, val_loss=145.44414\n",
      "Epoch 24821: train_loss=134.93318, val_loss=145.31668\n",
      "Epoch 24822: train_loss=134.88341, val_loss=145.33154\n",
      "Epoch 24823: train_loss=134.83943, val_loss=145.25803\n",
      "Epoch 24824: train_loss=134.80626, val_loss=145.25818\n",
      "Epoch 24825: train_loss=134.78325, val_loss=145.23660\n",
      "Epoch 24826: train_loss=134.76923, val_loss=145.22131\n",
      "Epoch 24827: train_loss=134.76199, val_loss=145.23940\n",
      "Epoch 24828: train_loss=134.75945, val_loss=145.20880\n",
      "Epoch 24829: train_loss=134.76041, val_loss=145.25475\n",
      "Epoch 24830: train_loss=134.76236, val_loss=145.20610\n",
      "Epoch 24831: train_loss=134.76447, val_loss=145.26360\n",
      "Epoch 24832: train_loss=134.76387, val_loss=145.19829\n",
      "Epoch 24833: train_loss=134.76123, val_loss=145.25702\n",
      "Epoch 24834: train_loss=134.75383, val_loss=145.18057\n",
      "Epoch 24835: train_loss=134.74390, val_loss=145.23102\n",
      "Epoch 24836: train_loss=134.72920, val_loss=145.15047\n",
      "Epoch 24837: train_loss=134.71284, val_loss=145.19011\n",
      "Epoch 24838: train_loss=134.69405, val_loss=145.11697\n",
      "Epoch 24839: train_loss=134.67552, val_loss=145.14833\n",
      "Epoch 24840: train_loss=134.65665, val_loss=145.08765\n",
      "Epoch 24841: train_loss=134.63846, val_loss=145.10844\n",
      "Epoch 24842: train_loss=134.62096, val_loss=145.06027\n",
      "Epoch 24843: train_loss=134.60503, val_loss=145.07140\n",
      "Epoch 24844: train_loss=134.59012, val_loss=145.03604\n",
      "Epoch 24845: train_loss=134.57628, val_loss=145.04039\n",
      "Epoch 24846: train_loss=134.56349, val_loss=145.01608\n",
      "Epoch 24847: train_loss=134.55141, val_loss=145.01309\n",
      "Epoch 24848: train_loss=134.53998, val_loss=144.99731\n",
      "Epoch 24849: train_loss=134.52905, val_loss=144.98988\n",
      "Epoch 24850: train_loss=134.51845, val_loss=144.98062\n",
      "Epoch 24851: train_loss=134.50807, val_loss=144.96858\n",
      "Epoch 24852: train_loss=134.49786, val_loss=144.96286\n",
      "Epoch 24853: train_loss=134.48781, val_loss=144.94475\n",
      "Epoch 24854: train_loss=134.47791, val_loss=144.94374\n",
      "Epoch 24855: train_loss=134.46835, val_loss=144.92142\n",
      "Epoch 24856: train_loss=134.45927, val_loss=144.92943\n",
      "Epoch 24857: train_loss=134.45068, val_loss=144.90237\n",
      "Epoch 24858: train_loss=134.44292, val_loss=144.92046\n",
      "Epoch 24859: train_loss=134.43605, val_loss=144.88544\n",
      "Epoch 24860: train_loss=134.43063, val_loss=144.91640\n",
      "Epoch 24861: train_loss=134.42720, val_loss=144.87387\n",
      "Epoch 24862: train_loss=134.42604, val_loss=144.92482\n",
      "Epoch 24863: train_loss=134.42757, val_loss=144.87300\n",
      "Epoch 24864: train_loss=134.43230, val_loss=144.94646\n",
      "Epoch 24865: train_loss=134.43927, val_loss=144.88249\n",
      "Epoch 24866: train_loss=134.44946, val_loss=144.97795\n",
      "Epoch 24867: train_loss=134.46075, val_loss=144.90019\n",
      "Epoch 24868: train_loss=134.47391, val_loss=145.01233\n",
      "Epoch 24869: train_loss=134.48586, val_loss=144.91806\n",
      "Epoch 24870: train_loss=134.49759, val_loss=145.03685\n",
      "Epoch 24871: train_loss=134.50398, val_loss=144.92097\n",
      "Epoch 24872: train_loss=134.50497, val_loss=145.02808\n",
      "Epoch 24873: train_loss=134.49480, val_loss=144.89162\n",
      "Epoch 24874: train_loss=134.47574, val_loss=144.97328\n",
      "Epoch 24875: train_loss=134.44504, val_loss=144.83047\n",
      "Epoch 24876: train_loss=134.40707, val_loss=144.88177\n",
      "Epoch 24877: train_loss=134.36313, val_loss=144.75336\n",
      "Epoch 24878: train_loss=134.31834, val_loss=144.77725\n",
      "Epoch 24879: train_loss=134.27515, val_loss=144.68790\n",
      "Epoch 24880: train_loss=134.23903, val_loss=144.69522\n",
      "Epoch 24881: train_loss=134.21130, val_loss=144.65280\n",
      "Epoch 24882: train_loss=134.19122, val_loss=144.64761\n",
      "Epoch 24883: train_loss=134.17747, val_loss=144.64378\n",
      "Epoch 24884: train_loss=134.16876, val_loss=144.62550\n",
      "Epoch 24885: train_loss=134.16374, val_loss=144.64940\n",
      "Epoch 24886: train_loss=134.16103, val_loss=144.61504\n",
      "Epoch 24887: train_loss=134.15979, val_loss=144.65483\n",
      "Epoch 24888: train_loss=134.15892, val_loss=144.60548\n",
      "Epoch 24889: train_loss=134.15782, val_loss=144.65652\n",
      "Epoch 24890: train_loss=134.15602, val_loss=144.59517\n",
      "Epoch 24891: train_loss=134.15233, val_loss=144.65105\n",
      "Epoch 24892: train_loss=134.14659, val_loss=144.58188\n",
      "Epoch 24893: train_loss=134.13838, val_loss=144.63426\n",
      "Epoch 24894: train_loss=134.12758, val_loss=144.55905\n",
      "Epoch 24895: train_loss=134.11458, val_loss=144.60304\n",
      "Epoch 24896: train_loss=134.09978, val_loss=144.52931\n",
      "Epoch 24897: train_loss=134.08380, val_loss=144.56581\n",
      "Epoch 24898: train_loss=134.06725, val_loss=144.50047\n",
      "Epoch 24899: train_loss=134.05066, val_loss=144.52986\n",
      "Epoch 24900: train_loss=134.03442, val_loss=144.47382\n",
      "Epoch 24901: train_loss=134.01865, val_loss=144.49443\n",
      "Epoch 24902: train_loss=134.00336, val_loss=144.44763\n",
      "Epoch 24903: train_loss=133.98871, val_loss=144.46039\n",
      "Epoch 24904: train_loss=133.97467, val_loss=144.42465\n",
      "Epoch 24905: train_loss=133.96133, val_loss=144.43172\n",
      "Epoch 24906: train_loss=133.94879, val_loss=144.40593\n",
      "Epoch 24907: train_loss=133.93694, val_loss=144.40578\n",
      "Epoch 24908: train_loss=133.92554, val_loss=144.38593\n",
      "Epoch 24909: train_loss=133.91455, val_loss=144.37996\n",
      "Epoch 24910: train_loss=133.90401, val_loss=144.36693\n",
      "Epoch 24911: train_loss=133.89359, val_loss=144.35617\n",
      "Epoch 24912: train_loss=133.88338, val_loss=144.34837\n",
      "Epoch 24913: train_loss=133.87338, val_loss=144.33409\n",
      "Epoch 24914: train_loss=133.86348, val_loss=144.33022\n",
      "Epoch 24915: train_loss=133.85367, val_loss=144.31300\n",
      "Epoch 24916: train_loss=133.84392, val_loss=144.31367\n",
      "Epoch 24917: train_loss=133.83449, val_loss=144.29214\n",
      "Epoch 24918: train_loss=133.82541, val_loss=144.29814\n",
      "Epoch 24919: train_loss=133.81674, val_loss=144.27205\n",
      "Epoch 24920: train_loss=133.80869, val_loss=144.28806\n",
      "Epoch 24921: train_loss=133.80165, val_loss=144.25661\n",
      "Epoch 24922: train_loss=133.79594, val_loss=144.28519\n",
      "Epoch 24923: train_loss=133.79219, val_loss=144.24486\n",
      "Epoch 24924: train_loss=133.79060, val_loss=144.29263\n",
      "Epoch 24925: train_loss=133.79221, val_loss=144.24341\n",
      "Epoch 24926: train_loss=133.79765, val_loss=144.31906\n",
      "Epoch 24927: train_loss=133.80789, val_loss=144.26024\n",
      "Epoch 24928: train_loss=133.82327, val_loss=144.36652\n",
      "Epoch 24929: train_loss=133.84232, val_loss=144.29308\n",
      "Epoch 24930: train_loss=133.86548, val_loss=144.42807\n",
      "Epoch 24931: train_loss=133.89182, val_loss=144.33743\n",
      "Epoch 24932: train_loss=133.91963, val_loss=144.48979\n",
      "Epoch 24933: train_loss=133.94263, val_loss=144.37218\n",
      "Epoch 24934: train_loss=133.95969, val_loss=144.51256\n",
      "Epoch 24935: train_loss=133.96001, val_loss=144.35620\n",
      "Epoch 24936: train_loss=133.94490, val_loss=144.45320\n",
      "Epoch 24937: train_loss=133.90616, val_loss=144.26987\n",
      "Epoch 24938: train_loss=133.85185, val_loss=144.31531\n",
      "Epoch 24939: train_loss=133.78436, val_loss=144.14912\n",
      "Epoch 24940: train_loss=133.71478, val_loss=144.15993\n",
      "Epoch 24941: train_loss=133.65242, val_loss=144.06233\n",
      "Epoch 24942: train_loss=133.60536, val_loss=144.06009\n",
      "Epoch 24943: train_loss=133.57559, val_loss=144.04060\n",
      "Epoch 24944: train_loss=133.56163, val_loss=144.02528\n",
      "Epoch 24945: train_loss=133.55957, val_loss=144.06094\n",
      "Epoch 24946: train_loss=133.56473, val_loss=144.02502\n",
      "Epoch 24947: train_loss=133.57298, val_loss=144.08800\n",
      "Epoch 24948: train_loss=133.57947, val_loss=144.02878\n",
      "Epoch 24949: train_loss=133.58244, val_loss=144.09413\n",
      "Epoch 24950: train_loss=133.57838, val_loss=144.01619\n",
      "Epoch 24951: train_loss=133.56816, val_loss=144.06689\n",
      "Epoch 24952: train_loss=133.55113, val_loss=143.98206\n",
      "Epoch 24953: train_loss=133.53011, val_loss=144.01439\n",
      "Epoch 24954: train_loss=133.50659, val_loss=143.94278\n",
      "Epoch 24955: train_loss=133.48354, val_loss=143.96085\n",
      "Epoch 24956: train_loss=133.46211, val_loss=143.91202\n",
      "Epoch 24957: train_loss=133.44322, val_loss=143.91656\n",
      "Epoch 24958: train_loss=133.42706, val_loss=143.89136\n",
      "Epoch 24959: train_loss=133.41379, val_loss=143.88422\n",
      "Epoch 24960: train_loss=133.40300, val_loss=143.88052\n",
      "Epoch 24961: train_loss=133.39412, val_loss=143.86240\n",
      "Epoch 24962: train_loss=133.38655, val_loss=143.87267\n",
      "Epoch 24963: train_loss=133.37947, val_loss=143.84444\n",
      "Epoch 24964: train_loss=133.37268, val_loss=143.86310\n",
      "Epoch 24965: train_loss=133.36583, val_loss=143.82784\n",
      "Epoch 24966: train_loss=133.35898, val_loss=143.85312\n",
      "Epoch 24967: train_loss=133.35191, val_loss=143.81198\n",
      "Epoch 24968: train_loss=133.34454, val_loss=143.84084\n",
      "Epoch 24969: train_loss=133.33707, val_loss=143.79428\n",
      "Epoch 24970: train_loss=133.32930, val_loss=143.82558\n",
      "Epoch 24971: train_loss=133.32146, val_loss=143.77631\n",
      "Epoch 24972: train_loss=133.31367, val_loss=143.81104\n",
      "Epoch 24973: train_loss=133.30554, val_loss=143.75922\n",
      "Epoch 24974: train_loss=133.29739, val_loss=143.79655\n",
      "Epoch 24975: train_loss=133.28896, val_loss=143.74249\n",
      "Epoch 24976: train_loss=133.28056, val_loss=143.78023\n",
      "Epoch 24977: train_loss=133.27148, val_loss=143.72322\n",
      "Epoch 24978: train_loss=133.26253, val_loss=143.76128\n",
      "Epoch 24979: train_loss=133.25308, val_loss=143.70410\n",
      "Epoch 24980: train_loss=133.24380, val_loss=143.74321\n",
      "Epoch 24981: train_loss=133.23419, val_loss=143.68600\n",
      "Epoch 24982: train_loss=133.22472, val_loss=143.72566\n",
      "Epoch 24983: train_loss=133.21530, val_loss=143.66724\n",
      "Epoch 24984: train_loss=133.20619, val_loss=143.70721\n",
      "Epoch 24985: train_loss=133.19719, val_loss=143.64857\n",
      "Epoch 24986: train_loss=133.18863, val_loss=143.69167\n",
      "Epoch 24987: train_loss=133.18013, val_loss=143.63287\n",
      "Epoch 24988: train_loss=133.17198, val_loss=143.67772\n",
      "Epoch 24989: train_loss=133.16393, val_loss=143.61586\n",
      "Epoch 24990: train_loss=133.15634, val_loss=143.66203\n",
      "Epoch 24991: train_loss=133.14862, val_loss=143.59792\n",
      "Epoch 24992: train_loss=133.14139, val_loss=143.64908\n",
      "Epoch 24993: train_loss=133.13448, val_loss=143.58395\n",
      "Epoch 24994: train_loss=133.12811, val_loss=143.64015\n",
      "Epoch 24995: train_loss=133.12215, val_loss=143.57181\n",
      "Epoch 24996: train_loss=133.11629, val_loss=143.63132\n",
      "Epoch 24997: train_loss=133.11105, val_loss=143.55841\n",
      "Epoch 24998: train_loss=133.10551, val_loss=143.62173\n",
      "Epoch 24999: train_loss=133.10007, val_loss=143.54474\n",
      "Epoch 25000: train_loss=133.09372, val_loss=143.61029\n",
      "Epoch 25001: train_loss=133.08659, val_loss=143.53018\n",
      "Epoch 25002: train_loss=133.07840, val_loss=143.59421\n",
      "Epoch 25003: train_loss=133.06914, val_loss=143.51041\n",
      "Epoch 25004: train_loss=133.05836, val_loss=143.57001\n",
      "Epoch 25005: train_loss=133.04654, val_loss=143.48550\n",
      "Epoch 25006: train_loss=133.03287, val_loss=143.54004\n",
      "Epoch 25007: train_loss=133.01823, val_loss=143.45908\n",
      "Epoch 25008: train_loss=133.00244, val_loss=143.50462\n",
      "Epoch 25009: train_loss=132.98543, val_loss=143.42781\n",
      "Epoch 25010: train_loss=132.96823, val_loss=143.46202\n",
      "Epoch 25011: train_loss=132.94954, val_loss=143.39447\n",
      "Epoch 25012: train_loss=132.93170, val_loss=143.42000\n",
      "Epoch 25013: train_loss=132.91377, val_loss=143.36665\n",
      "Epoch 25014: train_loss=132.89702, val_loss=143.38249\n",
      "Epoch 25015: train_loss=132.88112, val_loss=143.34315\n",
      "Epoch 25016: train_loss=132.86671, val_loss=143.34901\n",
      "Epoch 25017: train_loss=132.85353, val_loss=143.32321\n",
      "Epoch 25018: train_loss=132.84148, val_loss=143.32126\n",
      "Epoch 25019: train_loss=132.83051, val_loss=143.30806\n",
      "Epoch 25020: train_loss=132.82037, val_loss=143.29770\n",
      "Epoch 25021: train_loss=132.81091, val_loss=143.29391\n",
      "Epoch 25022: train_loss=132.80199, val_loss=143.27733\n",
      "Epoch 25023: train_loss=132.79344, val_loss=143.28194\n",
      "Epoch 25024: train_loss=132.78519, val_loss=143.25937\n",
      "Epoch 25025: train_loss=132.77737, val_loss=143.27014\n",
      "Epoch 25026: train_loss=132.76990, val_loss=143.23979\n",
      "Epoch 25027: train_loss=132.76317, val_loss=143.25990\n",
      "Epoch 25028: train_loss=132.75697, val_loss=143.22514\n",
      "Epoch 25029: train_loss=132.75227, val_loss=143.25838\n",
      "Epoch 25030: train_loss=132.74861, val_loss=143.21675\n",
      "Epoch 25031: train_loss=132.74702, val_loss=143.26495\n",
      "Epoch 25032: train_loss=132.74783, val_loss=143.21307\n",
      "Epoch 25033: train_loss=132.75182, val_loss=143.28362\n",
      "Epoch 25034: train_loss=132.75945, val_loss=143.22470\n",
      "Epoch 25035: train_loss=132.77188, val_loss=143.32703\n",
      "Epoch 25036: train_loss=132.78989, val_loss=143.25838\n",
      "Epoch 25037: train_loss=132.81299, val_loss=143.38953\n",
      "Epoch 25038: train_loss=132.83957, val_loss=143.30450\n",
      "Epoch 25039: train_loss=132.86957, val_loss=143.45833\n",
      "Epoch 25040: train_loss=132.89734, val_loss=143.35080\n",
      "Epoch 25041: train_loss=132.92349, val_loss=143.50337\n",
      "Epoch 25042: train_loss=132.93457, val_loss=143.35721\n",
      "Epoch 25043: train_loss=132.93237, val_loss=143.47084\n",
      "Epoch 25044: train_loss=132.90404, val_loss=143.28566\n",
      "Epoch 25045: train_loss=132.85736, val_loss=143.34041\n",
      "Epoch 25046: train_loss=132.78920, val_loss=143.15617\n",
      "Epoch 25047: train_loss=132.71454, val_loss=143.16971\n",
      "Epoch 25048: train_loss=132.64259, val_loss=143.04893\n",
      "Epoch 25049: train_loss=132.58464, val_loss=143.04729\n",
      "Epoch 25050: train_loss=132.54573, val_loss=143.01613\n",
      "Epoch 25051: train_loss=132.52689, val_loss=143.00356\n",
      "Epoch 25052: train_loss=132.52426, val_loss=143.03989\n",
      "Epoch 25053: train_loss=132.53157, val_loss=143.00592\n",
      "Epoch 25054: train_loss=132.54311, val_loss=143.07452\n",
      "Epoch 25055: train_loss=132.55283, val_loss=143.01373\n",
      "Epoch 25056: train_loss=132.55786, val_loss=143.08282\n",
      "Epoch 25057: train_loss=132.55400, val_loss=143.00046\n",
      "Epoch 25058: train_loss=132.54257, val_loss=143.05115\n",
      "Epoch 25059: train_loss=132.52277, val_loss=142.96323\n",
      "Epoch 25060: train_loss=132.49911, val_loss=142.99196\n",
      "Epoch 25061: train_loss=132.47328, val_loss=142.92172\n",
      "Epoch 25062: train_loss=132.44887, val_loss=142.93280\n",
      "Epoch 25063: train_loss=132.42708, val_loss=142.89378\n",
      "Epoch 25064: train_loss=132.40993, val_loss=142.89098\n",
      "Epoch 25065: train_loss=132.39691, val_loss=142.88316\n",
      "Epoch 25066: train_loss=132.38800, val_loss=142.86647\n",
      "Epoch 25067: train_loss=132.38193, val_loss=142.88094\n",
      "Epoch 25068: train_loss=132.37714, val_loss=142.85143\n",
      "Epoch 25069: train_loss=132.37305, val_loss=142.87859\n",
      "Epoch 25070: train_loss=132.36845, val_loss=142.83818\n",
      "Epoch 25071: train_loss=132.36330, val_loss=142.87112\n",
      "Epoch 25072: train_loss=132.35684, val_loss=142.82372\n",
      "Epoch 25073: train_loss=132.34938, val_loss=142.85669\n",
      "Epoch 25074: train_loss=132.34081, val_loss=142.80513\n",
      "Epoch 25075: train_loss=132.33134, val_loss=142.83617\n",
      "Epoch 25076: train_loss=132.32100, val_loss=142.78545\n",
      "Epoch 25077: train_loss=132.31001, val_loss=142.81342\n",
      "Epoch 25078: train_loss=132.29883, val_loss=142.76512\n",
      "Epoch 25079: train_loss=132.28731, val_loss=142.78786\n",
      "Epoch 25080: train_loss=132.27573, val_loss=142.74347\n",
      "Epoch 25081: train_loss=132.26430, val_loss=142.76225\n",
      "Epoch 25082: train_loss=132.25281, val_loss=142.72305\n",
      "Epoch 25083: train_loss=132.24165, val_loss=142.73790\n",
      "Epoch 25084: train_loss=132.23041, val_loss=142.70406\n",
      "Epoch 25085: train_loss=132.21977, val_loss=142.71500\n",
      "Epoch 25086: train_loss=132.20914, val_loss=142.68518\n",
      "Epoch 25087: train_loss=132.19876, val_loss=142.69148\n",
      "Epoch 25088: train_loss=132.18854, val_loss=142.66554\n",
      "Epoch 25089: train_loss=132.17865, val_loss=142.66960\n",
      "Epoch 25090: train_loss=132.16884, val_loss=142.64798\n",
      "Epoch 25091: train_loss=132.15924, val_loss=142.65080\n",
      "Epoch 25092: train_loss=132.14978, val_loss=142.63100\n",
      "Epoch 25093: train_loss=132.14040, val_loss=142.63234\n",
      "Epoch 25094: train_loss=132.13110, val_loss=142.61223\n",
      "Epoch 25095: train_loss=132.12206, val_loss=142.61301\n",
      "Epoch 25096: train_loss=132.11310, val_loss=142.59276\n",
      "Epoch 25097: train_loss=132.10434, val_loss=142.59753\n",
      "Epoch 25098: train_loss=132.09573, val_loss=142.57607\n",
      "Epoch 25099: train_loss=132.08765, val_loss=142.58556\n",
      "Epoch 25100: train_loss=132.08009, val_loss=142.55812\n",
      "Epoch 25101: train_loss=132.07338, val_loss=142.57758\n",
      "Epoch 25102: train_loss=132.06807, val_loss=142.54433\n",
      "Epoch 25103: train_loss=132.06444, val_loss=142.58090\n",
      "Epoch 25104: train_loss=132.06357, val_loss=142.53906\n",
      "Epoch 25105: train_loss=132.06526, val_loss=142.59846\n",
      "Epoch 25106: train_loss=132.07079, val_loss=142.54657\n",
      "Epoch 25107: train_loss=132.08093, val_loss=142.63506\n",
      "Epoch 25108: train_loss=132.09622, val_loss=142.57314\n",
      "Epoch 25109: train_loss=132.11792, val_loss=142.69878\n",
      "Epoch 25110: train_loss=132.14618, val_loss=142.62463\n",
      "Epoch 25111: train_loss=132.18025, val_loss=142.78432\n",
      "Epoch 25112: train_loss=132.21750, val_loss=142.68936\n",
      "Epoch 25113: train_loss=132.25577, val_loss=142.86459\n",
      "Epoch 25114: train_loss=132.28539, val_loss=142.73314\n",
      "Epoch 25115: train_loss=132.30359, val_loss=142.88173\n",
      "Epoch 25116: train_loss=132.29539, val_loss=142.69763\n",
      "Epoch 25117: train_loss=132.26315, val_loss=142.77863\n",
      "Epoch 25118: train_loss=132.20076, val_loss=142.56882\n",
      "Epoch 25119: train_loss=132.12099, val_loss=142.58791\n",
      "Epoch 25120: train_loss=132.03464, val_loss=142.42696\n",
      "Epoch 25121: train_loss=131.95833, val_loss=142.42249\n",
      "Epoch 25122: train_loss=131.90163, val_loss=142.36214\n",
      "Epoch 25123: train_loss=131.86969, val_loss=142.35255\n",
      "Epoch 25124: train_loss=131.86018, val_loss=142.38419\n",
      "Epoch 25125: train_loss=131.86702, val_loss=142.35904\n",
      "Epoch 25126: train_loss=131.88295, val_loss=142.43753\n",
      "Epoch 25127: train_loss=131.90019, val_loss=142.37918\n",
      "Epoch 25128: train_loss=131.91234, val_loss=142.45885\n",
      "Epoch 25129: train_loss=131.91405, val_loss=142.36749\n",
      "Epoch 25130: train_loss=131.90419, val_loss=142.42351\n",
      "Epoch 25131: train_loss=131.88336, val_loss=142.32561\n",
      "Epoch 25132: train_loss=131.85553, val_loss=142.35640\n",
      "Epoch 25133: train_loss=131.82489, val_loss=142.28114\n",
      "Epoch 25134: train_loss=131.79631, val_loss=142.29251\n",
      "Epoch 25135: train_loss=131.77209, val_loss=142.25214\n",
      "Epoch 25136: train_loss=131.75397, val_loss=142.24602\n",
      "Epoch 25137: train_loss=131.74179, val_loss=142.24193\n",
      "Epoch 25138: train_loss=131.73460, val_loss=142.22160\n",
      "Epoch 25139: train_loss=131.73053, val_loss=142.24399\n",
      "Epoch 25140: train_loss=131.72777, val_loss=142.21202\n",
      "Epoch 25141: train_loss=131.72554, val_loss=142.24757\n",
      "Epoch 25142: train_loss=131.72221, val_loss=142.20154\n",
      "Epoch 25143: train_loss=131.71718, val_loss=142.23785\n",
      "Epoch 25144: train_loss=131.70993, val_loss=142.18402\n",
      "Epoch 25145: train_loss=131.70088, val_loss=142.21634\n",
      "Epoch 25146: train_loss=131.69009, val_loss=142.16281\n",
      "Epoch 25147: train_loss=131.67818, val_loss=142.18896\n",
      "Epoch 25148: train_loss=131.66534, val_loss=142.14262\n",
      "Epoch 25149: train_loss=131.65228, val_loss=142.16119\n",
      "Epoch 25150: train_loss=131.63913, val_loss=142.12207\n",
      "Epoch 25151: train_loss=131.62651, val_loss=142.13066\n",
      "Epoch 25152: train_loss=131.61432, val_loss=142.10085\n",
      "Epoch 25153: train_loss=131.60304, val_loss=142.10225\n",
      "Epoch 25154: train_loss=131.59238, val_loss=142.08450\n",
      "Epoch 25155: train_loss=131.58247, val_loss=142.08243\n",
      "Epoch 25156: train_loss=131.57301, val_loss=142.07452\n",
      "Epoch 25157: train_loss=131.56406, val_loss=142.06358\n",
      "Epoch 25158: train_loss=131.55540, val_loss=142.05966\n",
      "Epoch 25159: train_loss=131.54706, val_loss=142.04201\n",
      "Epoch 25160: train_loss=131.53896, val_loss=142.04443\n",
      "Epoch 25161: train_loss=131.53111, val_loss=142.02213\n",
      "Epoch 25162: train_loss=131.52362, val_loss=142.03207\n",
      "Epoch 25163: train_loss=131.51656, val_loss=142.00577\n",
      "Epoch 25164: train_loss=131.50990, val_loss=142.02550\n",
      "Epoch 25165: train_loss=131.50366, val_loss=141.99303\n",
      "Epoch 25166: train_loss=131.49811, val_loss=142.02023\n",
      "Epoch 25167: train_loss=131.49329, val_loss=141.98050\n",
      "Epoch 25168: train_loss=131.48929, val_loss=142.01881\n",
      "Epoch 25169: train_loss=131.48653, val_loss=141.97269\n",
      "Epoch 25170: train_loss=131.48541, val_loss=142.02444\n",
      "Epoch 25171: train_loss=131.48569, val_loss=141.96872\n",
      "Epoch 25172: train_loss=131.48767, val_loss=142.03392\n",
      "Epoch 25173: train_loss=131.49054, val_loss=141.96925\n",
      "Epoch 25174: train_loss=131.49455, val_loss=142.05118\n",
      "Epoch 25175: train_loss=131.49887, val_loss=141.97701\n",
      "Epoch 25176: train_loss=131.50403, val_loss=142.06839\n",
      "Epoch 25177: train_loss=131.50780, val_loss=141.98087\n",
      "Epoch 25178: train_loss=131.51070, val_loss=142.07458\n",
      "Epoch 25179: train_loss=131.51024, val_loss=141.97388\n",
      "Epoch 25180: train_loss=131.50673, val_loss=142.06186\n",
      "Epoch 25181: train_loss=131.49806, val_loss=141.95216\n",
      "Epoch 25182: train_loss=131.48502, val_loss=142.02728\n",
      "Epoch 25183: train_loss=131.46642, val_loss=141.91568\n",
      "Epoch 25184: train_loss=131.44389, val_loss=141.97362\n",
      "Epoch 25185: train_loss=131.41762, val_loss=141.87021\n",
      "Epoch 25186: train_loss=131.39072, val_loss=141.90982\n",
      "Epoch 25187: train_loss=131.36331, val_loss=141.82376\n",
      "Epoch 25188: train_loss=131.33734, val_loss=141.84709\n",
      "Epoch 25189: train_loss=131.31355, val_loss=141.78720\n",
      "Epoch 25190: train_loss=131.29268, val_loss=141.80051\n",
      "Epoch 25191: train_loss=131.27513, val_loss=141.76759\n",
      "Epoch 25192: train_loss=131.26094, val_loss=141.76749\n",
      "Epoch 25193: train_loss=131.24924, val_loss=141.75476\n",
      "Epoch 25194: train_loss=131.23979, val_loss=141.74242\n",
      "Epoch 25195: train_loss=131.23189, val_loss=141.74405\n",
      "Epoch 25196: train_loss=131.22495, val_loss=141.72185\n",
      "Epoch 25197: train_loss=131.21901, val_loss=141.73735\n",
      "Epoch 25198: train_loss=131.21349, val_loss=141.70882\n",
      "Epoch 25199: train_loss=131.20877, val_loss=141.73482\n",
      "Epoch 25200: train_loss=131.20430, val_loss=141.69661\n",
      "Epoch 25201: train_loss=131.20029, val_loss=141.73055\n",
      "Epoch 25202: train_loss=131.19647, val_loss=141.68440\n",
      "Epoch 25203: train_loss=131.19310, val_loss=141.72621\n",
      "Epoch 25204: train_loss=131.19000, val_loss=141.67314\n",
      "Epoch 25205: train_loss=131.18767, val_loss=141.72398\n",
      "Epoch 25206: train_loss=131.18571, val_loss=141.66588\n",
      "Epoch 25207: train_loss=131.18451, val_loss=141.72830\n",
      "Epoch 25208: train_loss=131.18324, val_loss=141.66322\n",
      "Epoch 25209: train_loss=131.18271, val_loss=141.73210\n",
      "Epoch 25210: train_loss=131.18167, val_loss=141.65807\n",
      "Epoch 25211: train_loss=131.18059, val_loss=141.73151\n",
      "Epoch 25212: train_loss=131.17873, val_loss=141.65019\n",
      "Epoch 25213: train_loss=131.17659, val_loss=141.72597\n",
      "Epoch 25214: train_loss=131.17221, val_loss=141.63672\n",
      "Epoch 25215: train_loss=131.16660, val_loss=141.70963\n",
      "Epoch 25216: train_loss=131.15823, val_loss=141.61646\n",
      "Epoch 25217: train_loss=131.14804, val_loss=141.68541\n",
      "Epoch 25218: train_loss=131.13470, val_loss=141.59337\n",
      "Epoch 25219: train_loss=131.11967, val_loss=141.65269\n",
      "Epoch 25220: train_loss=131.10216, val_loss=141.56247\n",
      "Epoch 25221: train_loss=131.08351, val_loss=141.60782\n",
      "Epoch 25222: train_loss=131.06349, val_loss=141.52704\n",
      "Epoch 25223: train_loss=131.04408, val_loss=141.56090\n",
      "Epoch 25224: train_loss=131.02461, val_loss=141.49330\n",
      "Epoch 25225: train_loss=131.00621, val_loss=141.51534\n",
      "Epoch 25226: train_loss=130.98846, val_loss=141.46494\n",
      "Epoch 25227: train_loss=130.97275, val_loss=141.47881\n",
      "Epoch 25228: train_loss=130.95830, val_loss=141.44420\n",
      "Epoch 25229: train_loss=130.94571, val_loss=141.44849\n",
      "Epoch 25230: train_loss=130.93427, val_loss=141.42654\n",
      "Epoch 25231: train_loss=130.92403, val_loss=141.42297\n",
      "Epoch 25232: train_loss=130.91460, val_loss=141.41066\n",
      "Epoch 25233: train_loss=130.90579, val_loss=141.40196\n",
      "Epoch 25234: train_loss=130.89740, val_loss=141.40031\n",
      "Epoch 25235: train_loss=130.88943, val_loss=141.38562\n",
      "Epoch 25236: train_loss=130.88188, val_loss=141.38954\n",
      "Epoch 25237: train_loss=130.87460, val_loss=141.36742\n",
      "Epoch 25238: train_loss=130.86778, val_loss=141.37839\n",
      "Epoch 25239: train_loss=130.86137, val_loss=141.35045\n",
      "Epoch 25240: train_loss=130.85545, val_loss=141.36958\n",
      "Epoch 25241: train_loss=130.85028, val_loss=141.33566\n",
      "Epoch 25242: train_loss=130.84605, val_loss=141.36761\n",
      "Epoch 25243: train_loss=130.84311, val_loss=141.32748\n",
      "Epoch 25244: train_loss=130.84175, val_loss=141.37386\n",
      "Epoch 25245: train_loss=130.84213, val_loss=141.32597\n",
      "Epoch 25246: train_loss=130.84505, val_loss=141.39021\n",
      "Epoch 25247: train_loss=130.85066, val_loss=141.33200\n",
      "Epoch 25248: train_loss=130.85994, val_loss=141.41782\n",
      "Epoch 25249: train_loss=130.87161, val_loss=141.35001\n",
      "Epoch 25250: train_loss=130.88768, val_loss=141.46335\n",
      "Epoch 25251: train_loss=130.90594, val_loss=141.38266\n",
      "Epoch 25252: train_loss=130.92677, val_loss=141.51364\n",
      "Epoch 25253: train_loss=130.94537, val_loss=141.41286\n",
      "Epoch 25254: train_loss=130.96219, val_loss=141.54341\n",
      "Epoch 25255: train_loss=130.96869, val_loss=141.41426\n",
      "Epoch 25256: train_loss=130.96638, val_loss=141.51944\n",
      "Epoch 25257: train_loss=130.94743, val_loss=141.36618\n",
      "Epoch 25258: train_loss=130.91623, val_loss=141.43324\n",
      "Epoch 25259: train_loss=130.87061, val_loss=141.28268\n",
      "Epoch 25260: train_loss=130.81979, val_loss=141.31572\n",
      "Epoch 25261: train_loss=130.76698, val_loss=141.19991\n",
      "Epoch 25262: train_loss=130.71945, val_loss=141.21014\n",
      "Epoch 25263: train_loss=130.68037, val_loss=141.15120\n",
      "Epoch 25264: train_loss=130.65292, val_loss=141.14693\n",
      "Epoch 25265: train_loss=130.63693, val_loss=141.14328\n",
      "Epoch 25266: train_loss=130.63075, val_loss=141.12450\n",
      "Epoch 25267: train_loss=130.63158, val_loss=141.16171\n",
      "Epoch 25268: train_loss=130.63556, val_loss=141.12646\n",
      "Epoch 25269: train_loss=130.64015, val_loss=141.18082\n",
      "Epoch 25270: train_loss=130.64264, val_loss=141.12605\n",
      "Epoch 25271: train_loss=130.64204, val_loss=141.18050\n",
      "Epoch 25272: train_loss=130.63718, val_loss=141.11229\n",
      "Epoch 25273: train_loss=130.62895, val_loss=141.15770\n",
      "Epoch 25274: train_loss=130.61705, val_loss=141.08556\n",
      "Epoch 25275: train_loss=130.60312, val_loss=141.12187\n",
      "Epoch 25276: train_loss=130.58693, val_loss=141.05890\n",
      "Epoch 25277: train_loss=130.56992, val_loss=141.08382\n",
      "Epoch 25278: train_loss=130.55219, val_loss=141.03412\n",
      "Epoch 25279: train_loss=130.53578, val_loss=141.04546\n",
      "Epoch 25280: train_loss=130.52078, val_loss=141.01172\n",
      "Epoch 25281: train_loss=130.50761, val_loss=141.01099\n",
      "Epoch 25282: train_loss=130.49640, val_loss=140.99684\n",
      "Epoch 25283: train_loss=130.48708, val_loss=140.98936\n",
      "Epoch 25284: train_loss=130.47906, val_loss=140.99069\n",
      "Epoch 25285: train_loss=130.47206, val_loss=140.97365\n",
      "Epoch 25286: train_loss=130.46565, val_loss=140.98407\n",
      "Epoch 25287: train_loss=130.45981, val_loss=140.95778\n",
      "Epoch 25288: train_loss=130.45439, val_loss=140.97556\n",
      "Epoch 25289: train_loss=130.44917, val_loss=140.94254\n",
      "Epoch 25290: train_loss=130.44431, val_loss=140.96976\n",
      "Epoch 25291: train_loss=130.43930, val_loss=140.93243\n",
      "Epoch 25292: train_loss=130.43457, val_loss=140.96721\n",
      "Epoch 25293: train_loss=130.43001, val_loss=140.92381\n",
      "Epoch 25294: train_loss=130.42563, val_loss=140.96269\n",
      "Epoch 25295: train_loss=130.42140, val_loss=140.91138\n",
      "Epoch 25296: train_loss=130.41722, val_loss=140.95279\n",
      "Epoch 25297: train_loss=130.41287, val_loss=140.89583\n",
      "Epoch 25298: train_loss=130.40851, val_loss=140.94391\n",
      "Epoch 25299: train_loss=130.40402, val_loss=140.88649\n",
      "Epoch 25300: train_loss=130.39989, val_loss=140.94153\n",
      "Epoch 25301: train_loss=130.39543, val_loss=140.88100\n",
      "Epoch 25302: train_loss=130.39221, val_loss=140.93980\n",
      "Epoch 25303: train_loss=130.38882, val_loss=140.87190\n",
      "Epoch 25304: train_loss=130.38635, val_loss=140.93427\n",
      "Epoch 25305: train_loss=130.38329, val_loss=140.86081\n",
      "Epoch 25306: train_loss=130.38092, val_loss=140.92754\n",
      "Epoch 25307: train_loss=130.37717, val_loss=140.85069\n",
      "Epoch 25308: train_loss=130.37347, val_loss=140.92094\n",
      "Epoch 25309: train_loss=130.36742, val_loss=140.84062\n",
      "Epoch 25310: train_loss=130.36110, val_loss=140.90797\n",
      "Epoch 25311: train_loss=130.35176, val_loss=140.82333\n",
      "Epoch 25312: train_loss=130.34180, val_loss=140.88354\n",
      "Epoch 25313: train_loss=130.32857, val_loss=140.79794\n",
      "Epoch 25314: train_loss=130.31499, val_loss=140.84975\n",
      "Epoch 25315: train_loss=130.29890, val_loss=140.76819\n",
      "Epoch 25316: train_loss=130.28348, val_loss=140.81267\n",
      "Epoch 25317: train_loss=130.26678, val_loss=140.74008\n",
      "Epoch 25318: train_loss=130.25041, val_loss=140.77661\n",
      "Epoch 25319: train_loss=130.23378, val_loss=140.71445\n",
      "Epoch 25320: train_loss=130.21803, val_loss=140.74069\n",
      "Epoch 25321: train_loss=130.20216, val_loss=140.68959\n",
      "Epoch 25322: train_loss=130.18742, val_loss=140.70567\n",
      "Epoch 25323: train_loss=130.17339, val_loss=140.66873\n",
      "Epoch 25324: train_loss=130.16052, val_loss=140.67589\n",
      "Epoch 25325: train_loss=130.14906, val_loss=140.65387\n",
      "Epoch 25326: train_loss=130.13884, val_loss=140.65207\n",
      "Epoch 25327: train_loss=130.12953, val_loss=140.63945\n",
      "Epoch 25328: train_loss=130.12111, val_loss=140.63078\n",
      "Epoch 25329: train_loss=130.11307, val_loss=140.62680\n",
      "Epoch 25330: train_loss=130.10541, val_loss=140.61427\n",
      "Epoch 25331: train_loss=130.09819, val_loss=140.61890\n",
      "Epoch 25332: train_loss=130.09117, val_loss=140.59950\n",
      "Epoch 25333: train_loss=130.08449, val_loss=140.60808\n",
      "Epoch 25334: train_loss=130.07819, val_loss=140.58165\n",
      "Epoch 25335: train_loss=130.07239, val_loss=140.59875\n",
      "Epoch 25336: train_loss=130.06718, val_loss=140.56874\n",
      "Epoch 25337: train_loss=130.06282, val_loss=140.59828\n",
      "Epoch 25338: train_loss=130.05914, val_loss=140.56123\n",
      "Epoch 25339: train_loss=130.05681, val_loss=140.60069\n",
      "Epoch 25340: train_loss=130.05605, val_loss=140.55525\n",
      "Epoch 25341: train_loss=130.05775, val_loss=140.61070\n",
      "Epoch 25342: train_loss=130.06165, val_loss=140.55836\n",
      "Epoch 25343: train_loss=130.06946, val_loss=140.63863\n",
      "Epoch 25344: train_loss=130.08023, val_loss=140.58092\n",
      "Epoch 25345: train_loss=130.09714, val_loss=140.68922\n",
      "Epoch 25346: train_loss=130.11681, val_loss=140.61900\n",
      "Epoch 25347: train_loss=130.14272, val_loss=140.75232\n",
      "Epoch 25348: train_loss=130.16882, val_loss=140.66385\n",
      "Epoch 25349: train_loss=130.19849, val_loss=140.81232\n",
      "Epoch 25350: train_loss=130.22256, val_loss=140.69833\n",
      "Epoch 25351: train_loss=130.24254, val_loss=140.83719\n",
      "Epoch 25352: train_loss=130.24435, val_loss=140.68655\n",
      "Epoch 25353: train_loss=130.23221, val_loss=140.78427\n",
      "Epoch 25354: train_loss=130.19431, val_loss=140.60794\n",
      "Epoch 25355: train_loss=130.14192, val_loss=140.65218\n",
      "Epoch 25356: train_loss=130.07417, val_loss=140.49060\n",
      "Epoch 25357: train_loss=130.00616, val_loss=140.49927\n",
      "Epoch 25358: train_loss=129.94440, val_loss=140.40204\n",
      "Epoch 25359: train_loss=129.89825, val_loss=140.39735\n",
      "Epoch 25360: train_loss=129.87035, val_loss=140.38214\n",
      "Epoch 25361: train_loss=129.86029, val_loss=140.36845\n",
      "Epoch 25362: train_loss=129.86365, val_loss=140.41577\n",
      "Epoch 25363: train_loss=129.87439, val_loss=140.38234\n",
      "Epoch 25364: train_loss=129.88747, val_loss=140.45430\n",
      "Epoch 25365: train_loss=129.89703, val_loss=140.39259\n",
      "Epoch 25366: train_loss=129.90054, val_loss=140.45682\n",
      "Epoch 25367: train_loss=129.89537, val_loss=140.37526\n",
      "Epoch 25368: train_loss=129.88316, val_loss=140.42131\n",
      "Epoch 25369: train_loss=129.86406, val_loss=140.33858\n",
      "Epoch 25370: train_loss=129.84106, val_loss=140.36372\n",
      "Epoch 25371: train_loss=129.81709, val_loss=140.30017\n",
      "Epoch 25372: train_loss=129.79509, val_loss=140.31093\n",
      "Epoch 25373: train_loss=129.77577, val_loss=140.27826\n",
      "Epoch 25374: train_loss=129.76089, val_loss=140.27580\n",
      "Epoch 25375: train_loss=129.75021, val_loss=140.27113\n",
      "Epoch 25376: train_loss=129.74327, val_loss=140.25490\n",
      "Epoch 25377: train_loss=129.73886, val_loss=140.27014\n",
      "Epoch 25378: train_loss=129.73567, val_loss=140.24261\n",
      "Epoch 25379: train_loss=129.73279, val_loss=140.27071\n",
      "Epoch 25380: train_loss=129.72906, val_loss=140.23317\n",
      "Epoch 25381: train_loss=129.72473, val_loss=140.26273\n",
      "Epoch 25382: train_loss=129.71881, val_loss=140.21805\n",
      "Epoch 25383: train_loss=129.71175, val_loss=140.24510\n",
      "Epoch 25384: train_loss=129.70349, val_loss=140.19934\n",
      "Epoch 25385: train_loss=129.69420, val_loss=140.22363\n",
      "Epoch 25386: train_loss=129.68417, val_loss=140.18164\n",
      "Epoch 25387: train_loss=129.67377, val_loss=140.20096\n",
      "Epoch 25388: train_loss=129.66327, val_loss=140.16400\n",
      "Epoch 25389: train_loss=129.65306, val_loss=140.17792\n",
      "Epoch 25390: train_loss=129.64310, val_loss=140.14684\n",
      "Epoch 25391: train_loss=129.63327, val_loss=140.15532\n",
      "Epoch 25392: train_loss=129.62366, val_loss=140.13089\n",
      "Epoch 25393: train_loss=129.61461, val_loss=140.13559\n",
      "Epoch 25394: train_loss=129.60582, val_loss=140.11520\n",
      "Epoch 25395: train_loss=129.59734, val_loss=140.11501\n",
      "Epoch 25396: train_loss=129.58896, val_loss=140.09836\n",
      "Epoch 25397: train_loss=129.58095, val_loss=140.09763\n",
      "Epoch 25398: train_loss=129.57306, val_loss=140.08676\n",
      "Epoch 25399: train_loss=129.56526, val_loss=140.08469\n",
      "Epoch 25400: train_loss=129.55742, val_loss=140.07300\n",
      "Epoch 25401: train_loss=129.54970, val_loss=140.06834\n",
      "Epoch 25402: train_loss=129.54192, val_loss=140.05501\n",
      "Epoch 25403: train_loss=129.53424, val_loss=140.04930\n",
      "Epoch 25404: train_loss=129.52655, val_loss=140.03749\n",
      "Epoch 25405: train_loss=129.51898, val_loss=140.03551\n",
      "Epoch 25406: train_loss=129.51147, val_loss=140.02431\n",
      "Epoch 25407: train_loss=129.50398, val_loss=140.02509\n",
      "Epoch 25408: train_loss=129.49678, val_loss=140.00893\n",
      "Epoch 25409: train_loss=129.48985, val_loss=140.01315\n",
      "Epoch 25410: train_loss=129.48344, val_loss=139.99132\n",
      "Epoch 25411: train_loss=129.47798, val_loss=140.00583\n",
      "Epoch 25412: train_loss=129.47371, val_loss=139.97745\n",
      "Epoch 25413: train_loss=129.47130, val_loss=140.00830\n",
      "Epoch 25414: train_loss=129.47105, val_loss=139.97269\n",
      "Epoch 25415: train_loss=129.47395, val_loss=140.02686\n",
      "Epoch 25416: train_loss=129.48083, val_loss=139.98291\n",
      "Epoch 25417: train_loss=129.49339, val_loss=140.06882\n",
      "Epoch 25418: train_loss=129.51210, val_loss=140.01772\n",
      "Epoch 25419: train_loss=129.54030, val_loss=140.14627\n",
      "Epoch 25420: train_loss=129.57545, val_loss=140.08733\n",
      "Epoch 25421: train_loss=129.62286, val_loss=140.26126\n",
      "Epoch 25422: train_loss=129.67285, val_loss=140.18259\n",
      "Epoch 25423: train_loss=129.72798, val_loss=140.37405\n",
      "Epoch 25424: train_loss=129.76996, val_loss=140.24799\n",
      "Epoch 25425: train_loss=129.79987, val_loss=140.40009\n",
      "Epoch 25426: train_loss=129.79167, val_loss=140.20197\n",
      "Epoch 25427: train_loss=129.75227, val_loss=140.26241\n",
      "Epoch 25428: train_loss=129.66963, val_loss=140.03152\n",
      "Epoch 25429: train_loss=129.56909, val_loss=140.02370\n",
      "Epoch 25430: train_loss=129.46342, val_loss=139.86443\n",
      "Epoch 25431: train_loss=129.37857, val_loss=139.85196\n",
      "Epoch 25432: train_loss=129.32533, val_loss=139.82475\n",
      "Epoch 25433: train_loss=129.30659, val_loss=139.81956\n",
      "Epoch 25434: train_loss=129.31516, val_loss=139.88684\n",
      "Epoch 25435: train_loss=129.33919, val_loss=139.85489\n",
      "Epoch 25436: train_loss=129.36690, val_loss=139.94746\n",
      "Epoch 25437: train_loss=129.38623, val_loss=139.87030\n",
      "Epoch 25438: train_loss=129.39099, val_loss=139.93726\n",
      "Epoch 25439: train_loss=129.37727, val_loss=139.83319\n",
      "Epoch 25440: train_loss=129.35063, val_loss=139.86407\n",
      "Epoch 25441: train_loss=129.31482, val_loss=139.77325\n",
      "Epoch 25442: train_loss=129.27872, val_loss=139.78189\n",
      "Epoch 25443: train_loss=129.24786, val_loss=139.74055\n",
      "Epoch 25444: train_loss=129.22739, val_loss=139.73567\n",
      "Epoch 25445: train_loss=129.21703, val_loss=139.74388\n",
      "Epoch 25446: train_loss=129.21490, val_loss=139.72321\n",
      "Epoch 25447: train_loss=129.21791, val_loss=139.76192\n",
      "Epoch 25448: train_loss=129.22208, val_loss=139.72281\n",
      "Epoch 25449: train_loss=129.22470, val_loss=139.76836\n",
      "Epoch 25450: train_loss=129.22246, val_loss=139.71233\n",
      "Epoch 25451: train_loss=129.21550, val_loss=139.74802\n",
      "Epoch 25452: train_loss=129.20335, val_loss=139.68924\n",
      "Epoch 25453: train_loss=129.18871, val_loss=139.71225\n",
      "Epoch 25454: train_loss=129.17236, val_loss=139.66605\n",
      "Epoch 25455: train_loss=129.15669, val_loss=139.67555\n",
      "Epoch 25456: train_loss=129.14262, val_loss=139.64644\n",
      "Epoch 25457: train_loss=129.13055, val_loss=139.64424\n",
      "Epoch 25458: train_loss=129.12091, val_loss=139.63448\n",
      "Epoch 25459: train_loss=129.11319, val_loss=139.62378\n",
      "Epoch 25460: train_loss=129.10684, val_loss=139.63139\n",
      "Epoch 25461: train_loss=129.10167, val_loss=139.61139\n",
      "Epoch 25462: train_loss=129.09694, val_loss=139.62621\n",
      "Epoch 25463: train_loss=129.09236, val_loss=139.59613\n",
      "Epoch 25464: train_loss=129.08752, val_loss=139.61501\n",
      "Epoch 25465: train_loss=129.08217, val_loss=139.58044\n",
      "Epoch 25466: train_loss=129.07605, val_loss=139.60303\n",
      "Epoch 25467: train_loss=129.06931, val_loss=139.56668\n",
      "Epoch 25468: train_loss=129.06180, val_loss=139.58794\n",
      "Epoch 25469: train_loss=129.05380, val_loss=139.55217\n",
      "Epoch 25470: train_loss=129.04530, val_loss=139.56995\n",
      "Epoch 25471: train_loss=129.03661, val_loss=139.53571\n",
      "Epoch 25472: train_loss=129.02771, val_loss=139.55016\n",
      "Epoch 25473: train_loss=129.01884, val_loss=139.51933\n",
      "Epoch 25474: train_loss=129.01001, val_loss=139.52985\n",
      "Epoch 25475: train_loss=129.00133, val_loss=139.50349\n",
      "Epoch 25476: train_loss=128.99281, val_loss=139.51192\n",
      "Epoch 25477: train_loss=128.98450, val_loss=139.48962\n",
      "Epoch 25478: train_loss=128.97632, val_loss=139.49332\n",
      "Epoch 25479: train_loss=128.96828, val_loss=139.47536\n",
      "Epoch 25480: train_loss=128.96043, val_loss=139.47807\n",
      "Epoch 25481: train_loss=128.95271, val_loss=139.46310\n",
      "Epoch 25482: train_loss=128.94519, val_loss=139.46394\n",
      "Epoch 25483: train_loss=128.93765, val_loss=139.44774\n",
      "Epoch 25484: train_loss=128.93027, val_loss=139.44591\n",
      "Epoch 25485: train_loss=128.92293, val_loss=139.43060\n",
      "Epoch 25486: train_loss=128.91560, val_loss=139.43227\n",
      "Epoch 25487: train_loss=128.90834, val_loss=139.41818\n",
      "Epoch 25488: train_loss=128.90126, val_loss=139.42062\n",
      "Epoch 25489: train_loss=128.89430, val_loss=139.40343\n",
      "Epoch 25490: train_loss=128.88757, val_loss=139.40916\n",
      "Epoch 25491: train_loss=128.88127, val_loss=139.38797\n",
      "Epoch 25492: train_loss=128.87543, val_loss=139.40079\n",
      "Epoch 25493: train_loss=128.87030, val_loss=139.37546\n",
      "Epoch 25494: train_loss=128.86636, val_loss=139.39871\n",
      "Epoch 25495: train_loss=128.86348, val_loss=139.36659\n",
      "Epoch 25496: train_loss=128.86252, val_loss=139.40578\n",
      "Epoch 25497: train_loss=128.86357, val_loss=139.36667\n",
      "Epoch 25498: train_loss=128.86745, val_loss=139.42480\n",
      "Epoch 25499: train_loss=128.87424, val_loss=139.37543\n",
      "Epoch 25500: train_loss=128.88554, val_loss=139.45938\n",
      "Epoch 25501: train_loss=128.90083, val_loss=139.40286\n",
      "Epoch 25502: train_loss=128.92218, val_loss=139.51817\n",
      "Epoch 25503: train_loss=128.94702, val_loss=139.45276\n",
      "Epoch 25504: train_loss=128.98045, val_loss=139.59860\n",
      "Epoch 25505: train_loss=129.01328, val_loss=139.51396\n",
      "Epoch 25506: train_loss=129.05031, val_loss=139.67111\n",
      "Epoch 25507: train_loss=129.07578, val_loss=139.55141\n",
      "Epoch 25508: train_loss=129.09357, val_loss=139.68446\n",
      "Epoch 25509: train_loss=129.08565, val_loss=139.52104\n",
      "Epoch 25510: train_loss=129.05960, val_loss=139.59657\n",
      "Epoch 25511: train_loss=129.00429, val_loss=139.40947\n",
      "Epoch 25512: train_loss=128.93596, val_loss=139.42912\n",
      "Epoch 25513: train_loss=128.85774, val_loss=139.27998\n",
      "Epoch 25514: train_loss=128.78850, val_loss=139.27774\n",
      "Epoch 25515: train_loss=128.73470, val_loss=139.21620\n",
      "Epoch 25516: train_loss=128.70265, val_loss=139.21083\n",
      "Epoch 25517: train_loss=128.69133, val_loss=139.23361\n",
      "Epoch 25518: train_loss=128.69579, val_loss=139.21561\n",
      "Epoch 25519: train_loss=128.70987, val_loss=139.28285\n",
      "Epoch 25520: train_loss=128.72563, val_loss=139.23413\n",
      "Epoch 25521: train_loss=128.73799, val_loss=139.30447\n",
      "Epoch 25522: train_loss=128.74136, val_loss=139.22626\n",
      "Epoch 25523: train_loss=128.73499, val_loss=139.27650\n",
      "Epoch 25524: train_loss=128.71840, val_loss=139.19121\n",
      "Epoch 25525: train_loss=128.69600, val_loss=139.22095\n",
      "Epoch 25526: train_loss=128.67038, val_loss=139.15341\n",
      "Epoch 25527: train_loss=128.64590, val_loss=139.16469\n",
      "Epoch 25528: train_loss=128.62485, val_loss=139.12727\n",
      "Epoch 25529: train_loss=128.60904, val_loss=139.12454\n",
      "Epoch 25530: train_loss=128.59845, val_loss=139.11887\n",
      "Epoch 25531: train_loss=128.59198, val_loss=139.10481\n",
      "Epoch 25532: train_loss=128.58847, val_loss=139.12466\n",
      "Epoch 25533: train_loss=128.58681, val_loss=139.09816\n",
      "Epoch 25534: train_loss=128.58566, val_loss=139.12872\n",
      "Epoch 25535: train_loss=128.58403, val_loss=139.08849\n",
      "Epoch 25536: train_loss=128.58116, val_loss=139.12167\n",
      "Epoch 25537: train_loss=128.57649, val_loss=139.07593\n",
      "Epoch 25538: train_loss=128.57007, val_loss=139.10788\n",
      "Epoch 25539: train_loss=128.56163, val_loss=139.06108\n",
      "Epoch 25540: train_loss=128.55208, val_loss=139.08615\n",
      "Epoch 25541: train_loss=128.54147, val_loss=139.04124\n",
      "Epoch 25542: train_loss=128.53056, val_loss=139.05885\n",
      "Epoch 25543: train_loss=128.51973, val_loss=139.02292\n",
      "Epoch 25544: train_loss=128.50922, val_loss=139.03445\n",
      "Epoch 25545: train_loss=128.49908, val_loss=139.00807\n",
      "Epoch 25546: train_loss=128.48970, val_loss=139.01480\n",
      "Epoch 25547: train_loss=128.48091, val_loss=138.99725\n",
      "Epoch 25548: train_loss=128.47267, val_loss=138.99588\n",
      "Epoch 25549: train_loss=128.46487, val_loss=138.98381\n",
      "Epoch 25550: train_loss=128.45738, val_loss=138.97794\n",
      "Epoch 25551: train_loss=128.45023, val_loss=138.97122\n",
      "Epoch 25552: train_loss=128.44327, val_loss=138.96066\n",
      "Epoch 25553: train_loss=128.43643, val_loss=138.95824\n",
      "Epoch 25554: train_loss=128.42976, val_loss=138.94540\n",
      "Epoch 25555: train_loss=128.42326, val_loss=138.94832\n",
      "Epoch 25556: train_loss=128.41690, val_loss=138.93201\n",
      "Epoch 25557: train_loss=128.41087, val_loss=138.94084\n",
      "Epoch 25558: train_loss=128.40515, val_loss=138.91917\n",
      "Epoch 25559: train_loss=128.39977, val_loss=138.93257\n",
      "Epoch 25560: train_loss=128.39497, val_loss=138.90459\n",
      "Epoch 25561: train_loss=128.39088, val_loss=138.92685\n",
      "Epoch 25562: train_loss=128.38754, val_loss=138.89426\n",
      "Epoch 25563: train_loss=128.38545, val_loss=138.92963\n",
      "Epoch 25564: train_loss=128.38434, val_loss=138.89165\n",
      "Epoch 25565: train_loss=128.38496, val_loss=138.94054\n",
      "Epoch 25566: train_loss=128.38684, val_loss=138.89369\n",
      "Epoch 25567: train_loss=128.39096, val_loss=138.95677\n",
      "Epoch 25568: train_loss=128.39676, val_loss=138.90051\n",
      "Epoch 25569: train_loss=128.40511, val_loss=138.98004\n",
      "Epoch 25570: train_loss=128.41451, val_loss=138.91525\n",
      "Epoch 25571: train_loss=128.42685, val_loss=139.01285\n",
      "Epoch 25572: train_loss=128.43935, val_loss=138.94002\n",
      "Epoch 25573: train_loss=128.45670, val_loss=139.05450\n",
      "Epoch 25574: train_loss=128.47104, val_loss=138.96761\n",
      "Epoch 25575: train_loss=128.48758, val_loss=139.08705\n",
      "Epoch 25576: train_loss=128.49640, val_loss=138.97591\n",
      "Epoch 25577: train_loss=128.50105, val_loss=139.07869\n",
      "Epoch 25578: train_loss=128.49112, val_loss=138.94560\n",
      "Epoch 25579: train_loss=128.47244, val_loss=139.02104\n",
      "Epoch 25580: train_loss=128.43933, val_loss=138.88365\n",
      "Epoch 25581: train_loss=128.40051, val_loss=138.92708\n",
      "Epoch 25582: train_loss=128.35416, val_loss=138.80710\n",
      "Epoch 25583: train_loss=128.30908, val_loss=138.82466\n",
      "Epoch 25584: train_loss=128.26796, val_loss=138.74806\n",
      "Epoch 25585: train_loss=128.23563, val_loss=138.75026\n",
      "Epoch 25586: train_loss=128.21310, val_loss=138.72679\n",
      "Epoch 25587: train_loss=128.20042, val_loss=138.71910\n",
      "Epoch 25588: train_loss=128.19594, val_loss=138.73903\n",
      "Epoch 25589: train_loss=128.19685, val_loss=138.71436\n",
      "Epoch 25590: train_loss=128.20067, val_loss=138.75687\n",
      "Epoch 25591: train_loss=128.20483, val_loss=138.71481\n",
      "Epoch 25592: train_loss=128.20778, val_loss=138.76591\n",
      "Epoch 25593: train_loss=128.20770, val_loss=138.71194\n",
      "Epoch 25594: train_loss=128.20517, val_loss=138.76140\n",
      "Epoch 25595: train_loss=128.19919, val_loss=138.69901\n",
      "Epoch 25596: train_loss=128.19112, val_loss=138.74051\n",
      "Epoch 25597: train_loss=128.18025, val_loss=138.67659\n",
      "Epoch 25598: train_loss=128.16852, val_loss=138.70871\n",
      "Epoch 25599: train_loss=128.15498, val_loss=138.65102\n",
      "Epoch 25600: train_loss=128.14149, val_loss=138.67630\n",
      "Epoch 25601: train_loss=128.12775, val_loss=138.63080\n",
      "Epoch 25602: train_loss=128.11467, val_loss=138.64908\n",
      "Epoch 25603: train_loss=128.10231, val_loss=138.61671\n",
      "Epoch 25604: train_loss=128.09128, val_loss=138.62489\n",
      "Epoch 25605: train_loss=128.08112, val_loss=138.60310\n",
      "Epoch 25606: train_loss=128.07217, val_loss=138.60146\n",
      "Epoch 25607: train_loss=128.06412, val_loss=138.58826\n",
      "Epoch 25608: train_loss=128.05673, val_loss=138.58041\n",
      "Epoch 25609: train_loss=128.04994, val_loss=138.57828\n",
      "Epoch 25610: train_loss=128.04359, val_loss=138.56699\n",
      "Epoch 25611: train_loss=128.03754, val_loss=138.57414\n",
      "Epoch 25612: train_loss=128.03186, val_loss=138.55641\n",
      "Epoch 25613: train_loss=128.02660, val_loss=138.56702\n",
      "Epoch 25614: train_loss=128.02150, val_loss=138.54131\n",
      "Epoch 25615: train_loss=128.01720, val_loss=138.55856\n",
      "Epoch 25616: train_loss=128.01332, val_loss=138.52695\n",
      "Epoch 25617: train_loss=128.01041, val_loss=138.55588\n",
      "Epoch 25618: train_loss=128.00821, val_loss=138.52020\n",
      "Epoch 25619: train_loss=128.00740, val_loss=138.56270\n",
      "Epoch 25620: train_loss=128.00734, val_loss=138.52180\n",
      "Epoch 25621: train_loss=128.00929, val_loss=138.57738\n",
      "Epoch 25622: train_loss=128.01239, val_loss=138.52634\n",
      "Epoch 25623: train_loss=128.01801, val_loss=138.59627\n",
      "Epoch 25624: train_loss=128.02596, val_loss=138.53571\n",
      "Epoch 25625: train_loss=128.03683, val_loss=138.62196\n",
      "Epoch 25626: train_loss=128.04822, val_loss=138.55139\n",
      "Epoch 25627: train_loss=128.06175, val_loss=138.65388\n",
      "Epoch 25628: train_loss=128.07329, val_loss=138.57271\n",
      "Epoch 25629: train_loss=128.08545, val_loss=138.68269\n",
      "Epoch 25630: train_loss=128.09262, val_loss=138.58481\n",
      "Epoch 25631: train_loss=128.09683, val_loss=138.68529\n",
      "Epoch 25632: train_loss=128.09161, val_loss=138.56932\n",
      "Epoch 25633: train_loss=128.08128, val_loss=138.64900\n",
      "Epoch 25634: train_loss=128.05951, val_loss=138.52225\n",
      "Epoch 25635: train_loss=128.03143, val_loss=138.57407\n",
      "Epoch 25636: train_loss=127.99451, val_loss=138.45703\n",
      "Epoch 25637: train_loss=127.95650, val_loss=138.48602\n",
      "Epoch 25638: train_loss=127.91872, val_loss=138.40080\n",
      "Epoch 25639: train_loss=127.88570, val_loss=138.41484\n",
      "Epoch 25640: train_loss=127.85935, val_loss=138.37047\n",
      "Epoch 25641: train_loss=127.84020, val_loss=138.37085\n",
      "Epoch 25642: train_loss=127.82774, val_loss=138.36435\n",
      "Epoch 25643: train_loss=127.82095, val_loss=138.35146\n",
      "Epoch 25644: train_loss=127.81833, val_loss=138.37260\n",
      "Epoch 25645: train_loss=127.81811, val_loss=138.34557\n",
      "Epoch 25646: train_loss=127.81921, val_loss=138.38275\n",
      "Epoch 25647: train_loss=127.82037, val_loss=138.34221\n",
      "Epoch 25648: train_loss=127.82083, val_loss=138.38634\n",
      "Epoch 25649: train_loss=127.82027, val_loss=138.33537\n",
      "Epoch 25650: train_loss=127.81811, val_loss=138.38181\n",
      "Epoch 25651: train_loss=127.81476, val_loss=138.32500\n",
      "Epoch 25652: train_loss=127.80991, val_loss=138.37140\n",
      "Epoch 25653: train_loss=127.80367, val_loss=138.31216\n",
      "Epoch 25654: train_loss=127.79618, val_loss=138.35605\n",
      "Epoch 25655: train_loss=127.78757, val_loss=138.29880\n",
      "Epoch 25656: train_loss=127.77833, val_loss=138.33994\n",
      "Epoch 25657: train_loss=127.76847, val_loss=138.28450\n",
      "Epoch 25658: train_loss=127.75826, val_loss=138.31902\n",
      "Epoch 25659: train_loss=127.74772, val_loss=138.26582\n",
      "Epoch 25660: train_loss=127.73700, val_loss=138.29173\n",
      "Epoch 25661: train_loss=127.72596, val_loss=138.24352\n",
      "Epoch 25662: train_loss=127.71527, val_loss=138.26515\n",
      "Epoch 25663: train_loss=127.70477, val_loss=138.22659\n",
      "Epoch 25664: train_loss=127.69475, val_loss=138.24586\n",
      "Epoch 25665: train_loss=127.68497, val_loss=138.21538\n",
      "Epoch 25666: train_loss=127.67553, val_loss=138.22643\n",
      "Epoch 25667: train_loss=127.66656, val_loss=138.19994\n",
      "Epoch 25668: train_loss=127.65787, val_loss=138.20329\n",
      "Epoch 25669: train_loss=127.64980, val_loss=138.18387\n",
      "Epoch 25670: train_loss=127.64199, val_loss=138.18494\n",
      "Epoch 25671: train_loss=127.63467, val_loss=138.17400\n",
      "Epoch 25672: train_loss=127.62744, val_loss=138.17213\n",
      "Epoch 25673: train_loss=127.62061, val_loss=138.16408\n",
      "Epoch 25674: train_loss=127.61384, val_loss=138.15643\n",
      "Epoch 25675: train_loss=127.60724, val_loss=138.14934\n",
      "Epoch 25676: train_loss=127.60069, val_loss=138.13904\n",
      "Epoch 25677: train_loss=127.59421, val_loss=138.13620\n",
      "Epoch 25678: train_loss=127.58782, val_loss=138.12463\n",
      "Epoch 25679: train_loss=127.58158, val_loss=138.12708\n",
      "Epoch 25680: train_loss=127.57545, val_loss=138.11398\n",
      "Epoch 25681: train_loss=127.56946, val_loss=138.12117\n",
      "Epoch 25682: train_loss=127.56377, val_loss=138.10339\n",
      "Epoch 25683: train_loss=127.55858, val_loss=138.11531\n",
      "Epoch 25684: train_loss=127.55401, val_loss=138.09111\n",
      "Epoch 25685: train_loss=127.55050, val_loss=138.11166\n",
      "Epoch 25686: train_loss=127.54838, val_loss=138.08086\n",
      "Epoch 25687: train_loss=127.54885, val_loss=138.12122\n",
      "Epoch 25688: train_loss=127.55253, val_loss=138.08542\n",
      "Epoch 25689: train_loss=127.56136, val_loss=138.15666\n",
      "Epoch 25690: train_loss=127.57611, val_loss=138.11639\n",
      "Epoch 25691: train_loss=127.60059, val_loss=138.23003\n",
      "Epoch 25692: train_loss=127.63173, val_loss=138.18277\n",
      "Epoch 25693: train_loss=127.67600, val_loss=138.34755\n",
      "Epoch 25694: train_loss=127.72978, val_loss=138.28958\n",
      "Epoch 25695: train_loss=127.79720, val_loss=138.49588\n",
      "Epoch 25696: train_loss=127.86237, val_loss=138.40660\n",
      "Epoch 25697: train_loss=127.92853, val_loss=138.60706\n",
      "Epoch 25698: train_loss=127.96237, val_loss=138.44179\n",
      "Epoch 25699: train_loss=127.96735, val_loss=138.55086\n",
      "Epoch 25700: train_loss=127.90926, val_loss=138.29999\n",
      "Epoch 25701: train_loss=127.81161, val_loss=138.29852\n",
      "Epoch 25702: train_loss=127.67936, val_loss=138.07301\n",
      "Epoch 25703: train_loss=127.55401, val_loss=138.04250\n",
      "Epoch 25704: train_loss=127.45904, val_loss=137.96700\n",
      "Epoch 25705: train_loss=127.41368, val_loss=137.96049\n",
      "Epoch 25706: train_loss=127.41414, val_loss=138.02924\n",
      "Epoch 25707: train_loss=127.44671, val_loss=138.01340\n",
      "Epoch 25708: train_loss=127.49203, val_loss=138.12938\n",
      "Epoch 25709: train_loss=127.52735, val_loss=138.05487\n",
      "Epoch 25710: train_loss=127.54295, val_loss=138.13237\n",
      "Epoch 25711: train_loss=127.52719, val_loss=138.01047\n",
      "Epoch 25712: train_loss=127.49065, val_loss=138.03377\n",
      "Epoch 25713: train_loss=127.43958, val_loss=137.93153\n",
      "Epoch 25714: train_loss=127.39257, val_loss=137.93040\n",
      "Epoch 25715: train_loss=127.35828, val_loss=137.89806\n",
      "Epoch 25716: train_loss=127.34116, val_loss=137.88963\n",
      "Epoch 25717: train_loss=127.33947, val_loss=137.92311\n",
      "Epoch 25718: train_loss=127.34792, val_loss=137.89777\n",
      "Epoch 25719: train_loss=127.35967, val_loss=137.95682\n",
      "Epoch 25720: train_loss=127.36830, val_loss=137.90465\n",
      "Epoch 25721: train_loss=127.36964, val_loss=137.95337\n",
      "Epoch 25722: train_loss=127.36134, val_loss=137.88445\n",
      "Epoch 25723: train_loss=127.34597, val_loss=137.90996\n",
      "Epoch 25724: train_loss=127.32585, val_loss=137.85031\n",
      "Epoch 25725: train_loss=127.30517, val_loss=137.86034\n",
      "Epoch 25726: train_loss=127.28720, val_loss=137.83017\n",
      "Epoch 25727: train_loss=127.27361, val_loss=137.82861\n",
      "Epoch 25728: train_loss=127.26467, val_loss=137.82773\n",
      "Epoch 25729: train_loss=127.25989, val_loss=137.81134\n",
      "Epoch 25730: train_loss=127.25764, val_loss=137.83040\n",
      "Epoch 25731: train_loss=127.25633, val_loss=137.80305\n",
      "Epoch 25732: train_loss=127.25471, val_loss=137.83057\n",
      "Epoch 25733: train_loss=127.25142, val_loss=137.79488\n",
      "Epoch 25734: train_loss=127.24635, val_loss=137.82072\n",
      "Epoch 25735: train_loss=127.23959, val_loss=137.78072\n",
      "Epoch 25736: train_loss=127.23122, val_loss=137.79845\n",
      "Epoch 25737: train_loss=127.22173, val_loss=137.76158\n",
      "Epoch 25738: train_loss=127.21190, val_loss=137.77313\n",
      "Epoch 25739: train_loss=127.20210, val_loss=137.74707\n",
      "Epoch 25740: train_loss=127.19276, val_loss=137.75122\n",
      "Epoch 25741: train_loss=127.18426, val_loss=137.73698\n",
      "Epoch 25742: train_loss=127.17661, val_loss=137.73456\n",
      "Epoch 25743: train_loss=127.16986, val_loss=137.73189\n",
      "Epoch 25744: train_loss=127.16384, val_loss=137.72092\n",
      "Epoch 25745: train_loss=127.15826, val_loss=137.72366\n",
      "Epoch 25746: train_loss=127.15292, val_loss=137.70520\n",
      "Epoch 25747: train_loss=127.14779, val_loss=137.71281\n",
      "Epoch 25748: train_loss=127.14268, val_loss=137.69106\n",
      "Epoch 25749: train_loss=127.13759, val_loss=137.70393\n",
      "Epoch 25750: train_loss=127.13254, val_loss=137.68004\n",
      "Epoch 25751: train_loss=127.12751, val_loss=137.69717\n",
      "Epoch 25752: train_loss=127.12255, val_loss=137.67097\n",
      "Epoch 25753: train_loss=127.11769, val_loss=137.69110\n",
      "Epoch 25754: train_loss=127.11295, val_loss=137.65948\n",
      "Epoch 25755: train_loss=127.10815, val_loss=137.68092\n",
      "Epoch 25756: train_loss=127.10346, val_loss=137.64600\n",
      "Epoch 25757: train_loss=127.09866, val_loss=137.67105\n",
      "Epoch 25758: train_loss=127.09383, val_loss=137.63478\n",
      "Epoch 25759: train_loss=127.08902, val_loss=137.66420\n",
      "Epoch 25760: train_loss=127.08422, val_loss=137.62767\n",
      "Epoch 25761: train_loss=127.07958, val_loss=137.66090\n",
      "Epoch 25762: train_loss=127.07516, val_loss=137.62035\n",
      "Epoch 25763: train_loss=127.07102, val_loss=137.65364\n",
      "Epoch 25764: train_loss=127.06715, val_loss=137.60910\n",
      "Epoch 25765: train_loss=127.06346, val_loss=137.64684\n",
      "Epoch 25766: train_loss=127.05989, val_loss=137.60051\n",
      "Epoch 25767: train_loss=127.05659, val_loss=137.64232\n",
      "Epoch 25768: train_loss=127.05368, val_loss=137.59206\n",
      "Epoch 25769: train_loss=127.05064, val_loss=137.63931\n",
      "Epoch 25770: train_loss=127.04791, val_loss=137.58684\n",
      "Epoch 25771: train_loss=127.04511, val_loss=137.63745\n",
      "Epoch 25772: train_loss=127.04256, val_loss=137.58173\n",
      "Epoch 25773: train_loss=127.04026, val_loss=137.63664\n",
      "Epoch 25774: train_loss=127.03807, val_loss=137.57664\n",
      "Epoch 25775: train_loss=127.03555, val_loss=137.63281\n",
      "Epoch 25776: train_loss=127.03274, val_loss=137.56778\n",
      "Epoch 25777: train_loss=127.02944, val_loss=137.62453\n",
      "Epoch 25778: train_loss=127.02511, val_loss=137.55588\n",
      "Epoch 25779: train_loss=127.02027, val_loss=137.61296\n",
      "Epoch 25780: train_loss=127.01402, val_loss=137.54366\n",
      "Epoch 25781: train_loss=127.00748, val_loss=137.59943\n",
      "Epoch 25782: train_loss=126.99959, val_loss=137.53104\n",
      "Epoch 25783: train_loss=126.99111, val_loss=137.58218\n",
      "Epoch 25784: train_loss=126.98159, val_loss=137.51175\n",
      "Epoch 25785: train_loss=126.97144, val_loss=137.55623\n",
      "Epoch 25786: train_loss=126.96040, val_loss=137.49014\n",
      "Epoch 25787: train_loss=126.94897, val_loss=137.52956\n",
      "Epoch 25788: train_loss=126.93687, val_loss=137.46896\n",
      "Epoch 25789: train_loss=126.92456, val_loss=137.50143\n",
      "Epoch 25790: train_loss=126.91196, val_loss=137.44930\n",
      "Epoch 25791: train_loss=126.89931, val_loss=137.47305\n",
      "Epoch 25792: train_loss=126.88707, val_loss=137.42844\n",
      "Epoch 25793: train_loss=126.87569, val_loss=137.44460\n",
      "Epoch 25794: train_loss=126.86491, val_loss=137.41084\n",
      "Epoch 25795: train_loss=126.85520, val_loss=137.42120\n",
      "Epoch 25796: train_loss=126.84621, val_loss=137.39699\n",
      "Epoch 25797: train_loss=126.83807, val_loss=137.40244\n",
      "Epoch 25798: train_loss=126.83023, val_loss=137.38603\n",
      "Epoch 25799: train_loss=126.82303, val_loss=137.38651\n",
      "Epoch 25800: train_loss=126.81617, val_loss=137.37331\n",
      "Epoch 25801: train_loss=126.80962, val_loss=137.36868\n",
      "Epoch 25802: train_loss=126.80328, val_loss=137.36012\n",
      "Epoch 25803: train_loss=126.79703, val_loss=137.35342\n",
      "Epoch 25804: train_loss=126.79090, val_loss=137.34953\n",
      "Epoch 25805: train_loss=126.78485, val_loss=137.34138\n",
      "Epoch 25806: train_loss=126.77881, val_loss=137.34021\n",
      "Epoch 25807: train_loss=126.77299, val_loss=137.32700\n",
      "Epoch 25808: train_loss=126.76726, val_loss=137.32867\n",
      "Epoch 25809: train_loss=126.76171, val_loss=137.31262\n",
      "Epoch 25810: train_loss=126.75648, val_loss=137.32094\n",
      "Epoch 25811: train_loss=126.75182, val_loss=137.30153\n",
      "Epoch 25812: train_loss=126.74805, val_loss=137.32045\n",
      "Epoch 25813: train_loss=126.74540, val_loss=137.29498\n",
      "Epoch 25814: train_loss=126.74468, val_loss=137.32730\n",
      "Epoch 25815: train_loss=126.74640, val_loss=137.29306\n",
      "Epoch 25816: train_loss=126.75166, val_loss=137.34979\n",
      "Epoch 25817: train_loss=126.76163, val_loss=137.31128\n",
      "Epoch 25818: train_loss=126.77937, val_loss=137.40784\n",
      "Epoch 25819: train_loss=126.80534, val_loss=137.36433\n",
      "Epoch 25820: train_loss=126.84283, val_loss=137.51074\n",
      "Epoch 25821: train_loss=126.89097, val_loss=137.45988\n",
      "Epoch 25822: train_loss=126.95314, val_loss=137.65620\n",
      "Epoch 25823: train_loss=127.01960, val_loss=137.58406\n",
      "Epoch 25824: train_loss=127.09215, val_loss=137.79517\n",
      "Epoch 25825: train_loss=127.14438, val_loss=137.66080\n",
      "Epoch 25826: train_loss=127.17486, val_loss=137.80212\n",
      "Epoch 25827: train_loss=127.14895, val_loss=137.57268\n",
      "Epoch 25828: train_loss=127.07991, val_loss=137.59523\n",
      "Epoch 25829: train_loss=126.96120, val_loss=137.34639\n",
      "Epoch 25830: train_loss=126.83193, val_loss=137.31563\n",
      "Epoch 25831: train_loss=126.71671, val_loss=137.18933\n",
      "Epoch 25832: train_loss=126.64237, val_loss=137.17844\n",
      "Epoch 25833: train_loss=126.61471, val_loss=137.20557\n",
      "Epoch 25834: train_loss=126.62633, val_loss=137.19856\n",
      "Epoch 25835: train_loss=126.66126, val_loss=137.30377\n",
      "Epoch 25836: train_loss=126.70069, val_loss=137.25424\n",
      "Epoch 25837: train_loss=126.72964, val_loss=137.34657\n",
      "Epoch 25838: train_loss=126.73476, val_loss=137.23979\n",
      "Epoch 25839: train_loss=126.71683, val_loss=137.27939\n",
      "Epoch 25840: train_loss=126.67849, val_loss=137.16705\n",
      "Epoch 25841: train_loss=126.63335, val_loss=137.17416\n",
      "Epoch 25842: train_loss=126.59181, val_loss=137.11510\n",
      "Epoch 25843: train_loss=126.56239, val_loss=137.11209\n",
      "Epoch 25844: train_loss=126.54893, val_loss=137.12291\n",
      "Epoch 25845: train_loss=126.54911, val_loss=137.10754\n",
      "Epoch 25846: train_loss=126.55727, val_loss=137.15582\n",
      "Epoch 25847: train_loss=126.56719, val_loss=137.11597\n",
      "Epoch 25848: train_loss=126.57345, val_loss=137.16624\n",
      "Epoch 25849: train_loss=126.57190, val_loss=137.10532\n",
      "Epoch 25850: train_loss=126.56320, val_loss=137.13800\n",
      "Epoch 25851: train_loss=126.54766, val_loss=137.07649\n",
      "Epoch 25852: train_loss=126.52943, val_loss=137.09137\n",
      "Epoch 25853: train_loss=126.51138, val_loss=137.05223\n",
      "Epoch 25854: train_loss=126.49573, val_loss=137.05540\n",
      "Epoch 25855: train_loss=126.48439, val_loss=137.04723\n",
      "Epoch 25856: train_loss=126.47753, val_loss=137.03775\n",
      "Epoch 25857: train_loss=126.47418, val_loss=137.05284\n",
      "Epoch 25858: train_loss=126.47283, val_loss=137.02994\n",
      "Epoch 25859: train_loss=126.47167, val_loss=137.05406\n",
      "Epoch 25860: train_loss=126.46982, val_loss=137.01929\n",
      "Epoch 25861: train_loss=126.46596, val_loss=137.04414\n",
      "Epoch 25862: train_loss=126.46021, val_loss=137.00642\n",
      "Epoch 25863: train_loss=126.45268, val_loss=137.02551\n",
      "Epoch 25864: train_loss=126.44398, val_loss=136.99110\n",
      "Epoch 25865: train_loss=126.43456, val_loss=137.00330\n",
      "Epoch 25866: train_loss=126.42531, val_loss=136.97800\n",
      "Epoch 25867: train_loss=126.41638, val_loss=136.98232\n",
      "Epoch 25868: train_loss=126.40827, val_loss=136.96661\n",
      "Epoch 25869: train_loss=126.40099, val_loss=136.96298\n",
      "Epoch 25870: train_loss=126.39453, val_loss=136.95752\n",
      "Epoch 25871: train_loss=126.38874, val_loss=136.94850\n",
      "Epoch 25872: train_loss=126.38333, val_loss=136.95018\n",
      "Epoch 25873: train_loss=126.37823, val_loss=136.93488\n",
      "Epoch 25874: train_loss=126.37353, val_loss=136.94214\n",
      "Epoch 25875: train_loss=126.36897, val_loss=136.92198\n",
      "Epoch 25876: train_loss=126.36461, val_loss=136.93628\n",
      "Epoch 25877: train_loss=126.36034, val_loss=136.91249\n",
      "Epoch 25878: train_loss=126.35611, val_loss=136.92987\n",
      "Epoch 25879: train_loss=126.35191, val_loss=136.90109\n",
      "Epoch 25880: train_loss=126.34757, val_loss=136.92188\n",
      "Epoch 25881: train_loss=126.34335, val_loss=136.89001\n",
      "Epoch 25882: train_loss=126.33889, val_loss=136.91431\n",
      "Epoch 25883: train_loss=126.33441, val_loss=136.88115\n",
      "Epoch 25884: train_loss=126.32961, val_loss=136.90825\n",
      "Epoch 25885: train_loss=126.32471, val_loss=136.87375\n",
      "Epoch 25886: train_loss=126.31963, val_loss=136.90150\n",
      "Epoch 25887: train_loss=126.31464, val_loss=136.86342\n",
      "Epoch 25888: train_loss=126.30921, val_loss=136.88930\n",
      "Epoch 25889: train_loss=126.30396, val_loss=136.84854\n",
      "Epoch 25890: train_loss=126.29862, val_loss=136.87506\n",
      "Epoch 25891: train_loss=126.29337, val_loss=136.83463\n",
      "Epoch 25892: train_loss=126.28806, val_loss=136.86452\n",
      "Epoch 25893: train_loss=126.28294, val_loss=136.82584\n",
      "Epoch 25894: train_loss=126.27787, val_loss=136.85913\n",
      "Epoch 25895: train_loss=126.27291, val_loss=136.82050\n",
      "Epoch 25896: train_loss=126.26839, val_loss=136.85614\n",
      "Epoch 25897: train_loss=126.26419, val_loss=136.81302\n",
      "Epoch 25898: train_loss=126.26036, val_loss=136.84860\n",
      "Epoch 25899: train_loss=126.25659, val_loss=136.80269\n",
      "Epoch 25900: train_loss=126.25340, val_loss=136.84331\n",
      "Epoch 25901: train_loss=126.25080, val_loss=136.79602\n",
      "Epoch 25902: train_loss=126.24922, val_loss=136.84422\n",
      "Epoch 25903: train_loss=126.24857, val_loss=136.79414\n",
      "Epoch 25904: train_loss=126.24937, val_loss=136.85263\n",
      "Epoch 25905: train_loss=126.25173, val_loss=136.79677\n",
      "Epoch 25906: train_loss=126.25604, val_loss=136.86523\n",
      "Epoch 25907: train_loss=126.26163, val_loss=136.80347\n",
      "Epoch 25908: train_loss=126.26994, val_loss=136.88808\n",
      "Epoch 25909: train_loss=126.27889, val_loss=136.81970\n",
      "Epoch 25910: train_loss=126.29094, val_loss=136.91716\n",
      "Epoch 25911: train_loss=126.30137, val_loss=136.83698\n",
      "Epoch 25912: train_loss=126.31213, val_loss=136.93892\n",
      "Epoch 25913: train_loss=126.31773, val_loss=136.84399\n",
      "Epoch 25914: train_loss=126.32076, val_loss=136.93852\n",
      "Epoch 25915: train_loss=126.31470, val_loss=136.82944\n",
      "Epoch 25916: train_loss=126.30374, val_loss=136.90419\n",
      "Epoch 25917: train_loss=126.28275, val_loss=136.78647\n",
      "Epoch 25918: train_loss=126.25719, val_loss=136.83662\n",
      "Epoch 25919: train_loss=126.22528, val_loss=136.72812\n",
      "Epoch 25920: train_loss=126.19241, val_loss=136.75842\n",
      "Epoch 25921: train_loss=126.15965, val_loss=136.67818\n",
      "Epoch 25922: train_loss=126.13051, val_loss=136.69392\n",
      "Epoch 25923: train_loss=126.10595, val_loss=136.65143\n",
      "Epoch 25924: train_loss=126.08751, val_loss=136.65227\n",
      "Epoch 25925: train_loss=126.07566, val_loss=136.64511\n",
      "Epoch 25926: train_loss=126.06959, val_loss=136.63251\n",
      "Epoch 25927: train_loss=126.06776, val_loss=136.65230\n",
      "Epoch 25928: train_loss=126.06863, val_loss=136.62575\n",
      "Epoch 25929: train_loss=126.07044, val_loss=136.66080\n",
      "Epoch 25930: train_loss=126.07182, val_loss=136.62155\n",
      "Epoch 25931: train_loss=126.07195, val_loss=136.66304\n",
      "Epoch 25932: train_loss=126.07040, val_loss=136.61563\n",
      "Epoch 25933: train_loss=126.06700, val_loss=136.65663\n",
      "Epoch 25934: train_loss=126.06190, val_loss=136.60513\n",
      "Epoch 25935: train_loss=126.05517, val_loss=136.64127\n",
      "Epoch 25936: train_loss=126.04717, val_loss=136.58911\n",
      "Epoch 25937: train_loss=126.03812, val_loss=136.61928\n",
      "Epoch 25938: train_loss=126.02846, val_loss=136.57182\n",
      "Epoch 25939: train_loss=126.01869, val_loss=136.59673\n",
      "Epoch 25940: train_loss=126.00884, val_loss=136.55580\n",
      "Epoch 25941: train_loss=125.99914, val_loss=136.57407\n",
      "Epoch 25942: train_loss=125.98981, val_loss=136.54164\n",
      "Epoch 25943: train_loss=125.98101, val_loss=136.55490\n",
      "Epoch 25944: train_loss=125.97250, val_loss=136.53111\n",
      "Epoch 25945: train_loss=125.96456, val_loss=136.53716\n",
      "Epoch 25946: train_loss=125.95731, val_loss=136.51788\n",
      "Epoch 25947: train_loss=125.95050, val_loss=136.51762\n",
      "Epoch 25948: train_loss=125.94400, val_loss=136.50528\n",
      "Epoch 25949: train_loss=125.93785, val_loss=136.50282\n",
      "Epoch 25950: train_loss=125.93192, val_loss=136.49657\n",
      "Epoch 25951: train_loss=125.92615, val_loss=136.49190\n",
      "Epoch 25952: train_loss=125.92044, val_loss=136.48915\n",
      "Epoch 25953: train_loss=125.91493, val_loss=136.48169\n",
      "Epoch 25954: train_loss=125.90929, val_loss=136.48039\n",
      "Epoch 25955: train_loss=125.90390, val_loss=136.46774\n",
      "Epoch 25956: train_loss=125.89866, val_loss=136.47028\n",
      "Epoch 25957: train_loss=125.89364, val_loss=136.45517\n",
      "Epoch 25958: train_loss=125.88900, val_loss=136.46526\n",
      "Epoch 25959: train_loss=125.88499, val_loss=136.44640\n",
      "Epoch 25960: train_loss=125.88174, val_loss=136.46684\n",
      "Epoch 25961: train_loss=125.87959, val_loss=136.44116\n",
      "Epoch 25962: train_loss=125.87911, val_loss=136.47578\n",
      "Epoch 25963: train_loss=125.88083, val_loss=136.44038\n",
      "Epoch 25964: train_loss=125.88542, val_loss=136.49342\n",
      "Epoch 25965: train_loss=125.89360, val_loss=136.45178\n",
      "Epoch 25966: train_loss=125.90706, val_loss=136.53809\n",
      "Epoch 25967: train_loss=125.92686, val_loss=136.49165\n",
      "Epoch 25968: train_loss=125.95596, val_loss=136.62263\n",
      "Epoch 25969: train_loss=125.99510, val_loss=136.57033\n",
      "Epoch 25970: train_loss=126.04691, val_loss=136.75247\n",
      "Epoch 25971: train_loss=126.10680, val_loss=136.68768\n",
      "Epoch 25972: train_loss=126.17684, val_loss=136.90314\n",
      "Epoch 25973: train_loss=126.23930, val_loss=136.79359\n",
      "Epoch 25974: train_loss=126.29099, val_loss=136.97154\n",
      "Epoch 25975: train_loss=126.29920, val_loss=136.76997\n",
      "Epoch 25976: train_loss=126.26642, val_loss=136.83569\n",
      "Epoch 25977: train_loss=126.17605, val_loss=136.57715\n",
      "Epoch 25978: train_loss=126.05710, val_loss=136.55812\n",
      "Epoch 25979: train_loss=125.92948, val_loss=136.37743\n",
      "Epoch 25980: train_loss=125.82720, val_loss=136.35855\n",
      "Epoch 25981: train_loss=125.76735, val_loss=136.33861\n",
      "Epoch 25982: train_loss=125.75360, val_loss=136.33665\n",
      "Epoch 25983: train_loss=125.77538, val_loss=136.42905\n",
      "Epoch 25984: train_loss=125.81452, val_loss=136.39616\n",
      "Epoch 25985: train_loss=125.85316, val_loss=136.50490\n",
      "Epoch 25986: train_loss=125.87554, val_loss=136.41365\n",
      "Epoch 25987: train_loss=125.87397, val_loss=136.47591\n",
      "Epoch 25988: train_loss=125.84740, val_loss=136.35588\n",
      "Epoch 25989: train_loss=125.80584, val_loss=136.37126\n",
      "Epoch 25990: train_loss=125.75998, val_loss=136.28772\n",
      "Epoch 25991: train_loss=125.72208, val_loss=136.28690\n",
      "Epoch 25992: train_loss=125.69879, val_loss=136.27916\n",
      "Epoch 25993: train_loss=125.69208, val_loss=136.26897\n",
      "Epoch 25994: train_loss=125.69779, val_loss=136.31503\n",
      "Epoch 25995: train_loss=125.70870, val_loss=136.28183\n",
      "Epoch 25996: train_loss=125.71851, val_loss=136.33725\n",
      "Epoch 25997: train_loss=125.72147, val_loss=136.27570\n",
      "Epoch 25998: train_loss=125.71565, val_loss=136.31364\n",
      "Epoch 25999: train_loss=125.70210, val_loss=136.24791\n",
      "Epoch 26000: train_loss=125.68393, val_loss=136.26610\n",
      "Epoch 26001: train_loss=125.66512, val_loss=136.22330\n",
      "Epoch 26002: train_loss=125.64889, val_loss=136.22765\n",
      "Epoch 26003: train_loss=125.63706, val_loss=136.21944\n",
      "Epoch 26004: train_loss=125.63022, val_loss=136.21140\n",
      "Epoch 26005: train_loss=125.62716, val_loss=136.22641\n",
      "Epoch 26006: train_loss=125.62630, val_loss=136.20087\n",
      "Epoch 26007: train_loss=125.62578, val_loss=136.22681\n",
      "Epoch 26008: train_loss=125.62422, val_loss=136.19234\n",
      "Epoch 26009: train_loss=125.62093, val_loss=136.21973\n",
      "Epoch 26010: train_loss=125.61526, val_loss=136.18256\n",
      "Epoch 26011: train_loss=125.60780, val_loss=136.20282\n",
      "Epoch 26012: train_loss=125.59897, val_loss=136.16928\n",
      "Epoch 26013: train_loss=125.58987, val_loss=136.17972\n",
      "Epoch 26014: train_loss=125.58086, val_loss=136.15582\n",
      "Epoch 26015: train_loss=125.57265, val_loss=136.15955\n",
      "Epoch 26016: train_loss=125.56522, val_loss=136.14708\n",
      "Epoch 26017: train_loss=125.55878, val_loss=136.14279\n",
      "Epoch 26018: train_loss=125.55303, val_loss=136.14088\n",
      "Epoch 26019: train_loss=125.54787, val_loss=136.13025\n",
      "Epoch 26020: train_loss=125.54321, val_loss=136.13593\n",
      "Epoch 26021: train_loss=125.53876, val_loss=136.11998\n",
      "Epoch 26022: train_loss=125.53463, val_loss=136.13167\n",
      "Epoch 26023: train_loss=125.53054, val_loss=136.11012\n",
      "Epoch 26024: train_loss=125.52668, val_loss=136.12778\n",
      "Epoch 26025: train_loss=125.52274, val_loss=136.10231\n",
      "Epoch 26026: train_loss=125.51901, val_loss=136.12239\n",
      "Epoch 26027: train_loss=125.51499, val_loss=136.09123\n",
      "Epoch 26028: train_loss=125.51096, val_loss=136.11426\n",
      "Epoch 26029: train_loss=125.50674, val_loss=136.08134\n",
      "Epoch 26030: train_loss=125.50229, val_loss=136.10815\n",
      "Epoch 26031: train_loss=125.49788, val_loss=136.07318\n",
      "Epoch 26032: train_loss=125.49311, val_loss=136.10112\n",
      "Epoch 26033: train_loss=125.48838, val_loss=136.06503\n",
      "Epoch 26034: train_loss=125.48355, val_loss=136.09378\n",
      "Epoch 26035: train_loss=125.47863, val_loss=136.05591\n",
      "Epoch 26036: train_loss=125.47385, val_loss=136.08412\n",
      "Epoch 26037: train_loss=125.46920, val_loss=136.04449\n",
      "Epoch 26038: train_loss=125.46464, val_loss=136.07602\n",
      "Epoch 26039: train_loss=125.46033, val_loss=136.03621\n",
      "Epoch 26040: train_loss=125.45628, val_loss=136.07146\n",
      "Epoch 26041: train_loss=125.45238, val_loss=136.03018\n",
      "Epoch 26042: train_loss=125.44859, val_loss=136.06619\n",
      "Epoch 26043: train_loss=125.44498, val_loss=136.02055\n",
      "Epoch 26044: train_loss=125.44142, val_loss=136.05930\n",
      "Epoch 26045: train_loss=125.43802, val_loss=136.01176\n",
      "Epoch 26046: train_loss=125.43460, val_loss=136.05481\n",
      "Epoch 26047: train_loss=125.43150, val_loss=136.00497\n",
      "Epoch 26048: train_loss=125.42863, val_loss=136.05222\n",
      "Epoch 26049: train_loss=125.42606, val_loss=136.00012\n",
      "Epoch 26050: train_loss=125.42352, val_loss=136.05077\n",
      "Epoch 26051: train_loss=125.42088, val_loss=135.99538\n",
      "Epoch 26052: train_loss=125.41808, val_loss=136.05106\n",
      "Epoch 26053: train_loss=125.41518, val_loss=135.99829\n",
      "Epoch 26054: train_loss=125.41181, val_loss=136.06676\n",
      "Epoch 26055: train_loss=125.40678, val_loss=136.02220\n",
      "Epoch 26056: train_loss=125.40232, val_loss=136.09602\n",
      "Epoch 26057: train_loss=125.39917, val_loss=136.04414\n",
      "Epoch 26058: train_loss=125.39603, val_loss=136.11501\n",
      "Epoch 26059: train_loss=125.39265, val_loss=136.05402\n",
      "Epoch 26060: train_loss=125.38869, val_loss=136.11739\n",
      "Epoch 26061: train_loss=125.38390, val_loss=136.04686\n",
      "Epoch 26062: train_loss=125.37768, val_loss=136.10056\n",
      "Epoch 26063: train_loss=125.37048, val_loss=136.02010\n",
      "Epoch 26064: train_loss=125.36213, val_loss=136.06238\n",
      "Epoch 26065: train_loss=125.35307, val_loss=135.98079\n",
      "Epoch 26066: train_loss=125.34308, val_loss=136.01711\n",
      "Epoch 26067: train_loss=125.33318, val_loss=135.93953\n",
      "Epoch 26068: train_loss=125.32242, val_loss=135.97226\n",
      "Epoch 26069: train_loss=125.31156, val_loss=135.90422\n",
      "Epoch 26070: train_loss=125.30056, val_loss=135.93463\n",
      "Epoch 26071: train_loss=125.28951, val_loss=135.87733\n",
      "Epoch 26072: train_loss=125.27833, val_loss=135.90343\n",
      "Epoch 26073: train_loss=125.26742, val_loss=135.85835\n",
      "Epoch 26074: train_loss=125.25714, val_loss=135.88116\n",
      "Epoch 26075: train_loss=125.24769, val_loss=135.84787\n",
      "Epoch 26076: train_loss=125.23871, val_loss=135.86659\n",
      "Epoch 26077: train_loss=125.23060, val_loss=135.84200\n",
      "Epoch 26078: train_loss=125.22299, val_loss=135.85672\n",
      "Epoch 26079: train_loss=125.21636, val_loss=135.83429\n",
      "Epoch 26080: train_loss=125.21001, val_loss=135.84041\n",
      "Epoch 26081: train_loss=125.20388, val_loss=135.81575\n",
      "Epoch 26082: train_loss=125.19787, val_loss=135.81743\n",
      "Epoch 26083: train_loss=125.19209, val_loss=135.79575\n",
      "Epoch 26084: train_loss=125.18667, val_loss=135.79962\n",
      "Epoch 26085: train_loss=125.18130, val_loss=135.78056\n",
      "Epoch 26086: train_loss=125.17611, val_loss=135.78854\n",
      "Epoch 26087: train_loss=125.17104, val_loss=135.77029\n",
      "Epoch 26088: train_loss=125.16630, val_loss=135.78397\n",
      "Epoch 26089: train_loss=125.16204, val_loss=135.76357\n",
      "Epoch 26090: train_loss=125.15824, val_loss=135.78558\n",
      "Epoch 26091: train_loss=125.15573, val_loss=135.75845\n",
      "Epoch 26092: train_loss=125.15440, val_loss=135.78845\n",
      "Epoch 26093: train_loss=125.15495, val_loss=135.74959\n",
      "Epoch 26094: train_loss=125.15838, val_loss=135.79884\n",
      "Epoch 26095: train_loss=125.16549, val_loss=135.75536\n",
      "Epoch 26096: train_loss=125.17773, val_loss=135.83958\n",
      "Epoch 26097: train_loss=125.19646, val_loss=135.79155\n",
      "Epoch 26098: train_loss=125.22318, val_loss=135.92198\n",
      "Epoch 26099: train_loss=125.25994, val_loss=135.87186\n",
      "Epoch 26100: train_loss=125.31051, val_loss=136.06082\n",
      "Epoch 26101: train_loss=125.37266, val_loss=135.99850\n",
      "Epoch 26102: train_loss=125.44702, val_loss=136.22594\n",
      "Epoch 26103: train_loss=125.51803, val_loss=136.11935\n",
      "Epoch 26104: train_loss=125.58032, val_loss=136.32014\n",
      "Epoch 26105: train_loss=125.60349, val_loss=136.12003\n",
      "Epoch 26106: train_loss=125.58495, val_loss=136.20918\n",
      "Epoch 26107: train_loss=125.50266, val_loss=135.93443\n",
      "Epoch 26108: train_loss=125.38252, val_loss=135.92241\n",
      "Epoch 26109: train_loss=125.24432, val_loss=135.71652\n",
      "Epoch 26110: train_loss=125.12818, val_loss=135.69563\n",
      "Epoch 26111: train_loss=125.05581, val_loss=135.65984\n",
      "Epoch 26112: train_loss=125.03441, val_loss=135.65422\n",
      "Epoch 26113: train_loss=125.05479, val_loss=135.74936\n",
      "Epoch 26114: train_loss=125.09666, val_loss=135.71469\n",
      "Epoch 26115: train_loss=125.13868, val_loss=135.83084\n",
      "Epoch 26116: train_loss=125.16253, val_loss=135.73276\n",
      "Epoch 26117: train_loss=125.15977, val_loss=135.79800\n",
      "Epoch 26118: train_loss=125.12993, val_loss=135.67352\n",
      "Epoch 26119: train_loss=125.08447, val_loss=135.69002\n",
      "Epoch 26120: train_loss=125.03735, val_loss=135.61053\n",
      "Epoch 26121: train_loss=125.00101, val_loss=135.60730\n",
      "Epoch 26122: train_loss=124.98158, val_loss=135.60545\n",
      "Epoch 26123: train_loss=124.97923, val_loss=135.58920\n",
      "Epoch 26124: train_loss=124.98828, val_loss=135.64279\n",
      "Epoch 26125: train_loss=125.00079, val_loss=135.60309\n",
      "Epoch 26126: train_loss=125.01047, val_loss=135.66435\n",
      "Epoch 26127: train_loss=125.01125, val_loss=135.59955\n",
      "Epoch 26128: train_loss=125.00232, val_loss=135.64035\n",
      "Epoch 26129: train_loss=124.98594, val_loss=135.57538\n",
      "Epoch 26130: train_loss=124.96648, val_loss=135.59087\n",
      "Epoch 26131: train_loss=124.94726, val_loss=135.55127\n",
      "Epoch 26132: train_loss=124.93264, val_loss=135.54898\n",
      "Epoch 26133: train_loss=124.92316, val_loss=135.54492\n",
      "Epoch 26134: train_loss=124.91856, val_loss=135.53165\n",
      "Epoch 26135: train_loss=124.91724, val_loss=135.55547\n",
      "Epoch 26136: train_loss=124.91734, val_loss=135.53035\n",
      "Epoch 26137: train_loss=124.91731, val_loss=135.56273\n",
      "Epoch 26138: train_loss=124.91562, val_loss=135.52307\n",
      "Epoch 26139: train_loss=124.91182, val_loss=135.54906\n",
      "Epoch 26140: train_loss=124.90550, val_loss=135.50612\n",
      "Epoch 26141: train_loss=124.89777, val_loss=135.52733\n",
      "Epoch 26142: train_loss=124.88865, val_loss=135.49327\n",
      "Epoch 26143: train_loss=124.87941, val_loss=135.50549\n",
      "Epoch 26144: train_loss=124.87053, val_loss=135.47969\n",
      "Epoch 26145: train_loss=124.86250, val_loss=135.48383\n",
      "Epoch 26146: train_loss=124.85544, val_loss=135.47394\n",
      "Epoch 26147: train_loss=124.84929, val_loss=135.47028\n",
      "Epoch 26148: train_loss=124.84394, val_loss=135.46768\n",
      "Epoch 26149: train_loss=124.83910, val_loss=135.45581\n",
      "Epoch 26150: train_loss=124.83478, val_loss=135.46091\n",
      "Epoch 26151: train_loss=124.83076, val_loss=135.44283\n",
      "Epoch 26152: train_loss=124.82686, val_loss=135.45753\n",
      "Epoch 26153: train_loss=124.82325, val_loss=135.43463\n",
      "Epoch 26154: train_loss=124.82003, val_loss=135.45386\n",
      "Epoch 26155: train_loss=124.81698, val_loss=135.42645\n",
      "Epoch 26156: train_loss=124.81415, val_loss=135.45343\n",
      "Epoch 26157: train_loss=124.81108, val_loss=135.41994\n",
      "Epoch 26158: train_loss=124.80785, val_loss=135.44757\n",
      "Epoch 26159: train_loss=124.80437, val_loss=135.40770\n",
      "Epoch 26160: train_loss=124.80083, val_loss=135.43806\n",
      "Epoch 26161: train_loss=124.79699, val_loss=135.39902\n",
      "Epoch 26162: train_loss=124.79294, val_loss=135.43422\n",
      "Epoch 26163: train_loss=124.78868, val_loss=135.39357\n",
      "Epoch 26164: train_loss=124.78432, val_loss=135.42694\n",
      "Epoch 26165: train_loss=124.77966, val_loss=135.38196\n",
      "Epoch 26166: train_loss=124.77502, val_loss=135.41541\n",
      "Epoch 26167: train_loss=124.76994, val_loss=135.37170\n",
      "Epoch 26168: train_loss=124.76492, val_loss=135.40543\n",
      "Epoch 26169: train_loss=124.75982, val_loss=135.35938\n",
      "Epoch 26170: train_loss=124.75470, val_loss=135.39398\n",
      "Epoch 26171: train_loss=124.74936, val_loss=135.35139\n",
      "Epoch 26172: train_loss=124.74420, val_loss=135.38651\n",
      "Epoch 26173: train_loss=124.73906, val_loss=135.34158\n",
      "Epoch 26174: train_loss=124.73380, val_loss=135.37398\n",
      "Epoch 26175: train_loss=124.72868, val_loss=135.32875\n",
      "Epoch 26176: train_loss=124.72361, val_loss=135.36426\n",
      "Epoch 26177: train_loss=124.71874, val_loss=135.31927\n",
      "Epoch 26178: train_loss=124.71400, val_loss=135.35443\n",
      "Epoch 26179: train_loss=124.70947, val_loss=135.31062\n",
      "Epoch 26180: train_loss=124.70516, val_loss=135.34818\n",
      "Epoch 26181: train_loss=124.70129, val_loss=135.30324\n",
      "Epoch 26182: train_loss=124.69806, val_loss=135.34436\n",
      "Epoch 26183: train_loss=124.69562, val_loss=135.29501\n",
      "Epoch 26184: train_loss=124.69422, val_loss=135.34479\n",
      "Epoch 26185: train_loss=124.69409, val_loss=135.29570\n",
      "Epoch 26186: train_loss=124.69536, val_loss=135.35703\n",
      "Epoch 26187: train_loss=124.69831, val_loss=135.30032\n",
      "Epoch 26188: train_loss=124.70284, val_loss=135.37274\n",
      "Epoch 26189: train_loss=124.70908, val_loss=135.30701\n",
      "Epoch 26190: train_loss=124.71728, val_loss=135.39362\n",
      "Epoch 26191: train_loss=124.72641, val_loss=135.32181\n",
      "Epoch 26192: train_loss=124.73663, val_loss=135.42241\n",
      "Epoch 26193: train_loss=124.74593, val_loss=135.33914\n",
      "Epoch 26194: train_loss=124.75494, val_loss=135.44171\n",
      "Epoch 26195: train_loss=124.75895, val_loss=135.34200\n",
      "Epoch 26196: train_loss=124.75975, val_loss=135.43506\n",
      "Epoch 26197: train_loss=124.75317, val_loss=135.32455\n",
      "Epoch 26198: train_loss=124.74191, val_loss=135.40288\n",
      "Epoch 26199: train_loss=124.72309, val_loss=135.28824\n",
      "Epoch 26200: train_loss=124.70025, val_loss=135.34418\n",
      "Epoch 26201: train_loss=124.67343, val_loss=135.23846\n",
      "Epoch 26202: train_loss=124.64531, val_loss=135.27615\n",
      "Epoch 26203: train_loss=124.61749, val_loss=135.19797\n",
      "Epoch 26204: train_loss=124.59169, val_loss=135.21854\n",
      "Epoch 26205: train_loss=124.56975, val_loss=135.17221\n",
      "Epoch 26206: train_loss=124.55283, val_loss=135.17627\n",
      "Epoch 26207: train_loss=124.54134, val_loss=135.16330\n",
      "Epoch 26208: train_loss=124.53416, val_loss=135.15450\n",
      "Epoch 26209: train_loss=124.53052, val_loss=135.16769\n",
      "Epoch 26210: train_loss=124.52929, val_loss=135.14659\n",
      "Epoch 26211: train_loss=124.52980, val_loss=135.17740\n",
      "Epoch 26212: train_loss=124.53126, val_loss=135.14482\n",
      "Epoch 26213: train_loss=124.53297, val_loss=135.18748\n",
      "Epoch 26214: train_loss=124.53405, val_loss=135.14230\n",
      "Epoch 26215: train_loss=124.53394, val_loss=135.18761\n",
      "Epoch 26216: train_loss=124.53278, val_loss=135.13571\n",
      "Epoch 26217: train_loss=124.53035, val_loss=135.18460\n",
      "Epoch 26218: train_loss=124.52643, val_loss=135.12886\n",
      "Epoch 26219: train_loss=124.52137, val_loss=135.17375\n",
      "Epoch 26220: train_loss=124.51526, val_loss=135.11624\n",
      "Epoch 26221: train_loss=124.50857, val_loss=135.15849\n",
      "Epoch 26222: train_loss=124.50117, val_loss=135.10304\n",
      "Epoch 26223: train_loss=124.49347, val_loss=135.13963\n",
      "Epoch 26224: train_loss=124.48551, val_loss=135.08856\n",
      "Epoch 26225: train_loss=124.47745, val_loss=135.12367\n",
      "Epoch 26226: train_loss=124.46937, val_loss=135.07768\n",
      "Epoch 26227: train_loss=124.46150, val_loss=135.10634\n",
      "Epoch 26228: train_loss=124.45371, val_loss=135.06345\n",
      "Epoch 26229: train_loss=124.44629, val_loss=135.08765\n",
      "Epoch 26230: train_loss=124.43932, val_loss=135.04823\n",
      "Epoch 26231: train_loss=124.43286, val_loss=135.07190\n",
      "Epoch 26232: train_loss=124.42683, val_loss=135.03902\n",
      "Epoch 26233: train_loss=124.42091, val_loss=135.06447\n",
      "Epoch 26234: train_loss=124.41563, val_loss=135.03224\n",
      "Epoch 26235: train_loss=124.41059, val_loss=135.05542\n",
      "Epoch 26236: train_loss=124.40605, val_loss=135.02145\n",
      "Epoch 26237: train_loss=124.40189, val_loss=135.04703\n",
      "Epoch 26238: train_loss=124.39847, val_loss=135.01109\n",
      "Epoch 26239: train_loss=124.39565, val_loss=135.04253\n",
      "Epoch 26240: train_loss=124.39402, val_loss=135.00453\n",
      "Epoch 26241: train_loss=124.39333, val_loss=135.04912\n",
      "Epoch 26242: train_loss=124.39421, val_loss=135.00873\n",
      "Epoch 26243: train_loss=124.39684, val_loss=135.06755\n",
      "Epoch 26244: train_loss=124.40231, val_loss=135.01822\n",
      "Epoch 26245: train_loss=124.41087, val_loss=135.09602\n",
      "Epoch 26246: train_loss=124.42345, val_loss=135.03770\n",
      "Epoch 26247: train_loss=124.44065, val_loss=135.14262\n",
      "Epoch 26248: train_loss=124.46268, val_loss=135.07542\n",
      "Epoch 26249: train_loss=124.49068, val_loss=135.21086\n",
      "Epoch 26250: train_loss=124.52078, val_loss=135.13181\n",
      "Epoch 26251: train_loss=124.55444, val_loss=135.28479\n",
      "Epoch 26252: train_loss=124.58183, val_loss=135.17679\n",
      "Epoch 26253: train_loss=124.60459, val_loss=135.31639\n",
      "Epoch 26254: train_loss=124.60870, val_loss=135.17125\n",
      "Epoch 26255: train_loss=124.59840, val_loss=135.26801\n",
      "Epoch 26256: train_loss=124.56300, val_loss=135.09464\n",
      "Epoch 26257: train_loss=124.51416, val_loss=135.13855\n",
      "Epoch 26258: train_loss=124.45103, val_loss=134.98152\n",
      "Epoch 26259: train_loss=124.38783, val_loss=134.99788\n",
      "Epoch 26260: train_loss=124.33234, val_loss=134.90781\n",
      "Epoch 26261: train_loss=124.29116, val_loss=134.91014\n",
      "Epoch 26262: train_loss=124.26739, val_loss=134.89835\n",
      "Epoch 26263: train_loss=124.25963, val_loss=134.88699\n",
      "Epoch 26264: train_loss=124.26434, val_loss=134.93155\n",
      "Epoch 26265: train_loss=124.27609, val_loss=134.89871\n",
      "Epoch 26266: train_loss=124.28940, val_loss=134.96887\n",
      "Epoch 26267: train_loss=124.29987, val_loss=134.91138\n",
      "Epoch 26268: train_loss=124.30473, val_loss=134.97679\n",
      "Epoch 26269: train_loss=124.30325, val_loss=134.90041\n",
      "Epoch 26270: train_loss=124.29471, val_loss=134.94865\n",
      "Epoch 26271: train_loss=124.28085, val_loss=134.87125\n",
      "Epoch 26272: train_loss=124.26333, val_loss=134.90382\n",
      "Epoch 26273: train_loss=124.24459, val_loss=134.84595\n",
      "Epoch 26274: train_loss=124.22658, val_loss=134.86401\n",
      "Epoch 26275: train_loss=124.21125, val_loss=134.83067\n",
      "Epoch 26276: train_loss=124.19904, val_loss=134.83434\n",
      "Epoch 26277: train_loss=124.19043, val_loss=134.82790\n",
      "Epoch 26278: train_loss=124.18497, val_loss=134.81783\n",
      "Epoch 26279: train_loss=124.18187, val_loss=134.83174\n",
      "Epoch 26280: train_loss=124.18010, val_loss=134.81136\n",
      "Epoch 26281: train_loss=124.17908, val_loss=134.83667\n",
      "Epoch 26282: train_loss=124.17811, val_loss=134.80516\n",
      "Epoch 26283: train_loss=124.17620, val_loss=134.83508\n",
      "Epoch 26284: train_loss=124.17352, val_loss=134.79712\n",
      "Epoch 26285: train_loss=124.16982, val_loss=134.82680\n",
      "Epoch 26286: train_loss=124.16534, val_loss=134.78566\n",
      "Epoch 26287: train_loss=124.15987, val_loss=134.81459\n",
      "Epoch 26288: train_loss=124.15411, val_loss=134.77782\n",
      "Epoch 26289: train_loss=124.14772, val_loss=134.80388\n",
      "Epoch 26290: train_loss=124.14121, val_loss=134.76746\n",
      "Epoch 26291: train_loss=124.13445, val_loss=134.78696\n",
      "Epoch 26292: train_loss=124.12768, val_loss=134.75369\n",
      "Epoch 26293: train_loss=124.12090, val_loss=134.76891\n",
      "Epoch 26294: train_loss=124.11431, val_loss=134.74088\n",
      "Epoch 26295: train_loss=124.10807, val_loss=134.75464\n",
      "Epoch 26296: train_loss=124.10191, val_loss=134.73322\n",
      "Epoch 26297: train_loss=124.09597, val_loss=134.74278\n",
      "Epoch 26298: train_loss=124.09029, val_loss=134.72363\n",
      "Epoch 26299: train_loss=124.08482, val_loss=134.72934\n",
      "Epoch 26300: train_loss=124.07939, val_loss=134.71510\n",
      "Epoch 26301: train_loss=124.07430, val_loss=134.72096\n",
      "Epoch 26302: train_loss=124.06931, val_loss=134.70735\n",
      "Epoch 26303: train_loss=124.06432, val_loss=134.71255\n",
      "Epoch 26304: train_loss=124.05954, val_loss=134.69806\n",
      "Epoch 26305: train_loss=124.05488, val_loss=134.70334\n",
      "Epoch 26306: train_loss=124.05031, val_loss=134.68602\n",
      "Epoch 26307: train_loss=124.04617, val_loss=134.69580\n",
      "Epoch 26308: train_loss=124.04211, val_loss=134.67902\n",
      "Epoch 26309: train_loss=124.03852, val_loss=134.69647\n",
      "Epoch 26310: train_loss=124.03579, val_loss=134.67383\n",
      "Epoch 26311: train_loss=124.03391, val_loss=134.70129\n",
      "Epoch 26312: train_loss=124.03369, val_loss=134.67001\n",
      "Epoch 26313: train_loss=124.03535, val_loss=134.71355\n",
      "Epoch 26314: train_loss=124.04015, val_loss=134.67351\n",
      "Epoch 26315: train_loss=124.04890, val_loss=134.74371\n",
      "Epoch 26316: train_loss=124.06337, val_loss=134.69792\n",
      "Epoch 26317: train_loss=124.08485, val_loss=134.80771\n",
      "Epoch 26318: train_loss=124.11337, val_loss=134.75255\n",
      "Epoch 26319: train_loss=124.15145, val_loss=134.90627\n",
      "Epoch 26320: train_loss=124.19673, val_loss=134.84259\n",
      "Epoch 26321: train_loss=124.25274, val_loss=135.03638\n",
      "Epoch 26322: train_loss=124.30647, val_loss=134.94151\n",
      "Epoch 26323: train_loss=124.35909, val_loss=135.12898\n",
      "Epoch 26324: train_loss=124.38766, val_loss=134.97133\n",
      "Epoch 26325: train_loss=124.39438, val_loss=135.09053\n",
      "Epoch 26326: train_loss=124.35505, val_loss=134.86729\n",
      "Epoch 26327: train_loss=124.28600, val_loss=134.90147\n",
      "Epoch 26328: train_loss=124.18638, val_loss=134.69341\n",
      "Epoch 26329: train_loss=124.08623, val_loss=134.68953\n",
      "Epoch 26330: train_loss=124.00050, val_loss=134.58678\n",
      "Epoch 26331: train_loss=123.94563, val_loss=134.58205\n",
      "Epoch 26332: train_loss=123.92465, val_loss=134.60226\n",
      "Epoch 26333: train_loss=123.93193, val_loss=134.58656\n",
      "Epoch 26334: train_loss=123.95676, val_loss=134.67563\n",
      "Epoch 26335: train_loss=123.98653, val_loss=134.62241\n",
      "Epoch 26336: train_loss=124.01060, val_loss=134.71394\n",
      "Epoch 26337: train_loss=124.01972, val_loss=134.62190\n",
      "Epoch 26338: train_loss=124.01265, val_loss=134.68376\n",
      "Epoch 26339: train_loss=123.98958, val_loss=134.58168\n",
      "Epoch 26340: train_loss=123.95842, val_loss=134.60858\n",
      "Epoch 26341: train_loss=123.92489, val_loss=134.53778\n",
      "Epoch 26342: train_loss=123.89616, val_loss=134.54346\n",
      "Epoch 26343: train_loss=123.87690, val_loss=134.52779\n",
      "Epoch 26344: train_loss=123.86838, val_loss=134.51756\n",
      "Epoch 26345: train_loss=123.86861, val_loss=134.54611\n",
      "Epoch 26346: train_loss=123.87399, val_loss=134.51505\n",
      "Epoch 26347: train_loss=123.88035, val_loss=134.56329\n",
      "Epoch 26348: train_loss=123.88403, val_loss=134.51773\n",
      "Epoch 26349: train_loss=123.88348, val_loss=134.56435\n",
      "Epoch 26350: train_loss=123.87794, val_loss=134.50900\n",
      "Epoch 26351: train_loss=123.86813, val_loss=134.53860\n",
      "Epoch 26352: train_loss=123.85567, val_loss=134.48924\n",
      "Epoch 26353: train_loss=123.84257, val_loss=134.50418\n",
      "Epoch 26354: train_loss=123.83047, val_loss=134.47470\n",
      "Epoch 26355: train_loss=123.82035, val_loss=134.47707\n",
      "Epoch 26356: train_loss=123.81288, val_loss=134.46960\n",
      "Epoch 26357: train_loss=123.80775, val_loss=134.45969\n",
      "Epoch 26358: train_loss=123.80447, val_loss=134.47112\n",
      "Epoch 26359: train_loss=123.80232, val_loss=134.45267\n",
      "Epoch 26360: train_loss=123.80076, val_loss=134.47697\n",
      "Epoch 26361: train_loss=123.79918, val_loss=134.44977\n",
      "Epoch 26362: train_loss=123.79719, val_loss=134.47775\n",
      "Epoch 26363: train_loss=123.79461, val_loss=134.44286\n",
      "Epoch 26364: train_loss=123.79115, val_loss=134.47041\n",
      "Epoch 26365: train_loss=123.78687, val_loss=134.43195\n",
      "Epoch 26366: train_loss=123.78160, val_loss=134.45732\n",
      "Epoch 26367: train_loss=123.77563, val_loss=134.42137\n",
      "Epoch 26368: train_loss=123.76926, val_loss=134.44453\n",
      "Epoch 26369: train_loss=123.76257, val_loss=134.41508\n",
      "Epoch 26370: train_loss=123.75594, val_loss=134.43321\n",
      "Epoch 26371: train_loss=123.74947, val_loss=134.40800\n",
      "Epoch 26372: train_loss=123.74308, val_loss=134.41887\n",
      "Epoch 26373: train_loss=123.73702, val_loss=134.39703\n",
      "Epoch 26374: train_loss=123.73131, val_loss=134.40253\n",
      "Epoch 26375: train_loss=123.72564, val_loss=134.38631\n",
      "Epoch 26376: train_loss=123.72049, val_loss=134.39050\n",
      "Epoch 26377: train_loss=123.71552, val_loss=134.38147\n",
      "Epoch 26378: train_loss=123.71048, val_loss=134.38519\n",
      "Epoch 26379: train_loss=123.70565, val_loss=134.37575\n",
      "Epoch 26380: train_loss=123.70087, val_loss=134.37590\n",
      "Epoch 26381: train_loss=123.69617, val_loss=134.36635\n",
      "Epoch 26382: train_loss=123.69153, val_loss=134.36664\n",
      "Epoch 26383: train_loss=123.68694, val_loss=134.35640\n",
      "Epoch 26384: train_loss=123.68237, val_loss=134.35776\n",
      "Epoch 26385: train_loss=123.67796, val_loss=134.34840\n",
      "Epoch 26386: train_loss=123.67356, val_loss=134.35522\n",
      "Epoch 26387: train_loss=123.66936, val_loss=134.34235\n",
      "Epoch 26388: train_loss=123.66548, val_loss=134.35217\n",
      "Epoch 26389: train_loss=123.66205, val_loss=134.33260\n",
      "Epoch 26390: train_loss=123.65929, val_loss=134.35065\n",
      "Epoch 26391: train_loss=123.65734, val_loss=134.32353\n",
      "Epoch 26392: train_loss=123.65661, val_loss=134.35562\n",
      "Epoch 26393: train_loss=123.65769, val_loss=134.32201\n",
      "Epoch 26394: train_loss=123.66106, val_loss=134.37483\n",
      "Epoch 26395: train_loss=123.66756, val_loss=134.33311\n",
      "Epoch 26396: train_loss=123.67701, val_loss=134.41267\n",
      "Epoch 26397: train_loss=123.69121, val_loss=134.35988\n",
      "Epoch 26398: train_loss=123.71077, val_loss=134.47113\n",
      "Epoch 26399: train_loss=123.73603, val_loss=134.40636\n",
      "Epoch 26400: train_loss=123.76833, val_loss=134.55255\n",
      "Epoch 26401: train_loss=123.80556, val_loss=134.47151\n",
      "Epoch 26402: train_loss=123.84752, val_loss=134.64473\n",
      "Epoch 26403: train_loss=123.88679, val_loss=134.53777\n",
      "Epoch 26404: train_loss=123.92379, val_loss=134.70906\n",
      "Epoch 26405: train_loss=123.94138, val_loss=134.55775\n",
      "Epoch 26406: train_loss=123.94263, val_loss=134.67891\n",
      "Epoch 26407: train_loss=123.91117, val_loss=134.48201\n",
      "Epoch 26408: train_loss=123.85850, val_loss=134.53404\n",
      "Epoch 26409: train_loss=123.78297, val_loss=134.34351\n",
      "Epoch 26410: train_loss=123.70307, val_loss=134.35263\n",
      "Epoch 26411: train_loss=123.63053, val_loss=134.24321\n",
      "Epoch 26412: train_loss=123.57811, val_loss=134.24284\n",
      "Epoch 26413: train_loss=123.55117, val_loss=134.24197\n",
      "Epoch 26414: train_loss=123.54717, val_loss=134.23164\n",
      "Epoch 26415: train_loss=123.55936, val_loss=134.29953\n",
      "Epoch 26416: train_loss=123.58001, val_loss=134.25829\n",
      "Epoch 26417: train_loss=123.60050, val_loss=134.34581\n",
      "Epoch 26418: train_loss=123.61462, val_loss=134.26852\n",
      "Epoch 26419: train_loss=123.61765, val_loss=134.33867\n",
      "Epoch 26420: train_loss=123.60843, val_loss=134.24353\n",
      "Epoch 26421: train_loss=123.58924, val_loss=134.28682\n",
      "Epoch 26422: train_loss=123.56480, val_loss=134.20609\n",
      "Epoch 26423: train_loss=123.53943, val_loss=134.22729\n",
      "Epoch 26424: train_loss=123.51769, val_loss=134.18335\n",
      "Epoch 26425: train_loss=123.50117, val_loss=134.18811\n",
      "Epoch 26426: train_loss=123.49098, val_loss=134.18484\n",
      "Epoch 26427: train_loss=123.48633, val_loss=134.17392\n",
      "Epoch 26428: train_loss=123.48577, val_loss=134.19954\n",
      "Epoch 26429: train_loss=123.48754, val_loss=134.17084\n",
      "Epoch 26430: train_loss=123.48958, val_loss=134.20912\n",
      "Epoch 26431: train_loss=123.49063, val_loss=134.16660\n",
      "Epoch 26432: train_loss=123.48946, val_loss=134.20609\n",
      "Epoch 26433: train_loss=123.48605, val_loss=134.15686\n",
      "Epoch 26434: train_loss=123.48004, val_loss=134.19312\n",
      "Epoch 26435: train_loss=123.47258, val_loss=134.14798\n",
      "Epoch 26436: train_loss=123.46391, val_loss=134.17406\n",
      "Epoch 26437: train_loss=123.45483, val_loss=134.13731\n",
      "Epoch 26438: train_loss=123.44570, val_loss=134.15247\n",
      "Epoch 26439: train_loss=123.43759, val_loss=134.12688\n",
      "Epoch 26440: train_loss=123.43022, val_loss=134.13139\n",
      "Epoch 26441: train_loss=123.42387, val_loss=134.11855\n",
      "Epoch 26442: train_loss=123.41830, val_loss=134.11569\n",
      "Epoch 26443: train_loss=123.41365, val_loss=134.11668\n",
      "Epoch 26444: train_loss=123.40949, val_loss=134.10786\n",
      "Epoch 26445: train_loss=123.40574, val_loss=134.11626\n",
      "Epoch 26446: train_loss=123.40239, val_loss=134.09853\n",
      "Epoch 26447: train_loss=123.39919, val_loss=134.11212\n",
      "Epoch 26448: train_loss=123.39627, val_loss=134.08832\n",
      "Epoch 26449: train_loss=123.39351, val_loss=134.10896\n",
      "Epoch 26450: train_loss=123.39090, val_loss=134.08063\n",
      "Epoch 26451: train_loss=123.38841, val_loss=134.10762\n",
      "Epoch 26452: train_loss=123.38615, val_loss=134.07625\n",
      "Epoch 26453: train_loss=123.38384, val_loss=134.11014\n",
      "Epoch 26454: train_loss=123.38185, val_loss=134.07327\n",
      "Epoch 26455: train_loss=123.37982, val_loss=134.11064\n",
      "Epoch 26456: train_loss=123.37827, val_loss=134.06729\n",
      "Epoch 26457: train_loss=123.37693, val_loss=134.10945\n",
      "Epoch 26458: train_loss=123.37621, val_loss=134.06084\n",
      "Epoch 26459: train_loss=123.37576, val_loss=134.11166\n",
      "Epoch 26460: train_loss=123.37648, val_loss=134.05869\n",
      "Epoch 26461: train_loss=123.37731, val_loss=134.11841\n",
      "Epoch 26462: train_loss=123.37932, val_loss=134.06117\n",
      "Epoch 26463: train_loss=123.38120, val_loss=134.13097\n",
      "Epoch 26464: train_loss=123.38427, val_loss=134.06544\n",
      "Epoch 26465: train_loss=123.38755, val_loss=134.14240\n",
      "Epoch 26466: train_loss=123.39165, val_loss=134.06819\n",
      "Epoch 26467: train_loss=123.39532, val_loss=134.15390\n",
      "Epoch 26468: train_loss=123.39967, val_loss=134.07236\n",
      "Epoch 26469: train_loss=123.40256, val_loss=134.16258\n",
      "Epoch 26470: train_loss=123.40486, val_loss=134.07436\n",
      "Epoch 26471: train_loss=123.40469, val_loss=134.16527\n",
      "Epoch 26472: train_loss=123.40296, val_loss=134.06808\n",
      "Epoch 26473: train_loss=123.39747, val_loss=134.15054\n",
      "Epoch 26474: train_loss=123.38965, val_loss=134.04930\n",
      "Epoch 26475: train_loss=123.37788, val_loss=134.11951\n",
      "Epoch 26476: train_loss=123.36397, val_loss=134.02116\n",
      "Epoch 26477: train_loss=123.34692, val_loss=134.07716\n",
      "Epoch 26478: train_loss=123.32906, val_loss=133.99146\n",
      "Epoch 26479: train_loss=123.30981, val_loss=134.03238\n",
      "Epoch 26480: train_loss=123.29128, val_loss=133.96559\n",
      "Epoch 26481: train_loss=123.27406, val_loss=133.99219\n",
      "Epoch 26482: train_loss=123.25891, val_loss=133.94794\n",
      "Epoch 26483: train_loss=123.24616, val_loss=133.96001\n",
      "Epoch 26484: train_loss=123.23609, val_loss=133.93828\n",
      "Epoch 26485: train_loss=123.22840, val_loss=133.93828\n",
      "Epoch 26486: train_loss=123.22272, val_loss=133.93576\n",
      "Epoch 26487: train_loss=123.21864, val_loss=133.92476\n",
      "Epoch 26488: train_loss=123.21579, val_loss=133.93951\n",
      "Epoch 26489: train_loss=123.21359, val_loss=133.92039\n",
      "Epoch 26490: train_loss=123.21199, val_loss=133.94472\n",
      "Epoch 26491: train_loss=123.21078, val_loss=133.91490\n",
      "Epoch 26492: train_loss=123.20965, val_loss=133.94662\n",
      "Epoch 26493: train_loss=123.20908, val_loss=133.90852\n",
      "Epoch 26494: train_loss=123.20866, val_loss=133.94876\n",
      "Epoch 26495: train_loss=123.20860, val_loss=133.90451\n",
      "Epoch 26496: train_loss=123.20901, val_loss=133.95461\n",
      "Epoch 26497: train_loss=123.20961, val_loss=133.90535\n",
      "Epoch 26498: train_loss=123.21116, val_loss=133.96370\n",
      "Epoch 26499: train_loss=123.21293, val_loss=133.90738\n",
      "Epoch 26500: train_loss=123.21590, val_loss=133.97635\n",
      "Epoch 26501: train_loss=123.21973, val_loss=133.91237\n",
      "Epoch 26502: train_loss=123.22509, val_loss=133.99341\n",
      "Epoch 26503: train_loss=123.23162, val_loss=133.92068\n",
      "Epoch 26504: train_loss=123.23914, val_loss=134.01271\n",
      "Epoch 26505: train_loss=123.24683, val_loss=133.93173\n",
      "Epoch 26506: train_loss=123.25460, val_loss=134.03600\n",
      "Epoch 26507: train_loss=123.26308, val_loss=133.94461\n",
      "Epoch 26508: train_loss=123.27021, val_loss=134.05396\n",
      "Epoch 26509: train_loss=123.27564, val_loss=133.94943\n",
      "Epoch 26510: train_loss=123.27789, val_loss=134.05548\n",
      "Epoch 26511: train_loss=123.27591, val_loss=133.93996\n",
      "Epoch 26512: train_loss=123.26895, val_loss=134.03255\n",
      "Epoch 26513: train_loss=123.25627, val_loss=133.91075\n",
      "Epoch 26514: train_loss=123.23797, val_loss=133.98251\n",
      "Epoch 26515: train_loss=123.21448, val_loss=133.86784\n",
      "Epoch 26516: train_loss=123.18802, val_loss=133.91768\n",
      "Epoch 26517: train_loss=123.16000, val_loss=133.82535\n",
      "Epoch 26518: train_loss=123.13387, val_loss=133.85493\n",
      "Epoch 26519: train_loss=123.11037, val_loss=133.79617\n",
      "Epoch 26520: train_loss=123.09150, val_loss=133.80914\n",
      "Epoch 26521: train_loss=123.07773, val_loss=133.78578\n",
      "Epoch 26522: train_loss=123.06860, val_loss=133.78377\n",
      "Epoch 26523: train_loss=123.06355, val_loss=133.79137\n",
      "Epoch 26524: train_loss=123.06160, val_loss=133.77440\n",
      "Epoch 26525: train_loss=123.06162, val_loss=133.80186\n",
      "Epoch 26526: train_loss=123.06260, val_loss=133.77078\n",
      "Epoch 26527: train_loss=123.06371, val_loss=133.81111\n",
      "Epoch 26528: train_loss=123.06506, val_loss=133.76952\n",
      "Epoch 26529: train_loss=123.06593, val_loss=133.81778\n",
      "Epoch 26530: train_loss=123.06611, val_loss=133.76849\n",
      "Epoch 26531: train_loss=123.06571, val_loss=133.81953\n",
      "Epoch 26532: train_loss=123.06423, val_loss=133.76320\n",
      "Epoch 26533: train_loss=123.06212, val_loss=133.81534\n",
      "Epoch 26534: train_loss=123.05927, val_loss=133.75578\n",
      "Epoch 26535: train_loss=123.05609, val_loss=133.80911\n",
      "Epoch 26536: train_loss=123.05228, val_loss=133.74828\n",
      "Epoch 26537: train_loss=123.04835, val_loss=133.80150\n",
      "Epoch 26538: train_loss=123.04397, val_loss=133.74084\n",
      "Epoch 26539: train_loss=123.03964, val_loss=133.79422\n",
      "Epoch 26540: train_loss=123.03506, val_loss=133.73315\n",
      "Epoch 26541: train_loss=123.03070, val_loss=133.78442\n",
      "Epoch 26542: train_loss=123.02590, val_loss=133.72316\n",
      "Epoch 26543: train_loss=123.02149, val_loss=133.77426\n",
      "Epoch 26544: train_loss=123.01683, val_loss=133.71379\n",
      "Epoch 26545: train_loss=123.01268, val_loss=133.76559\n",
      "Epoch 26546: train_loss=123.00804, val_loss=133.70599\n",
      "Epoch 26547: train_loss=123.00387, val_loss=133.75764\n",
      "Epoch 26548: train_loss=122.99945, val_loss=133.69780\n",
      "Epoch 26549: train_loss=122.99541, val_loss=133.74962\n",
      "Epoch 26550: train_loss=122.99147, val_loss=133.68925\n",
      "Epoch 26551: train_loss=122.98795, val_loss=133.74335\n",
      "Epoch 26552: train_loss=122.98474, val_loss=133.68298\n",
      "Epoch 26553: train_loss=122.98202, val_loss=133.74036\n",
      "Epoch 26554: train_loss=122.97948, val_loss=133.67920\n",
      "Epoch 26555: train_loss=122.97779, val_loss=133.74046\n",
      "Epoch 26556: train_loss=122.97665, val_loss=133.67592\n",
      "Epoch 26557: train_loss=122.97635, val_loss=133.74292\n",
      "Epoch 26558: train_loss=122.97678, val_loss=133.67441\n",
      "Epoch 26559: train_loss=122.97796, val_loss=133.74881\n",
      "Epoch 26560: train_loss=122.97971, val_loss=133.67586\n",
      "Epoch 26561: train_loss=122.98212, val_loss=133.75798\n",
      "Epoch 26562: train_loss=122.98499, val_loss=133.67902\n",
      "Epoch 26563: train_loss=122.98788, val_loss=133.76698\n",
      "Epoch 26564: train_loss=122.99031, val_loss=133.68260\n",
      "Epoch 26565: train_loss=122.99227, val_loss=133.77399\n",
      "Epoch 26566: train_loss=122.99236, val_loss=133.68048\n",
      "Epoch 26567: train_loss=122.99072, val_loss=133.76746\n",
      "Epoch 26568: train_loss=122.98616, val_loss=133.66774\n",
      "Epoch 26569: train_loss=122.97945, val_loss=133.74615\n",
      "Epoch 26570: train_loss=122.96887, val_loss=133.64534\n",
      "Epoch 26571: train_loss=122.95613, val_loss=133.71326\n",
      "Epoch 26572: train_loss=122.94027, val_loss=133.62000\n",
      "Epoch 26573: train_loss=122.92277, val_loss=133.67163\n",
      "Epoch 26574: train_loss=122.90433, val_loss=133.59171\n",
      "Epoch 26575: train_loss=122.88602, val_loss=133.62543\n",
      "Epoch 26576: train_loss=122.86856, val_loss=133.56682\n",
      "Epoch 26577: train_loss=122.85310, val_loss=133.58476\n",
      "Epoch 26578: train_loss=122.84021, val_loss=133.55304\n",
      "Epoch 26579: train_loss=122.83036, val_loss=133.55655\n",
      "Epoch 26580: train_loss=122.82339, val_loss=133.55116\n",
      "Epoch 26581: train_loss=122.81892, val_loss=133.54115\n",
      "Epoch 26582: train_loss=122.81641, val_loss=133.55687\n",
      "Epoch 26583: train_loss=122.81519, val_loss=133.53496\n",
      "Epoch 26584: train_loss=122.81460, val_loss=133.56339\n",
      "Epoch 26585: train_loss=122.81417, val_loss=133.53062\n",
      "Epoch 26586: train_loss=122.81371, val_loss=133.56805\n",
      "Epoch 26587: train_loss=122.81338, val_loss=133.52808\n",
      "Epoch 26588: train_loss=122.81256, val_loss=133.57176\n",
      "Epoch 26589: train_loss=122.81182, val_loss=133.52524\n",
      "Epoch 26590: train_loss=122.81075, val_loss=133.57327\n",
      "Epoch 26591: train_loss=122.80968, val_loss=133.52107\n",
      "Epoch 26592: train_loss=122.80873, val_loss=133.57425\n",
      "Epoch 26593: train_loss=122.80819, val_loss=133.51781\n",
      "Epoch 26594: train_loss=122.80806, val_loss=133.57759\n",
      "Epoch 26595: train_loss=122.80873, val_loss=133.51590\n",
      "Epoch 26596: train_loss=122.80981, val_loss=133.58386\n",
      "Epoch 26597: train_loss=122.81246, val_loss=133.51668\n",
      "Epoch 26598: train_loss=122.81567, val_loss=133.59663\n",
      "Epoch 26599: train_loss=122.82028, val_loss=133.52440\n",
      "Epoch 26600: train_loss=122.82627, val_loss=133.61687\n",
      "Epoch 26601: train_loss=122.83330, val_loss=133.53621\n",
      "Epoch 26602: train_loss=122.84111, val_loss=133.63821\n",
      "Epoch 26603: train_loss=122.84884, val_loss=133.54691\n",
      "Epoch 26604: train_loss=122.85665, val_loss=133.65639\n",
      "Epoch 26605: train_loss=122.86319, val_loss=133.55467\n",
      "Epoch 26606: train_loss=122.86830, val_loss=133.66719\n",
      "Epoch 26607: train_loss=122.87053, val_loss=133.55437\n",
      "Epoch 26608: train_loss=122.86890, val_loss=133.65961\n",
      "Epoch 26609: train_loss=122.86179, val_loss=133.53824\n",
      "Epoch 26610: train_loss=122.84955, val_loss=133.62584\n",
      "Epoch 26611: train_loss=122.83127, val_loss=133.50360\n",
      "Epoch 26612: train_loss=122.80847, val_loss=133.56758\n",
      "Epoch 26613: train_loss=122.78162, val_loss=133.45900\n",
      "Epoch 26614: train_loss=122.75350, val_loss=133.49966\n",
      "Epoch 26615: train_loss=122.72620, val_loss=133.42139\n",
      "Epoch 26616: train_loss=122.70228, val_loss=133.44272\n",
      "Epoch 26617: train_loss=122.68356, val_loss=133.40361\n",
      "Epoch 26618: train_loss=122.67006, val_loss=133.40726\n",
      "Epoch 26619: train_loss=122.66174, val_loss=133.40405\n",
      "Epoch 26620: train_loss=122.65806, val_loss=133.39032\n",
      "Epoch 26621: train_loss=122.65746, val_loss=133.41486\n",
      "Epoch 26622: train_loss=122.65884, val_loss=133.38612\n",
      "Epoch 26623: train_loss=122.66082, val_loss=133.42751\n",
      "Epoch 26624: train_loss=122.66283, val_loss=133.38629\n",
      "Epoch 26625: train_loss=122.66422, val_loss=133.43639\n",
      "Epoch 26626: train_loss=122.66518, val_loss=133.38452\n",
      "Epoch 26627: train_loss=122.66508, val_loss=133.43831\n",
      "Epoch 26628: train_loss=122.66413, val_loss=133.37996\n",
      "Epoch 26629: train_loss=122.66219, val_loss=133.43431\n",
      "Epoch 26630: train_loss=122.65917, val_loss=133.37260\n",
      "Epoch 26631: train_loss=122.65540, val_loss=133.42520\n",
      "Epoch 26632: train_loss=122.65070, val_loss=133.36256\n",
      "Epoch 26633: train_loss=122.64530, val_loss=133.41344\n",
      "Epoch 26634: train_loss=122.63940, val_loss=133.35321\n",
      "Epoch 26635: train_loss=122.63309, val_loss=133.40016\n",
      "Epoch 26636: train_loss=122.62654, val_loss=133.34254\n",
      "Epoch 26637: train_loss=122.61963, val_loss=133.38474\n",
      "Epoch 26638: train_loss=122.61283, val_loss=133.33182\n",
      "Epoch 26639: train_loss=122.60588, val_loss=133.37033\n",
      "Epoch 26640: train_loss=122.59971, val_loss=133.32237\n",
      "Epoch 26641: train_loss=122.59342, val_loss=133.35747\n",
      "Epoch 26642: train_loss=122.58759, val_loss=133.31363\n",
      "Epoch 26643: train_loss=122.58166, val_loss=133.34509\n",
      "Epoch 26644: train_loss=122.57602, val_loss=133.30525\n",
      "Epoch 26645: train_loss=122.57039, val_loss=133.33354\n",
      "Epoch 26646: train_loss=122.56510, val_loss=133.29665\n",
      "Epoch 26647: train_loss=122.55981, val_loss=133.32104\n",
      "Epoch 26648: train_loss=122.55476, val_loss=133.28667\n",
      "Epoch 26649: train_loss=122.54990, val_loss=133.31007\n",
      "Epoch 26650: train_loss=122.54531, val_loss=133.27824\n",
      "Epoch 26651: train_loss=122.54093, val_loss=133.30141\n",
      "Epoch 26652: train_loss=122.53680, val_loss=133.27061\n",
      "Epoch 26653: train_loss=122.53286, val_loss=133.29536\n",
      "Epoch 26654: train_loss=122.52940, val_loss=133.26416\n",
      "Epoch 26655: train_loss=122.52618, val_loss=133.29184\n",
      "Epoch 26656: train_loss=122.52344, val_loss=133.25795\n",
      "Epoch 26657: train_loss=122.52126, val_loss=133.29271\n",
      "Epoch 26658: train_loss=122.52047, val_loss=133.25502\n",
      "Epoch 26659: train_loss=122.52103, val_loss=133.30383\n",
      "Epoch 26660: train_loss=122.52412, val_loss=133.25937\n",
      "Epoch 26661: train_loss=122.52951, val_loss=133.32951\n",
      "Epoch 26662: train_loss=122.53910, val_loss=133.27475\n",
      "Epoch 26663: train_loss=122.55248, val_loss=133.37312\n",
      "Epoch 26664: train_loss=122.57207, val_loss=133.30772\n",
      "Epoch 26665: train_loss=122.59879, val_loss=133.44753\n",
      "Epoch 26666: train_loss=122.63294, val_loss=133.37059\n",
      "Epoch 26667: train_loss=122.67616, val_loss=133.55608\n",
      "Epoch 26668: train_loss=122.72455, val_loss=133.46016\n",
      "Epoch 26669: train_loss=122.77899, val_loss=133.67589\n",
      "Epoch 26670: train_loss=122.82745, val_loss=133.53824\n",
      "Epoch 26671: train_loss=122.86591, val_loss=133.73039\n",
      "Epoch 26672: train_loss=122.87395, val_loss=133.52612\n",
      "Epoch 26673: train_loss=122.85244, val_loss=133.63641\n",
      "Epoch 26674: train_loss=122.78958, val_loss=133.39064\n",
      "Epoch 26675: train_loss=122.70158, val_loss=133.41907\n",
      "Epoch 26676: train_loss=122.60035, val_loss=133.23000\n",
      "Epoch 26677: train_loss=122.51115, val_loss=133.23004\n",
      "Epoch 26678: train_loss=122.44885, val_loss=133.17509\n",
      "Epoch 26679: train_loss=122.42074, val_loss=133.16907\n",
      "Epoch 26680: train_loss=122.42402, val_loss=133.23247\n",
      "Epoch 26681: train_loss=122.44840, val_loss=133.19870\n",
      "Epoch 26682: train_loss=122.47997, val_loss=133.30881\n",
      "Epoch 26683: train_loss=122.50665, val_loss=133.22765\n",
      "Epoch 26684: train_loss=122.51994, val_loss=133.32085\n",
      "Epoch 26685: train_loss=122.51533, val_loss=133.20552\n",
      "Epoch 26686: train_loss=122.49506, val_loss=133.25896\n",
      "Epoch 26687: train_loss=122.46423, val_loss=133.15541\n",
      "Epoch 26688: train_loss=122.43051, val_loss=133.17769\n",
      "Epoch 26689: train_loss=122.40153, val_loss=133.12776\n",
      "Epoch 26690: train_loss=122.38171, val_loss=133.13005\n",
      "Epoch 26691: train_loss=122.37270, val_loss=133.14012\n",
      "Epoch 26692: train_loss=122.37281, val_loss=133.12086\n",
      "Epoch 26693: train_loss=122.37815, val_loss=133.16711\n",
      "Epoch 26694: train_loss=122.38509, val_loss=133.12433\n",
      "Epoch 26695: train_loss=122.39001, val_loss=133.17880\n",
      "Epoch 26696: train_loss=122.39118, val_loss=133.11945\n",
      "Epoch 26697: train_loss=122.38761, val_loss=133.16632\n",
      "Epoch 26698: train_loss=122.38004, val_loss=133.10603\n",
      "Epoch 26699: train_loss=122.36950, val_loss=133.13951\n",
      "Epoch 26700: train_loss=122.35794, val_loss=133.09238\n",
      "Epoch 26701: train_loss=122.34634, val_loss=133.11012\n",
      "Epoch 26702: train_loss=122.33602, val_loss=133.08424\n",
      "Epoch 26703: train_loss=122.32781, val_loss=133.08687\n",
      "Epoch 26704: train_loss=122.32199, val_loss=133.08360\n",
      "Epoch 26705: train_loss=122.31830, val_loss=133.07211\n",
      "Epoch 26706: train_loss=122.31601, val_loss=133.08678\n",
      "Epoch 26707: train_loss=122.31461, val_loss=133.06459\n",
      "Epoch 26708: train_loss=122.31331, val_loss=133.08945\n",
      "Epoch 26709: train_loss=122.31187, val_loss=133.05881\n",
      "Epoch 26710: train_loss=122.31003, val_loss=133.08855\n",
      "Epoch 26711: train_loss=122.30772, val_loss=133.05302\n",
      "Epoch 26712: train_loss=122.30489, val_loss=133.08412\n",
      "Epoch 26713: train_loss=122.30186, val_loss=133.04512\n",
      "Epoch 26714: train_loss=122.29840, val_loss=133.07657\n",
      "Epoch 26715: train_loss=122.29470, val_loss=133.03680\n",
      "Epoch 26716: train_loss=122.29045, val_loss=133.06697\n",
      "Epoch 26717: train_loss=122.28611, val_loss=133.02884\n",
      "Epoch 26718: train_loss=122.28130, val_loss=133.05702\n",
      "Epoch 26719: train_loss=122.27648, val_loss=133.02077\n",
      "Epoch 26720: train_loss=122.27145, val_loss=133.04581\n",
      "Epoch 26721: train_loss=122.26644, val_loss=133.01254\n",
      "Epoch 26722: train_loss=122.26157, val_loss=133.03496\n",
      "Epoch 26723: train_loss=122.25688, val_loss=133.00432\n",
      "Epoch 26724: train_loss=122.25220, val_loss=133.02440\n",
      "Epoch 26725: train_loss=122.24773, val_loss=132.99637\n",
      "Epoch 26726: train_loss=122.24323, val_loss=133.01567\n",
      "Epoch 26727: train_loss=122.23911, val_loss=132.99033\n",
      "Epoch 26728: train_loss=122.23495, val_loss=133.00995\n",
      "Epoch 26729: train_loss=122.23107, val_loss=132.98465\n",
      "Epoch 26730: train_loss=122.22718, val_loss=133.00360\n",
      "Epoch 26731: train_loss=122.22390, val_loss=132.97641\n",
      "Epoch 26732: train_loss=122.22073, val_loss=132.99855\n",
      "Epoch 26733: train_loss=122.21821, val_loss=132.96861\n",
      "Epoch 26734: train_loss=122.21604, val_loss=132.99843\n",
      "Epoch 26735: train_loss=122.21500, val_loss=132.96443\n",
      "Epoch 26736: train_loss=122.21481, val_loss=133.00645\n",
      "Epoch 26737: train_loss=122.21648, val_loss=132.96558\n",
      "Epoch 26738: train_loss=122.21947, val_loss=133.02414\n",
      "Epoch 26739: train_loss=122.22509, val_loss=132.97319\n",
      "Epoch 26740: train_loss=122.23286, val_loss=133.05212\n",
      "Epoch 26741: train_loss=122.24370, val_loss=132.98840\n",
      "Epoch 26742: train_loss=122.25719, val_loss=133.09026\n",
      "Epoch 26743: train_loss=122.27341, val_loss=133.01326\n",
      "Epoch 26744: train_loss=122.29195, val_loss=133.13785\n",
      "Epoch 26745: train_loss=122.31100, val_loss=133.04567\n",
      "Epoch 26746: train_loss=122.33106, val_loss=133.18307\n",
      "Epoch 26747: train_loss=122.34631, val_loss=133.06941\n",
      "Epoch 26748: train_loss=122.35861, val_loss=133.20145\n",
      "Epoch 26749: train_loss=122.36057, val_loss=133.06468\n",
      "Epoch 26750: train_loss=122.35556, val_loss=133.17445\n",
      "Epoch 26751: train_loss=122.33738, val_loss=133.02414\n",
      "Epoch 26752: train_loss=122.31072, val_loss=133.10019\n",
      "Epoch 26753: train_loss=122.27433, val_loss=132.96120\n",
      "Epoch 26754: train_loss=122.23576, val_loss=133.00793\n",
      "Epoch 26755: train_loss=122.19810, val_loss=132.90710\n",
      "Epoch 26756: train_loss=122.16537, val_loss=132.93231\n",
      "Epoch 26757: train_loss=122.14001, val_loss=132.88087\n",
      "Epoch 26758: train_loss=122.12226, val_loss=132.88737\n",
      "Epoch 26759: train_loss=122.11186, val_loss=132.88150\n",
      "Epoch 26760: train_loss=122.10752, val_loss=132.86909\n",
      "Epoch 26761: train_loss=122.10786, val_loss=132.89751\n",
      "Epoch 26762: train_loss=122.11118, val_loss=132.86668\n",
      "Epoch 26763: train_loss=122.11578, val_loss=132.91689\n",
      "Epoch 26764: train_loss=122.12106, val_loss=132.86963\n",
      "Epoch 26765: train_loss=122.12598, val_loss=132.93230\n",
      "Epoch 26766: train_loss=122.12984, val_loss=132.87177\n",
      "Epoch 26767: train_loss=122.13192, val_loss=132.93912\n",
      "Epoch 26768: train_loss=122.13221, val_loss=132.87030\n",
      "Epoch 26769: train_loss=122.13033, val_loss=132.93559\n",
      "Epoch 26770: train_loss=122.12637, val_loss=132.86253\n",
      "Epoch 26771: train_loss=122.12045, val_loss=132.92155\n",
      "Epoch 26772: train_loss=122.11319, val_loss=132.84956\n",
      "Epoch 26773: train_loss=122.10474, val_loss=132.90001\n",
      "Epoch 26774: train_loss=122.09576, val_loss=132.83394\n",
      "Epoch 26775: train_loss=122.08618, val_loss=132.87599\n",
      "Epoch 26776: train_loss=122.07676, val_loss=132.81970\n",
      "Epoch 26777: train_loss=122.06738, val_loss=132.85413\n",
      "Epoch 26778: train_loss=122.05897, val_loss=132.80890\n",
      "Epoch 26779: train_loss=122.05084, val_loss=132.83492\n",
      "Epoch 26780: train_loss=122.04347, val_loss=132.80008\n",
      "Epoch 26781: train_loss=122.03653, val_loss=132.81694\n",
      "Epoch 26782: train_loss=122.03025, val_loss=132.79149\n",
      "Epoch 26783: train_loss=122.02439, val_loss=132.80138\n",
      "Epoch 26784: train_loss=122.01933, val_loss=132.78542\n",
      "Epoch 26785: train_loss=122.01451, val_loss=132.78961\n",
      "Epoch 26786: train_loss=122.01015, val_loss=132.78175\n",
      "Epoch 26787: train_loss=122.00604, val_loss=132.78018\n",
      "Epoch 26788: train_loss=122.00218, val_loss=132.77843\n",
      "Epoch 26789: train_loss=121.99859, val_loss=132.77106\n",
      "Epoch 26790: train_loss=121.99503, val_loss=132.77393\n",
      "Epoch 26791: train_loss=121.99171, val_loss=132.76164\n",
      "Epoch 26792: train_loss=121.98857, val_loss=132.77086\n",
      "Epoch 26793: train_loss=121.98570, val_loss=132.75388\n",
      "Epoch 26794: train_loss=121.98304, val_loss=132.76973\n",
      "Epoch 26795: train_loss=121.98093, val_loss=132.74643\n",
      "Epoch 26796: train_loss=121.97943, val_loss=132.77330\n",
      "Epoch 26797: train_loss=121.97923, val_loss=132.74275\n",
      "Epoch 26798: train_loss=121.98034, val_loss=132.78543\n",
      "Epoch 26799: train_loss=121.98398, val_loss=132.74422\n",
      "Epoch 26800: train_loss=121.99041, val_loss=132.81213\n",
      "Epoch 26801: train_loss=122.00121, val_loss=132.75972\n",
      "Epoch 26802: train_loss=122.01627, val_loss=132.86180\n",
      "Epoch 26803: train_loss=122.03730, val_loss=132.79669\n",
      "Epoch 26804: train_loss=122.06466, val_loss=132.93886\n",
      "Epoch 26805: train_loss=122.09827, val_loss=132.85854\n",
      "Epoch 26806: train_loss=122.13963, val_loss=133.03772\n",
      "Epoch 26807: train_loss=122.18186, val_loss=132.93355\n",
      "Epoch 26808: train_loss=122.22780, val_loss=133.13179\n",
      "Epoch 26809: train_loss=122.26299, val_loss=132.98605\n",
      "Epoch 26810: train_loss=122.28767, val_loss=133.15793\n",
      "Epoch 26811: train_loss=122.28426, val_loss=132.95871\n",
      "Epoch 26812: train_loss=122.25694, val_loss=133.06075\n",
      "Epoch 26813: train_loss=122.19764, val_loss=132.84055\n",
      "Epoch 26814: train_loss=122.12331, val_loss=132.87672\n",
      "Epoch 26815: train_loss=122.04041, val_loss=132.71170\n",
      "Epoch 26816: train_loss=121.96882, val_loss=132.72043\n",
      "Epoch 26817: train_loss=121.91856, val_loss=132.66646\n",
      "Epoch 26818: train_loss=121.89359, val_loss=132.66226\n",
      "Epoch 26819: train_loss=121.89124, val_loss=132.70566\n",
      "Epoch 26820: train_loss=121.90519, val_loss=132.67622\n",
      "Epoch 26821: train_loss=121.92727, val_loss=132.77039\n",
      "Epoch 26822: train_loss=121.95010, val_loss=132.70447\n",
      "Epoch 26823: train_loss=121.96674, val_loss=132.80132\n",
      "Epoch 26824: train_loss=121.97218, val_loss=132.70326\n",
      "Epoch 26825: train_loss=121.96621, val_loss=132.77419\n",
      "Epoch 26826: train_loss=121.94881, val_loss=132.67039\n",
      "Epoch 26827: train_loss=121.92501, val_loss=132.71237\n",
      "Epoch 26828: train_loss=121.89927, val_loss=132.63568\n",
      "Epoch 26829: train_loss=121.87603, val_loss=132.65573\n",
      "Epoch 26830: train_loss=121.85816, val_loss=132.62296\n",
      "Epoch 26831: train_loss=121.84633, val_loss=132.62372\n",
      "Epoch 26832: train_loss=121.84049, val_loss=132.63124\n",
      "Epoch 26833: train_loss=121.83943, val_loss=132.61282\n",
      "Epoch 26834: train_loss=121.84124, val_loss=132.64731\n",
      "Epoch 26835: train_loss=121.84443, val_loss=132.61157\n",
      "Epoch 26836: train_loss=121.84731, val_loss=132.65863\n",
      "Epoch 26837: train_loss=121.84908, val_loss=132.60931\n",
      "Epoch 26838: train_loss=121.84845, val_loss=132.65872\n",
      "Epoch 26839: train_loss=121.84618, val_loss=132.60396\n",
      "Epoch 26840: train_loss=121.84145, val_loss=132.64833\n",
      "Epoch 26841: train_loss=121.83538, val_loss=132.59444\n",
      "Epoch 26842: train_loss=121.82799, val_loss=132.63072\n",
      "Epoch 26843: train_loss=121.82039, val_loss=132.58374\n",
      "Epoch 26844: train_loss=121.81236, val_loss=132.61018\n",
      "Epoch 26845: train_loss=121.80448, val_loss=132.57365\n",
      "Epoch 26846: train_loss=121.79686, val_loss=132.58893\n",
      "Epoch 26847: train_loss=121.79004, val_loss=132.56512\n",
      "Epoch 26848: train_loss=121.78404, val_loss=132.57120\n",
      "Epoch 26849: train_loss=121.77889, val_loss=132.56139\n",
      "Epoch 26850: train_loss=121.77449, val_loss=132.55927\n",
      "Epoch 26851: train_loss=121.77070, val_loss=132.56067\n",
      "Epoch 26852: train_loss=121.76737, val_loss=132.55029\n",
      "Epoch 26853: train_loss=121.76443, val_loss=132.55995\n",
      "Epoch 26854: train_loss=121.76171, val_loss=132.54288\n",
      "Epoch 26855: train_loss=121.75919, val_loss=132.55913\n",
      "Epoch 26856: train_loss=121.75685, val_loss=132.53596\n",
      "Epoch 26857: train_loss=121.75460, val_loss=132.55891\n",
      "Epoch 26858: train_loss=121.75269, val_loss=132.53056\n",
      "Epoch 26859: train_loss=121.75080, val_loss=132.55930\n",
      "Epoch 26860: train_loss=121.74958, val_loss=132.52444\n",
      "Epoch 26861: train_loss=121.74867, val_loss=132.56296\n",
      "Epoch 26862: train_loss=121.74920, val_loss=132.52184\n",
      "Epoch 26863: train_loss=121.75042, val_loss=132.57315\n",
      "Epoch 26864: train_loss=121.75319, val_loss=132.52344\n",
      "Epoch 26865: train_loss=121.75718, val_loss=132.58966\n",
      "Epoch 26866: train_loss=121.76262, val_loss=132.53020\n",
      "Epoch 26867: train_loss=121.76967, val_loss=132.61284\n",
      "Epoch 26868: train_loss=121.77763, val_loss=132.54211\n",
      "Epoch 26869: train_loss=121.78658, val_loss=132.63904\n",
      "Epoch 26870: train_loss=121.79587, val_loss=132.55540\n",
      "Epoch 26871: train_loss=121.80500, val_loss=132.66298\n",
      "Epoch 26872: train_loss=121.81268, val_loss=132.56619\n",
      "Epoch 26873: train_loss=121.81849, val_loss=132.67535\n",
      "Epoch 26874: train_loss=121.82010, val_loss=132.56650\n",
      "Epoch 26875: train_loss=121.81844, val_loss=132.66689\n",
      "Epoch 26876: train_loss=121.81113, val_loss=132.54993\n",
      "Epoch 26877: train_loss=121.80035, val_loss=132.63548\n",
      "Epoch 26878: train_loss=121.78458, val_loss=132.52036\n",
      "Epoch 26879: train_loss=121.76585, val_loss=132.58751\n",
      "Epoch 26880: train_loss=121.74513, val_loss=132.48657\n",
      "Epoch 26881: train_loss=121.72385, val_loss=132.53613\n",
      "Epoch 26882: train_loss=121.70364, val_loss=132.45937\n",
      "Epoch 26883: train_loss=121.68562, val_loss=132.49350\n",
      "Epoch 26884: train_loss=121.67036, val_loss=132.44263\n",
      "Epoch 26885: train_loss=121.65764, val_loss=132.46191\n",
      "Epoch 26886: train_loss=121.64774, val_loss=132.43459\n",
      "Epoch 26887: train_loss=121.63999, val_loss=132.44014\n",
      "Epoch 26888: train_loss=121.63414, val_loss=132.43292\n",
      "Epoch 26889: train_loss=121.62977, val_loss=132.42696\n",
      "Epoch 26890: train_loss=121.62651, val_loss=132.43611\n",
      "Epoch 26891: train_loss=121.62420, val_loss=132.41994\n",
      "Epoch 26892: train_loss=121.62249, val_loss=132.44159\n",
      "Epoch 26893: train_loss=121.62129, val_loss=132.41586\n",
      "Epoch 26894: train_loss=121.62039, val_loss=132.44684\n",
      "Epoch 26895: train_loss=121.62000, val_loss=132.41130\n",
      "Epoch 26896: train_loss=121.62006, val_loss=132.45160\n",
      "Epoch 26897: train_loss=121.62045, val_loss=132.40807\n",
      "Epoch 26898: train_loss=121.62128, val_loss=132.45947\n",
      "Epoch 26899: train_loss=121.62297, val_loss=132.40897\n",
      "Epoch 26900: train_loss=121.62557, val_loss=132.47322\n",
      "Epoch 26901: train_loss=121.62936, val_loss=132.41353\n",
      "Epoch 26902: train_loss=121.63432, val_loss=132.49170\n",
      "Epoch 26903: train_loss=121.64082, val_loss=132.42194\n",
      "Epoch 26904: train_loss=121.64856, val_loss=132.51463\n",
      "Epoch 26905: train_loss=121.65697, val_loss=132.43390\n",
      "Epoch 26906: train_loss=121.66624, val_loss=132.53990\n",
      "Epoch 26907: train_loss=121.67556, val_loss=132.44780\n",
      "Epoch 26908: train_loss=121.68485, val_loss=132.56274\n",
      "Epoch 26909: train_loss=121.69189, val_loss=132.45804\n",
      "Epoch 26910: train_loss=121.69727, val_loss=132.57338\n",
      "Epoch 26911: train_loss=121.69836, val_loss=132.45595\n",
      "Epoch 26912: train_loss=121.69545, val_loss=132.56108\n",
      "Epoch 26913: train_loss=121.68696, val_loss=132.43677\n",
      "Epoch 26914: train_loss=121.67400, val_loss=132.52484\n",
      "Epoch 26915: train_loss=121.65591, val_loss=132.40456\n",
      "Epoch 26916: train_loss=121.63478, val_loss=132.47209\n",
      "Epoch 26917: train_loss=121.61130, val_loss=132.36804\n",
      "Epoch 26918: train_loss=121.58766, val_loss=132.41516\n",
      "Epoch 26919: train_loss=121.56576, val_loss=132.33847\n",
      "Epoch 26920: train_loss=121.54650, val_loss=132.36812\n",
      "Epoch 26921: train_loss=121.53063, val_loss=132.32243\n",
      "Epoch 26922: train_loss=121.51825, val_loss=132.33603\n",
      "Epoch 26923: train_loss=121.50918, val_loss=132.31776\n",
      "Epoch 26924: train_loss=121.50282, val_loss=132.31612\n",
      "Epoch 26925: train_loss=121.49876, val_loss=132.32068\n",
      "Epoch 26926: train_loss=121.49639, val_loss=132.30594\n",
      "Epoch 26927: train_loss=121.49519, val_loss=132.32787\n",
      "Epoch 26928: train_loss=121.49476, val_loss=132.30144\n",
      "Epoch 26929: train_loss=121.49497, val_loss=132.33629\n",
      "Epoch 26930: train_loss=121.49560, val_loss=132.29924\n",
      "Epoch 26931: train_loss=121.49677, val_loss=132.34523\n",
      "Epoch 26932: train_loss=121.49821, val_loss=132.29877\n",
      "Epoch 26933: train_loss=121.50005, val_loss=132.35468\n",
      "Epoch 26934: train_loss=121.50196, val_loss=132.29935\n",
      "Epoch 26935: train_loss=121.50416, val_loss=132.36476\n",
      "Epoch 26936: train_loss=121.50690, val_loss=132.30167\n",
      "Epoch 26937: train_loss=121.50985, val_loss=132.37660\n",
      "Epoch 26938: train_loss=121.51301, val_loss=132.30583\n",
      "Epoch 26939: train_loss=121.51646, val_loss=132.38895\n",
      "Epoch 26940: train_loss=121.52044, val_loss=132.31023\n",
      "Epoch 26941: train_loss=121.52441, val_loss=132.40166\n",
      "Epoch 26942: train_loss=121.52850, val_loss=132.31549\n",
      "Epoch 26943: train_loss=121.53233, val_loss=132.41193\n",
      "Epoch 26944: train_loss=121.53477, val_loss=132.31755\n",
      "Epoch 26945: train_loss=121.53635, val_loss=132.41544\n",
      "Epoch 26946: train_loss=121.53580, val_loss=132.31432\n",
      "Epoch 26947: train_loss=121.53336, val_loss=132.40790\n",
      "Epoch 26948: train_loss=121.52786, val_loss=132.30237\n",
      "Epoch 26949: train_loss=121.51980, val_loss=132.38550\n",
      "Epoch 26950: train_loss=121.50847, val_loss=132.28114\n",
      "Epoch 26951: train_loss=121.49465, val_loss=132.34991\n",
      "Epoch 26952: train_loss=121.47894, val_loss=132.25499\n",
      "Epoch 26953: train_loss=121.46207, val_loss=132.30858\n",
      "Epoch 26954: train_loss=121.44579, val_loss=132.23128\n",
      "Epoch 26955: train_loss=121.43018, val_loss=132.27003\n",
      "Epoch 26956: train_loss=121.41581, val_loss=132.21367\n",
      "Epoch 26957: train_loss=121.40344, val_loss=132.23952\n",
      "Epoch 26958: train_loss=121.39322, val_loss=132.20340\n",
      "Epoch 26959: train_loss=121.38487, val_loss=132.21739\n",
      "Epoch 26960: train_loss=121.37806, val_loss=132.19812\n",
      "Epoch 26961: train_loss=121.37254, val_loss=132.20207\n",
      "Epoch 26962: train_loss=121.36789, val_loss=132.19579\n",
      "Epoch 26963: train_loss=121.36395, val_loss=132.19118\n",
      "Epoch 26964: train_loss=121.36060, val_loss=132.19514\n",
      "Epoch 26965: train_loss=121.35768, val_loss=132.18263\n",
      "Epoch 26966: train_loss=121.35503, val_loss=132.19502\n",
      "Epoch 26967: train_loss=121.35283, val_loss=132.17523\n",
      "Epoch 26968: train_loss=121.35101, val_loss=132.19650\n",
      "Epoch 26969: train_loss=121.34959, val_loss=132.16969\n",
      "Epoch 26970: train_loss=121.34871, val_loss=132.20107\n",
      "Epoch 26971: train_loss=121.34858, val_loss=132.16698\n",
      "Epoch 26972: train_loss=121.34953, val_loss=132.21158\n",
      "Epoch 26973: train_loss=121.35197, val_loss=132.16846\n",
      "Epoch 26974: train_loss=121.35599, val_loss=132.22917\n",
      "Epoch 26975: train_loss=121.36185, val_loss=132.17583\n",
      "Epoch 26976: train_loss=121.37002, val_loss=132.25748\n",
      "Epoch 26977: train_loss=121.38118, val_loss=132.19267\n",
      "Epoch 26978: train_loss=121.39484, val_loss=132.29770\n",
      "Epoch 26979: train_loss=121.41145, val_loss=132.22086\n",
      "Epoch 26980: train_loss=121.43138, val_loss=132.35214\n",
      "Epoch 26981: train_loss=121.45428, val_loss=132.26123\n",
      "Epoch 26982: train_loss=121.47994, val_loss=132.41386\n",
      "Epoch 26983: train_loss=121.50416, val_loss=132.30119\n",
      "Epoch 26984: train_loss=121.52615, val_loss=132.45618\n",
      "Epoch 26985: train_loss=121.53802, val_loss=132.31454\n",
      "Epoch 26986: train_loss=121.54081, val_loss=132.44460\n",
      "Epoch 26987: train_loss=121.52676, val_loss=132.27873\n",
      "Epoch 26988: train_loss=121.50071, val_loss=132.36627\n",
      "Epoch 26989: train_loss=121.45966, val_loss=132.20190\n",
      "Epoch 26990: train_loss=121.41222, val_loss=132.25034\n",
      "Epoch 26991: train_loss=121.36298, val_loss=132.12672\n",
      "Epoch 26992: train_loss=121.31881, val_loss=132.14943\n",
      "Epoch 26993: train_loss=121.28444, val_loss=132.09122\n",
      "Epoch 26994: train_loss=121.26189, val_loss=132.09450\n",
      "Epoch 26995: train_loss=121.25118, val_loss=132.09920\n",
      "Epoch 26996: train_loss=121.25028, val_loss=132.08153\n",
      "Epoch 26997: train_loss=121.25601, val_loss=132.12959\n",
      "Epoch 26998: train_loss=121.26553, val_loss=132.08881\n",
      "Epoch 26999: train_loss=121.27567, val_loss=132.15854\n",
      "Epoch 27000: train_loss=121.28456, val_loss=132.09665\n",
      "Epoch 27001: train_loss=121.28995, val_loss=132.16904\n",
      "Epoch 27002: train_loss=121.29087, val_loss=132.09306\n",
      "Epoch 27003: train_loss=121.28680, val_loss=132.15622\n",
      "Epoch 27004: train_loss=121.27863, val_loss=132.07837\n",
      "Epoch 27005: train_loss=121.26698, val_loss=132.12668\n",
      "Epoch 27006: train_loss=121.25362, val_loss=132.05933\n",
      "Epoch 27007: train_loss=121.23966, val_loss=132.09200\n",
      "Epoch 27008: train_loss=121.22659, val_loss=132.04362\n",
      "Epoch 27009: train_loss=121.21503, val_loss=132.06122\n",
      "Epoch 27010: train_loss=121.20533, val_loss=132.03427\n",
      "Epoch 27011: train_loss=121.19784, val_loss=132.03889\n",
      "Epoch 27012: train_loss=121.19227, val_loss=132.03340\n",
      "Epoch 27013: train_loss=121.18845, val_loss=132.02571\n",
      "Epoch 27014: train_loss=121.18593, val_loss=132.03682\n",
      "Epoch 27015: train_loss=121.18420, val_loss=132.01888\n",
      "Epoch 27016: train_loss=121.18301, val_loss=132.04094\n",
      "Epoch 27017: train_loss=121.18210, val_loss=132.01378\n",
      "Epoch 27018: train_loss=121.18119, val_loss=132.04359\n",
      "Epoch 27019: train_loss=121.18056, val_loss=132.00906\n",
      "Epoch 27020: train_loss=121.18000, val_loss=132.04553\n",
      "Epoch 27021: train_loss=121.17965, val_loss=132.00461\n",
      "Epoch 27022: train_loss=121.17928, val_loss=132.04836\n",
      "Epoch 27023: train_loss=121.17921, val_loss=132.00256\n",
      "Epoch 27024: train_loss=121.17928, val_loss=132.05368\n",
      "Epoch 27025: train_loss=121.17972, val_loss=132.00221\n",
      "Epoch 27026: train_loss=121.18005, val_loss=132.05939\n",
      "Epoch 27027: train_loss=121.18102, val_loss=132.00146\n",
      "Epoch 27028: train_loss=121.18163, val_loss=132.06367\n",
      "Epoch 27029: train_loss=121.18249, val_loss=131.99973\n",
      "Epoch 27030: train_loss=121.18249, val_loss=132.06595\n",
      "Epoch 27031: train_loss=121.18268, val_loss=131.99788\n",
      "Epoch 27032: train_loss=121.18221, val_loss=132.06795\n",
      "Epoch 27033: train_loss=121.18204, val_loss=131.99603\n",
      "Epoch 27034: train_loss=121.18112, val_loss=132.06865\n",
      "Epoch 27035: train_loss=121.18038, val_loss=131.99258\n",
      "Epoch 27036: train_loss=121.17888, val_loss=132.06647\n",
      "Epoch 27037: train_loss=121.17715, val_loss=131.98755\n",
      "Epoch 27038: train_loss=121.17432, val_loss=132.06015\n",
      "Epoch 27039: train_loss=121.17070, val_loss=131.97975\n",
      "Epoch 27040: train_loss=121.16611, val_loss=132.04866\n",
      "Epoch 27041: train_loss=121.16078, val_loss=131.96884\n",
      "Epoch 27042: train_loss=121.15444, val_loss=132.03363\n",
      "Epoch 27043: train_loss=121.14767, val_loss=131.95673\n",
      "Epoch 27044: train_loss=121.14003, val_loss=132.01628\n",
      "Epoch 27045: train_loss=121.13227, val_loss=131.94434\n",
      "Epoch 27046: train_loss=121.12415, val_loss=131.99796\n",
      "Epoch 27047: train_loss=121.11623, val_loss=131.93178\n",
      "Epoch 27048: train_loss=121.10802, val_loss=131.97826\n",
      "Epoch 27049: train_loss=121.09995, val_loss=131.91850\n",
      "Epoch 27050: train_loss=121.09174, val_loss=131.95746\n",
      "Epoch 27051: train_loss=121.08386, val_loss=131.90573\n",
      "Epoch 27052: train_loss=121.07623, val_loss=131.93831\n",
      "Epoch 27053: train_loss=121.06900, val_loss=131.89549\n",
      "Epoch 27054: train_loss=121.06219, val_loss=131.92204\n",
      "Epoch 27055: train_loss=121.05586, val_loss=131.88759\n",
      "Epoch 27056: train_loss=121.04996, val_loss=131.90857\n",
      "Epoch 27057: train_loss=121.04453, val_loss=131.88080\n",
      "Epoch 27058: train_loss=121.03946, val_loss=131.89619\n",
      "Epoch 27059: train_loss=121.03474, val_loss=131.87407\n",
      "Epoch 27060: train_loss=121.03025, val_loss=131.88556\n",
      "Epoch 27061: train_loss=121.02597, val_loss=131.86835\n",
      "Epoch 27062: train_loss=121.02204, val_loss=131.87770\n",
      "Epoch 27063: train_loss=121.01814, val_loss=131.86353\n",
      "Epoch 27064: train_loss=121.01456, val_loss=131.87112\n",
      "Epoch 27065: train_loss=121.01098, val_loss=131.85760\n",
      "Epoch 27066: train_loss=121.00751, val_loss=131.86539\n",
      "Epoch 27067: train_loss=121.00414, val_loss=131.85121\n",
      "Epoch 27068: train_loss=121.00108, val_loss=131.86110\n",
      "Epoch 27069: train_loss=120.99811, val_loss=131.84454\n",
      "Epoch 27070: train_loss=120.99552, val_loss=131.86067\n",
      "Epoch 27071: train_loss=120.99345, val_loss=131.83965\n",
      "Epoch 27072: train_loss=120.99229, val_loss=131.86598\n",
      "Epoch 27073: train_loss=120.99235, val_loss=131.83783\n",
      "Epoch 27074: train_loss=120.99451, val_loss=131.88292\n",
      "Epoch 27075: train_loss=120.99963, val_loss=131.84486\n",
      "Epoch 27076: train_loss=121.00866, val_loss=131.92020\n",
      "Epoch 27077: train_loss=121.02443, val_loss=131.87230\n",
      "Epoch 27078: train_loss=121.04813, val_loss=131.99667\n",
      "Epoch 27079: train_loss=121.08305, val_loss=131.94061\n",
      "Epoch 27080: train_loss=121.13139, val_loss=132.13162\n",
      "Epoch 27081: train_loss=121.19490, val_loss=132.06747\n",
      "Epoch 27082: train_loss=121.27718, val_loss=132.33127\n",
      "Epoch 27083: train_loss=121.36865, val_loss=132.24022\n",
      "Epoch 27084: train_loss=121.46822, val_loss=132.52631\n",
      "Epoch 27085: train_loss=121.54240, val_loss=132.34756\n",
      "Epoch 27086: train_loss=121.58484, val_loss=132.53221\n",
      "Epoch 27087: train_loss=121.54668, val_loss=132.21913\n",
      "Epoch 27088: train_loss=121.44549, val_loss=132.23636\n",
      "Epoch 27089: train_loss=121.28105, val_loss=131.92186\n",
      "Epoch 27090: train_loss=121.11250, val_loss=131.88445\n",
      "Epoch 27091: train_loss=120.98211, val_loss=131.78059\n",
      "Epoch 27092: train_loss=120.92123, val_loss=131.78001\n",
      "Epoch 27093: train_loss=120.93011, val_loss=131.89169\n",
      "Epoch 27094: train_loss=120.98586, val_loss=131.86971\n",
      "Epoch 27095: train_loss=121.05376, val_loss=132.03412\n",
      "Epoch 27096: train_loss=121.10115, val_loss=131.91766\n",
      "Epoch 27097: train_loss=121.10968, val_loss=132.00479\n",
      "Epoch 27098: train_loss=121.07396, val_loss=131.83594\n",
      "Epoch 27099: train_loss=121.01279, val_loss=131.85210\n",
      "Epoch 27100: train_loss=120.94847, val_loss=131.75525\n",
      "Epoch 27101: train_loss=120.90241, val_loss=131.75351\n",
      "Epoch 27102: train_loss=120.88556, val_loss=131.78015\n",
      "Epoch 27103: train_loss=120.89515, val_loss=131.76114\n",
      "Epoch 27104: train_loss=120.91965, val_loss=131.85081\n",
      "Epoch 27105: train_loss=120.94337, val_loss=131.78659\n",
      "Epoch 27106: train_loss=120.95497, val_loss=131.86145\n",
      "Epoch 27107: train_loss=120.94878, val_loss=131.76630\n",
      "Epoch 27108: train_loss=120.92777, val_loss=131.80080\n",
      "Epoch 27109: train_loss=120.89990, val_loss=131.73123\n",
      "Epoch 27110: train_loss=120.87425, val_loss=131.73895\n",
      "Epoch 27111: train_loss=120.85811, val_loss=131.73312\n",
      "Epoch 27112: train_loss=120.85367, val_loss=131.72084\n",
      "Epoch 27113: train_loss=120.85828, val_loss=131.76266\n",
      "Epoch 27114: train_loss=120.86627, val_loss=131.72549\n",
      "Epoch 27115: train_loss=120.87260, val_loss=131.77719\n",
      "Epoch 27116: train_loss=120.87390, val_loss=131.72113\n",
      "Epoch 27117: train_loss=120.86885, val_loss=131.75899\n",
      "Epoch 27118: train_loss=120.85876, val_loss=131.70621\n",
      "Epoch 27119: train_loss=120.84641, val_loss=131.72577\n",
      "Epoch 27120: train_loss=120.83454, val_loss=131.69797\n",
      "Epoch 27121: train_loss=120.82539, val_loss=131.70000\n",
      "Epoch 27122: train_loss=120.81993, val_loss=131.70282\n",
      "Epoch 27123: train_loss=120.81794, val_loss=131.68890\n",
      "Epoch 27124: train_loss=120.81792, val_loss=131.71255\n",
      "Epoch 27125: train_loss=120.81840, val_loss=131.68535\n",
      "Epoch 27126: train_loss=120.81812, val_loss=131.71480\n",
      "Epoch 27127: train_loss=120.81618, val_loss=131.68034\n",
      "Epoch 27128: train_loss=120.81261, val_loss=131.70537\n",
      "Epoch 27129: train_loss=120.80773, val_loss=131.67259\n",
      "Epoch 27130: train_loss=120.80194, val_loss=131.69012\n",
      "Epoch 27131: train_loss=120.79607, val_loss=131.66653\n",
      "Epoch 27132: train_loss=120.79032, val_loss=131.67502\n",
      "Epoch 27133: train_loss=120.78532, val_loss=131.66376\n",
      "Epoch 27134: train_loss=120.78109, val_loss=131.66304\n",
      "Epoch 27135: train_loss=120.77749, val_loss=131.66328\n",
      "Epoch 27136: train_loss=120.77460, val_loss=131.65465\n",
      "Epoch 27137: train_loss=120.77194, val_loss=131.66296\n",
      "Epoch 27138: train_loss=120.76958, val_loss=131.64775\n",
      "Epoch 27139: train_loss=120.76740, val_loss=131.66209\n",
      "Epoch 27140: train_loss=120.76524, val_loss=131.64215\n",
      "Epoch 27141: train_loss=120.76309, val_loss=131.66133\n",
      "Epoch 27142: train_loss=120.76101, val_loss=131.63765\n",
      "Epoch 27143: train_loss=120.75881, val_loss=131.66066\n",
      "Epoch 27144: train_loss=120.75683, val_loss=131.63310\n",
      "Epoch 27145: train_loss=120.75471, val_loss=131.65929\n",
      "Epoch 27146: train_loss=120.75259, val_loss=131.62885\n",
      "Epoch 27147: train_loss=120.75033, val_loss=131.65779\n",
      "Epoch 27148: train_loss=120.74821, val_loss=131.62431\n",
      "Epoch 27149: train_loss=120.74573, val_loss=131.65436\n",
      "Epoch 27150: train_loss=120.74312, val_loss=131.61893\n",
      "Epoch 27151: train_loss=120.74023, val_loss=131.64992\n",
      "Epoch 27152: train_loss=120.73738, val_loss=131.61371\n",
      "Epoch 27153: train_loss=120.73423, val_loss=131.64459\n",
      "Epoch 27154: train_loss=120.73090, val_loss=131.60782\n",
      "Epoch 27155: train_loss=120.72763, val_loss=131.63826\n",
      "Epoch 27156: train_loss=120.72414, val_loss=131.60217\n",
      "Epoch 27157: train_loss=120.72079, val_loss=131.63257\n",
      "Epoch 27158: train_loss=120.71741, val_loss=131.59709\n",
      "Epoch 27159: train_loss=120.71404, val_loss=131.62729\n",
      "Epoch 27160: train_loss=120.71078, val_loss=131.59175\n",
      "Epoch 27161: train_loss=120.70748, val_loss=131.62062\n",
      "Epoch 27162: train_loss=120.70415, val_loss=131.58479\n",
      "Epoch 27163: train_loss=120.70099, val_loss=131.61476\n",
      "Epoch 27164: train_loss=120.69791, val_loss=131.57890\n",
      "Epoch 27165: train_loss=120.69485, val_loss=131.61012\n",
      "Epoch 27166: train_loss=120.69207, val_loss=131.57420\n",
      "Epoch 27167: train_loss=120.68932, val_loss=131.60765\n",
      "Epoch 27168: train_loss=120.68722, val_loss=131.57043\n",
      "Epoch 27169: train_loss=120.68543, val_loss=131.60788\n",
      "Epoch 27170: train_loss=120.68419, val_loss=131.56720\n",
      "Epoch 27171: train_loss=120.68357, val_loss=131.61092\n",
      "Epoch 27172: train_loss=120.68383, val_loss=131.56554\n",
      "Epoch 27173: train_loss=120.68517, val_loss=131.61934\n",
      "Epoch 27174: train_loss=120.68803, val_loss=131.56805\n",
      "Epoch 27175: train_loss=120.69241, val_loss=131.63637\n",
      "Epoch 27176: train_loss=120.69855, val_loss=131.57704\n",
      "Epoch 27177: train_loss=120.70632, val_loss=131.66277\n",
      "Epoch 27178: train_loss=120.71637, val_loss=131.59360\n",
      "Epoch 27179: train_loss=120.72762, val_loss=131.69621\n",
      "Epoch 27180: train_loss=120.74093, val_loss=131.61487\n",
      "Epoch 27181: train_loss=120.75511, val_loss=131.73135\n",
      "Epoch 27182: train_loss=120.76866, val_loss=131.63547\n",
      "Epoch 27183: train_loss=120.78053, val_loss=131.75668\n",
      "Epoch 27184: train_loss=120.78761, val_loss=131.64392\n",
      "Epoch 27185: train_loss=120.78995, val_loss=131.75549\n",
      "Epoch 27186: train_loss=120.78436, val_loss=131.62959\n",
      "Epoch 27187: train_loss=120.77266, val_loss=131.71979\n",
      "Epoch 27188: train_loss=120.75272, val_loss=131.59212\n",
      "Epoch 27189: train_loss=120.72823, val_loss=131.65601\n",
      "Epoch 27190: train_loss=120.69949, val_loss=131.54404\n",
      "Epoch 27191: train_loss=120.66988, val_loss=131.58368\n",
      "Epoch 27192: train_loss=120.64225, val_loss=131.50604\n",
      "Epoch 27193: train_loss=120.61848, val_loss=131.52623\n",
      "Epoch 27194: train_loss=120.60043, val_loss=131.49129\n",
      "Epoch 27195: train_loss=120.58842, val_loss=131.49376\n",
      "Epoch 27196: train_loss=120.58218, val_loss=131.49799\n",
      "Epoch 27197: train_loss=120.58075, val_loss=131.48248\n",
      "Epoch 27198: train_loss=120.58266, val_loss=131.51439\n",
      "Epoch 27199: train_loss=120.58613, val_loss=131.48344\n",
      "Epoch 27200: train_loss=120.58985, val_loss=131.53142\n",
      "Epoch 27201: train_loss=120.59316, val_loss=131.48666\n",
      "Epoch 27202: train_loss=120.59553, val_loss=131.54044\n",
      "Epoch 27203: train_loss=120.59639, val_loss=131.48618\n",
      "Epoch 27204: train_loss=120.59571, val_loss=131.54077\n",
      "Epoch 27205: train_loss=120.59388, val_loss=131.48172\n",
      "Epoch 27206: train_loss=120.59067, val_loss=131.53360\n",
      "Epoch 27207: train_loss=120.58649, val_loss=131.47412\n",
      "Epoch 27208: train_loss=120.58151, val_loss=131.52167\n",
      "Epoch 27209: train_loss=120.57589, val_loss=131.46455\n",
      "Epoch 27210: train_loss=120.56976, val_loss=131.50665\n",
      "Epoch 27211: train_loss=120.56367, val_loss=131.45424\n",
      "Epoch 27212: train_loss=120.55738, val_loss=131.49086\n",
      "Epoch 27213: train_loss=120.55125, val_loss=131.44447\n",
      "Epoch 27214: train_loss=120.54526, val_loss=131.47667\n",
      "Epoch 27215: train_loss=120.53955, val_loss=131.43617\n",
      "Epoch 27216: train_loss=120.53416, val_loss=131.46410\n",
      "Epoch 27217: train_loss=120.52905, val_loss=131.43024\n",
      "Epoch 27218: train_loss=120.52411, val_loss=131.45396\n",
      "Epoch 27219: train_loss=120.51946, val_loss=131.42390\n",
      "Epoch 27220: train_loss=120.51498, val_loss=131.44388\n",
      "Epoch 27221: train_loss=120.51067, val_loss=131.41792\n",
      "Epoch 27222: train_loss=120.50652, val_loss=131.43477\n",
      "Epoch 27223: train_loss=120.50263, val_loss=131.41234\n",
      "Epoch 27224: train_loss=120.49888, val_loss=131.42729\n",
      "Epoch 27225: train_loss=120.49541, val_loss=131.40668\n",
      "Epoch 27226: train_loss=120.49219, val_loss=131.42157\n",
      "Epoch 27227: train_loss=120.48919, val_loss=131.40071\n",
      "Epoch 27228: train_loss=120.48630, val_loss=131.41681\n",
      "Epoch 27229: train_loss=120.48382, val_loss=131.39337\n",
      "Epoch 27230: train_loss=120.48156, val_loss=131.41386\n",
      "Epoch 27231: train_loss=120.48004, val_loss=131.38727\n",
      "Epoch 27232: train_loss=120.47912, val_loss=131.41766\n",
      "Epoch 27233: train_loss=120.47984, val_loss=131.38547\n",
      "Epoch 27234: train_loss=120.48214, val_loss=131.43271\n",
      "Epoch 27235: train_loss=120.48717, val_loss=131.39142\n",
      "Epoch 27236: train_loss=120.49541, val_loss=131.46460\n",
      "Epoch 27237: train_loss=120.50882, val_loss=131.41362\n",
      "Epoch 27238: train_loss=120.52819, val_loss=131.52583\n",
      "Epoch 27239: train_loss=120.55495, val_loss=131.46452\n",
      "Epoch 27240: train_loss=120.59150, val_loss=131.62708\n",
      "Epoch 27241: train_loss=120.63729, val_loss=131.55263\n",
      "Epoch 27242: train_loss=120.69382, val_loss=131.76538\n",
      "Epoch 27243: train_loss=120.75507, val_loss=131.66437\n",
      "Epoch 27244: train_loss=120.81888, val_loss=131.89267\n",
      "Epoch 27245: train_loss=120.86670, val_loss=131.73241\n",
      "Epoch 27246: train_loss=120.89479, val_loss=131.90521\n",
      "Epoch 27247: train_loss=120.87841, val_loss=131.66554\n",
      "Epoch 27248: train_loss=120.82400, val_loss=131.73315\n",
      "Epoch 27249: train_loss=120.72707, val_loss=131.47937\n",
      "Epoch 27250: train_loss=120.61572, val_loss=131.48041\n",
      "Epoch 27251: train_loss=120.51213, val_loss=131.33742\n",
      "Epoch 27252: train_loss=120.43936, val_loss=131.33275\n",
      "Epoch 27253: train_loss=120.40688, val_loss=131.34413\n",
      "Epoch 27254: train_loss=120.41105, val_loss=131.33308\n",
      "Epoch 27255: train_loss=120.43941, val_loss=131.43976\n",
      "Epoch 27256: train_loss=120.47699, val_loss=131.38576\n",
      "Epoch 27257: train_loss=120.50887, val_loss=131.50249\n",
      "Epoch 27258: train_loss=120.52509, val_loss=131.39708\n",
      "Epoch 27259: train_loss=120.52159, val_loss=131.47394\n",
      "Epoch 27260: train_loss=120.49925, val_loss=131.35120\n",
      "Epoch 27261: train_loss=120.46476, val_loss=131.38533\n",
      "Epoch 27262: train_loss=120.42793, val_loss=131.30180\n",
      "Epoch 27263: train_loss=120.39668, val_loss=131.31154\n",
      "Epoch 27264: train_loss=120.37671, val_loss=131.29622\n",
      "Epoch 27265: train_loss=120.36921, val_loss=131.28761\n",
      "Epoch 27266: train_loss=120.37201, val_loss=131.32639\n",
      "Epoch 27267: train_loss=120.38084, val_loss=131.29364\n",
      "Epoch 27268: train_loss=120.39087, val_loss=131.35472\n",
      "Epoch 27269: train_loss=120.39828, val_loss=131.29878\n",
      "Epoch 27270: train_loss=120.40015, val_loss=131.35573\n",
      "Epoch 27271: train_loss=120.39623, val_loss=131.28961\n",
      "Epoch 27272: train_loss=120.38714, val_loss=131.32986\n",
      "Epoch 27273: train_loss=120.37488, val_loss=131.27248\n",
      "Epoch 27274: train_loss=120.36151, val_loss=131.29466\n",
      "Epoch 27275: train_loss=120.34951, val_loss=131.26172\n",
      "Epoch 27276: train_loss=120.33997, val_loss=131.26784\n",
      "Epoch 27277: train_loss=120.33355, val_loss=131.26306\n",
      "Epoch 27278: train_loss=120.33011, val_loss=131.25435\n",
      "Epoch 27279: train_loss=120.32887, val_loss=131.27069\n",
      "Epoch 27280: train_loss=120.32889, val_loss=131.24829\n",
      "Epoch 27281: train_loss=120.32920, val_loss=131.27606\n",
      "Epoch 27282: train_loss=120.32922, val_loss=131.24394\n",
      "Epoch 27283: train_loss=120.32817, val_loss=131.27492\n",
      "Epoch 27284: train_loss=120.32629, val_loss=131.23857\n",
      "Epoch 27285: train_loss=120.32326, val_loss=131.26852\n",
      "Epoch 27286: train_loss=120.31955, val_loss=131.23251\n",
      "Epoch 27287: train_loss=120.31512, val_loss=131.25868\n",
      "Epoch 27288: train_loss=120.31061, val_loss=131.22644\n",
      "Epoch 27289: train_loss=120.30569, val_loss=131.24687\n",
      "Epoch 27290: train_loss=120.30099, val_loss=131.21957\n",
      "Epoch 27291: train_loss=120.29623, val_loss=131.23386\n",
      "Epoch 27292: train_loss=120.29182, val_loss=131.21292\n",
      "Epoch 27293: train_loss=120.28760, val_loss=131.22151\n",
      "Epoch 27294: train_loss=120.28361, val_loss=131.20694\n",
      "Epoch 27295: train_loss=120.27985, val_loss=131.21036\n",
      "Epoch 27296: train_loss=120.27636, val_loss=131.20186\n",
      "Epoch 27297: train_loss=120.27312, val_loss=131.20163\n",
      "Epoch 27298: train_loss=120.27000, val_loss=131.19720\n",
      "Epoch 27299: train_loss=120.26696, val_loss=131.19511\n",
      "Epoch 27300: train_loss=120.26391, val_loss=131.19420\n",
      "Epoch 27301: train_loss=120.26099, val_loss=131.18968\n",
      "Epoch 27302: train_loss=120.25802, val_loss=131.19116\n",
      "Epoch 27303: train_loss=120.25523, val_loss=131.18340\n",
      "Epoch 27304: train_loss=120.25238, val_loss=131.18796\n",
      "Epoch 27305: train_loss=120.24976, val_loss=131.17604\n",
      "Epoch 27306: train_loss=120.24741, val_loss=131.18581\n",
      "Epoch 27307: train_loss=120.24538, val_loss=131.16815\n",
      "Epoch 27308: train_loss=120.24396, val_loss=131.18709\n",
      "Epoch 27309: train_loss=120.24337, val_loss=131.16237\n",
      "Epoch 27310: train_loss=120.24370, val_loss=131.19475\n",
      "Epoch 27311: train_loss=120.24548, val_loss=131.16127\n",
      "Epoch 27312: train_loss=120.24915, val_loss=131.21225\n",
      "Epoch 27313: train_loss=120.25535, val_loss=131.16835\n",
      "Epoch 27314: train_loss=120.26455, val_loss=131.24438\n",
      "Epoch 27315: train_loss=120.27741, val_loss=131.18779\n",
      "Epoch 27316: train_loss=120.29355, val_loss=131.29158\n",
      "Epoch 27317: train_loss=120.31309, val_loss=131.22124\n",
      "Epoch 27318: train_loss=120.33587, val_loss=131.35211\n",
      "Epoch 27319: train_loss=120.35979, val_loss=131.26305\n",
      "Epoch 27320: train_loss=120.38438, val_loss=131.40880\n",
      "Epoch 27321: train_loss=120.40500, val_loss=131.29520\n",
      "Epoch 27322: train_loss=120.42120, val_loss=131.43555\n",
      "Epoch 27323: train_loss=120.42662, val_loss=131.29477\n",
      "Epoch 27324: train_loss=120.42195, val_loss=131.40678\n",
      "Epoch 27325: train_loss=120.40168, val_loss=131.24994\n",
      "Epoch 27326: train_loss=120.37167, val_loss=131.32350\n",
      "Epoch 27327: train_loss=120.33131, val_loss=131.17838\n",
      "Epoch 27328: train_loss=120.28832, val_loss=131.22037\n",
      "Epoch 27329: train_loss=120.24741, val_loss=131.11996\n",
      "Epoch 27330: train_loss=120.21336, val_loss=131.14049\n",
      "Epoch 27331: train_loss=120.18844, val_loss=131.09753\n",
      "Epoch 27332: train_loss=120.17290, val_loss=131.09909\n",
      "Epoch 27333: train_loss=120.16611, val_loss=131.10796\n",
      "Epoch 27334: train_loss=120.16622, val_loss=131.09134\n",
      "Epoch 27335: train_loss=120.17094, val_loss=131.13507\n",
      "Epoch 27336: train_loss=120.17822, val_loss=131.09793\n",
      "Epoch 27337: train_loss=120.18600, val_loss=131.16098\n",
      "Epoch 27338: train_loss=120.19336, val_loss=131.10568\n",
      "Epoch 27339: train_loss=120.19858, val_loss=131.17513\n",
      "Epoch 27340: train_loss=120.20176, val_loss=131.10669\n",
      "Epoch 27341: train_loss=120.20161, val_loss=131.17331\n",
      "Epoch 27342: train_loss=120.19897, val_loss=131.09879\n",
      "Epoch 27343: train_loss=120.19317, val_loss=131.15820\n",
      "Epoch 27344: train_loss=120.18584, val_loss=131.08603\n",
      "Epoch 27345: train_loss=120.17661, val_loss=131.13496\n",
      "Epoch 27346: train_loss=120.16685, val_loss=131.07068\n",
      "Epoch 27347: train_loss=120.15644, val_loss=131.10774\n",
      "Epoch 27348: train_loss=120.14640, val_loss=131.05640\n",
      "Epoch 27349: train_loss=120.13679, val_loss=131.08284\n",
      "Epoch 27350: train_loss=120.12830, val_loss=131.04759\n",
      "Epoch 27351: train_loss=120.12077, val_loss=131.06410\n",
      "Epoch 27352: train_loss=120.11460, val_loss=131.04326\n",
      "Epoch 27353: train_loss=120.10941, val_loss=131.05066\n",
      "Epoch 27354: train_loss=120.10509, val_loss=131.04155\n",
      "Epoch 27355: train_loss=120.10151, val_loss=131.04036\n",
      "Epoch 27356: train_loss=120.09835, val_loss=131.04007\n",
      "Epoch 27357: train_loss=120.09560, val_loss=131.03175\n",
      "Epoch 27358: train_loss=120.09325, val_loss=131.03960\n",
      "Epoch 27359: train_loss=120.09108, val_loss=131.02481\n",
      "Epoch 27360: train_loss=120.08918, val_loss=131.03961\n",
      "Epoch 27361: train_loss=120.08768, val_loss=131.01833\n",
      "Epoch 27362: train_loss=120.08648, val_loss=131.04114\n",
      "Epoch 27363: train_loss=120.08604, val_loss=131.01268\n",
      "Epoch 27364: train_loss=120.08623, val_loss=131.04732\n",
      "Epoch 27365: train_loss=120.08775, val_loss=131.01077\n",
      "Epoch 27366: train_loss=120.09051, val_loss=131.06120\n",
      "Epoch 27367: train_loss=120.09509, val_loss=131.01549\n",
      "Epoch 27368: train_loss=120.10145, val_loss=131.08536\n",
      "Epoch 27369: train_loss=120.11088, val_loss=131.02881\n",
      "Epoch 27370: train_loss=120.12309, val_loss=131.12335\n",
      "Epoch 27371: train_loss=120.13902, val_loss=131.05644\n",
      "Epoch 27372: train_loss=120.15918, val_loss=131.17981\n",
      "Epoch 27373: train_loss=120.18216, val_loss=131.09770\n",
      "Epoch 27374: train_loss=120.20847, val_loss=131.24442\n",
      "Epoch 27375: train_loss=120.23390, val_loss=131.14027\n",
      "Epoch 27376: train_loss=120.25788, val_loss=131.29123\n",
      "Epoch 27377: train_loss=120.27261, val_loss=131.15849\n",
      "Epoch 27378: train_loss=120.27944, val_loss=131.28874\n",
      "Epoch 27379: train_loss=120.26985, val_loss=131.13072\n",
      "Epoch 27380: train_loss=120.24942, val_loss=131.22287\n",
      "Epoch 27381: train_loss=120.21400, val_loss=131.06241\n",
      "Epoch 27382: train_loss=120.17197, val_loss=131.11707\n",
      "Epoch 27383: train_loss=120.12618, val_loss=130.99016\n",
      "Epoch 27384: train_loss=120.08450, val_loss=131.01942\n",
      "Epoch 27385: train_loss=120.05019, val_loss=130.94966\n",
      "Epoch 27386: train_loss=120.02554, val_loss=130.95996\n",
      "Epoch 27387: train_loss=120.01102, val_loss=130.94783\n",
      "Epoch 27388: train_loss=120.00524, val_loss=130.93993\n",
      "Epoch 27389: train_loss=120.00629, val_loss=130.97202\n",
      "Epoch 27390: train_loss=120.01191, val_loss=130.94325\n",
      "Epoch 27391: train_loss=120.01991, val_loss=131.00159\n",
      "Epoch 27392: train_loss=120.02839, val_loss=130.95253\n",
      "Epoch 27393: train_loss=120.03596, val_loss=131.02316\n",
      "Epoch 27394: train_loss=120.04195, val_loss=130.95761\n",
      "Epoch 27395: train_loss=120.04484, val_loss=131.02869\n",
      "Epoch 27396: train_loss=120.04478, val_loss=130.95343\n",
      "Epoch 27397: train_loss=120.04103, val_loss=131.01810\n",
      "Epoch 27398: train_loss=120.03505, val_loss=130.94221\n",
      "Epoch 27399: train_loss=120.02668, val_loss=130.99669\n",
      "Epoch 27400: train_loss=120.01732, val_loss=130.92676\n",
      "Epoch 27401: train_loss=120.00671, val_loss=130.96945\n",
      "Epoch 27402: train_loss=119.99622, val_loss=130.91124\n",
      "Epoch 27403: train_loss=119.98616, val_loss=130.94296\n",
      "Epoch 27404: train_loss=119.97688, val_loss=130.89984\n",
      "Epoch 27405: train_loss=119.96849, val_loss=130.92107\n",
      "Epoch 27406: train_loss=119.96124, val_loss=130.89407\n",
      "Epoch 27407: train_loss=119.95519, val_loss=130.90691\n",
      "Epoch 27408: train_loss=119.95008, val_loss=130.89214\n",
      "Epoch 27409: train_loss=119.94592, val_loss=130.89665\n",
      "Epoch 27410: train_loss=119.94232, val_loss=130.89104\n",
      "Epoch 27411: train_loss=119.93920, val_loss=130.88765\n",
      "Epoch 27412: train_loss=119.93638, val_loss=130.88881\n",
      "Epoch 27413: train_loss=119.93382, val_loss=130.87915\n",
      "Epoch 27414: train_loss=119.93155, val_loss=130.88704\n",
      "Epoch 27415: train_loss=119.92950, val_loss=130.87126\n",
      "Epoch 27416: train_loss=119.92776, val_loss=130.88699\n",
      "Epoch 27417: train_loss=119.92642, val_loss=130.86455\n",
      "Epoch 27418: train_loss=119.92564, val_loss=130.88901\n",
      "Epoch 27419: train_loss=119.92544, val_loss=130.85921\n",
      "Epoch 27420: train_loss=119.92604, val_loss=130.89536\n",
      "Epoch 27421: train_loss=119.92784, val_loss=130.85733\n",
      "Epoch 27422: train_loss=119.93070, val_loss=130.90919\n",
      "Epoch 27423: train_loss=119.93536, val_loss=130.86359\n",
      "Epoch 27424: train_loss=119.94186, val_loss=130.93556\n",
      "Epoch 27425: train_loss=119.95080, val_loss=130.87856\n",
      "Epoch 27426: train_loss=119.96195, val_loss=130.97150\n",
      "Epoch 27427: train_loss=119.97566, val_loss=130.90134\n",
      "Epoch 27428: train_loss=119.99213, val_loss=131.01633\n",
      "Epoch 27429: train_loss=120.01062, val_loss=130.93176\n",
      "Epoch 27430: train_loss=120.03157, val_loss=131.06616\n",
      "Epoch 27431: train_loss=120.05179, val_loss=130.96324\n",
      "Epoch 27432: train_loss=120.07104, val_loss=131.10422\n",
      "Epoch 27433: train_loss=120.08376, val_loss=130.97934\n",
      "Epoch 27434: train_loss=120.09134, val_loss=131.10858\n",
      "Epoch 27435: train_loss=120.08730, val_loss=130.96294\n",
      "Epoch 27436: train_loss=120.07442, val_loss=131.06314\n",
      "Epoch 27437: train_loss=120.04895, val_loss=130.91281\n",
      "Epoch 27438: train_loss=120.01694, val_loss=130.98058\n",
      "Epoch 27439: train_loss=119.97881, val_loss=130.85092\n",
      "Epoch 27440: train_loss=119.94086, val_loss=130.89102\n",
      "Epoch 27441: train_loss=119.90646, val_loss=130.80626\n",
      "Epoch 27442: train_loss=119.87861, val_loss=130.82535\n",
      "Epoch 27443: train_loss=119.85904, val_loss=130.79301\n",
      "Epoch 27444: train_loss=119.84747, val_loss=130.79305\n",
      "Epoch 27445: train_loss=119.84286, val_loss=130.80405\n",
      "Epoch 27446: train_loss=119.84345, val_loss=130.78488\n",
      "Epoch 27447: train_loss=119.84755, val_loss=130.82587\n",
      "Epoch 27448: train_loss=119.85330, val_loss=130.78801\n",
      "Epoch 27449: train_loss=119.85959, val_loss=130.84529\n",
      "Epoch 27450: train_loss=119.86498, val_loss=130.79134\n",
      "Epoch 27451: train_loss=119.86884, val_loss=130.85484\n",
      "Epoch 27452: train_loss=119.87059, val_loss=130.79010\n",
      "Epoch 27453: train_loss=119.86996, val_loss=130.85236\n",
      "Epoch 27454: train_loss=119.86722, val_loss=130.78442\n",
      "Epoch 27455: train_loss=119.86251, val_loss=130.84216\n",
      "Epoch 27456: train_loss=119.85659, val_loss=130.77570\n",
      "Epoch 27457: train_loss=119.84955, val_loss=130.82510\n",
      "Epoch 27458: train_loss=119.84160, val_loss=130.76424\n",
      "Epoch 27459: train_loss=119.83332, val_loss=130.80371\n",
      "Epoch 27460: train_loss=119.82490, val_loss=130.75221\n",
      "Epoch 27461: train_loss=119.81683, val_loss=130.78265\n",
      "Epoch 27462: train_loss=119.80950, val_loss=130.74297\n",
      "Epoch 27463: train_loss=119.80279, val_loss=130.76500\n",
      "Epoch 27464: train_loss=119.79681, val_loss=130.73604\n",
      "Epoch 27465: train_loss=119.79142, val_loss=130.75018\n",
      "Epoch 27466: train_loss=119.78674, val_loss=130.73050\n",
      "Epoch 27467: train_loss=119.78250, val_loss=130.73854\n",
      "Epoch 27468: train_loss=119.77876, val_loss=130.72626\n",
      "Epoch 27469: train_loss=119.77544, val_loss=130.72859\n",
      "Epoch 27470: train_loss=119.77223, val_loss=130.72235\n",
      "Epoch 27471: train_loss=119.76914, val_loss=130.72160\n",
      "Epoch 27472: train_loss=119.76623, val_loss=130.71941\n",
      "Epoch 27473: train_loss=119.76336, val_loss=130.71596\n",
      "Epoch 27474: train_loss=119.76057, val_loss=130.71689\n",
      "Epoch 27475: train_loss=119.75786, val_loss=130.70990\n",
      "Epoch 27476: train_loss=119.75522, val_loss=130.71452\n",
      "Epoch 27477: train_loss=119.75266, val_loss=130.70323\n",
      "Epoch 27478: train_loss=119.75028, val_loss=130.71243\n",
      "Epoch 27479: train_loss=119.74828, val_loss=130.69556\n",
      "Epoch 27480: train_loss=119.74679, val_loss=130.71312\n",
      "Epoch 27481: train_loss=119.74600, val_loss=130.68907\n",
      "Epoch 27482: train_loss=119.74633, val_loss=130.72086\n",
      "Epoch 27483: train_loss=119.74819, val_loss=130.68771\n",
      "Epoch 27484: train_loss=119.75195, val_loss=130.74074\n",
      "Epoch 27485: train_loss=119.75900, val_loss=130.69635\n",
      "Epoch 27486: train_loss=119.76997, val_loss=130.77925\n",
      "Epoch 27487: train_loss=119.78603, val_loss=130.72316\n",
      "Epoch 27488: train_loss=119.80860, val_loss=130.84814\n",
      "Epoch 27489: train_loss=119.83846, val_loss=130.77867\n",
      "Epoch 27490: train_loss=119.87673, val_loss=130.94992\n",
      "Epoch 27491: train_loss=119.92155, val_loss=130.86267\n",
      "Epoch 27492: train_loss=119.97416, val_loss=131.07173\n",
      "Epoch 27493: train_loss=120.02560, val_loss=130.95079\n",
      "Epoch 27494: train_loss=120.07465, val_loss=131.16124\n",
      "Epoch 27495: train_loss=120.10440, val_loss=130.98386\n",
      "Epoch 27496: train_loss=120.11317, val_loss=131.13568\n",
      "Epoch 27497: train_loss=120.08256, val_loss=130.90044\n",
      "Epoch 27498: train_loss=120.02212, val_loss=130.96449\n",
      "Epoch 27499: train_loss=119.93367, val_loss=130.74133\n",
      "Epoch 27500: train_loss=119.84061, val_loss=130.75331\n",
      "Epoch 27501: train_loss=119.75854, val_loss=130.63713\n",
      "Epoch 27502: train_loss=119.70346, val_loss=130.63815\n",
      "Epoch 27503: train_loss=119.67984, val_loss=130.65102\n",
      "Epoch 27504: train_loss=119.68356, val_loss=130.63574\n",
      "Epoch 27505: train_loss=119.70563, val_loss=130.72968\n",
      "Epoch 27506: train_loss=119.73526, val_loss=130.67557\n",
      "Epoch 27507: train_loss=119.76234, val_loss=130.78574\n",
      "Epoch 27508: train_loss=119.77828, val_loss=130.68816\n",
      "Epoch 27509: train_loss=119.77979, val_loss=130.77132\n",
      "Epoch 27510: train_loss=119.76572, val_loss=130.65594\n",
      "Epoch 27511: train_loss=119.74114, val_loss=130.70279\n",
      "Epoch 27512: train_loss=119.71140, val_loss=130.61285\n",
      "Epoch 27513: train_loss=119.68294, val_loss=130.63326\n",
      "Epoch 27514: train_loss=119.66095, val_loss=130.59784\n",
      "Epoch 27515: train_loss=119.64784, val_loss=130.59804\n",
      "Epoch 27516: train_loss=119.64335, val_loss=130.61369\n",
      "Epoch 27517: train_loss=119.64548, val_loss=130.59276\n",
      "Epoch 27518: train_loss=119.65165, val_loss=130.64114\n",
      "Epoch 27519: train_loss=119.65877, val_loss=130.59843\n",
      "Epoch 27520: train_loss=119.66432, val_loss=130.65636\n",
      "Epoch 27521: train_loss=119.66662, val_loss=130.59760\n",
      "Epoch 27522: train_loss=119.66477, val_loss=130.64876\n",
      "Epoch 27523: train_loss=119.65924, val_loss=130.58736\n",
      "Epoch 27524: train_loss=119.65049, val_loss=130.62453\n",
      "Epoch 27525: train_loss=119.64052, val_loss=130.57437\n",
      "Epoch 27526: train_loss=119.63029, val_loss=130.59604\n",
      "Epoch 27527: train_loss=119.62111, val_loss=130.56520\n",
      "Epoch 27528: train_loss=119.61359, val_loss=130.57341\n",
      "Epoch 27529: train_loss=119.60799, val_loss=130.56409\n",
      "Epoch 27530: train_loss=119.60411, val_loss=130.55956\n",
      "Epoch 27531: train_loss=119.60174, val_loss=130.56650\n",
      "Epoch 27532: train_loss=119.60025, val_loss=130.55040\n",
      "Epoch 27533: train_loss=119.59940, val_loss=130.57063\n",
      "Epoch 27534: train_loss=119.59894, val_loss=130.54646\n",
      "Epoch 27535: train_loss=119.59869, val_loss=130.57570\n",
      "Epoch 27536: train_loss=119.59824, val_loss=130.54395\n",
      "Epoch 27537: train_loss=119.59769, val_loss=130.57864\n",
      "Epoch 27538: train_loss=119.59700, val_loss=130.54085\n",
      "Epoch 27539: train_loss=119.59597, val_loss=130.57890\n",
      "Epoch 27540: train_loss=119.59474, val_loss=130.53696\n",
      "Epoch 27541: train_loss=119.59325, val_loss=130.57738\n",
      "Epoch 27542: train_loss=119.59196, val_loss=130.53195\n",
      "Epoch 27543: train_loss=119.59021, val_loss=130.57457\n",
      "Epoch 27544: train_loss=119.58880, val_loss=130.52667\n",
      "Epoch 27545: train_loss=119.58720, val_loss=130.57181\n",
      "Epoch 27546: train_loss=119.58570, val_loss=130.52214\n",
      "Epoch 27547: train_loss=119.58388, val_loss=130.56956\n",
      "Epoch 27548: train_loss=119.58232, val_loss=130.51839\n",
      "Epoch 27549: train_loss=119.58025, val_loss=130.56755\n",
      "Epoch 27550: train_loss=119.57847, val_loss=130.51466\n",
      "Epoch 27551: train_loss=119.57619, val_loss=130.56531\n",
      "Epoch 27552: train_loss=119.57424, val_loss=130.51141\n",
      "Epoch 27553: train_loss=119.57182, val_loss=130.56226\n",
      "Epoch 27554: train_loss=119.56967, val_loss=130.50652\n",
      "Epoch 27555: train_loss=119.56723, val_loss=130.55827\n",
      "Epoch 27556: train_loss=119.56527, val_loss=130.50212\n",
      "Epoch 27557: train_loss=119.56322, val_loss=130.55568\n",
      "Epoch 27558: train_loss=119.56165, val_loss=130.49770\n",
      "Epoch 27559: train_loss=119.56013, val_loss=130.55336\n",
      "Epoch 27560: train_loss=119.55904, val_loss=130.49330\n",
      "Epoch 27561: train_loss=119.55794, val_loss=130.55302\n",
      "Epoch 27562: train_loss=119.55768, val_loss=130.49200\n",
      "Epoch 27563: train_loss=119.55741, val_loss=130.55762\n",
      "Epoch 27564: train_loss=119.55820, val_loss=130.49300\n",
      "Epoch 27565: train_loss=119.55909, val_loss=130.56479\n",
      "Epoch 27566: train_loss=119.56114, val_loss=130.49583\n",
      "Epoch 27567: train_loss=119.56356, val_loss=130.57625\n",
      "Epoch 27568: train_loss=119.56778, val_loss=130.50108\n",
      "Epoch 27569: train_loss=119.57233, val_loss=130.59065\n",
      "Epoch 27570: train_loss=119.57809, val_loss=130.50803\n",
      "Epoch 27571: train_loss=119.58426, val_loss=130.60692\n",
      "Epoch 27572: train_loss=119.59060, val_loss=130.51575\n",
      "Epoch 27573: train_loss=119.59636, val_loss=130.62038\n",
      "Epoch 27574: train_loss=119.60066, val_loss=130.51970\n",
      "Epoch 27575: train_loss=119.60305, val_loss=130.62349\n",
      "Epoch 27576: train_loss=119.60225, val_loss=130.51567\n",
      "Epoch 27577: train_loss=119.59846, val_loss=130.61212\n",
      "Epoch 27578: train_loss=119.59088, val_loss=130.50064\n",
      "Epoch 27579: train_loss=119.58020, val_loss=130.58249\n",
      "Epoch 27580: train_loss=119.56590, val_loss=130.47530\n",
      "Epoch 27581: train_loss=119.54932, val_loss=130.53984\n",
      "Epoch 27582: train_loss=119.53111, val_loss=130.44670\n",
      "Epoch 27583: train_loss=119.51236, val_loss=130.49332\n",
      "Epoch 27584: train_loss=119.49479, val_loss=130.42299\n",
      "Epoch 27585: train_loss=119.47888, val_loss=130.45230\n",
      "Epoch 27586: train_loss=119.46540, val_loss=130.40884\n",
      "Epoch 27587: train_loss=119.45469, val_loss=130.42215\n",
      "Epoch 27588: train_loss=119.44671, val_loss=130.40515\n",
      "Epoch 27589: train_loss=119.44139, val_loss=130.40367\n",
      "Epoch 27590: train_loss=119.43829, val_loss=130.41069\n",
      "Epoch 27591: train_loss=119.43688, val_loss=130.39658\n",
      "Epoch 27592: train_loss=119.43674, val_loss=130.41994\n",
      "Epoch 27593: train_loss=119.43712, val_loss=130.39319\n",
      "Epoch 27594: train_loss=119.43802, val_loss=130.42780\n",
      "Epoch 27595: train_loss=119.43906, val_loss=130.39078\n",
      "Epoch 27596: train_loss=119.44010, val_loss=130.43454\n",
      "Epoch 27597: train_loss=119.44139, val_loss=130.38963\n",
      "Epoch 27598: train_loss=119.44302, val_loss=130.44235\n",
      "Epoch 27599: train_loss=119.44498, val_loss=130.38986\n",
      "Epoch 27600: train_loss=119.44725, val_loss=130.45160\n",
      "Epoch 27601: train_loss=119.45003, val_loss=130.39146\n",
      "Epoch 27602: train_loss=119.45302, val_loss=130.46190\n",
      "Epoch 27603: train_loss=119.45660, val_loss=130.39371\n",
      "Epoch 27604: train_loss=119.46031, val_loss=130.47316\n",
      "Epoch 27605: train_loss=119.46492, val_loss=130.39954\n",
      "Epoch 27606: train_loss=119.47021, val_loss=130.49121\n",
      "Epoch 27607: train_loss=119.47650, val_loss=130.41042\n",
      "Epoch 27608: train_loss=119.48363, val_loss=130.51257\n",
      "Epoch 27609: train_loss=119.49105, val_loss=130.42206\n",
      "Epoch 27610: train_loss=119.49866, val_loss=130.53215\n",
      "Epoch 27611: train_loss=119.50584, val_loss=130.43112\n",
      "Epoch 27612: train_loss=119.51198, val_loss=130.54478\n",
      "Epoch 27613: train_loss=119.51580, val_loss=130.43361\n",
      "Epoch 27614: train_loss=119.51713, val_loss=130.54282\n",
      "Epoch 27615: train_loss=119.51406, val_loss=130.42390\n",
      "Epoch 27616: train_loss=119.50745, val_loss=130.52150\n",
      "Epoch 27617: train_loss=119.49615, val_loss=130.40128\n",
      "Epoch 27618: train_loss=119.48061, val_loss=130.48129\n",
      "Epoch 27619: train_loss=119.46187, val_loss=130.36931\n",
      "Epoch 27620: train_loss=119.44085, val_loss=130.42827\n",
      "Epoch 27621: train_loss=119.41894, val_loss=130.33698\n",
      "Epoch 27622: train_loss=119.39775, val_loss=130.37610\n",
      "Epoch 27623: train_loss=119.37885, val_loss=130.31506\n",
      "Epoch 27624: train_loss=119.36313, val_loss=130.33669\n",
      "Epoch 27625: train_loss=119.35118, val_loss=130.30759\n",
      "Epoch 27626: train_loss=119.34286, val_loss=130.31194\n",
      "Epoch 27627: train_loss=119.33774, val_loss=130.31084\n",
      "Epoch 27628: train_loss=119.33534, val_loss=130.29942\n",
      "Epoch 27629: train_loss=119.33485, val_loss=130.31995\n",
      "Epoch 27630: train_loss=119.33566, val_loss=130.29491\n",
      "Epoch 27631: train_loss=119.33722, val_loss=130.33049\n",
      "Epoch 27632: train_loss=119.33884, val_loss=130.29355\n",
      "Epoch 27633: train_loss=119.34044, val_loss=130.33916\n",
      "Epoch 27634: train_loss=119.34211, val_loss=130.29350\n",
      "Epoch 27635: train_loss=119.34391, val_loss=130.34715\n",
      "Epoch 27636: train_loss=119.34541, val_loss=130.29430\n",
      "Epoch 27637: train_loss=119.34695, val_loss=130.35492\n",
      "Epoch 27638: train_loss=119.34856, val_loss=130.29524\n",
      "Epoch 27639: train_loss=119.35018, val_loss=130.36139\n",
      "Epoch 27640: train_loss=119.35175, val_loss=130.29591\n",
      "Epoch 27641: train_loss=119.35337, val_loss=130.36845\n",
      "Epoch 27642: train_loss=119.35519, val_loss=130.29784\n",
      "Epoch 27643: train_loss=119.35668, val_loss=130.37537\n",
      "Epoch 27644: train_loss=119.35819, val_loss=130.29945\n",
      "Epoch 27645: train_loss=119.36002, val_loss=130.38124\n",
      "Epoch 27646: train_loss=119.36155, val_loss=130.30029\n",
      "Epoch 27647: train_loss=119.36319, val_loss=130.38596\n",
      "Epoch 27648: train_loss=119.36443, val_loss=130.30057\n",
      "Epoch 27649: train_loss=119.36596, val_loss=130.39090\n",
      "Epoch 27650: train_loss=119.36729, val_loss=130.30124\n",
      "Epoch 27651: train_loss=119.36815, val_loss=130.39355\n",
      "Epoch 27652: train_loss=119.36796, val_loss=130.29955\n",
      "Epoch 27653: train_loss=119.36665, val_loss=130.39027\n",
      "Epoch 27654: train_loss=119.36372, val_loss=130.29211\n",
      "Epoch 27655: train_loss=119.35873, val_loss=130.37630\n",
      "Epoch 27656: train_loss=119.35197, val_loss=130.27850\n",
      "Epoch 27657: train_loss=119.34341, val_loss=130.35384\n",
      "Epoch 27658: train_loss=119.33337, val_loss=130.26157\n",
      "Epoch 27659: train_loss=119.32211, val_loss=130.32545\n",
      "Epoch 27660: train_loss=119.30970, val_loss=130.24271\n",
      "Epoch 27661: train_loss=119.29711, val_loss=130.29410\n",
      "Epoch 27662: train_loss=119.28471, val_loss=130.22571\n",
      "Epoch 27663: train_loss=119.27292, val_loss=130.26491\n",
      "Epoch 27664: train_loss=119.26212, val_loss=130.21304\n",
      "Epoch 27665: train_loss=119.25228, val_loss=130.23940\n",
      "Epoch 27666: train_loss=119.24390, val_loss=130.20465\n",
      "Epoch 27667: train_loss=119.23679, val_loss=130.21927\n",
      "Epoch 27668: train_loss=119.23095, val_loss=130.20042\n",
      "Epoch 27669: train_loss=119.22629, val_loss=130.20506\n",
      "Epoch 27670: train_loss=119.22261, val_loss=130.19958\n",
      "Epoch 27671: train_loss=119.21960, val_loss=130.19501\n",
      "Epoch 27672: train_loss=119.21716, val_loss=130.19965\n",
      "Epoch 27673: train_loss=119.21515, val_loss=130.18753\n",
      "Epoch 27674: train_loss=119.21336, val_loss=130.20036\n",
      "Epoch 27675: train_loss=119.21201, val_loss=130.18077\n",
      "Epoch 27676: train_loss=119.21104, val_loss=130.20253\n",
      "Epoch 27677: train_loss=119.21037, val_loss=130.17564\n",
      "Epoch 27678: train_loss=119.21041, val_loss=130.20757\n",
      "Epoch 27679: train_loss=119.21106, val_loss=130.17332\n",
      "Epoch 27680: train_loss=119.21255, val_loss=130.21794\n",
      "Epoch 27681: train_loss=119.21561, val_loss=130.17419\n",
      "Epoch 27682: train_loss=119.22027, val_loss=130.23582\n",
      "Epoch 27683: train_loss=119.22698, val_loss=130.18222\n",
      "Epoch 27684: train_loss=119.23627, val_loss=130.26691\n",
      "Epoch 27685: train_loss=119.24908, val_loss=130.20273\n",
      "Epoch 27686: train_loss=119.26672, val_loss=130.31932\n",
      "Epoch 27687: train_loss=119.28942, val_loss=130.24242\n",
      "Epoch 27688: train_loss=119.31763, val_loss=130.39279\n",
      "Epoch 27689: train_loss=119.34879, val_loss=130.29817\n",
      "Epoch 27690: train_loss=119.38406, val_loss=130.47505\n",
      "Epoch 27691: train_loss=119.41729, val_loss=130.35435\n",
      "Epoch 27692: train_loss=119.44898, val_loss=130.53406\n",
      "Epoch 27693: train_loss=119.46764, val_loss=130.37560\n",
      "Epoch 27694: train_loss=119.47369, val_loss=130.52126\n",
      "Epoch 27695: train_loss=119.45618, val_loss=130.32854\n",
      "Epoch 27696: train_loss=119.42091, val_loss=130.41631\n",
      "Epoch 27697: train_loss=119.36538, val_loss=130.22662\n",
      "Epoch 27698: train_loss=119.30293, val_loss=130.26694\n",
      "Epoch 27699: train_loss=119.24075, val_loss=130.13724\n",
      "Epoch 27700: train_loss=119.18925, val_loss=130.15126\n",
      "Epoch 27701: train_loss=119.15461, val_loss=130.11305\n",
      "Epoch 27702: train_loss=119.13861, val_loss=130.10832\n",
      "Epoch 27703: train_loss=119.13841, val_loss=130.14725\n",
      "Epoch 27704: train_loss=119.14944, val_loss=130.11734\n",
      "Epoch 27705: train_loss=119.16635, val_loss=130.19838\n",
      "Epoch 27706: train_loss=119.18364, val_loss=130.13715\n",
      "Epoch 27707: train_loss=119.19693, val_loss=130.22475\n",
      "Epoch 27708: train_loss=119.20238, val_loss=130.13829\n",
      "Epoch 27709: train_loss=119.19984, val_loss=130.20992\n",
      "Epoch 27710: train_loss=119.18954, val_loss=130.11836\n",
      "Epoch 27711: train_loss=119.17400, val_loss=130.16733\n",
      "Epoch 27712: train_loss=119.15540, val_loss=130.09390\n",
      "Epoch 27713: train_loss=119.13731, val_loss=130.12219\n",
      "Epoch 27714: train_loss=119.12192, val_loss=130.08058\n",
      "Epoch 27715: train_loss=119.11041, val_loss=130.09032\n",
      "Epoch 27716: train_loss=119.10279, val_loss=130.08078\n",
      "Epoch 27717: train_loss=119.09870, val_loss=130.07370\n",
      "Epoch 27718: train_loss=119.09753, val_loss=130.09038\n",
      "Epoch 27719: train_loss=119.09818, val_loss=130.06808\n",
      "Epoch 27720: train_loss=119.09999, val_loss=130.10269\n",
      "Epoch 27721: train_loss=119.10239, val_loss=130.06689\n",
      "Epoch 27722: train_loss=119.10445, val_loss=130.11055\n",
      "Epoch 27723: train_loss=119.10547, val_loss=130.06474\n",
      "Epoch 27724: train_loss=119.10583, val_loss=130.11153\n",
      "Epoch 27725: train_loss=119.10484, val_loss=130.06042\n",
      "Epoch 27726: train_loss=119.10329, val_loss=130.10732\n",
      "Epoch 27727: train_loss=119.10072, val_loss=130.05505\n",
      "Epoch 27728: train_loss=119.09756, val_loss=130.10031\n",
      "Epoch 27729: train_loss=119.09363, val_loss=130.04948\n",
      "Epoch 27730: train_loss=119.08940, val_loss=130.09003\n",
      "Epoch 27731: train_loss=119.08462, val_loss=130.04175\n",
      "Epoch 27732: train_loss=119.07999, val_loss=130.07774\n",
      "Epoch 27733: train_loss=119.07516, val_loss=130.03439\n",
      "Epoch 27734: train_loss=119.07063, val_loss=130.06610\n",
      "Epoch 27735: train_loss=119.06594, val_loss=130.02777\n",
      "Epoch 27736: train_loss=119.06149, val_loss=130.05530\n",
      "Epoch 27737: train_loss=119.05713, val_loss=130.02258\n",
      "Epoch 27738: train_loss=119.05289, val_loss=130.04594\n",
      "Epoch 27739: train_loss=119.04900, val_loss=130.01761\n",
      "Epoch 27740: train_loss=119.04562, val_loss=130.03755\n",
      "Epoch 27741: train_loss=119.04210, val_loss=130.01189\n",
      "Epoch 27742: train_loss=119.03895, val_loss=130.02904\n",
      "Epoch 27743: train_loss=119.03579, val_loss=130.00568\n",
      "Epoch 27744: train_loss=119.03307, val_loss=130.02228\n",
      "Epoch 27745: train_loss=119.03032, val_loss=129.99974\n",
      "Epoch 27746: train_loss=119.02808, val_loss=130.01877\n",
      "Epoch 27747: train_loss=119.02599, val_loss=129.99500\n",
      "Epoch 27748: train_loss=119.02441, val_loss=130.01910\n",
      "Epoch 27749: train_loss=119.02344, val_loss=129.99210\n",
      "Epoch 27750: train_loss=119.02328, val_loss=130.02647\n",
      "Epoch 27751: train_loss=119.02418, val_loss=129.99184\n",
      "Epoch 27752: train_loss=119.02670, val_loss=130.04060\n",
      "Epoch 27753: train_loss=119.03096, val_loss=129.99594\n",
      "Epoch 27754: train_loss=119.03764, val_loss=130.06577\n",
      "Epoch 27755: train_loss=119.04718, val_loss=130.00977\n",
      "Epoch 27756: train_loss=119.06046, val_loss=130.10724\n",
      "Epoch 27757: train_loss=119.07784, val_loss=130.03905\n",
      "Epoch 27758: train_loss=119.10078, val_loss=130.17067\n",
      "Epoch 27759: train_loss=119.12800, val_loss=130.08778\n",
      "Epoch 27760: train_loss=119.16130, val_loss=130.25227\n",
      "Epoch 27761: train_loss=119.19511, val_loss=130.14796\n",
      "Epoch 27762: train_loss=119.23222, val_loss=130.33224\n",
      "Epoch 27763: train_loss=119.26312, val_loss=130.19818\n",
      "Epoch 27764: train_loss=119.28889, val_loss=130.37206\n",
      "Epoch 27765: train_loss=119.29576, val_loss=130.19696\n",
      "Epoch 27766: train_loss=119.28661, val_loss=130.32271\n",
      "Epoch 27767: train_loss=119.25142, val_loss=130.12140\n",
      "Epoch 27768: train_loss=119.20023, val_loss=130.18735\n",
      "Epoch 27769: train_loss=119.13483, val_loss=130.01086\n",
      "Epoch 27770: train_loss=119.06941, val_loss=130.03586\n",
      "Epoch 27771: train_loss=119.01266, val_loss=129.94243\n",
      "Epoch 27772: train_loss=118.97416, val_loss=129.94821\n",
      "Epoch 27773: train_loss=118.95546, val_loss=129.94943\n",
      "Epoch 27774: train_loss=118.95421, val_loss=129.93460\n",
      "Epoch 27775: train_loss=118.96552, val_loss=130.00208\n",
      "Epoch 27776: train_loss=118.98395, val_loss=129.95709\n",
      "Epoch 27777: train_loss=119.00299, val_loss=130.04967\n",
      "Epoch 27778: train_loss=119.01733, val_loss=129.97292\n",
      "Epoch 27779: train_loss=119.02429, val_loss=130.05766\n",
      "Epoch 27780: train_loss=119.02149, val_loss=129.96315\n",
      "Epoch 27781: train_loss=119.01062, val_loss=130.02542\n",
      "Epoch 27782: train_loss=118.99338, val_loss=129.93784\n",
      "Epoch 27783: train_loss=118.97378, val_loss=129.97688\n",
      "Epoch 27784: train_loss=118.95468, val_loss=129.91759\n",
      "Epoch 27785: train_loss=118.93845, val_loss=129.93610\n",
      "Epoch 27786: train_loss=118.92655, val_loss=129.91344\n",
      "Epoch 27787: train_loss=118.91920, val_loss=129.91341\n",
      "Epoch 27788: train_loss=118.91584, val_loss=129.92166\n",
      "Epoch 27789: train_loss=118.91546, val_loss=129.90376\n",
      "Epoch 27790: train_loss=118.91674, val_loss=129.93280\n",
      "Epoch 27791: train_loss=118.91894, val_loss=129.90010\n",
      "Epoch 27792: train_loss=118.92121, val_loss=129.94133\n",
      "Epoch 27793: train_loss=118.92277, val_loss=129.89825\n",
      "Epoch 27794: train_loss=118.92327, val_loss=129.94414\n",
      "Epoch 27795: train_loss=118.92261, val_loss=129.89607\n",
      "Epoch 27796: train_loss=118.92067, val_loss=129.94229\n",
      "Epoch 27797: train_loss=118.91776, val_loss=129.89221\n",
      "Epoch 27798: train_loss=118.91376, val_loss=129.93355\n",
      "Epoch 27799: train_loss=118.90910, val_loss=129.88620\n",
      "Epoch 27800: train_loss=118.90418, val_loss=129.92078\n",
      "Epoch 27801: train_loss=118.89889, val_loss=129.87859\n",
      "Epoch 27802: train_loss=118.89383, val_loss=129.90720\n",
      "Epoch 27803: train_loss=118.88872, val_loss=129.87224\n",
      "Epoch 27804: train_loss=118.88400, val_loss=129.89561\n",
      "Epoch 27805: train_loss=118.87965, val_loss=129.86703\n",
      "Epoch 27806: train_loss=118.87592, val_loss=129.88596\n",
      "Epoch 27807: train_loss=118.87228, val_loss=129.86119\n",
      "Epoch 27808: train_loss=118.86885, val_loss=129.87704\n",
      "Epoch 27809: train_loss=118.86569, val_loss=129.85596\n",
      "Epoch 27810: train_loss=118.86263, val_loss=129.86980\n",
      "Epoch 27811: train_loss=118.85971, val_loss=129.85110\n",
      "Epoch 27812: train_loss=118.85699, val_loss=129.86429\n",
      "Epoch 27813: train_loss=118.85429, val_loss=129.84761\n",
      "Epoch 27814: train_loss=118.85175, val_loss=129.86188\n",
      "Epoch 27815: train_loss=118.84930, val_loss=129.84441\n",
      "Epoch 27816: train_loss=118.84711, val_loss=129.86105\n",
      "Epoch 27817: train_loss=118.84525, val_loss=129.84041\n",
      "Epoch 27818: train_loss=118.84374, val_loss=129.86154\n",
      "Epoch 27819: train_loss=118.84260, val_loss=129.83481\n",
      "Epoch 27820: train_loss=118.84204, val_loss=129.86377\n",
      "Epoch 27821: train_loss=118.84228, val_loss=129.83031\n",
      "Epoch 27822: train_loss=118.84343, val_loss=129.87181\n",
      "Epoch 27823: train_loss=118.84614, val_loss=129.83051\n",
      "Epoch 27824: train_loss=118.85046, val_loss=129.89044\n",
      "Epoch 27825: train_loss=118.85748, val_loss=129.83939\n",
      "Epoch 27826: train_loss=118.86792, val_loss=129.92580\n",
      "Epoch 27827: train_loss=118.88243, val_loss=129.86470\n",
      "Epoch 27828: train_loss=118.90290, val_loss=129.98686\n",
      "Epoch 27829: train_loss=118.92807, val_loss=129.91214\n",
      "Epoch 27830: train_loss=118.96085, val_loss=130.07301\n",
      "Epoch 27831: train_loss=118.99738, val_loss=129.97952\n",
      "Epoch 27832: train_loss=119.04039, val_loss=130.17160\n",
      "Epoch 27833: train_loss=119.08030, val_loss=130.04765\n",
      "Epoch 27834: train_loss=119.11826, val_loss=130.23981\n",
      "Epoch 27835: train_loss=119.13885, val_loss=130.07050\n",
      "Epoch 27836: train_loss=119.14462, val_loss=130.21840\n",
      "Epoch 27837: train_loss=119.12005, val_loss=130.00737\n",
      "Epoch 27838: train_loss=119.07498, val_loss=130.08717\n",
      "Epoch 27839: train_loss=119.00690, val_loss=129.88498\n",
      "Epoch 27840: train_loss=118.93356, val_loss=129.91545\n",
      "Epoch 27841: train_loss=118.86443, val_loss=129.79182\n",
      "Epoch 27842: train_loss=118.81277, val_loss=129.80061\n",
      "Epoch 27843: train_loss=118.78252, val_loss=129.78304\n",
      "Epoch 27844: train_loss=118.77377, val_loss=129.77417\n",
      "Epoch 27845: train_loss=118.78194, val_loss=129.83757\n",
      "Epoch 27846: train_loss=118.80056, val_loss=129.79793\n",
      "Epoch 27847: train_loss=118.82251, val_loss=129.89558\n",
      "Epoch 27848: train_loss=118.84103, val_loss=129.82016\n",
      "Epoch 27849: train_loss=118.85254, val_loss=129.91261\n",
      "Epoch 27850: train_loss=118.85284, val_loss=129.81219\n",
      "Epoch 27851: train_loss=118.84390, val_loss=129.87970\n",
      "Epoch 27852: train_loss=118.82652, val_loss=129.78178\n",
      "Epoch 27853: train_loss=118.80539, val_loss=129.82327\n",
      "Epoch 27854: train_loss=118.78344, val_loss=129.75537\n",
      "Epoch 27855: train_loss=118.76436, val_loss=129.77495\n",
      "Epoch 27856: train_loss=118.75032, val_loss=129.74910\n",
      "Epoch 27857: train_loss=118.74186, val_loss=129.74928\n",
      "Epoch 27858: train_loss=118.73856, val_loss=129.76186\n",
      "Epoch 27859: train_loss=118.73909, val_loss=129.74258\n",
      "Epoch 27860: train_loss=118.74196, val_loss=129.77936\n",
      "Epoch 27861: train_loss=118.74557, val_loss=129.74310\n",
      "Epoch 27862: train_loss=118.74886, val_loss=129.79068\n",
      "Epoch 27863: train_loss=118.75075, val_loss=129.74213\n",
      "Epoch 27864: train_loss=118.75111, val_loss=129.79123\n",
      "Epoch 27865: train_loss=118.74951, val_loss=129.73688\n",
      "Epoch 27866: train_loss=118.74638, val_loss=129.78122\n",
      "Epoch 27867: train_loss=118.74149, val_loss=129.72807\n",
      "Epoch 27868: train_loss=118.73601, val_loss=129.76498\n",
      "Epoch 27869: train_loss=118.72977, val_loss=129.71840\n",
      "Epoch 27870: train_loss=118.72349, val_loss=129.74664\n",
      "Epoch 27871: train_loss=118.71732, val_loss=129.71159\n",
      "Epoch 27872: train_loss=118.71168, val_loss=129.73280\n",
      "Epoch 27873: train_loss=118.70654, val_loss=129.70811\n",
      "Epoch 27874: train_loss=118.70190, val_loss=129.72084\n",
      "Epoch 27875: train_loss=118.69788, val_loss=129.70494\n",
      "Epoch 27876: train_loss=118.69441, val_loss=129.71140\n",
      "Epoch 27877: train_loss=118.69127, val_loss=129.70271\n",
      "Epoch 27878: train_loss=118.68842, val_loss=129.70445\n",
      "Epoch 27879: train_loss=118.68570, val_loss=129.70015\n",
      "Epoch 27880: train_loss=118.68311, val_loss=129.69826\n",
      "Epoch 27881: train_loss=118.68064, val_loss=129.69582\n",
      "Epoch 27882: train_loss=118.67805, val_loss=129.69086\n",
      "Epoch 27883: train_loss=118.67563, val_loss=129.69196\n",
      "Epoch 27884: train_loss=118.67321, val_loss=129.68602\n",
      "Epoch 27885: train_loss=118.67078, val_loss=129.69017\n",
      "Epoch 27886: train_loss=118.66857, val_loss=129.68102\n",
      "Epoch 27887: train_loss=118.66649, val_loss=129.69048\n",
      "Epoch 27888: train_loss=118.66468, val_loss=129.67569\n",
      "Epoch 27889: train_loss=118.66329, val_loss=129.69313\n",
      "Epoch 27890: train_loss=118.66255, val_loss=129.66994\n",
      "Epoch 27891: train_loss=118.66283, val_loss=129.69963\n",
      "Epoch 27892: train_loss=118.66411, val_loss=129.66711\n",
      "Epoch 27893: train_loss=118.66713, val_loss=129.71509\n",
      "Epoch 27894: train_loss=118.67213, val_loss=129.67310\n",
      "Epoch 27895: train_loss=118.67971, val_loss=129.74594\n",
      "Epoch 27896: train_loss=118.69064, val_loss=129.69090\n",
      "Epoch 27897: train_loss=118.70585, val_loss=129.79422\n",
      "Epoch 27898: train_loss=118.72551, val_loss=129.72461\n",
      "Epoch 27899: train_loss=118.75104, val_loss=129.86369\n",
      "Epoch 27900: train_loss=118.78076, val_loss=129.77812\n",
      "Epoch 27901: train_loss=118.81703, val_loss=129.95148\n",
      "Epoch 27902: train_loss=118.85321, val_loss=129.84178\n",
      "Epoch 27903: train_loss=118.89113, val_loss=130.02966\n",
      "Epoch 27904: train_loss=118.91930, val_loss=129.88661\n",
      "Epoch 27905: train_loss=118.94077, val_loss=130.05550\n",
      "Epoch 27906: train_loss=118.93937, val_loss=129.86940\n",
      "Epoch 27907: train_loss=118.92136, val_loss=129.98340\n",
      "Epoch 27908: train_loss=118.87676, val_loss=129.77769\n",
      "Epoch 27909: train_loss=118.81813, val_loss=129.83281\n",
      "Epoch 27910: train_loss=118.74998, val_loss=129.66980\n",
      "Epoch 27911: train_loss=118.68793, val_loss=129.69185\n",
      "Epoch 27912: train_loss=118.63950, val_loss=129.61830\n",
      "Epoch 27913: train_loss=118.60970, val_loss=129.62170\n",
      "Epoch 27914: train_loss=118.59868, val_loss=129.63947\n",
      "Epoch 27915: train_loss=118.60303, val_loss=129.61896\n",
      "Epoch 27916: train_loss=118.61774, val_loss=129.69565\n",
      "Epoch 27917: train_loss=118.63710, val_loss=129.64253\n",
      "Epoch 27918: train_loss=118.65517, val_loss=129.73779\n",
      "Epoch 27919: train_loss=118.66785, val_loss=129.65361\n",
      "Epoch 27920: train_loss=118.67246, val_loss=129.73871\n",
      "Epoch 27921: train_loss=118.66793, val_loss=129.63954\n",
      "Epoch 27922: train_loss=118.65623, val_loss=129.70259\n",
      "Epoch 27923: train_loss=118.63921, val_loss=129.61278\n",
      "Epoch 27924: train_loss=118.61971, val_loss=129.65320\n",
      "Epoch 27925: train_loss=118.60104, val_loss=129.59212\n",
      "Epoch 27926: train_loss=118.58469, val_loss=129.61172\n",
      "Epoch 27927: train_loss=118.57262, val_loss=129.58752\n",
      "Epoch 27928: train_loss=118.56513, val_loss=129.58788\n",
      "Epoch 27929: train_loss=118.56165, val_loss=129.59508\n",
      "Epoch 27930: train_loss=118.56107, val_loss=129.57771\n",
      "Epoch 27931: train_loss=118.56246, val_loss=129.60837\n",
      "Epoch 27932: train_loss=118.56504, val_loss=129.57555\n",
      "Epoch 27933: train_loss=118.56753, val_loss=129.61880\n",
      "Epoch 27934: train_loss=118.56948, val_loss=129.57545\n",
      "Epoch 27935: train_loss=118.57039, val_loss=129.62450\n",
      "Epoch 27936: train_loss=118.57011, val_loss=129.57430\n",
      "Epoch 27937: train_loss=118.56875, val_loss=129.62299\n",
      "Epoch 27938: train_loss=118.56621, val_loss=129.57042\n",
      "Epoch 27939: train_loss=118.56299, val_loss=129.61514\n",
      "Epoch 27940: train_loss=118.55894, val_loss=129.56363\n",
      "Epoch 27941: train_loss=118.55447, val_loss=129.60359\n",
      "Epoch 27942: train_loss=118.54962, val_loss=129.55688\n",
      "Epoch 27943: train_loss=118.54471, val_loss=129.59196\n",
      "Epoch 27944: train_loss=118.53979, val_loss=129.55171\n",
      "Epoch 27945: train_loss=118.53493, val_loss=129.58202\n",
      "Epoch 27946: train_loss=118.53056, val_loss=129.54706\n",
      "Epoch 27947: train_loss=118.52641, val_loss=129.57283\n",
      "Epoch 27948: train_loss=118.52271, val_loss=129.54230\n",
      "Epoch 27949: train_loss=118.51916, val_loss=129.56425\n",
      "Epoch 27950: train_loss=118.51593, val_loss=129.53786\n",
      "Epoch 27951: train_loss=118.51292, val_loss=129.55881\n",
      "Epoch 27952: train_loss=118.51028, val_loss=129.53348\n",
      "Epoch 27953: train_loss=118.50785, val_loss=129.55484\n",
      "Epoch 27954: train_loss=118.50559, val_loss=129.52922\n",
      "Epoch 27955: train_loss=118.50346, val_loss=129.55296\n",
      "Epoch 27956: train_loss=118.50180, val_loss=129.52472\n",
      "Epoch 27957: train_loss=118.50062, val_loss=129.55344\n",
      "Epoch 27958: train_loss=118.50001, val_loss=129.52174\n",
      "Epoch 27959: train_loss=118.50003, val_loss=129.55997\n",
      "Epoch 27960: train_loss=118.50120, val_loss=129.52106\n",
      "Epoch 27961: train_loss=118.50337, val_loss=129.57214\n",
      "Epoch 27962: train_loss=118.50717, val_loss=129.52402\n",
      "Epoch 27963: train_loss=118.51282, val_loss=129.59436\n",
      "Epoch 27964: train_loss=118.52137, val_loss=129.53580\n",
      "Epoch 27965: train_loss=118.53292, val_loss=129.63138\n",
      "Epoch 27966: train_loss=118.54816, val_loss=129.56042\n",
      "Epoch 27967: train_loss=118.56733, val_loss=129.68541\n",
      "Epoch 27968: train_loss=118.59019, val_loss=129.60120\n",
      "Epoch 27969: train_loss=118.61764, val_loss=129.75583\n",
      "Epoch 27970: train_loss=118.64559, val_loss=129.65033\n",
      "Epoch 27971: train_loss=118.67491, val_loss=129.82104\n",
      "Epoch 27972: train_loss=118.69878, val_loss=129.68761\n",
      "Epoch 27973: train_loss=118.71788, val_loss=129.84955\n",
      "Epoch 27974: train_loss=118.72234, val_loss=129.68376\n",
      "Epoch 27975: train_loss=118.71402, val_loss=129.80849\n",
      "Epoch 27976: train_loss=118.68677, val_loss=129.62563\n",
      "Epoch 27977: train_loss=118.64678, val_loss=129.70293\n",
      "Epoch 27978: train_loss=118.59601, val_loss=129.54140\n",
      "Epoch 27979: train_loss=118.54393, val_loss=129.58040\n",
      "Epoch 27980: train_loss=118.49689, val_loss=129.48094\n",
      "Epoch 27981: train_loss=118.46050, val_loss=129.49513\n",
      "Epoch 27982: train_loss=118.43812, val_loss=129.47284\n",
      "Epoch 27983: train_loss=118.42925, val_loss=129.46451\n",
      "Epoch 27984: train_loss=118.43150, val_loss=129.50566\n",
      "Epoch 27985: train_loss=118.44109, val_loss=129.47342\n",
      "Epoch 27986: train_loss=118.45407, val_loss=129.54924\n",
      "Epoch 27987: train_loss=118.46722, val_loss=129.48901\n",
      "Epoch 27988: train_loss=118.47711, val_loss=129.57124\n",
      "Epoch 27989: train_loss=118.48219, val_loss=129.49045\n",
      "Epoch 27990: train_loss=118.48163, val_loss=129.56416\n",
      "Epoch 27991: train_loss=118.47573, val_loss=129.47763\n",
      "Epoch 27992: train_loss=118.46545, val_loss=129.53543\n",
      "Epoch 27993: train_loss=118.45282, val_loss=129.45810\n",
      "Epoch 27994: train_loss=118.43876, val_loss=129.49741\n",
      "Epoch 27995: train_loss=118.42523, val_loss=129.44171\n",
      "Epoch 27996: train_loss=118.41315, val_loss=129.46463\n",
      "Epoch 27997: train_loss=118.40334, val_loss=129.43486\n",
      "Epoch 27998: train_loss=118.39606, val_loss=129.44240\n",
      "Epoch 27999: train_loss=118.39108, val_loss=129.43661\n",
      "Epoch 28000: train_loss=118.38815, val_loss=129.42986\n",
      "Epoch 28001: train_loss=118.38668, val_loss=129.44336\n",
      "Epoch 28002: train_loss=118.38621, val_loss=129.42509\n",
      "Epoch 28003: train_loss=118.38647, val_loss=129.45245\n",
      "Epoch 28004: train_loss=118.38706, val_loss=129.42282\n",
      "Epoch 28005: train_loss=118.38783, val_loss=129.45999\n",
      "Epoch 28006: train_loss=118.38867, val_loss=129.42184\n",
      "Epoch 28007: train_loss=118.38953, val_loss=129.46660\n",
      "Epoch 28008: train_loss=118.39043, val_loss=129.42067\n",
      "Epoch 28009: train_loss=118.39137, val_loss=129.47150\n",
      "Epoch 28010: train_loss=118.39229, val_loss=129.41858\n",
      "Epoch 28011: train_loss=118.39305, val_loss=129.47505\n",
      "Epoch 28012: train_loss=118.39410, val_loss=129.41812\n",
      "Epoch 28013: train_loss=118.39484, val_loss=129.48085\n",
      "Epoch 28014: train_loss=118.39572, val_loss=129.41905\n",
      "Epoch 28015: train_loss=118.39646, val_loss=129.48532\n",
      "Epoch 28016: train_loss=118.39711, val_loss=129.41782\n",
      "Epoch 28017: train_loss=118.39768, val_loss=129.48802\n",
      "Epoch 28018: train_loss=118.39809, val_loss=129.41606\n",
      "Epoch 28019: train_loss=118.39828, val_loss=129.48990\n",
      "Epoch 28020: train_loss=118.39886, val_loss=129.41565\n",
      "Epoch 28021: train_loss=118.39939, val_loss=129.49423\n",
      "Epoch 28022: train_loss=118.39991, val_loss=129.41614\n",
      "Epoch 28023: train_loss=118.40015, val_loss=129.49684\n",
      "Epoch 28024: train_loss=118.40029, val_loss=129.41467\n",
      "Epoch 28025: train_loss=118.39951, val_loss=129.49596\n",
      "Epoch 28026: train_loss=118.39854, val_loss=129.41104\n",
      "Epoch 28027: train_loss=118.39711, val_loss=129.49190\n",
      "Epoch 28028: train_loss=118.39508, val_loss=129.40538\n",
      "Epoch 28029: train_loss=118.39216, val_loss=129.48328\n",
      "Epoch 28030: train_loss=118.38808, val_loss=129.39717\n",
      "Epoch 28031: train_loss=118.38274, val_loss=129.47090\n",
      "Epoch 28032: train_loss=118.37653, val_loss=129.38698\n",
      "Epoch 28033: train_loss=118.36935, val_loss=129.45357\n",
      "Epoch 28034: train_loss=118.36182, val_loss=129.37500\n",
      "Epoch 28035: train_loss=118.35355, val_loss=129.43280\n",
      "Epoch 28036: train_loss=118.34546, val_loss=129.36214\n",
      "Epoch 28037: train_loss=118.33733, val_loss=129.41159\n",
      "Epoch 28038: train_loss=118.32942, val_loss=129.35144\n",
      "Epoch 28039: train_loss=118.32184, val_loss=129.39391\n",
      "Epoch 28040: train_loss=118.31474, val_loss=129.34315\n",
      "Epoch 28041: train_loss=118.30819, val_loss=129.37747\n",
      "Epoch 28042: train_loss=118.30238, val_loss=129.33525\n",
      "Epoch 28043: train_loss=118.29711, val_loss=129.36331\n",
      "Epoch 28044: train_loss=118.29253, val_loss=129.32851\n",
      "Epoch 28045: train_loss=118.28836, val_loss=129.35197\n",
      "Epoch 28046: train_loss=118.28452, val_loss=129.32326\n",
      "Epoch 28047: train_loss=118.28117, val_loss=129.34445\n",
      "Epoch 28048: train_loss=118.27803, val_loss=129.31860\n",
      "Epoch 28049: train_loss=118.27519, val_loss=129.33865\n",
      "Epoch 28050: train_loss=118.27261, val_loss=129.31380\n",
      "Epoch 28051: train_loss=118.27029, val_loss=129.33441\n",
      "Epoch 28052: train_loss=118.26836, val_loss=129.30801\n",
      "Epoch 28053: train_loss=118.26669, val_loss=129.33372\n",
      "Epoch 28054: train_loss=118.26543, val_loss=129.30515\n",
      "Epoch 28055: train_loss=118.26494, val_loss=129.33870\n",
      "Epoch 28056: train_loss=118.26538, val_loss=129.30415\n",
      "Epoch 28057: train_loss=118.26713, val_loss=129.35005\n",
      "Epoch 28058: train_loss=118.27055, val_loss=129.30609\n",
      "Epoch 28059: train_loss=118.27624, val_loss=129.37302\n",
      "Epoch 28060: train_loss=118.28503, val_loss=129.31825\n",
      "Epoch 28061: train_loss=118.29745, val_loss=129.41554\n",
      "Epoch 28062: train_loss=118.31500, val_loss=129.34995\n",
      "Epoch 28063: train_loss=118.33797, val_loss=129.48613\n",
      "Epoch 28064: train_loss=118.36768, val_loss=129.40675\n",
      "Epoch 28065: train_loss=118.40572, val_loss=129.58731\n",
      "Epoch 28066: train_loss=118.44977, val_loss=129.48680\n",
      "Epoch 28067: train_loss=118.49908, val_loss=129.70021\n",
      "Epoch 28068: train_loss=118.54691, val_loss=129.56288\n",
      "Epoch 28069: train_loss=118.58817, val_loss=129.77086\n",
      "Epoch 28070: train_loss=118.60977, val_loss=129.57841\n",
      "Epoch 28071: train_loss=118.60801, val_loss=129.72606\n",
      "Epoch 28072: train_loss=118.57164, val_loss=129.48705\n",
      "Epoch 28073: train_loss=118.50698, val_loss=129.55283\n",
      "Epoch 28074: train_loss=118.42195, val_loss=129.34178\n",
      "Epoch 28075: train_loss=118.33604, val_loss=129.36092\n",
      "Epoch 28076: train_loss=118.26431, val_loss=129.25827\n",
      "Epoch 28077: train_loss=118.21803, val_loss=129.26057\n",
      "Epoch 28078: train_loss=118.20028, val_loss=129.27930\n",
      "Epoch 28079: train_loss=118.20634, val_loss=129.25951\n",
      "Epoch 28080: train_loss=118.22821, val_loss=129.35358\n",
      "Epoch 28081: train_loss=118.25613, val_loss=129.29431\n",
      "Epoch 28082: train_loss=118.28072, val_loss=129.40375\n",
      "Epoch 28083: train_loss=118.29486, val_loss=129.30457\n",
      "Epoch 28084: train_loss=118.29545, val_loss=129.38995\n",
      "Epoch 28085: train_loss=118.28246, val_loss=129.27722\n",
      "Epoch 28086: train_loss=118.25977, val_loss=129.32866\n",
      "Epoch 28087: train_loss=118.23272, val_loss=129.24098\n",
      "Epoch 28088: train_loss=118.20679, val_loss=129.26488\n",
      "Epoch 28089: train_loss=118.18672, val_loss=129.22679\n",
      "Epoch 28090: train_loss=118.17419, val_loss=129.22868\n",
      "Epoch 28091: train_loss=118.16913, val_loss=129.23811\n",
      "Epoch 28092: train_loss=118.16970, val_loss=129.21782\n",
      "Epoch 28093: train_loss=118.17413, val_loss=129.25887\n",
      "Epoch 28094: train_loss=118.18022, val_loss=129.21936\n",
      "Epoch 28095: train_loss=118.18602, val_loss=129.27705\n",
      "Epoch 28096: train_loss=118.18967, val_loss=129.22232\n",
      "Epoch 28097: train_loss=118.19040, val_loss=129.27835\n",
      "Epoch 28098: train_loss=118.18770, val_loss=129.21748\n",
      "Epoch 28099: train_loss=118.18250, val_loss=129.26360\n",
      "Epoch 28100: train_loss=118.17516, val_loss=129.20723\n",
      "Epoch 28101: train_loss=118.16705, val_loss=129.24055\n",
      "Epoch 28102: train_loss=118.15880, val_loss=129.19669\n",
      "Epoch 28103: train_loss=118.15125, val_loss=129.21790\n",
      "Epoch 28104: train_loss=118.14455, val_loss=129.18976\n",
      "Epoch 28105: train_loss=118.13908, val_loss=129.20088\n",
      "Epoch 28106: train_loss=118.13450, val_loss=129.18991\n",
      "Epoch 28107: train_loss=118.13100, val_loss=129.19130\n",
      "Epoch 28108: train_loss=118.12823, val_loss=129.19162\n",
      "Epoch 28109: train_loss=118.12604, val_loss=129.18338\n",
      "Epoch 28110: train_loss=118.12424, val_loss=129.19191\n",
      "Epoch 28111: train_loss=118.12261, val_loss=129.17633\n",
      "Epoch 28112: train_loss=118.12129, val_loss=129.19241\n",
      "Epoch 28113: train_loss=118.12011, val_loss=129.17024\n",
      "Epoch 28114: train_loss=118.11906, val_loss=129.19250\n",
      "Epoch 28115: train_loss=118.11805, val_loss=129.16554\n",
      "Epoch 28116: train_loss=118.11745, val_loss=129.19580\n",
      "Epoch 28117: train_loss=118.11731, val_loss=129.16272\n",
      "Epoch 28118: train_loss=118.11783, val_loss=129.20190\n",
      "Epoch 28119: train_loss=118.11889, val_loss=129.16212\n",
      "Epoch 28120: train_loss=118.12089, val_loss=129.21237\n",
      "Epoch 28121: train_loss=118.12350, val_loss=129.16347\n",
      "Epoch 28122: train_loss=118.12696, val_loss=129.22504\n",
      "Epoch 28123: train_loss=118.13075, val_loss=129.16692\n",
      "Epoch 28124: train_loss=118.13522, val_loss=129.23888\n",
      "Epoch 28125: train_loss=118.13963, val_loss=129.17073\n",
      "Epoch 28126: train_loss=118.14421, val_loss=129.25081\n",
      "Epoch 28127: train_loss=118.14830, val_loss=129.17453\n",
      "Epoch 28128: train_loss=118.15205, val_loss=129.26186\n",
      "Epoch 28129: train_loss=118.15537, val_loss=129.17824\n",
      "Epoch 28130: train_loss=118.15765, val_loss=129.26912\n",
      "Epoch 28131: train_loss=118.15879, val_loss=129.17879\n",
      "Epoch 28132: train_loss=118.15851, val_loss=129.26846\n",
      "Epoch 28133: train_loss=118.15686, val_loss=129.17426\n",
      "Epoch 28134: train_loss=118.15372, val_loss=129.25914\n",
      "Epoch 28135: train_loss=118.14877, val_loss=129.16359\n",
      "Epoch 28136: train_loss=118.14252, val_loss=129.24052\n",
      "Epoch 28137: train_loss=118.13452, val_loss=129.14729\n",
      "Epoch 28138: train_loss=118.12511, val_loss=129.21471\n",
      "Epoch 28139: train_loss=118.11465, val_loss=129.13147\n",
      "Epoch 28140: train_loss=118.10373, val_loss=129.18869\n",
      "Epoch 28141: train_loss=118.09284, val_loss=129.11739\n",
      "Epoch 28142: train_loss=118.08266, val_loss=129.16267\n",
      "Epoch 28143: train_loss=118.07283, val_loss=129.10455\n",
      "Epoch 28144: train_loss=118.06413, val_loss=129.13931\n",
      "Epoch 28145: train_loss=118.05631, val_loss=129.09494\n",
      "Epoch 28146: train_loss=118.04988, val_loss=129.12193\n",
      "Epoch 28147: train_loss=118.04427, val_loss=129.08824\n",
      "Epoch 28148: train_loss=118.03960, val_loss=129.10938\n",
      "Epoch 28149: train_loss=118.03562, val_loss=129.08311\n",
      "Epoch 28150: train_loss=118.03185, val_loss=129.10107\n",
      "Epoch 28151: train_loss=118.02865, val_loss=129.08017\n",
      "Epoch 28152: train_loss=118.02559, val_loss=129.09534\n",
      "Epoch 28153: train_loss=118.02290, val_loss=129.07672\n",
      "Epoch 28154: train_loss=118.02016, val_loss=129.08994\n",
      "Epoch 28155: train_loss=118.01768, val_loss=129.07217\n",
      "Epoch 28156: train_loss=118.01521, val_loss=129.08495\n",
      "Epoch 28157: train_loss=118.01296, val_loss=129.06650\n",
      "Epoch 28158: train_loss=118.01086, val_loss=129.08153\n",
      "Epoch 28159: train_loss=118.00908, val_loss=129.05991\n",
      "Epoch 28160: train_loss=118.00768, val_loss=129.08130\n",
      "Epoch 28161: train_loss=118.00684, val_loss=129.05608\n",
      "Epoch 28162: train_loss=118.00659, val_loss=129.08774\n",
      "Epoch 28163: train_loss=118.00737, val_loss=129.05531\n",
      "Epoch 28164: train_loss=118.00968, val_loss=129.10202\n",
      "Epoch 28165: train_loss=118.01382, val_loss=129.05865\n",
      "Epoch 28166: train_loss=118.02074, val_loss=129.12822\n",
      "Epoch 28167: train_loss=118.03101, val_loss=129.07286\n",
      "Epoch 28168: train_loss=118.04605, val_loss=129.17632\n",
      "Epoch 28169: train_loss=118.06717, val_loss=129.10796\n",
      "Epoch 28170: train_loss=118.09574, val_loss=129.25723\n",
      "Epoch 28171: train_loss=118.13304, val_loss=129.17641\n",
      "Epoch 28172: train_loss=118.18052, val_loss=129.37935\n",
      "Epoch 28173: train_loss=118.23416, val_loss=129.27489\n",
      "Epoch 28174: train_loss=118.29219, val_loss=129.50613\n",
      "Epoch 28175: train_loss=118.34264, val_loss=129.35313\n",
      "Epoch 28176: train_loss=118.38016, val_loss=129.55698\n",
      "Epoch 28177: train_loss=118.38721, val_loss=129.33559\n",
      "Epoch 28178: train_loss=118.36167, val_loss=129.45454\n",
      "Epoch 28179: train_loss=118.29750, val_loss=129.19942\n",
      "Epoch 28180: train_loss=118.20885, val_loss=129.23613\n",
      "Epoch 28181: train_loss=118.11090, val_loss=129.04933\n",
      "Epoch 28182: train_loss=118.02763, val_loss=129.05675\n",
      "Epoch 28183: train_loss=117.97108, val_loss=129.00456\n",
      "Epoch 28184: train_loss=117.94687, val_loss=128.99951\n",
      "Epoch 28185: train_loss=117.95060, val_loss=129.06239\n",
      "Epoch 28186: train_loss=117.97363, val_loss=129.02917\n",
      "Epoch 28187: train_loss=118.00546, val_loss=129.14595\n",
      "Epoch 28188: train_loss=118.03408, val_loss=129.06474\n",
      "Epoch 28189: train_loss=118.05105, val_loss=129.17197\n",
      "Epoch 28190: train_loss=118.05265, val_loss=129.05510\n",
      "Epoch 28191: train_loss=118.03887, val_loss=129.12489\n",
      "Epoch 28192: train_loss=118.01356, val_loss=129.01329\n",
      "Epoch 28193: train_loss=117.98283, val_loss=129.04752\n",
      "Epoch 28194: train_loss=117.95361, val_loss=128.98228\n",
      "Epoch 28195: train_loss=117.93182, val_loss=128.99242\n",
      "Epoch 28196: train_loss=117.91933, val_loss=128.98633\n",
      "Epoch 28197: train_loss=117.91580, val_loss=128.97484\n",
      "Epoch 28198: train_loss=117.91904, val_loss=129.01299\n",
      "Epoch 28199: train_loss=117.92603, val_loss=128.97839\n",
      "Epoch 28200: train_loss=117.93410, val_loss=129.03841\n",
      "Epoch 28201: train_loss=117.94006, val_loss=128.98381\n",
      "Epoch 28202: train_loss=117.94292, val_loss=129.04318\n",
      "Epoch 28203: train_loss=117.94118, val_loss=128.97858\n",
      "Epoch 28204: train_loss=117.93604, val_loss=129.02612\n",
      "Epoch 28205: train_loss=117.92750, val_loss=128.96632\n",
      "Epoch 28206: train_loss=117.91786, val_loss=128.99931\n",
      "Epoch 28207: train_loss=117.90802, val_loss=128.95589\n",
      "Epoch 28208: train_loss=117.89921, val_loss=128.97479\n",
      "Epoch 28209: train_loss=117.89195, val_loss=128.95329\n",
      "Epoch 28210: train_loss=117.88645, val_loss=128.95822\n",
      "Epoch 28211: train_loss=117.88252, val_loss=128.95555\n",
      "Epoch 28212: train_loss=117.88017, val_loss=128.94742\n",
      "Epoch 28213: train_loss=117.87881, val_loss=128.95961\n",
      "Epoch 28214: train_loss=117.87812, val_loss=128.94072\n",
      "Epoch 28215: train_loss=117.87766, val_loss=128.96346\n",
      "Epoch 28216: train_loss=117.87749, val_loss=128.93608\n",
      "Epoch 28217: train_loss=117.87727, val_loss=128.96683\n",
      "Epoch 28218: train_loss=117.87696, val_loss=128.93420\n",
      "Epoch 28219: train_loss=117.87655, val_loss=128.97000\n",
      "Epoch 28220: train_loss=117.87590, val_loss=128.93159\n",
      "Epoch 28221: train_loss=117.87518, val_loss=128.97092\n",
      "Epoch 28222: train_loss=117.87432, val_loss=128.92902\n",
      "Epoch 28223: train_loss=117.87351, val_loss=128.97159\n",
      "Epoch 28224: train_loss=117.87258, val_loss=128.92551\n",
      "Epoch 28225: train_loss=117.87177, val_loss=128.96974\n",
      "Epoch 28226: train_loss=117.87098, val_loss=128.92081\n",
      "Epoch 28227: train_loss=117.87033, val_loss=128.97072\n",
      "Epoch 28228: train_loss=117.86974, val_loss=128.91960\n",
      "Epoch 28229: train_loss=117.86930, val_loss=128.97330\n",
      "Epoch 28230: train_loss=117.86913, val_loss=128.91855\n",
      "Epoch 28231: train_loss=117.86906, val_loss=128.97569\n",
      "Epoch 28232: train_loss=117.86929, val_loss=128.91644\n",
      "Epoch 28233: train_loss=117.86949, val_loss=128.97771\n",
      "Epoch 28234: train_loss=117.86990, val_loss=128.91399\n",
      "Epoch 28235: train_loss=117.87009, val_loss=128.97922\n",
      "Epoch 28236: train_loss=117.87009, val_loss=128.91338\n",
      "Epoch 28237: train_loss=117.87013, val_loss=128.98177\n",
      "Epoch 28238: train_loss=117.86973, val_loss=128.91212\n",
      "Epoch 28239: train_loss=117.86916, val_loss=128.98164\n",
      "Epoch 28240: train_loss=117.86815, val_loss=128.90891\n",
      "Epoch 28241: train_loss=117.86687, val_loss=128.97870\n",
      "Epoch 28242: train_loss=117.86523, val_loss=128.90454\n",
      "Epoch 28243: train_loss=117.86301, val_loss=128.97450\n",
      "Epoch 28244: train_loss=117.86037, val_loss=128.90112\n",
      "Epoch 28245: train_loss=117.85714, val_loss=128.96906\n",
      "Epoch 28246: train_loss=117.85326, val_loss=128.89561\n",
      "Epoch 28247: train_loss=117.84937, val_loss=128.95926\n",
      "Epoch 28248: train_loss=117.84479, val_loss=128.88690\n",
      "Epoch 28249: train_loss=117.84011, val_loss=128.94662\n",
      "Epoch 28250: train_loss=117.83495, val_loss=128.87904\n",
      "Epoch 28251: train_loss=117.83007, val_loss=128.93503\n",
      "Epoch 28252: train_loss=117.82487, val_loss=128.87196\n",
      "Epoch 28253: train_loss=117.82010, val_loss=128.92424\n",
      "Epoch 28254: train_loss=117.81493, val_loss=128.86534\n",
      "Epoch 28255: train_loss=117.81034, val_loss=128.91408\n",
      "Epoch 28256: train_loss=117.80592, val_loss=128.85811\n",
      "Epoch 28257: train_loss=117.80195, val_loss=128.90460\n",
      "Epoch 28258: train_loss=117.79814, val_loss=128.85301\n",
      "Epoch 28259: train_loss=117.79485, val_loss=128.89981\n",
      "Epoch 28260: train_loss=117.79214, val_loss=128.85017\n",
      "Epoch 28261: train_loss=117.79022, val_loss=128.89821\n",
      "Epoch 28262: train_loss=117.78896, val_loss=128.84680\n",
      "Epoch 28263: train_loss=117.78872, val_loss=128.89943\n",
      "Epoch 28264: train_loss=117.78959, val_loss=128.84694\n",
      "Epoch 28265: train_loss=117.79166, val_loss=128.91194\n",
      "Epoch 28266: train_loss=117.79508, val_loss=128.85255\n",
      "Epoch 28267: train_loss=117.80028, val_loss=128.93085\n",
      "Epoch 28268: train_loss=117.80719, val_loss=128.86215\n",
      "Epoch 28269: train_loss=117.81657, val_loss=128.95775\n",
      "Epoch 28270: train_loss=117.82804, val_loss=128.87982\n",
      "Epoch 28271: train_loss=117.84225, val_loss=128.99776\n",
      "Epoch 28272: train_loss=117.85739, val_loss=128.90591\n",
      "Epoch 28273: train_loss=117.87458, val_loss=129.03990\n",
      "Epoch 28274: train_loss=117.89073, val_loss=128.93112\n",
      "Epoch 28275: train_loss=117.90716, val_loss=129.07253\n",
      "Epoch 28276: train_loss=117.91808, val_loss=128.94591\n",
      "Epoch 28277: train_loss=117.92503, val_loss=129.08110\n",
      "Epoch 28278: train_loss=117.92251, val_loss=128.93748\n",
      "Epoch 28279: train_loss=117.91292, val_loss=129.04749\n",
      "Epoch 28280: train_loss=117.89292, val_loss=128.89803\n",
      "Epoch 28281: train_loss=117.86725, val_loss=128.97675\n",
      "Epoch 28282: train_loss=117.83511, val_loss=128.84476\n",
      "Epoch 28283: train_loss=117.80216, val_loss=128.89572\n",
      "Epoch 28284: train_loss=117.77058, val_loss=128.80360\n",
      "Epoch 28285: train_loss=117.74381, val_loss=128.83160\n",
      "Epoch 28286: train_loss=117.72340, val_loss=128.78706\n",
      "Epoch 28287: train_loss=117.70997, val_loss=128.79391\n",
      "Epoch 28288: train_loss=117.70274, val_loss=128.79390\n",
      "Epoch 28289: train_loss=117.70076, val_loss=128.78207\n",
      "Epoch 28290: train_loss=117.70257, val_loss=128.81412\n",
      "Epoch 28291: train_loss=117.70667, val_loss=128.78156\n",
      "Epoch 28292: train_loss=117.71207, val_loss=128.83316\n",
      "Epoch 28293: train_loss=117.71762, val_loss=128.78413\n",
      "Epoch 28294: train_loss=117.72253, val_loss=128.84747\n",
      "Epoch 28295: train_loss=117.72600, val_loss=128.78758\n",
      "Epoch 28296: train_loss=117.72823, val_loss=128.85487\n",
      "Epoch 28297: train_loss=117.72873, val_loss=128.78679\n",
      "Epoch 28298: train_loss=117.72811, val_loss=128.85245\n",
      "Epoch 28299: train_loss=117.72562, val_loss=128.78075\n",
      "Epoch 28300: train_loss=117.72241, val_loss=128.84297\n",
      "Epoch 28301: train_loss=117.71762, val_loss=128.77385\n",
      "Epoch 28302: train_loss=117.71240, val_loss=128.83174\n",
      "Epoch 28303: train_loss=117.70647, val_loss=128.76630\n",
      "Epoch 28304: train_loss=117.70050, val_loss=128.81636\n",
      "Epoch 28305: train_loss=117.69424, val_loss=128.75624\n",
      "Epoch 28306: train_loss=117.68801, val_loss=128.79858\n",
      "Epoch 28307: train_loss=117.68185, val_loss=128.74702\n",
      "Epoch 28308: train_loss=117.67596, val_loss=128.78424\n",
      "Epoch 28309: train_loss=117.67030, val_loss=128.74239\n",
      "Epoch 28310: train_loss=117.66494, val_loss=128.77316\n",
      "Epoch 28311: train_loss=117.66000, val_loss=128.73804\n",
      "Epoch 28312: train_loss=117.65556, val_loss=128.76213\n",
      "Epoch 28313: train_loss=117.65159, val_loss=128.73230\n",
      "Epoch 28314: train_loss=117.64800, val_loss=128.75125\n",
      "Epoch 28315: train_loss=117.64480, val_loss=128.72649\n",
      "Epoch 28316: train_loss=117.64193, val_loss=128.74617\n",
      "Epoch 28317: train_loss=117.63936, val_loss=128.72339\n",
      "Epoch 28318: train_loss=117.63717, val_loss=128.74358\n",
      "Epoch 28319: train_loss=117.63519, val_loss=128.71902\n",
      "Epoch 28320: train_loss=117.63366, val_loss=128.74263\n",
      "Epoch 28321: train_loss=117.63256, val_loss=128.71365\n",
      "Epoch 28322: train_loss=117.63206, val_loss=128.74530\n",
      "Epoch 28323: train_loss=117.63232, val_loss=128.71159\n",
      "Epoch 28324: train_loss=117.63350, val_loss=128.75558\n",
      "Epoch 28325: train_loss=117.63579, val_loss=128.71362\n",
      "Epoch 28326: train_loss=117.63966, val_loss=128.77321\n",
      "Epoch 28327: train_loss=117.64587, val_loss=128.72063\n",
      "Epoch 28328: train_loss=117.65506, val_loss=128.80406\n",
      "Epoch 28329: train_loss=117.66785, val_loss=128.74107\n",
      "Epoch 28330: train_loss=117.68567, val_loss=128.85799\n",
      "Epoch 28331: train_loss=117.70834, val_loss=128.78125\n",
      "Epoch 28332: train_loss=117.73722, val_loss=128.93527\n",
      "Epoch 28333: train_loss=117.77008, val_loss=128.84097\n",
      "Epoch 28334: train_loss=117.80901, val_loss=129.02803\n",
      "Epoch 28335: train_loss=117.84771, val_loss=128.90533\n",
      "Epoch 28336: train_loss=117.88489, val_loss=129.09976\n",
      "Epoch 28337: train_loss=117.91021, val_loss=128.93634\n",
      "Epoch 28338: train_loss=117.92157, val_loss=129.09901\n",
      "Epoch 28339: train_loss=117.90804, val_loss=128.89583\n",
      "Epoch 28340: train_loss=117.87337, val_loss=128.99477\n",
      "Epoch 28341: train_loss=117.81560, val_loss=128.78940\n",
      "Epoch 28342: train_loss=117.74904, val_loss=128.83385\n",
      "Epoch 28343: train_loss=117.68179, val_loss=128.69051\n",
      "Epoch 28344: train_loss=117.62557, val_loss=128.70590\n",
      "Epoch 28345: train_loss=117.58728, val_loss=128.66212\n",
      "Epoch 28346: train_loss=117.56905, val_loss=128.65994\n",
      "Epoch 28347: train_loss=117.56843, val_loss=128.70111\n",
      "Epoch 28348: train_loss=117.58058, val_loss=128.66963\n",
      "Epoch 28349: train_loss=117.59927, val_loss=128.75688\n",
      "Epoch 28350: train_loss=117.61874, val_loss=128.69133\n",
      "Epoch 28351: train_loss=117.63411, val_loss=128.78690\n",
      "Epoch 28352: train_loss=117.64146, val_loss=128.69467\n",
      "Epoch 28353: train_loss=117.64005, val_loss=128.77588\n",
      "Epoch 28354: train_loss=117.63013, val_loss=128.67845\n",
      "Epoch 28355: train_loss=117.61456, val_loss=128.73550\n",
      "Epoch 28356: train_loss=117.59543, val_loss=128.65314\n",
      "Epoch 28357: train_loss=117.57620, val_loss=128.68510\n",
      "Epoch 28358: train_loss=117.55917, val_loss=128.63586\n",
      "Epoch 28359: train_loss=117.54595, val_loss=128.64671\n",
      "Epoch 28360: train_loss=117.53744, val_loss=128.63629\n",
      "Epoch 28361: train_loss=117.53319, val_loss=128.63045\n",
      "Epoch 28362: train_loss=117.53249, val_loss=128.65146\n",
      "Epoch 28363: train_loss=117.53416, val_loss=128.62796\n",
      "Epoch 28364: train_loss=117.53690, val_loss=128.66620\n",
      "Epoch 28365: train_loss=117.53957, val_loss=128.62726\n",
      "Epoch 28366: train_loss=117.54138, val_loss=128.67325\n",
      "Epoch 28367: train_loss=117.54225, val_loss=128.62495\n",
      "Epoch 28368: train_loss=117.54170, val_loss=128.67149\n",
      "Epoch 28369: train_loss=117.53983, val_loss=128.62161\n",
      "Epoch 28370: train_loss=117.53690, val_loss=128.66669\n",
      "Epoch 28371: train_loss=117.53319, val_loss=128.61693\n",
      "Epoch 28372: train_loss=117.52865, val_loss=128.65567\n",
      "Epoch 28373: train_loss=117.52412, val_loss=128.60980\n",
      "Epoch 28374: train_loss=117.51899, val_loss=128.64206\n",
      "Epoch 28375: train_loss=117.51389, val_loss=128.60527\n",
      "Epoch 28376: train_loss=117.50885, val_loss=128.63037\n",
      "Epoch 28377: train_loss=117.50414, val_loss=128.60103\n",
      "Epoch 28378: train_loss=117.49974, val_loss=128.61792\n",
      "Epoch 28379: train_loss=117.49565, val_loss=128.59631\n",
      "Epoch 28380: train_loss=117.49203, val_loss=128.60547\n",
      "Epoch 28381: train_loss=117.48869, val_loss=128.59230\n",
      "Epoch 28382: train_loss=117.48558, val_loss=128.59660\n",
      "Epoch 28383: train_loss=117.48287, val_loss=128.59189\n",
      "Epoch 28384: train_loss=117.48038, val_loss=128.59123\n",
      "Epoch 28385: train_loss=117.47803, val_loss=128.59125\n",
      "Epoch 28386: train_loss=117.47583, val_loss=128.58542\n",
      "Epoch 28387: train_loss=117.47365, val_loss=128.58904\n",
      "Epoch 28388: train_loss=117.47162, val_loss=128.57774\n",
      "Epoch 28389: train_loss=117.46977, val_loss=128.58594\n",
      "Epoch 28390: train_loss=117.46815, val_loss=128.57018\n",
      "Epoch 28391: train_loss=117.46696, val_loss=128.58971\n",
      "Epoch 28392: train_loss=117.46638, val_loss=128.56888\n",
      "Epoch 28393: train_loss=117.46648, val_loss=128.60037\n",
      "Epoch 28394: train_loss=117.46769, val_loss=128.56918\n",
      "Epoch 28395: train_loss=117.47026, val_loss=128.61505\n",
      "Epoch 28396: train_loss=117.47494, val_loss=128.57120\n",
      "Epoch 28397: train_loss=117.48261, val_loss=128.64185\n",
      "Epoch 28398: train_loss=117.49392, val_loss=128.58514\n",
      "Epoch 28399: train_loss=117.51028, val_loss=128.69188\n",
      "Epoch 28400: train_loss=117.53195, val_loss=128.62181\n",
      "Epoch 28401: train_loss=117.56007, val_loss=128.76968\n",
      "Epoch 28402: train_loss=117.59313, val_loss=128.68111\n",
      "Epoch 28403: train_loss=117.63254, val_loss=128.86530\n",
      "Epoch 28404: train_loss=117.67287, val_loss=128.75023\n",
      "Epoch 28405: train_loss=117.71376, val_loss=128.95129\n",
      "Epoch 28406: train_loss=117.74611, val_loss=128.79669\n",
      "Epoch 28407: train_loss=117.76680, val_loss=128.97395\n",
      "Epoch 28408: train_loss=117.76434, val_loss=128.77217\n",
      "Epoch 28409: train_loss=117.73890, val_loss=128.88615\n",
      "Epoch 28410: train_loss=117.68819, val_loss=128.67041\n",
      "Epoch 28411: train_loss=117.62297, val_loss=128.72284\n",
      "Epoch 28412: train_loss=117.55066, val_loss=128.56032\n",
      "Epoch 28413: train_loss=117.48719, val_loss=128.58138\n",
      "Epoch 28414: train_loss=117.44041, val_loss=128.51784\n",
      "Epoch 28415: train_loss=117.41406, val_loss=128.51797\n",
      "Epoch 28416: train_loss=117.40742, val_loss=128.54727\n",
      "Epoch 28417: train_loss=117.41619, val_loss=128.52200\n",
      "Epoch 28418: train_loss=117.43382, val_loss=128.60686\n",
      "Epoch 28419: train_loss=117.45438, val_loss=128.54625\n",
      "Epoch 28420: train_loss=117.47209, val_loss=128.64470\n",
      "Epoch 28421: train_loss=117.48247, val_loss=128.55353\n",
      "Epoch 28422: train_loss=117.48357, val_loss=128.63696\n",
      "Epoch 28423: train_loss=117.47506, val_loss=128.53529\n",
      "Epoch 28424: train_loss=117.45943, val_loss=128.59230\n",
      "Epoch 28425: train_loss=117.43933, val_loss=128.50757\n",
      "Epoch 28426: train_loss=117.41878, val_loss=128.54002\n",
      "Epoch 28427: train_loss=117.40084, val_loss=128.49161\n",
      "Epoch 28428: train_loss=117.38716, val_loss=128.50252\n",
      "Epoch 28429: train_loss=117.37867, val_loss=128.49422\n",
      "Epoch 28430: train_loss=117.37499, val_loss=128.48643\n",
      "Epoch 28431: train_loss=117.37499, val_loss=128.51053\n",
      "Epoch 28432: train_loss=117.37746, val_loss=128.48402\n",
      "Epoch 28433: train_loss=117.38092, val_loss=128.52641\n",
      "Epoch 28434: train_loss=117.38420, val_loss=128.48384\n",
      "Epoch 28435: train_loss=117.38626, val_loss=128.53172\n",
      "Epoch 28436: train_loss=117.38657, val_loss=128.48082\n",
      "Epoch 28437: train_loss=117.38561, val_loss=128.52925\n",
      "Epoch 28438: train_loss=117.38293, val_loss=128.47707\n",
      "Epoch 28439: train_loss=117.37930, val_loss=128.52173\n",
      "Epoch 28440: train_loss=117.37456, val_loss=128.47232\n",
      "Epoch 28441: train_loss=117.36966, val_loss=128.50888\n",
      "Epoch 28442: train_loss=117.36417, val_loss=128.46495\n",
      "Epoch 28443: train_loss=117.35868, val_loss=128.49338\n",
      "Epoch 28444: train_loss=117.35339, val_loss=128.45795\n",
      "Epoch 28445: train_loss=117.34841, val_loss=128.47910\n",
      "Epoch 28446: train_loss=117.34390, val_loss=128.45589\n",
      "Epoch 28447: train_loss=117.33970, val_loss=128.47063\n",
      "Epoch 28448: train_loss=117.33601, val_loss=128.45386\n",
      "Epoch 28449: train_loss=117.33268, val_loss=128.46046\n",
      "Epoch 28450: train_loss=117.32963, val_loss=128.45001\n",
      "Epoch 28451: train_loss=117.32689, val_loss=128.45056\n",
      "Epoch 28452: train_loss=117.32431, val_loss=128.44489\n",
      "Epoch 28453: train_loss=117.32191, val_loss=128.44200\n",
      "Epoch 28454: train_loss=117.31964, val_loss=128.44392\n",
      "Epoch 28455: train_loss=117.31738, val_loss=128.43947\n",
      "Epoch 28456: train_loss=117.31529, val_loss=128.44460\n",
      "Epoch 28457: train_loss=117.31330, val_loss=128.43422\n",
      "Epoch 28458: train_loss=117.31158, val_loss=128.44409\n",
      "Epoch 28459: train_loss=117.31012, val_loss=128.42635\n",
      "Epoch 28460: train_loss=117.30909, val_loss=128.44447\n",
      "Epoch 28461: train_loss=117.30865, val_loss=128.41956\n",
      "Epoch 28462: train_loss=117.30900, val_loss=128.45125\n",
      "Epoch 28463: train_loss=117.31036, val_loss=128.41812\n",
      "Epoch 28464: train_loss=117.31294, val_loss=128.46707\n",
      "Epoch 28465: train_loss=117.31729, val_loss=128.42348\n",
      "Epoch 28466: train_loss=117.32421, val_loss=128.49426\n",
      "Epoch 28467: train_loss=117.33411, val_loss=128.43677\n",
      "Epoch 28468: train_loss=117.34780, val_loss=128.53584\n",
      "Epoch 28469: train_loss=117.36543, val_loss=128.46431\n",
      "Epoch 28470: train_loss=117.38815, val_loss=128.59857\n",
      "Epoch 28471: train_loss=117.41476, val_loss=128.51128\n",
      "Epoch 28472: train_loss=117.44720, val_loss=128.68102\n",
      "Epoch 28473: train_loss=117.48123, val_loss=128.57114\n",
      "Epoch 28474: train_loss=117.51657, val_loss=128.76003\n",
      "Epoch 28475: train_loss=117.54650, val_loss=128.61642\n",
      "Epoch 28476: train_loss=117.56898, val_loss=128.79340\n",
      "Epoch 28477: train_loss=117.57516, val_loss=128.60912\n",
      "Epoch 28478: train_loss=117.56375, val_loss=128.73943\n",
      "Epoch 28479: train_loss=117.53068, val_loss=128.53717\n",
      "Epoch 28480: train_loss=117.48183, val_loss=128.61339\n",
      "Epoch 28481: train_loss=117.42109, val_loss=128.43938\n",
      "Epoch 28482: train_loss=117.36048, val_loss=128.47308\n",
      "Epoch 28483: train_loss=117.30756, val_loss=128.37663\n",
      "Epoch 28484: train_loss=117.27059, val_loss=128.38496\n",
      "Epoch 28485: train_loss=117.25107, val_loss=128.37773\n",
      "Epoch 28486: train_loss=117.24740, val_loss=128.36360\n",
      "Epoch 28487: train_loss=117.25565, val_loss=128.42290\n",
      "Epoch 28488: train_loss=117.27086, val_loss=128.38109\n",
      "Epoch 28489: train_loss=117.28790, val_loss=128.47153\n",
      "Epoch 28490: train_loss=117.30214, val_loss=128.39857\n",
      "Epoch 28491: train_loss=117.31164, val_loss=128.48874\n",
      "Epoch 28492: train_loss=117.31351, val_loss=128.39474\n",
      "Epoch 28493: train_loss=117.30859, val_loss=128.46730\n",
      "Epoch 28494: train_loss=117.29705, val_loss=128.37202\n",
      "Epoch 28495: train_loss=117.28201, val_loss=128.42351\n",
      "Epoch 28496: train_loss=117.26514, val_loss=128.35052\n",
      "Epoch 28497: train_loss=117.24865, val_loss=128.38391\n",
      "Epoch 28498: train_loss=117.23454, val_loss=128.34048\n",
      "Epoch 28499: train_loss=117.22354, val_loss=128.35249\n",
      "Epoch 28500: train_loss=117.21606, val_loss=128.33981\n",
      "Epoch 28501: train_loss=117.21194, val_loss=128.33434\n",
      "Epoch 28502: train_loss=117.21040, val_loss=128.34865\n",
      "Epoch 28503: train_loss=117.21085, val_loss=128.32828\n",
      "Epoch 28504: train_loss=117.21242, val_loss=128.36099\n",
      "Epoch 28505: train_loss=117.21431, val_loss=128.32779\n",
      "Epoch 28506: train_loss=117.21596, val_loss=128.37059\n",
      "Epoch 28507: train_loss=117.21725, val_loss=128.32661\n",
      "Epoch 28508: train_loss=117.21786, val_loss=128.37444\n",
      "Epoch 28509: train_loss=117.21802, val_loss=128.32436\n",
      "Epoch 28510: train_loss=117.21754, val_loss=128.37485\n",
      "Epoch 28511: train_loss=117.21665, val_loss=128.32155\n",
      "Epoch 28512: train_loss=117.21508, val_loss=128.37299\n",
      "Epoch 28513: train_loss=117.21343, val_loss=128.31735\n",
      "Epoch 28514: train_loss=117.21125, val_loss=128.36852\n",
      "Epoch 28515: train_loss=117.20896, val_loss=128.31337\n",
      "Epoch 28516: train_loss=117.20623, val_loss=128.36475\n",
      "Epoch 28517: train_loss=117.20394, val_loss=128.31073\n",
      "Epoch 28518: train_loss=117.20161, val_loss=128.36201\n",
      "Epoch 28519: train_loss=117.19971, val_loss=128.30595\n",
      "Epoch 28520: train_loss=117.19751, val_loss=128.35741\n",
      "Epoch 28521: train_loss=117.19604, val_loss=128.30162\n",
      "Epoch 28522: train_loss=117.19437, val_loss=128.35579\n",
      "Epoch 28523: train_loss=117.19320, val_loss=128.29912\n",
      "Epoch 28524: train_loss=117.19181, val_loss=128.35551\n",
      "Epoch 28525: train_loss=117.19112, val_loss=128.29591\n",
      "Epoch 28526: train_loss=117.19030, val_loss=128.35521\n",
      "Epoch 28527: train_loss=117.18996, val_loss=128.29333\n",
      "Epoch 28528: train_loss=117.18968, val_loss=128.35721\n",
      "Epoch 28529: train_loss=117.18990, val_loss=128.29295\n",
      "Epoch 28530: train_loss=117.19032, val_loss=128.36183\n",
      "Epoch 28531: train_loss=117.19119, val_loss=128.29254\n",
      "Epoch 28532: train_loss=117.19249, val_loss=128.36690\n",
      "Epoch 28533: train_loss=117.19439, val_loss=128.29373\n",
      "Epoch 28534: train_loss=117.19672, val_loss=128.37544\n",
      "Epoch 28535: train_loss=117.19922, val_loss=128.29659\n",
      "Epoch 28536: train_loss=117.20188, val_loss=128.38399\n",
      "Epoch 28537: train_loss=117.20415, val_loss=128.29994\n",
      "Epoch 28538: train_loss=117.20623, val_loss=128.39157\n",
      "Epoch 28539: train_loss=117.20815, val_loss=128.30086\n",
      "Epoch 28540: train_loss=117.20931, val_loss=128.39438\n",
      "Epoch 28541: train_loss=117.20941, val_loss=128.30069\n",
      "Epoch 28542: train_loss=117.20885, val_loss=128.39418\n",
      "Epoch 28543: train_loss=117.20663, val_loss=128.29663\n",
      "Epoch 28544: train_loss=117.20289, val_loss=128.38376\n",
      "Epoch 28545: train_loss=117.19741, val_loss=128.28516\n",
      "Epoch 28546: train_loss=117.19068, val_loss=128.36401\n",
      "Epoch 28547: train_loss=117.18222, val_loss=128.27121\n",
      "Epoch 28548: train_loss=117.17233, val_loss=128.34007\n",
      "Epoch 28549: train_loss=117.16142, val_loss=128.25528\n",
      "Epoch 28550: train_loss=117.14973, val_loss=128.30960\n",
      "Epoch 28551: train_loss=117.13849, val_loss=128.23880\n",
      "Epoch 28552: train_loss=117.12730, val_loss=128.27975\n",
      "Epoch 28553: train_loss=117.11676, val_loss=128.22855\n",
      "Epoch 28554: train_loss=117.10741, val_loss=128.25710\n",
      "Epoch 28555: train_loss=117.09936, val_loss=128.22267\n",
      "Epoch 28556: train_loss=117.09259, val_loss=128.23616\n",
      "Epoch 28557: train_loss=117.08730, val_loss=128.21831\n",
      "Epoch 28558: train_loss=117.08321, val_loss=128.22159\n",
      "Epoch 28559: train_loss=117.08015, val_loss=128.22200\n",
      "Epoch 28560: train_loss=117.07795, val_loss=128.21472\n",
      "Epoch 28561: train_loss=117.07637, val_loss=128.22432\n",
      "Epoch 28562: train_loss=117.07505, val_loss=128.20667\n",
      "Epoch 28563: train_loss=117.07413, val_loss=128.22501\n",
      "Epoch 28564: train_loss=117.07340, val_loss=128.20001\n",
      "Epoch 28565: train_loss=117.07298, val_loss=128.22888\n",
      "Epoch 28566: train_loss=117.07281, val_loss=128.19859\n",
      "Epoch 28567: train_loss=117.07320, val_loss=128.23679\n",
      "Epoch 28568: train_loss=117.07446, val_loss=128.19685\n",
      "Epoch 28569: train_loss=117.07654, val_loss=128.24783\n",
      "Epoch 28570: train_loss=117.08067, val_loss=128.20081\n",
      "Epoch 28571: train_loss=117.08634, val_loss=128.27383\n",
      "Epoch 28572: train_loss=117.09540, val_loss=128.21417\n",
      "Epoch 28573: train_loss=117.10758, val_loss=128.31345\n",
      "Epoch 28574: train_loss=117.12443, val_loss=128.23872\n",
      "Epoch 28575: train_loss=117.14590, val_loss=128.37347\n",
      "Epoch 28576: train_loss=117.17273, val_loss=128.28641\n",
      "Epoch 28577: train_loss=117.20576, val_loss=128.46222\n",
      "Epoch 28578: train_loss=117.24300, val_loss=128.35304\n",
      "Epoch 28579: train_loss=117.28440, val_loss=128.55595\n",
      "Epoch 28580: train_loss=117.32298, val_loss=128.41078\n",
      "Epoch 28581: train_loss=117.35505, val_loss=128.60678\n",
      "Epoch 28582: train_loss=117.36926, val_loss=128.41681\n",
      "Epoch 28583: train_loss=117.36371, val_loss=128.56557\n",
      "Epoch 28584: train_loss=117.33055, val_loss=128.34386\n",
      "Epoch 28585: train_loss=117.27682, val_loss=128.42235\n",
      "Epoch 28586: train_loss=117.20748, val_loss=128.22630\n",
      "Epoch 28587: train_loss=117.13728, val_loss=128.25766\n",
      "Epoch 28588: train_loss=117.07654, val_loss=128.15053\n",
      "Epoch 28589: train_loss=117.03378, val_loss=128.16130\n",
      "Epoch 28590: train_loss=117.01184, val_loss=128.15932\n",
      "Epoch 28591: train_loss=117.00912, val_loss=128.14420\n",
      "Epoch 28592: train_loss=117.02046, val_loss=128.21255\n",
      "Epoch 28593: train_loss=117.03886, val_loss=128.16106\n",
      "Epoch 28594: train_loss=117.05734, val_loss=128.25598\n",
      "Epoch 28595: train_loss=117.07092, val_loss=128.17569\n",
      "Epoch 28596: train_loss=117.07745, val_loss=128.26576\n",
      "Epoch 28597: train_loss=117.07474, val_loss=128.16670\n",
      "Epoch 28598: train_loss=117.06474, val_loss=128.23163\n",
      "Epoch 28599: train_loss=117.04816, val_loss=128.13921\n",
      "Epoch 28600: train_loss=117.02922, val_loss=128.18150\n",
      "Epoch 28601: train_loss=117.01053, val_loss=128.12257\n",
      "Epoch 28602: train_loss=116.99451, val_loss=128.14113\n",
      "Epoch 28603: train_loss=116.98314, val_loss=128.12079\n",
      "Epoch 28604: train_loss=116.97674, val_loss=128.11646\n",
      "Epoch 28605: train_loss=116.97484, val_loss=128.13152\n",
      "Epoch 28606: train_loss=116.97602, val_loss=128.10994\n",
      "Epoch 28607: train_loss=116.97887, val_loss=128.14989\n",
      "Epoch 28608: train_loss=116.98196, val_loss=128.11172\n",
      "Epoch 28609: train_loss=116.98420, val_loss=128.15889\n",
      "Epoch 28610: train_loss=116.98528, val_loss=128.10812\n",
      "Epoch 28611: train_loss=116.98467, val_loss=128.15508\n",
      "Epoch 28612: train_loss=116.98268, val_loss=128.10294\n",
      "Epoch 28613: train_loss=116.97934, val_loss=128.14944\n",
      "Epoch 28614: train_loss=116.97520, val_loss=128.10022\n",
      "Epoch 28615: train_loss=116.97040, val_loss=128.13817\n",
      "Epoch 28616: train_loss=116.96556, val_loss=128.09262\n",
      "Epoch 28617: train_loss=116.96056, val_loss=128.12198\n",
      "Epoch 28618: train_loss=116.95558, val_loss=128.08394\n",
      "Epoch 28619: train_loss=116.95080, val_loss=128.10771\n",
      "Epoch 28620: train_loss=116.94614, val_loss=128.08253\n",
      "Epoch 28621: train_loss=116.94190, val_loss=128.09865\n",
      "Epoch 28622: train_loss=116.93815, val_loss=128.07996\n",
      "Epoch 28623: train_loss=116.93467, val_loss=128.08711\n",
      "Epoch 28624: train_loss=116.93166, val_loss=128.07498\n",
      "Epoch 28625: train_loss=116.92881, val_loss=128.07607\n",
      "Epoch 28626: train_loss=116.92638, val_loss=128.07298\n",
      "Epoch 28627: train_loss=116.92394, val_loss=128.07283\n",
      "Epoch 28628: train_loss=116.92177, val_loss=128.07565\n",
      "Epoch 28629: train_loss=116.91962, val_loss=128.06863\n",
      "Epoch 28630: train_loss=116.91759, val_loss=128.07402\n",
      "Epoch 28631: train_loss=116.91573, val_loss=128.06015\n",
      "Epoch 28632: train_loss=116.91397, val_loss=128.07062\n",
      "Epoch 28633: train_loss=116.91259, val_loss=128.05409\n",
      "Epoch 28634: train_loss=116.91163, val_loss=128.07762\n",
      "Epoch 28635: train_loss=116.91170, val_loss=128.05203\n",
      "Epoch 28636: train_loss=116.91273, val_loss=128.08832\n",
      "Epoch 28637: train_loss=116.91541, val_loss=128.05043\n",
      "Epoch 28638: train_loss=116.92006, val_loss=128.10759\n",
      "Epoch 28639: train_loss=116.92702, val_loss=128.05820\n",
      "Epoch 28640: train_loss=116.93693, val_loss=128.14330\n",
      "Epoch 28641: train_loss=116.95026, val_loss=128.07751\n",
      "Epoch 28642: train_loss=116.96739, val_loss=128.19363\n",
      "Epoch 28643: train_loss=116.98913, val_loss=128.11374\n",
      "Epoch 28644: train_loss=117.01620, val_loss=128.26701\n",
      "Epoch 28645: train_loss=117.04614, val_loss=128.16316\n",
      "Epoch 28646: train_loss=117.07814, val_loss=128.34038\n",
      "Epoch 28647: train_loss=117.10809, val_loss=128.21069\n",
      "Epoch 28648: train_loss=117.13525, val_loss=128.39445\n",
      "Epoch 28649: train_loss=117.15214, val_loss=128.22751\n",
      "Epoch 28650: train_loss=117.15657, val_loss=128.38159\n",
      "Epoch 28651: train_loss=117.14288, val_loss=128.18610\n",
      "Epoch 28652: train_loss=117.11269, val_loss=128.29146\n",
      "Epoch 28653: train_loss=117.06668, val_loss=128.10318\n",
      "Epoch 28654: train_loss=117.01304, val_loss=128.16069\n",
      "Epoch 28655: train_loss=116.95879, val_loss=128.02545\n",
      "Epoch 28656: train_loss=116.91285, val_loss=128.05199\n",
      "Epoch 28657: train_loss=116.87892, val_loss=127.99680\n",
      "Epoch 28658: train_loss=116.85909, val_loss=128.00012\n",
      "Epoch 28659: train_loss=116.85223, val_loss=128.01604\n",
      "Epoch 28660: train_loss=116.85534, val_loss=127.99168\n",
      "Epoch 28661: train_loss=116.86505, val_loss=128.05461\n",
      "Epoch 28662: train_loss=116.87760, val_loss=128.00372\n",
      "Epoch 28663: train_loss=116.89037, val_loss=128.08899\n",
      "Epoch 28664: train_loss=116.89983, val_loss=128.01373\n",
      "Epoch 28665: train_loss=116.90558, val_loss=128.09798\n",
      "Epoch 28666: train_loss=116.90550, val_loss=128.00867\n",
      "Epoch 28667: train_loss=116.90089, val_loss=128.08163\n",
      "Epoch 28668: train_loss=116.89137, val_loss=127.99487\n",
      "Epoch 28669: train_loss=116.87959, val_loss=128.04974\n",
      "Epoch 28670: train_loss=116.86602, val_loss=127.97640\n",
      "Epoch 28671: train_loss=116.85288, val_loss=128.01184\n",
      "Epoch 28672: train_loss=116.84078, val_loss=127.96378\n",
      "Epoch 28673: train_loss=116.83088, val_loss=127.98447\n",
      "Epoch 28674: train_loss=116.82301, val_loss=127.96126\n",
      "Epoch 28675: train_loss=116.81742, val_loss=127.96444\n",
      "Epoch 28676: train_loss=116.81371, val_loss=127.96237\n",
      "Epoch 28677: train_loss=116.81162, val_loss=127.95171\n",
      "Epoch 28678: train_loss=116.81067, val_loss=127.96874\n",
      "Epoch 28679: train_loss=116.81042, val_loss=127.94714\n",
      "Epoch 28680: train_loss=116.81063, val_loss=127.97639\n",
      "Epoch 28681: train_loss=116.81118, val_loss=127.94295\n",
      "Epoch 28682: train_loss=116.81187, val_loss=127.98063\n",
      "Epoch 28683: train_loss=116.81261, val_loss=127.93947\n",
      "Epoch 28684: train_loss=116.81364, val_loss=127.98730\n",
      "Epoch 28685: train_loss=116.81467, val_loss=127.93962\n",
      "Epoch 28686: train_loss=116.81610, val_loss=127.99535\n",
      "Epoch 28687: train_loss=116.81766, val_loss=127.93916\n",
      "Epoch 28688: train_loss=116.81950, val_loss=128.00171\n",
      "Epoch 28689: train_loss=116.82149, val_loss=127.93929\n",
      "Epoch 28690: train_loss=116.82385, val_loss=128.01074\n",
      "Epoch 28691: train_loss=116.82658, val_loss=127.94153\n",
      "Epoch 28692: train_loss=116.82978, val_loss=128.02267\n",
      "Epoch 28693: train_loss=116.83351, val_loss=127.94544\n",
      "Epoch 28694: train_loss=116.83787, val_loss=128.03528\n",
      "Epoch 28695: train_loss=116.84235, val_loss=127.95008\n",
      "Epoch 28696: train_loss=116.84726, val_loss=128.04820\n",
      "Epoch 28697: train_loss=116.85159, val_loss=127.95474\n",
      "Epoch 28698: train_loss=116.85577, val_loss=128.05875\n",
      "Epoch 28699: train_loss=116.85907, val_loss=127.95747\n",
      "Epoch 28700: train_loss=116.86201, val_loss=128.06433\n",
      "Epoch 28701: train_loss=116.86315, val_loss=127.95596\n",
      "Epoch 28702: train_loss=116.86285, val_loss=128.06108\n",
      "Epoch 28703: train_loss=116.86015, val_loss=127.94882\n",
      "Epoch 28704: train_loss=116.85563, val_loss=128.04738\n",
      "Epoch 28705: train_loss=116.84839, val_loss=127.93575\n",
      "Epoch 28706: train_loss=116.83963, val_loss=128.02240\n",
      "Epoch 28707: train_loss=116.82825, val_loss=127.91545\n",
      "Epoch 28708: train_loss=116.81588, val_loss=127.98671\n",
      "Epoch 28709: train_loss=116.80150, val_loss=127.89336\n",
      "Epoch 28710: train_loss=116.78737, val_loss=127.94936\n",
      "Epoch 28711: train_loss=116.77277, val_loss=127.87611\n",
      "Epoch 28712: train_loss=116.76012, val_loss=127.91505\n",
      "Epoch 28713: train_loss=116.74874, val_loss=127.86378\n",
      "Epoch 28714: train_loss=116.73961, val_loss=127.88836\n",
      "Epoch 28715: train_loss=116.73215, val_loss=127.85949\n",
      "Epoch 28716: train_loss=116.72627, val_loss=127.87108\n",
      "Epoch 28717: train_loss=116.72179, val_loss=127.85928\n",
      "Epoch 28718: train_loss=116.71845, val_loss=127.85809\n",
      "Epoch 28719: train_loss=116.71600, val_loss=127.86147\n",
      "Epoch 28720: train_loss=116.71417, val_loss=127.84968\n",
      "Epoch 28721: train_loss=116.71297, val_loss=127.86414\n",
      "Epoch 28722: train_loss=116.71187, val_loss=127.84339\n",
      "Epoch 28723: train_loss=116.71104, val_loss=127.86545\n",
      "Epoch 28724: train_loss=116.71054, val_loss=127.83610\n",
      "Epoch 28725: train_loss=116.71027, val_loss=127.86765\n",
      "Epoch 28726: train_loss=116.71040, val_loss=127.83261\n",
      "Epoch 28727: train_loss=116.71120, val_loss=127.87579\n",
      "Epoch 28728: train_loss=116.71269, val_loss=127.83212\n",
      "Epoch 28729: train_loss=116.71556, val_loss=127.88916\n",
      "Epoch 28730: train_loss=116.71980, val_loss=127.83424\n",
      "Epoch 28731: train_loss=116.72594, val_loss=127.91006\n",
      "Epoch 28732: train_loss=116.73385, val_loss=127.84425\n",
      "Epoch 28733: train_loss=116.74461, val_loss=127.94370\n",
      "Epoch 28734: train_loss=116.75723, val_loss=127.86411\n",
      "Epoch 28735: train_loss=116.77388, val_loss=127.99122\n",
      "Epoch 28736: train_loss=116.79310, val_loss=127.89625\n",
      "Epoch 28737: train_loss=116.81680, val_loss=128.05405\n",
      "Epoch 28738: train_loss=116.84303, val_loss=127.93856\n",
      "Epoch 28739: train_loss=116.87186, val_loss=128.11887\n",
      "Epoch 28740: train_loss=116.89831, val_loss=127.97781\n",
      "Epoch 28741: train_loss=116.92130, val_loss=128.16029\n",
      "Epoch 28742: train_loss=116.93326, val_loss=127.98690\n",
      "Epoch 28743: train_loss=116.93295, val_loss=128.14040\n",
      "Epoch 28744: train_loss=116.91541, val_loss=127.94482\n",
      "Epoch 28745: train_loss=116.88299, val_loss=128.04852\n",
      "Epoch 28746: train_loss=116.83717, val_loss=127.86414\n",
      "Epoch 28747: train_loss=116.78628, val_loss=127.92131\n",
      "Epoch 28748: train_loss=116.73534, val_loss=127.79399\n",
      "Epoch 28749: train_loss=116.69305, val_loss=127.82011\n",
      "Epoch 28750: train_loss=116.66253, val_loss=127.77404\n",
      "Epoch 28751: train_loss=116.64607, val_loss=127.77328\n",
      "Epoch 28752: train_loss=116.64233, val_loss=127.79919\n",
      "Epoch 28753: train_loss=116.64818, val_loss=127.76977\n",
      "Epoch 28754: train_loss=116.65963, val_loss=127.84128\n",
      "Epoch 28755: train_loss=116.67249, val_loss=127.78343\n",
      "Epoch 28756: train_loss=116.68445, val_loss=127.87074\n",
      "Epoch 28757: train_loss=116.69164, val_loss=127.78889\n",
      "Epoch 28758: train_loss=116.69437, val_loss=127.87086\n",
      "Epoch 28759: train_loss=116.69088, val_loss=127.77947\n",
      "Epoch 28760: train_loss=116.68340, val_loss=127.84628\n",
      "Epoch 28761: train_loss=116.67160, val_loss=127.76280\n",
      "Epoch 28762: train_loss=116.65855, val_loss=127.81111\n",
      "Epoch 28763: train_loss=116.64516, val_loss=127.74804\n",
      "Epoch 28764: train_loss=116.63314, val_loss=127.77734\n",
      "Epoch 28765: train_loss=116.62276, val_loss=127.74059\n",
      "Epoch 28766: train_loss=116.61478, val_loss=127.75082\n",
      "Epoch 28767: train_loss=116.60920, val_loss=127.74089\n",
      "Epoch 28768: train_loss=116.60585, val_loss=127.73624\n",
      "Epoch 28769: train_loss=116.60418, val_loss=127.74889\n",
      "Epoch 28770: train_loss=116.60368, val_loss=127.73037\n",
      "Epoch 28771: train_loss=116.60396, val_loss=127.75790\n",
      "Epoch 28772: train_loss=116.60461, val_loss=127.72668\n",
      "Epoch 28773: train_loss=116.60558, val_loss=127.76531\n",
      "Epoch 28774: train_loss=116.60664, val_loss=127.72337\n",
      "Epoch 28775: train_loss=116.60786, val_loss=127.77070\n",
      "Epoch 28776: train_loss=116.60898, val_loss=127.72153\n",
      "Epoch 28777: train_loss=116.61025, val_loss=127.77811\n",
      "Epoch 28778: train_loss=116.61166, val_loss=127.72241\n",
      "Epoch 28779: train_loss=116.61314, val_loss=127.78629\n",
      "Epoch 28780: train_loss=116.61465, val_loss=127.72383\n",
      "Epoch 28781: train_loss=116.61657, val_loss=127.79402\n",
      "Epoch 28782: train_loss=116.61843, val_loss=127.72331\n",
      "Epoch 28783: train_loss=116.62065, val_loss=127.79960\n",
      "Epoch 28784: train_loss=116.62286, val_loss=127.72352\n",
      "Epoch 28785: train_loss=116.62484, val_loss=127.80869\n",
      "Epoch 28786: train_loss=116.62706, val_loss=127.72705\n",
      "Epoch 28787: train_loss=116.62894, val_loss=127.81604\n",
      "Epoch 28788: train_loss=116.63055, val_loss=127.72768\n",
      "Epoch 28789: train_loss=116.63179, val_loss=127.81889\n",
      "Epoch 28790: train_loss=116.63200, val_loss=127.72527\n",
      "Epoch 28791: train_loss=116.63192, val_loss=127.81635\n",
      "Epoch 28792: train_loss=116.63046, val_loss=127.72099\n",
      "Epoch 28793: train_loss=116.62861, val_loss=127.81229\n",
      "Epoch 28794: train_loss=116.62511, val_loss=127.71561\n",
      "Epoch 28795: train_loss=116.62132, val_loss=127.80155\n",
      "Epoch 28796: train_loss=116.61580, val_loss=127.70598\n",
      "Epoch 28797: train_loss=116.60967, val_loss=127.78463\n",
      "Epoch 28798: train_loss=116.60239, val_loss=127.69276\n",
      "Epoch 28799: train_loss=116.59469, val_loss=127.76241\n",
      "Epoch 28800: train_loss=116.58637, val_loss=127.67976\n",
      "Epoch 28801: train_loss=116.57787, val_loss=127.74213\n",
      "Epoch 28802: train_loss=116.56923, val_loss=127.67033\n",
      "Epoch 28803: train_loss=116.56123, val_loss=127.72151\n",
      "Epoch 28804: train_loss=116.55318, val_loss=127.66008\n",
      "Epoch 28805: train_loss=116.54572, val_loss=127.69998\n",
      "Epoch 28806: train_loss=116.53859, val_loss=127.65022\n",
      "Epoch 28807: train_loss=116.53221, val_loss=127.67990\n",
      "Epoch 28808: train_loss=116.52647, val_loss=127.64320\n",
      "Epoch 28809: train_loss=116.52137, val_loss=127.66611\n",
      "Epoch 28810: train_loss=116.51695, val_loss=127.64231\n",
      "Epoch 28811: train_loss=116.51308, val_loss=127.65714\n",
      "Epoch 28812: train_loss=116.50974, val_loss=127.64024\n",
      "Epoch 28813: train_loss=116.50676, val_loss=127.64807\n",
      "Epoch 28814: train_loss=116.50401, val_loss=127.63547\n",
      "Epoch 28815: train_loss=116.50144, val_loss=127.63895\n",
      "Epoch 28816: train_loss=116.49908, val_loss=127.62804\n",
      "Epoch 28817: train_loss=116.49679, val_loss=127.63036\n",
      "Epoch 28818: train_loss=116.49455, val_loss=127.62183\n",
      "Epoch 28819: train_loss=116.49238, val_loss=127.62716\n",
      "Epoch 28820: train_loss=116.49012, val_loss=127.62012\n",
      "Epoch 28821: train_loss=116.48804, val_loss=127.62610\n",
      "Epoch 28822: train_loss=116.48596, val_loss=127.61530\n",
      "Epoch 28823: train_loss=116.48405, val_loss=127.62404\n",
      "Epoch 28824: train_loss=116.48222, val_loss=127.60874\n",
      "Epoch 28825: train_loss=116.48075, val_loss=127.62422\n",
      "Epoch 28826: train_loss=116.47973, val_loss=127.60192\n",
      "Epoch 28827: train_loss=116.47932, val_loss=127.62848\n",
      "Epoch 28828: train_loss=116.48011, val_loss=127.59648\n",
      "Epoch 28829: train_loss=116.48264, val_loss=127.64391\n",
      "Epoch 28830: train_loss=116.48730, val_loss=127.59998\n",
      "Epoch 28831: train_loss=116.49571, val_loss=127.67870\n",
      "Epoch 28832: train_loss=116.50880, val_loss=127.61909\n",
      "Epoch 28833: train_loss=116.52911, val_loss=127.74612\n",
      "Epoch 28834: train_loss=116.55852, val_loss=127.67172\n",
      "Epoch 28835: train_loss=116.60141, val_loss=127.87035\n",
      "Epoch 28836: train_loss=116.65855, val_loss=127.78133\n",
      "Epoch 28837: train_loss=116.73454, val_loss=128.06561\n",
      "Epoch 28838: train_loss=116.82419, val_loss=127.94782\n",
      "Epoch 28839: train_loss=116.92423, val_loss=128.28534\n",
      "Epoch 28840: train_loss=117.01638, val_loss=128.08914\n",
      "Epoch 28841: train_loss=117.08156, val_loss=128.36336\n",
      "Epoch 28842: train_loss=117.08624, val_loss=128.03024\n",
      "Epoch 28843: train_loss=117.01909, val_loss=128.12669\n",
      "Epoch 28844: train_loss=116.87861, val_loss=127.74920\n",
      "Epoch 28845: train_loss=116.70558, val_loss=127.73527\n",
      "Epoch 28846: train_loss=116.54952, val_loss=127.55355\n",
      "Epoch 28847: train_loss=116.45361, val_loss=127.54947\n",
      "Epoch 28848: train_loss=116.43018, val_loss=127.62669\n",
      "Epoch 28849: train_loss=116.46653, val_loss=127.60499\n",
      "Epoch 28850: train_loss=116.53374, val_loss=127.79494\n",
      "Epoch 28851: train_loss=116.59626, val_loss=127.68063\n",
      "Epoch 28852: train_loss=116.62903, val_loss=127.82278\n",
      "Epoch 28853: train_loss=116.61738, val_loss=127.63222\n",
      "Epoch 28854: train_loss=116.56941, val_loss=127.68307\n",
      "Epoch 28855: train_loss=116.50375, val_loss=127.54197\n",
      "Epoch 28856: train_loss=116.44707, val_loss=127.55184\n",
      "Epoch 28857: train_loss=116.41421, val_loss=127.54259\n",
      "Epoch 28858: train_loss=116.40936, val_loss=127.52660\n",
      "Epoch 28859: train_loss=116.42566, val_loss=127.61474\n",
      "Epoch 28860: train_loss=116.45055, val_loss=127.55437\n",
      "Epoch 28861: train_loss=116.47133, val_loss=127.65490\n",
      "Epoch 28862: train_loss=116.47778, val_loss=127.55231\n",
      "Epoch 28863: train_loss=116.46967, val_loss=127.61649\n",
      "Epoch 28864: train_loss=116.44864, val_loss=127.52122\n",
      "Epoch 28865: train_loss=116.42411, val_loss=127.55000\n",
      "Epoch 28866: train_loss=116.40253, val_loss=127.51069\n",
      "Epoch 28867: train_loss=116.38966, val_loss=127.51067\n",
      "Epoch 28868: train_loss=116.38621, val_loss=127.53255\n",
      "Epoch 28869: train_loss=116.39004, val_loss=127.50465\n",
      "Epoch 28870: train_loss=116.39731, val_loss=127.55991\n",
      "Epoch 28871: train_loss=116.40380, val_loss=127.50677\n",
      "Epoch 28872: train_loss=116.40677, val_loss=127.56448\n",
      "Epoch 28873: train_loss=116.40484, val_loss=127.50047\n",
      "Epoch 28874: train_loss=116.39880, val_loss=127.54288\n",
      "Epoch 28875: train_loss=116.38987, val_loss=127.49005\n",
      "Epoch 28876: train_loss=116.38037, val_loss=127.51334\n",
      "Epoch 28877: train_loss=116.37172, val_loss=127.48748\n",
      "Epoch 28878: train_loss=116.36543, val_loss=127.49155\n",
      "Epoch 28879: train_loss=116.36167, val_loss=127.49453\n",
      "Epoch 28880: train_loss=116.36024, val_loss=127.48049\n",
      "Epoch 28881: train_loss=116.36019, val_loss=127.50307\n",
      "Epoch 28882: train_loss=116.36074, val_loss=127.47366\n",
      "Epoch 28883: train_loss=116.36104, val_loss=127.50426\n",
      "Epoch 28884: train_loss=116.36045, val_loss=127.46883\n",
      "Epoch 28885: train_loss=116.35891, val_loss=127.50159\n",
      "Epoch 28886: train_loss=116.35628, val_loss=127.46564\n",
      "Epoch 28887: train_loss=116.35301, val_loss=127.49263\n",
      "Epoch 28888: train_loss=116.34912, val_loss=127.46124\n",
      "Epoch 28889: train_loss=116.34512, val_loss=127.47952\n",
      "Epoch 28890: train_loss=116.34120, val_loss=127.45659\n",
      "Epoch 28891: train_loss=116.33748, val_loss=127.46619\n",
      "Epoch 28892: train_loss=116.33415, val_loss=127.45512\n",
      "Epoch 28893: train_loss=116.33128, val_loss=127.45624\n",
      "Epoch 28894: train_loss=116.32877, val_loss=127.45453\n",
      "Epoch 28895: train_loss=116.32664, val_loss=127.44837\n",
      "Epoch 28896: train_loss=116.32469, val_loss=127.45458\n",
      "Epoch 28897: train_loss=116.32294, val_loss=127.44136\n",
      "Epoch 28898: train_loss=116.32131, val_loss=127.45424\n",
      "Epoch 28899: train_loss=116.31982, val_loss=127.43627\n",
      "Epoch 28900: train_loss=116.31850, val_loss=127.45469\n",
      "Epoch 28901: train_loss=116.31716, val_loss=127.43176\n",
      "Epoch 28902: train_loss=116.31606, val_loss=127.45558\n",
      "Epoch 28903: train_loss=116.31503, val_loss=127.42670\n",
      "Epoch 28904: train_loss=116.31431, val_loss=127.45655\n",
      "Epoch 28905: train_loss=116.31368, val_loss=127.42123\n",
      "Epoch 28906: train_loss=116.31316, val_loss=127.45621\n",
      "Epoch 28907: train_loss=116.31249, val_loss=127.41645\n",
      "Epoch 28908: train_loss=116.31202, val_loss=127.45770\n",
      "Epoch 28909: train_loss=116.31124, val_loss=127.41398\n",
      "Epoch 28910: train_loss=116.31063, val_loss=127.45902\n",
      "Epoch 28911: train_loss=116.30994, val_loss=127.41043\n",
      "Epoch 28912: train_loss=116.30956, val_loss=127.45988\n",
      "Epoch 28913: train_loss=116.30881, val_loss=127.40815\n",
      "Epoch 28914: train_loss=116.30807, val_loss=127.46078\n",
      "Epoch 28915: train_loss=116.30728, val_loss=127.40469\n",
      "Epoch 28916: train_loss=116.30650, val_loss=127.45980\n",
      "Epoch 28917: train_loss=116.30594, val_loss=127.40074\n",
      "Epoch 28918: train_loss=116.30559, val_loss=127.46114\n",
      "Epoch 28919: train_loss=116.30553, val_loss=127.39911\n",
      "Epoch 28920: train_loss=116.30576, val_loss=127.46518\n",
      "Epoch 28921: train_loss=116.30615, val_loss=127.39855\n",
      "Epoch 28922: train_loss=116.30687, val_loss=127.46933\n",
      "Epoch 28923: train_loss=116.30772, val_loss=127.39712\n",
      "Epoch 28924: train_loss=116.30934, val_loss=127.47417\n",
      "Epoch 28925: train_loss=116.31100, val_loss=127.39701\n",
      "Epoch 28926: train_loss=116.31369, val_loss=127.48379\n",
      "Epoch 28927: train_loss=116.31627, val_loss=127.40204\n",
      "Epoch 28928: train_loss=116.32014, val_loss=127.49733\n",
      "Epoch 28929: train_loss=116.32320, val_loss=127.40686\n",
      "Epoch 28930: train_loss=116.32715, val_loss=127.50655\n",
      "Epoch 28931: train_loss=116.32950, val_loss=127.40726\n",
      "Epoch 28932: train_loss=116.33220, val_loss=127.50930\n",
      "Epoch 28933: train_loss=116.33255, val_loss=127.40386\n",
      "Epoch 28934: train_loss=116.33218, val_loss=127.50547\n",
      "Epoch 28935: train_loss=116.32916, val_loss=127.39906\n",
      "Epoch 28936: train_loss=116.32516, val_loss=127.49541\n",
      "Epoch 28937: train_loss=116.31834, val_loss=127.38953\n",
      "Epoch 28938: train_loss=116.31072, val_loss=127.47486\n",
      "Epoch 28939: train_loss=116.30068, val_loss=127.37476\n",
      "Epoch 28940: train_loss=116.29060, val_loss=127.44633\n",
      "Epoch 28941: train_loss=116.27917, val_loss=127.35735\n",
      "Epoch 28942: train_loss=116.26854, val_loss=127.41447\n",
      "Epoch 28943: train_loss=116.25732, val_loss=127.34290\n",
      "Epoch 28944: train_loss=116.24727, val_loss=127.38847\n",
      "Epoch 28945: train_loss=116.23776, val_loss=127.33448\n",
      "Epoch 28946: train_loss=116.22974, val_loss=127.36622\n",
      "Epoch 28947: train_loss=116.22260, val_loss=127.32825\n",
      "Epoch 28948: train_loss=116.21659, val_loss=127.34682\n",
      "Epoch 28949: train_loss=116.21149, val_loss=127.32540\n",
      "Epoch 28950: train_loss=116.20750, val_loss=127.33459\n",
      "Epoch 28951: train_loss=116.20411, val_loss=127.32726\n",
      "Epoch 28952: train_loss=116.20143, val_loss=127.32687\n",
      "Epoch 28953: train_loss=116.19916, val_loss=127.32825\n",
      "Epoch 28954: train_loss=116.19724, val_loss=127.31842\n",
      "Epoch 28955: train_loss=116.19561, val_loss=127.32768\n",
      "Epoch 28956: train_loss=116.19414, val_loss=127.31045\n",
      "Epoch 28957: train_loss=116.19310, val_loss=127.32884\n",
      "Epoch 28958: train_loss=116.19228, val_loss=127.30621\n",
      "Epoch 28959: train_loss=116.19170, val_loss=127.33500\n",
      "Epoch 28960: train_loss=116.19174, val_loss=127.30320\n",
      "Epoch 28961: train_loss=116.19224, val_loss=127.34237\n",
      "Epoch 28962: train_loss=116.19346, val_loss=127.30116\n",
      "Epoch 28963: train_loss=116.19581, val_loss=127.35381\n",
      "Epoch 28964: train_loss=116.19928, val_loss=127.30206\n",
      "Epoch 28965: train_loss=116.20472, val_loss=127.37518\n",
      "Epoch 28966: train_loss=116.21225, val_loss=127.31209\n",
      "Epoch 28967: train_loss=116.22299, val_loss=127.41212\n",
      "Epoch 28968: train_loss=116.23707, val_loss=127.33463\n",
      "Epoch 28969: train_loss=116.25684, val_loss=127.46986\n",
      "Epoch 28970: train_loss=116.28111, val_loss=127.37457\n",
      "Epoch 28971: train_loss=116.31187, val_loss=127.55018\n",
      "Epoch 28972: train_loss=116.34613, val_loss=127.43371\n",
      "Epoch 28973: train_loss=116.38489, val_loss=127.64117\n",
      "Epoch 28974: train_loss=116.42152, val_loss=127.49315\n",
      "Epoch 28975: train_loss=116.45518, val_loss=127.70543\n",
      "Epoch 28976: train_loss=116.47580, val_loss=127.51463\n",
      "Epoch 28977: train_loss=116.48174, val_loss=127.68974\n",
      "Epoch 28978: train_loss=116.46323, val_loss=127.46354\n",
      "Epoch 28979: train_loss=116.42444, val_loss=127.57362\n",
      "Epoch 28980: train_loss=116.36437, val_loss=127.35700\n",
      "Epoch 28981: train_loss=116.29661, val_loss=127.40981\n",
      "Epoch 28982: train_loss=116.23031, val_loss=127.26901\n",
      "Epoch 28983: train_loss=116.17830, val_loss=127.28920\n",
      "Epoch 28984: train_loss=116.14454, val_loss=127.25326\n",
      "Epoch 28985: train_loss=116.13057, val_loss=127.24702\n",
      "Epoch 28986: train_loss=116.13304, val_loss=127.29765\n",
      "Epoch 28987: train_loss=116.14640, val_loss=127.25869\n",
      "Epoch 28988: train_loss=116.16515, val_loss=127.35390\n",
      "Epoch 28989: train_loss=116.18301, val_loss=127.27843\n",
      "Epoch 28990: train_loss=116.19709, val_loss=127.38045\n",
      "Epoch 28991: train_loss=116.20286, val_loss=127.27825\n",
      "Epoch 28992: train_loss=116.20099, val_loss=127.36433\n",
      "Epoch 28993: train_loss=116.19050, val_loss=127.25933\n",
      "Epoch 28994: train_loss=116.17510, val_loss=127.32110\n",
      "Epoch 28995: train_loss=116.15592, val_loss=127.23679\n",
      "Epoch 28996: train_loss=116.13782, val_loss=127.27337\n",
      "Epoch 28997: train_loss=116.12186, val_loss=127.22443\n",
      "Epoch 28998: train_loss=116.10996, val_loss=127.23751\n",
      "Epoch 28999: train_loss=116.10223, val_loss=127.22710\n",
      "Epoch 29000: train_loss=116.09852, val_loss=127.22045\n",
      "Epoch 29001: train_loss=116.09795, val_loss=127.24288\n",
      "Epoch 29002: train_loss=116.09953, val_loss=127.21728\n",
      "Epoch 29003: train_loss=116.10217, val_loss=127.25784\n",
      "Epoch 29004: train_loss=116.10471, val_loss=127.21547\n",
      "Epoch 29005: train_loss=116.10676, val_loss=127.26324\n",
      "Epoch 29006: train_loss=116.10745, val_loss=127.21107\n",
      "Epoch 29007: train_loss=116.10724, val_loss=127.26150\n",
      "Epoch 29008: train_loss=116.10555, val_loss=127.20696\n",
      "Epoch 29009: train_loss=116.10326, val_loss=127.25550\n",
      "Epoch 29010: train_loss=116.09978, val_loss=127.20218\n",
      "Epoch 29011: train_loss=116.09608, val_loss=127.24577\n",
      "Epoch 29012: train_loss=116.09158, val_loss=127.19641\n",
      "Epoch 29013: train_loss=116.08713, val_loss=127.23241\n",
      "Epoch 29014: train_loss=116.08230, val_loss=127.19080\n",
      "Epoch 29015: train_loss=116.07766, val_loss=127.22029\n",
      "Epoch 29016: train_loss=116.07301, val_loss=127.18890\n",
      "Epoch 29017: train_loss=116.06886, val_loss=127.21009\n",
      "Epoch 29018: train_loss=116.06506, val_loss=127.18658\n",
      "Epoch 29019: train_loss=116.06157, val_loss=127.19963\n",
      "Epoch 29020: train_loss=116.05835, val_loss=127.18408\n",
      "Epoch 29021: train_loss=116.05555, val_loss=127.19012\n",
      "Epoch 29022: train_loss=116.05296, val_loss=127.18051\n",
      "Epoch 29023: train_loss=116.05053, val_loss=127.18018\n",
      "Epoch 29024: train_loss=116.04836, val_loss=127.17702\n",
      "Epoch 29025: train_loss=116.04619, val_loss=127.17468\n",
      "Epoch 29026: train_loss=116.04417, val_loss=127.17711\n",
      "Epoch 29027: train_loss=116.04208, val_loss=127.17141\n",
      "Epoch 29028: train_loss=116.04022, val_loss=127.17700\n",
      "Epoch 29029: train_loss=116.03838, val_loss=127.16647\n",
      "Epoch 29030: train_loss=116.03664, val_loss=127.17528\n",
      "Epoch 29031: train_loss=116.03500, val_loss=127.15894\n",
      "Epoch 29032: train_loss=116.03358, val_loss=127.17357\n",
      "Epoch 29033: train_loss=116.03249, val_loss=127.15194\n",
      "Epoch 29034: train_loss=116.03182, val_loss=127.17770\n",
      "Epoch 29035: train_loss=116.03152, val_loss=127.15048\n",
      "Epoch 29036: train_loss=116.03218, val_loss=127.18852\n",
      "Epoch 29037: train_loss=116.03371, val_loss=127.15080\n",
      "Epoch 29038: train_loss=116.03722, val_loss=127.20688\n",
      "Epoch 29039: train_loss=116.04281, val_loss=127.15578\n",
      "Epoch 29040: train_loss=116.05198, val_loss=127.23962\n",
      "Epoch 29041: train_loss=116.06494, val_loss=127.17249\n",
      "Epoch 29042: train_loss=116.08356, val_loss=127.29485\n",
      "Epoch 29043: train_loss=116.10745, val_loss=127.21298\n",
      "Epoch 29044: train_loss=116.13933, val_loss=127.38618\n",
      "Epoch 29045: train_loss=116.17780, val_loss=127.28337\n",
      "Epoch 29046: train_loss=116.22436, val_loss=127.50285\n",
      "Epoch 29047: train_loss=116.27340, val_loss=127.36833\n",
      "Epoch 29048: train_loss=116.32397, val_loss=127.60769\n",
      "Epoch 29049: train_loss=116.36375, val_loss=127.42263\n",
      "Epoch 29050: train_loss=116.38809, val_loss=127.62824\n",
      "Epoch 29051: train_loss=116.38214, val_loss=127.38535\n",
      "Epoch 29052: train_loss=116.34694, val_loss=127.50832\n",
      "Epoch 29053: train_loss=116.27815, val_loss=127.25402\n",
      "Epoch 29054: train_loss=116.19337, val_loss=127.30284\n",
      "Epoch 29055: train_loss=116.10653, val_loss=127.13213\n",
      "Epoch 29056: train_loss=116.03691, val_loss=127.14673\n",
      "Epoch 29057: train_loss=115.99316, val_loss=127.11272\n",
      "Epoch 29058: train_loss=115.97827, val_loss=127.10464\n",
      "Epoch 29059: train_loss=115.98732, val_loss=127.18010\n",
      "Epoch 29060: train_loss=116.01108, val_loss=127.13284\n",
      "Epoch 29061: train_loss=116.04089, val_loss=127.25536\n",
      "Epoch 29062: train_loss=116.06590, val_loss=127.16043\n",
      "Epoch 29063: train_loss=116.08070, val_loss=127.27555\n",
      "Epoch 29064: train_loss=116.08094, val_loss=127.14990\n",
      "Epoch 29065: train_loss=116.06841, val_loss=127.23094\n",
      "Epoch 29066: train_loss=116.04509, val_loss=127.11396\n",
      "Epoch 29067: train_loss=116.01781, val_loss=127.16058\n",
      "Epoch 29068: train_loss=115.99108, val_loss=127.08851\n",
      "Epoch 29069: train_loss=115.97024, val_loss=127.10560\n",
      "Epoch 29070: train_loss=115.95679, val_loss=127.09099\n",
      "Epoch 29071: train_loss=115.95151, val_loss=127.08204\n",
      "Epoch 29072: train_loss=115.95287, val_loss=127.11557\n",
      "Epoch 29073: train_loss=115.95792, val_loss=127.08180\n",
      "Epoch 29074: train_loss=115.96394, val_loss=127.13790\n",
      "Epoch 29075: train_loss=115.96849, val_loss=127.08430\n",
      "Epoch 29076: train_loss=115.97097, val_loss=127.14330\n",
      "Epoch 29077: train_loss=115.97002, val_loss=127.08055\n",
      "Epoch 29078: train_loss=115.96655, val_loss=127.13191\n",
      "Epoch 29079: train_loss=115.96024, val_loss=127.07357\n",
      "Epoch 29080: train_loss=115.95302, val_loss=127.11050\n",
      "Epoch 29081: train_loss=115.94512, val_loss=127.06640\n",
      "Epoch 29082: train_loss=115.93781, val_loss=127.08727\n",
      "Epoch 29083: train_loss=115.93140, val_loss=127.06487\n",
      "Epoch 29084: train_loss=115.92651, val_loss=127.07127\n",
      "Epoch 29085: train_loss=115.92310, val_loss=127.06879\n",
      "Epoch 29086: train_loss=115.92092, val_loss=127.06136\n",
      "Epoch 29087: train_loss=115.91972, val_loss=127.07516\n",
      "Epoch 29088: train_loss=115.91920, val_loss=127.05530\n",
      "Epoch 29089: train_loss=115.91894, val_loss=127.08062\n",
      "Epoch 29090: train_loss=115.91875, val_loss=127.05180\n",
      "Epoch 29091: train_loss=115.91835, val_loss=127.08282\n",
      "Epoch 29092: train_loss=115.91780, val_loss=127.04790\n",
      "Epoch 29093: train_loss=115.91703, val_loss=127.08294\n",
      "Epoch 29094: train_loss=115.91595, val_loss=127.04414\n",
      "Epoch 29095: train_loss=115.91469, val_loss=127.08094\n",
      "Epoch 29096: train_loss=115.91310, val_loss=127.04108\n",
      "Epoch 29097: train_loss=115.91148, val_loss=127.08035\n",
      "Epoch 29098: train_loss=115.90964, val_loss=127.03904\n",
      "Epoch 29099: train_loss=115.90782, val_loss=127.07764\n",
      "Epoch 29100: train_loss=115.90586, val_loss=127.03471\n",
      "Epoch 29101: train_loss=115.90401, val_loss=127.07253\n",
      "Epoch 29102: train_loss=115.90199, val_loss=127.02986\n",
      "Epoch 29103: train_loss=115.90029, val_loss=127.07024\n",
      "Epoch 29104: train_loss=115.89859, val_loss=127.02761\n",
      "Epoch 29105: train_loss=115.89725, val_loss=127.06989\n",
      "Epoch 29106: train_loss=115.89602, val_loss=127.02455\n",
      "Epoch 29107: train_loss=115.89552, val_loss=127.07097\n",
      "Epoch 29108: train_loss=115.89549, val_loss=127.02187\n",
      "Epoch 29109: train_loss=115.89634, val_loss=127.07713\n",
      "Epoch 29110: train_loss=115.89773, val_loss=127.02243\n",
      "Epoch 29111: train_loss=115.90026, val_loss=127.08857\n",
      "Epoch 29112: train_loss=115.90362, val_loss=127.02545\n",
      "Epoch 29113: train_loss=115.90855, val_loss=127.10587\n",
      "Epoch 29114: train_loss=115.91460, val_loss=127.03381\n",
      "Epoch 29115: train_loss=115.92276, val_loss=127.13336\n",
      "Epoch 29116: train_loss=115.93240, val_loss=127.04981\n",
      "Epoch 29117: train_loss=115.94446, val_loss=127.16921\n",
      "Epoch 29118: train_loss=115.95770, val_loss=127.07094\n",
      "Epoch 29119: train_loss=115.97315, val_loss=127.20855\n",
      "Epoch 29120: train_loss=115.98843, val_loss=127.09296\n",
      "Epoch 29121: train_loss=116.00445, val_loss=127.24277\n",
      "Epoch 29122: train_loss=116.01747, val_loss=127.10877\n",
      "Epoch 29123: train_loss=116.02760, val_loss=127.25839\n",
      "Epoch 29124: train_loss=116.03077, val_loss=127.10784\n",
      "Epoch 29125: train_loss=116.02786, val_loss=127.24189\n",
      "Epoch 29126: train_loss=116.01550, val_loss=127.08260\n",
      "Epoch 29127: train_loss=115.99586, val_loss=127.18651\n",
      "Epoch 29128: train_loss=115.96906, val_loss=127.03732\n",
      "Epoch 29129: train_loss=115.93919, val_loss=127.10898\n",
      "Epoch 29130: train_loss=115.90831, val_loss=126.99375\n",
      "Epoch 29131: train_loss=115.87985, val_loss=127.03763\n",
      "Epoch 29132: train_loss=115.85596, val_loss=126.97145\n",
      "Epoch 29133: train_loss=115.83798, val_loss=126.98945\n",
      "Epoch 29134: train_loss=115.82660, val_loss=126.97402\n",
      "Epoch 29135: train_loss=115.82146, val_loss=126.96706\n",
      "Epoch 29136: train_loss=115.82127, val_loss=126.99323\n",
      "Epoch 29137: train_loss=115.82457, val_loss=126.96451\n",
      "Epoch 29138: train_loss=115.82977, val_loss=127.01753\n",
      "Epoch 29139: train_loss=115.83528, val_loss=126.96833\n",
      "Epoch 29140: train_loss=115.84011, val_loss=127.03402\n",
      "Epoch 29141: train_loss=115.84425, val_loss=126.96986\n",
      "Epoch 29142: train_loss=115.84715, val_loss=127.04082\n",
      "Epoch 29143: train_loss=115.84869, val_loss=126.96825\n",
      "Epoch 29144: train_loss=115.84860, val_loss=127.04179\n",
      "Epoch 29145: train_loss=115.84747, val_loss=126.96708\n",
      "Epoch 29146: train_loss=115.84502, val_loss=127.03849\n",
      "Epoch 29147: train_loss=115.84200, val_loss=126.96288\n",
      "Epoch 29148: train_loss=115.83786, val_loss=127.02802\n",
      "Epoch 29149: train_loss=115.83301, val_loss=126.95505\n",
      "Epoch 29150: train_loss=115.82761, val_loss=127.01243\n",
      "Epoch 29151: train_loss=115.82193, val_loss=126.94508\n",
      "Epoch 29152: train_loss=115.81618, val_loss=126.99580\n",
      "Epoch 29153: train_loss=115.81055, val_loss=126.93781\n",
      "Epoch 29154: train_loss=115.80477, val_loss=126.98159\n",
      "Epoch 29155: train_loss=115.79932, val_loss=126.93240\n",
      "Epoch 29156: train_loss=115.79401, val_loss=126.96780\n",
      "Epoch 29157: train_loss=115.78898, val_loss=126.92835\n",
      "Epoch 29158: train_loss=115.78427, val_loss=126.95555\n",
      "Epoch 29159: train_loss=115.78000, val_loss=126.92553\n",
      "Epoch 29160: train_loss=115.77600, val_loss=126.94444\n",
      "Epoch 29161: train_loss=115.77247, val_loss=126.92245\n",
      "Epoch 29162: train_loss=115.76935, val_loss=126.93472\n",
      "Epoch 29163: train_loss=115.76662, val_loss=126.91888\n",
      "Epoch 29164: train_loss=115.76400, val_loss=126.92746\n",
      "Epoch 29165: train_loss=115.76165, val_loss=126.91782\n",
      "Epoch 29166: train_loss=115.75939, val_loss=126.92388\n",
      "Epoch 29167: train_loss=115.75721, val_loss=126.91637\n",
      "Epoch 29168: train_loss=115.75513, val_loss=126.91955\n",
      "Epoch 29169: train_loss=115.75305, val_loss=126.91230\n",
      "Epoch 29170: train_loss=115.75095, val_loss=126.91345\n",
      "Epoch 29171: train_loss=115.74898, val_loss=126.90710\n",
      "Epoch 29172: train_loss=115.74693, val_loss=126.90968\n",
      "Epoch 29173: train_loss=115.74494, val_loss=126.90480\n",
      "Epoch 29174: train_loss=115.74296, val_loss=126.90933\n",
      "Epoch 29175: train_loss=115.74103, val_loss=126.90260\n",
      "Epoch 29176: train_loss=115.73916, val_loss=126.90922\n",
      "Epoch 29177: train_loss=115.73734, val_loss=126.89754\n",
      "Epoch 29178: train_loss=115.73580, val_loss=126.90771\n",
      "Epoch 29179: train_loss=115.73443, val_loss=126.88900\n",
      "Epoch 29180: train_loss=115.73356, val_loss=126.90849\n",
      "Epoch 29181: train_loss=115.73347, val_loss=126.88350\n",
      "Epoch 29182: train_loss=115.73441, val_loss=126.92258\n",
      "Epoch 29183: train_loss=115.73731, val_loss=126.88604\n",
      "Epoch 29184: train_loss=115.74290, val_loss=126.95209\n",
      "Epoch 29185: train_loss=115.75295, val_loss=126.89946\n",
      "Epoch 29186: train_loss=115.76958, val_loss=127.01150\n",
      "Epoch 29187: train_loss=115.79539, val_loss=126.94184\n",
      "Epoch 29188: train_loss=115.83305, val_loss=127.12429\n",
      "Epoch 29189: train_loss=115.88597, val_loss=127.04285\n",
      "Epoch 29190: train_loss=115.95959, val_loss=127.32094\n",
      "Epoch 29191: train_loss=116.05134, val_loss=127.21824\n",
      "Epoch 29192: train_loss=116.16120, val_loss=127.57186\n",
      "Epoch 29193: train_loss=116.26987, val_loss=127.40029\n",
      "Epoch 29194: train_loss=116.36246, val_loss=127.71669\n",
      "Epoch 29195: train_loss=116.39761, val_loss=127.39722\n",
      "Epoch 29196: train_loss=116.35983, val_loss=127.52728\n",
      "Epoch 29197: train_loss=116.23007, val_loss=127.11440\n",
      "Epoch 29198: train_loss=116.04756, val_loss=127.09751\n",
      "Epoch 29199: train_loss=115.86217, val_loss=126.86118\n",
      "Epoch 29200: train_loss=115.73399, val_loss=126.85284\n",
      "Epoch 29201: train_loss=115.68942, val_loss=126.91486\n",
      "Epoch 29202: train_loss=115.71950, val_loss=126.90198\n",
      "Epoch 29203: train_loss=115.79250, val_loss=127.10891\n",
      "Epoch 29204: train_loss=115.86789, val_loss=126.99683\n",
      "Epoch 29205: train_loss=115.91141, val_loss=127.15293\n",
      "Epoch 29206: train_loss=115.90268, val_loss=126.94626\n",
      "Epoch 29207: train_loss=115.84974, val_loss=126.99676\n",
      "Epoch 29208: train_loss=115.77540, val_loss=126.84494\n",
      "Epoch 29209: train_loss=115.71042, val_loss=126.85326\n",
      "Epoch 29210: train_loss=115.67506, val_loss=126.85398\n",
      "Epoch 29211: train_loss=115.67402, val_loss=126.83675\n",
      "Epoch 29212: train_loss=115.69759, val_loss=126.94231\n",
      "Epoch 29213: train_loss=115.72897, val_loss=126.87118\n",
      "Epoch 29214: train_loss=115.75185, val_loss=126.97947\n",
      "Epoch 29215: train_loss=115.75505, val_loss=126.86241\n",
      "Epoch 29216: train_loss=115.73921, val_loss=126.92193\n",
      "Epoch 29217: train_loss=115.71033, val_loss=126.82553\n",
      "Epoch 29218: train_loss=115.68089, val_loss=126.84642\n",
      "Epoch 29219: train_loss=115.66008, val_loss=126.82533\n",
      "Epoch 29220: train_loss=115.65169, val_loss=126.81803\n",
      "Epoch 29221: train_loss=115.65450, val_loss=126.86282\n",
      "Epoch 29222: train_loss=115.66375, val_loss=126.82341\n",
      "Epoch 29223: train_loss=115.67367, val_loss=126.89275\n",
      "Epoch 29224: train_loss=115.67952, val_loss=126.82635\n",
      "Epoch 29225: train_loss=115.67864, val_loss=126.88385\n",
      "Epoch 29226: train_loss=115.67158, val_loss=126.81474\n",
      "Epoch 29227: train_loss=115.66032, val_loss=126.84887\n",
      "Epoch 29228: train_loss=115.64846, val_loss=126.80769\n",
      "Epoch 29229: train_loss=115.63858, val_loss=126.81884\n",
      "Epoch 29230: train_loss=115.63237, val_loss=126.81519\n",
      "Epoch 29231: train_loss=115.62989, val_loss=126.80502\n",
      "Epoch 29232: train_loss=115.63029, val_loss=126.83118\n",
      "Epoch 29233: train_loss=115.63232, val_loss=126.80136\n",
      "Epoch 29234: train_loss=115.63432, val_loss=126.84103\n",
      "Epoch 29235: train_loss=115.63525, val_loss=126.79912\n",
      "Epoch 29236: train_loss=115.63426, val_loss=126.83982\n",
      "Epoch 29237: train_loss=115.63145, val_loss=126.79732\n",
      "Epoch 29238: train_loss=115.62715, val_loss=126.82830\n",
      "Epoch 29239: train_loss=115.62216, val_loss=126.79490\n",
      "Epoch 29240: train_loss=115.61697, val_loss=126.81306\n",
      "Epoch 29241: train_loss=115.61237, val_loss=126.79492\n",
      "Epoch 29242: train_loss=115.60860, val_loss=126.79951\n",
      "Epoch 29243: train_loss=115.60564, val_loss=126.79679\n",
      "Epoch 29244: train_loss=115.60356, val_loss=126.79076\n",
      "Epoch 29245: train_loss=115.60207, val_loss=126.80224\n",
      "Epoch 29246: train_loss=115.60102, val_loss=126.78667\n",
      "Epoch 29247: train_loss=115.60021, val_loss=126.80721\n",
      "Epoch 29248: train_loss=115.59952, val_loss=126.78310\n",
      "Epoch 29249: train_loss=115.59861, val_loss=126.80882\n",
      "Epoch 29250: train_loss=115.59744, val_loss=126.77962\n",
      "Epoch 29251: train_loss=115.59603, val_loss=126.80698\n",
      "Epoch 29252: train_loss=115.59433, val_loss=126.77629\n",
      "Epoch 29253: train_loss=115.59240, val_loss=126.80521\n",
      "Epoch 29254: train_loss=115.59031, val_loss=126.77515\n",
      "Epoch 29255: train_loss=115.58804, val_loss=126.80235\n",
      "Epoch 29256: train_loss=115.58563, val_loss=126.77292\n",
      "Epoch 29257: train_loss=115.58323, val_loss=126.79704\n",
      "Epoch 29258: train_loss=115.58070, val_loss=126.76898\n",
      "Epoch 29259: train_loss=115.57825, val_loss=126.79048\n",
      "Epoch 29260: train_loss=115.57572, val_loss=126.76588\n",
      "Epoch 29261: train_loss=115.57346, val_loss=126.78780\n",
      "Epoch 29262: train_loss=115.57118, val_loss=126.76520\n",
      "Epoch 29263: train_loss=115.56887, val_loss=126.78478\n",
      "Epoch 29264: train_loss=115.56667, val_loss=126.76224\n",
      "Epoch 29265: train_loss=115.56436, val_loss=126.77972\n",
      "Epoch 29266: train_loss=115.56227, val_loss=126.75764\n",
      "Epoch 29267: train_loss=115.56023, val_loss=126.77510\n",
      "Epoch 29268: train_loss=115.55820, val_loss=126.75447\n",
      "Epoch 29269: train_loss=115.55634, val_loss=126.77497\n",
      "Epoch 29270: train_loss=115.55458, val_loss=126.75314\n",
      "Epoch 29271: train_loss=115.55310, val_loss=126.77621\n",
      "Epoch 29272: train_loss=115.55188, val_loss=126.74969\n",
      "Epoch 29273: train_loss=115.55099, val_loss=126.77810\n",
      "Epoch 29274: train_loss=115.55051, val_loss=126.74509\n",
      "Epoch 29275: train_loss=115.55047, val_loss=126.78272\n",
      "Epoch 29276: train_loss=115.55122, val_loss=126.74220\n",
      "Epoch 29277: train_loss=115.55265, val_loss=126.79273\n",
      "Epoch 29278: train_loss=115.55478, val_loss=126.74435\n",
      "Epoch 29279: train_loss=115.55831, val_loss=126.81060\n",
      "Epoch 29280: train_loss=115.56301, val_loss=126.74982\n",
      "Epoch 29281: train_loss=115.56929, val_loss=126.83421\n",
      "Epoch 29282: train_loss=115.57712, val_loss=126.75921\n",
      "Epoch 29283: train_loss=115.58668, val_loss=126.86410\n",
      "Epoch 29284: train_loss=115.59782, val_loss=126.77378\n",
      "Epoch 29285: train_loss=115.61118, val_loss=126.89988\n",
      "Epoch 29286: train_loss=115.62510, val_loss=126.79410\n",
      "Epoch 29287: train_loss=115.64022, val_loss=126.93840\n",
      "Epoch 29288: train_loss=115.65327, val_loss=126.81511\n",
      "Epoch 29289: train_loss=115.66458, val_loss=126.96489\n",
      "Epoch 29290: train_loss=115.67139, val_loss=126.82309\n",
      "Epoch 29291: train_loss=115.67368, val_loss=126.96345\n",
      "Epoch 29292: train_loss=115.66896, val_loss=126.81004\n",
      "Epoch 29293: train_loss=115.65834, val_loss=126.92924\n",
      "Epoch 29294: train_loss=115.64092, val_loss=126.77831\n",
      "Epoch 29295: train_loss=115.61920, val_loss=126.86963\n",
      "Epoch 29296: train_loss=115.59418, val_loss=126.73948\n",
      "Epoch 29297: train_loss=115.56927, val_loss=126.80396\n",
      "Epoch 29298: train_loss=115.54620, val_loss=126.71037\n",
      "Epoch 29299: train_loss=115.52628, val_loss=126.75290\n",
      "Epoch 29300: train_loss=115.51061, val_loss=126.70020\n",
      "Epoch 29301: train_loss=115.49881, val_loss=126.72143\n",
      "Epoch 29302: train_loss=115.49086, val_loss=126.70370\n",
      "Epoch 29303: train_loss=115.48605, val_loss=126.70458\n",
      "Epoch 29304: train_loss=115.48365, val_loss=126.71326\n",
      "Epoch 29305: train_loss=115.48300, val_loss=126.69588\n",
      "Epoch 29306: train_loss=115.48363, val_loss=126.72506\n",
      "Epoch 29307: train_loss=115.48508, val_loss=126.69235\n",
      "Epoch 29308: train_loss=115.48719, val_loss=126.73711\n",
      "Epoch 29309: train_loss=115.48975, val_loss=126.69040\n",
      "Epoch 29310: train_loss=115.49259, val_loss=126.74894\n",
      "Epoch 29311: train_loss=115.49593, val_loss=126.69159\n",
      "Epoch 29312: train_loss=115.49940, val_loss=126.76438\n",
      "Epoch 29313: train_loss=115.50344, val_loss=126.69814\n",
      "Epoch 29314: train_loss=115.50781, val_loss=126.78396\n",
      "Epoch 29315: train_loss=115.51284, val_loss=126.70643\n",
      "Epoch 29316: train_loss=115.51794, val_loss=126.80276\n",
      "Epoch 29317: train_loss=115.52332, val_loss=126.71302\n",
      "Epoch 29318: train_loss=115.52843, val_loss=126.81674\n",
      "Epoch 29319: train_loss=115.53336, val_loss=126.71568\n",
      "Epoch 29320: train_loss=115.53785, val_loss=126.82578\n",
      "Epoch 29321: train_loss=115.54129, val_loss=126.71728\n",
      "Epoch 29322: train_loss=115.54364, val_loss=126.83154\n",
      "Epoch 29323: train_loss=115.54404, val_loss=126.71788\n",
      "Epoch 29324: train_loss=115.54222, val_loss=126.82790\n",
      "Epoch 29325: train_loss=115.53821, val_loss=126.71065\n",
      "Epoch 29326: train_loss=115.53164, val_loss=126.80979\n",
      "Epoch 29327: train_loss=115.52308, val_loss=126.69595\n",
      "Epoch 29328: train_loss=115.51296, val_loss=126.78210\n",
      "Epoch 29329: train_loss=115.50212, val_loss=126.67876\n",
      "Epoch 29330: train_loss=115.49039, val_loss=126.75054\n",
      "Epoch 29331: train_loss=115.47887, val_loss=126.66246\n",
      "Epoch 29332: train_loss=115.46741, val_loss=126.71965\n",
      "Epoch 29333: train_loss=115.45698, val_loss=126.65083\n",
      "Epoch 29334: train_loss=115.44749, val_loss=126.69489\n",
      "Epoch 29335: train_loss=115.43939, val_loss=126.64443\n",
      "Epoch 29336: train_loss=115.43229, val_loss=126.67435\n",
      "Epoch 29337: train_loss=115.42628, val_loss=126.64086\n",
      "Epoch 29338: train_loss=115.42126, val_loss=126.65947\n",
      "Epoch 29339: train_loss=115.41721, val_loss=126.63986\n",
      "Epoch 29340: train_loss=115.41386, val_loss=126.64894\n",
      "Epoch 29341: train_loss=115.41108, val_loss=126.64014\n",
      "Epoch 29342: train_loss=115.40862, val_loss=126.64214\n",
      "Epoch 29343: train_loss=115.40639, val_loss=126.64131\n",
      "Epoch 29344: train_loss=115.40443, val_loss=126.63647\n",
      "Epoch 29345: train_loss=115.40253, val_loss=126.64113\n",
      "Epoch 29346: train_loss=115.40085, val_loss=126.63173\n",
      "Epoch 29347: train_loss=115.39914, val_loss=126.64300\n",
      "Epoch 29348: train_loss=115.39764, val_loss=126.62745\n",
      "Epoch 29349: train_loss=115.39630, val_loss=126.64482\n",
      "Epoch 29350: train_loss=115.39532, val_loss=126.62247\n",
      "Epoch 29351: train_loss=115.39475, val_loss=126.65009\n",
      "Epoch 29352: train_loss=115.39484, val_loss=126.61901\n",
      "Epoch 29353: train_loss=115.39565, val_loss=126.66184\n",
      "Epoch 29354: train_loss=115.39781, val_loss=126.62016\n",
      "Epoch 29355: train_loss=115.40165, val_loss=126.68327\n",
      "Epoch 29356: train_loss=115.40777, val_loss=126.62666\n",
      "Epoch 29357: train_loss=115.41708, val_loss=126.72015\n",
      "Epoch 29358: train_loss=115.43119, val_loss=126.64653\n",
      "Epoch 29359: train_loss=115.45042, val_loss=126.78282\n",
      "Epoch 29360: train_loss=115.47650, val_loss=126.69125\n",
      "Epoch 29361: train_loss=115.51129, val_loss=126.88255\n",
      "Epoch 29362: train_loss=115.55370, val_loss=126.76600\n",
      "Epoch 29363: train_loss=115.60373, val_loss=127.00793\n",
      "Epoch 29364: train_loss=115.65680, val_loss=126.85432\n",
      "Epoch 29365: train_loss=115.70805, val_loss=127.11316\n",
      "Epoch 29366: train_loss=115.74564, val_loss=126.90345\n",
      "Epoch 29367: train_loss=115.76392, val_loss=127.12002\n",
      "Epoch 29368: train_loss=115.74879, val_loss=126.85212\n",
      "Epoch 29369: train_loss=115.70293, val_loss=126.97982\n",
      "Epoch 29370: train_loss=115.62730, val_loss=126.71429\n",
      "Epoch 29371: train_loss=115.53893, val_loss=126.76836\n",
      "Epoch 29372: train_loss=115.45445, val_loss=126.60377\n",
      "Epoch 29373: train_loss=115.38970, val_loss=126.62304\n",
      "Epoch 29374: train_loss=115.35267, val_loss=126.60020\n",
      "Epoch 29375: train_loss=115.34219, val_loss=126.58889\n",
      "Epoch 29376: train_loss=115.35282, val_loss=126.67047\n",
      "Epoch 29377: train_loss=115.37593, val_loss=126.61382\n",
      "Epoch 29378: train_loss=115.40247, val_loss=126.74113\n",
      "Epoch 29379: train_loss=115.42535, val_loss=126.63718\n",
      "Epoch 29380: train_loss=115.43802, val_loss=126.75869\n",
      "Epoch 29381: train_loss=115.43796, val_loss=126.62686\n",
      "Epoch 29382: train_loss=115.42575, val_loss=126.71570\n",
      "Epoch 29383: train_loss=115.40455, val_loss=126.59476\n",
      "Epoch 29384: train_loss=115.37915, val_loss=126.64878\n",
      "Epoch 29385: train_loss=115.35513, val_loss=126.57267\n",
      "Epoch 29386: train_loss=115.33537, val_loss=126.59551\n",
      "Epoch 29387: train_loss=115.32239, val_loss=126.57542\n",
      "Epoch 29388: train_loss=115.31624, val_loss=126.56953\n",
      "Epoch 29389: train_loss=115.31569, val_loss=126.59653\n",
      "Epoch 29390: train_loss=115.31904, val_loss=126.56563\n",
      "Epoch 29391: train_loss=115.32430, val_loss=126.62183\n",
      "Epoch 29392: train_loss=115.33002, val_loss=126.56815\n",
      "Epoch 29393: train_loss=115.33441, val_loss=126.63579\n",
      "Epoch 29394: train_loss=115.33690, val_loss=126.56739\n",
      "Epoch 29395: train_loss=115.33655, val_loss=126.63387\n",
      "Epoch 29396: train_loss=115.33395, val_loss=126.56188\n",
      "Epoch 29397: train_loss=115.32880, val_loss=126.61809\n",
      "Epoch 29398: train_loss=115.32244, val_loss=126.55413\n",
      "Epoch 29399: train_loss=115.31509, val_loss=126.59669\n",
      "Epoch 29400: train_loss=115.30793, val_loss=126.54710\n",
      "Epoch 29401: train_loss=115.30139, val_loss=126.57568\n",
      "Epoch 29402: train_loss=115.29559, val_loss=126.54390\n",
      "Epoch 29403: train_loss=115.29066, val_loss=126.55991\n",
      "Epoch 29404: train_loss=115.28670, val_loss=126.54417\n",
      "Epoch 29405: train_loss=115.28349, val_loss=126.54753\n",
      "Epoch 29406: train_loss=115.28095, val_loss=126.54520\n",
      "Epoch 29407: train_loss=115.27909, val_loss=126.53880\n",
      "Epoch 29408: train_loss=115.27753, val_loss=126.54829\n",
      "Epoch 29409: train_loss=115.27622, val_loss=126.53220\n",
      "Epoch 29410: train_loss=115.27524, val_loss=126.55025\n",
      "Epoch 29411: train_loss=115.27438, val_loss=126.52567\n",
      "Epoch 29412: train_loss=115.27396, val_loss=126.55325\n",
      "Epoch 29413: train_loss=115.27374, val_loss=126.52084\n",
      "Epoch 29414: train_loss=115.27369, val_loss=126.55705\n",
      "Epoch 29415: train_loss=115.27383, val_loss=126.51664\n",
      "Epoch 29416: train_loss=115.27442, val_loss=126.56277\n",
      "Epoch 29417: train_loss=115.27516, val_loss=126.51527\n",
      "Epoch 29418: train_loss=115.27637, val_loss=126.57133\n",
      "Epoch 29419: train_loss=115.27789, val_loss=126.51527\n",
      "Epoch 29420: train_loss=115.27981, val_loss=126.58112\n",
      "Epoch 29421: train_loss=115.28265, val_loss=126.51530\n",
      "Epoch 29422: train_loss=115.28592, val_loss=126.59317\n",
      "Epoch 29423: train_loss=115.29016, val_loss=126.51735\n",
      "Epoch 29424: train_loss=115.29496, val_loss=126.60917\n",
      "Epoch 29425: train_loss=115.30096, val_loss=126.52361\n",
      "Epoch 29426: train_loss=115.30733, val_loss=126.63039\n",
      "Epoch 29427: train_loss=115.31467, val_loss=126.53275\n",
      "Epoch 29428: train_loss=115.32196, val_loss=126.65146\n",
      "Epoch 29429: train_loss=115.32944, val_loss=126.54141\n",
      "Epoch 29430: train_loss=115.33600, val_loss=126.66721\n",
      "Epoch 29431: train_loss=115.34128, val_loss=126.54598\n",
      "Epoch 29432: train_loss=115.34449, val_loss=126.67302\n",
      "Epoch 29433: train_loss=115.34515, val_loss=126.54300\n",
      "Epoch 29434: train_loss=115.34279, val_loss=126.66266\n",
      "Epoch 29435: train_loss=115.33678, val_loss=126.53041\n",
      "Epoch 29436: train_loss=115.32758, val_loss=126.63589\n",
      "Epoch 29437: train_loss=115.31557, val_loss=126.51002\n",
      "Epoch 29438: train_loss=115.30138, val_loss=126.59741\n",
      "Epoch 29439: train_loss=115.28660, val_loss=126.48837\n",
      "Epoch 29440: train_loss=115.27118, val_loss=126.55759\n",
      "Epoch 29441: train_loss=115.25713, val_loss=126.47092\n",
      "Epoch 29442: train_loss=115.24391, val_loss=126.52223\n",
      "Epoch 29443: train_loss=115.23294, val_loss=126.45950\n",
      "Epoch 29444: train_loss=115.22306, val_loss=126.49378\n",
      "Epoch 29445: train_loss=115.21503, val_loss=126.45457\n",
      "Epoch 29446: train_loss=115.20853, val_loss=126.47269\n",
      "Epoch 29447: train_loss=115.20361, val_loss=126.45476\n",
      "Epoch 29448: train_loss=115.19996, val_loss=126.45992\n",
      "Epoch 29449: train_loss=115.19722, val_loss=126.45760\n",
      "Epoch 29450: train_loss=115.19516, val_loss=126.45100\n",
      "Epoch 29451: train_loss=115.19373, val_loss=126.46151\n",
      "Epoch 29452: train_loss=115.19255, val_loss=126.44534\n",
      "Epoch 29453: train_loss=115.19170, val_loss=126.46564\n",
      "Epoch 29454: train_loss=115.19109, val_loss=126.43983\n",
      "Epoch 29455: train_loss=115.19086, val_loss=126.46904\n",
      "Epoch 29456: train_loss=115.19091, val_loss=126.43530\n",
      "Epoch 29457: train_loss=115.19147, val_loss=126.47709\n",
      "Epoch 29458: train_loss=115.19267, val_loss=126.43427\n",
      "Epoch 29459: train_loss=115.19462, val_loss=126.49039\n",
      "Epoch 29460: train_loss=115.19767, val_loss=126.43649\n",
      "Epoch 29461: train_loss=115.20185, val_loss=126.51000\n",
      "Epoch 29462: train_loss=115.20833, val_loss=126.44234\n",
      "Epoch 29463: train_loss=115.21711, val_loss=126.54117\n",
      "Epoch 29464: train_loss=115.22995, val_loss=126.45918\n",
      "Epoch 29465: train_loss=115.24642, val_loss=126.59383\n",
      "Epoch 29466: train_loss=115.26756, val_loss=126.49333\n",
      "Epoch 29467: train_loss=115.29303, val_loss=126.66543\n",
      "Epoch 29468: train_loss=115.32224, val_loss=126.54144\n",
      "Epoch 29469: train_loss=115.35440, val_loss=126.74339\n",
      "Epoch 29470: train_loss=115.38544, val_loss=126.58738\n",
      "Epoch 29471: train_loss=115.41215, val_loss=126.79417\n",
      "Epoch 29472: train_loss=115.42793, val_loss=126.60213\n",
      "Epoch 29473: train_loss=115.43053, val_loss=126.77935\n",
      "Epoch 29474: train_loss=115.41444, val_loss=126.56161\n",
      "Epoch 29475: train_loss=115.38257, val_loss=126.68584\n",
      "Epoch 29476: train_loss=115.33633, val_loss=126.48163\n",
      "Epoch 29477: train_loss=115.28419, val_loss=126.55525\n",
      "Epoch 29478: train_loss=115.23291, val_loss=126.41244\n",
      "Epoch 29479: train_loss=115.18908, val_loss=126.44926\n",
      "Epoch 29480: train_loss=115.15819, val_loss=126.39157\n",
      "Epoch 29481: train_loss=115.13976, val_loss=126.39733\n",
      "Epoch 29482: train_loss=115.13322, val_loss=126.41339\n",
      "Epoch 29483: train_loss=115.13584, val_loss=126.38683\n",
      "Epoch 29484: train_loss=115.14462, val_loss=126.45419\n",
      "Epoch 29485: train_loss=115.15709, val_loss=126.39563\n",
      "Epoch 29486: train_loss=115.16962, val_loss=126.49022\n",
      "Epoch 29487: train_loss=115.18076, val_loss=126.40641\n",
      "Epoch 29488: train_loss=115.18787, val_loss=126.50789\n",
      "Epoch 29489: train_loss=115.19088, val_loss=126.40705\n",
      "Epoch 29490: train_loss=115.18858, val_loss=126.49820\n",
      "Epoch 29491: train_loss=115.18239, val_loss=126.39554\n",
      "Epoch 29492: train_loss=115.17235, val_loss=126.46969\n",
      "Epoch 29493: train_loss=115.16090, val_loss=126.37947\n",
      "Epoch 29494: train_loss=115.14806, val_loss=126.43407\n",
      "Epoch 29495: train_loss=115.13611, val_loss=126.36633\n",
      "Epoch 29496: train_loss=115.12494, val_loss=126.40241\n",
      "Epoch 29497: train_loss=115.11559, val_loss=126.36292\n",
      "Epoch 29498: train_loss=115.10810, val_loss=126.38037\n",
      "Epoch 29499: train_loss=115.10272, val_loss=126.36578\n",
      "Epoch 29500: train_loss=115.09900, val_loss=126.36563\n",
      "Epoch 29501: train_loss=115.09689, val_loss=126.37150\n",
      "Epoch 29502: train_loss=115.09579, val_loss=126.35598\n",
      "Epoch 29503: train_loss=115.09560, val_loss=126.37836\n",
      "Epoch 29504: train_loss=115.09601, val_loss=126.35049\n",
      "Epoch 29505: train_loss=115.09686, val_loss=126.38743\n",
      "Epoch 29506: train_loss=115.09795, val_loss=126.34794\n",
      "Epoch 29507: train_loss=115.09904, val_loss=126.39498\n",
      "Epoch 29508: train_loss=115.10014, val_loss=126.34620\n",
      "Epoch 29509: train_loss=115.10126, val_loss=126.40182\n",
      "Epoch 29510: train_loss=115.10260, val_loss=126.34494\n",
      "Epoch 29511: train_loss=115.10383, val_loss=126.40929\n",
      "Epoch 29512: train_loss=115.10568, val_loss=126.34506\n",
      "Epoch 29513: train_loss=115.10755, val_loss=126.41835\n",
      "Epoch 29514: train_loss=115.11022, val_loss=126.34721\n",
      "Epoch 29515: train_loss=115.11304, val_loss=126.43166\n",
      "Epoch 29516: train_loss=115.11697, val_loss=126.35122\n",
      "Epoch 29517: train_loss=115.12139, val_loss=126.44597\n",
      "Epoch 29518: train_loss=115.12663, val_loss=126.35512\n",
      "Epoch 29519: train_loss=115.13146, val_loss=126.46049\n",
      "Epoch 29520: train_loss=115.13712, val_loss=126.35998\n",
      "Epoch 29521: train_loss=115.14188, val_loss=126.47434\n",
      "Epoch 29522: train_loss=115.14712, val_loss=126.36534\n",
      "Epoch 29523: train_loss=115.15071, val_loss=126.48560\n",
      "Epoch 29524: train_loss=115.15372, val_loss=126.36835\n",
      "Epoch 29525: train_loss=115.15465, val_loss=126.48807\n",
      "Epoch 29526: train_loss=115.15437, val_loss=126.36497\n",
      "Epoch 29527: train_loss=115.15157, val_loss=126.47888\n",
      "Epoch 29528: train_loss=115.14687, val_loss=126.35419\n",
      "Epoch 29529: train_loss=115.13983, val_loss=126.45765\n",
      "Epoch 29530: train_loss=115.13091, val_loss=126.33843\n",
      "Epoch 29531: train_loss=115.11986, val_loss=126.42851\n",
      "Epoch 29532: train_loss=115.10808, val_loss=126.32145\n",
      "Epoch 29533: train_loss=115.09544, val_loss=126.39553\n",
      "Epoch 29534: train_loss=115.08325, val_loss=126.30579\n",
      "Epoch 29535: train_loss=115.07134, val_loss=126.36382\n",
      "Epoch 29536: train_loss=115.06052, val_loss=126.29412\n",
      "Epoch 29537: train_loss=115.05055, val_loss=126.33561\n",
      "Epoch 29538: train_loss=115.04179, val_loss=126.28877\n",
      "Epoch 29539: train_loss=115.03451, val_loss=126.31518\n",
      "Epoch 29540: train_loss=115.02852, val_loss=126.28774\n",
      "Epoch 29541: train_loss=115.02392, val_loss=126.29968\n",
      "Epoch 29542: train_loss=115.02032, val_loss=126.28865\n",
      "Epoch 29543: train_loss=115.01758, val_loss=126.28873\n",
      "Epoch 29544: train_loss=115.01552, val_loss=126.29037\n",
      "Epoch 29545: train_loss=115.01387, val_loss=126.28091\n",
      "Epoch 29546: train_loss=115.01255, val_loss=126.29333\n",
      "Epoch 29547: train_loss=115.01162, val_loss=126.27479\n",
      "Epoch 29548: train_loss=115.01085, val_loss=126.29813\n",
      "Epoch 29549: train_loss=115.01064, val_loss=126.27157\n",
      "Epoch 29550: train_loss=115.01067, val_loss=126.30537\n",
      "Epoch 29551: train_loss=115.01123, val_loss=126.26896\n",
      "Epoch 29552: train_loss=115.01248, val_loss=126.31487\n",
      "Epoch 29553: train_loss=115.01442, val_loss=126.26774\n",
      "Epoch 29554: train_loss=115.01733, val_loss=126.32976\n",
      "Epoch 29555: train_loss=115.02177, val_loss=126.27088\n",
      "Epoch 29556: train_loss=115.02779, val_loss=126.35360\n",
      "Epoch 29557: train_loss=115.03630, val_loss=126.28086\n",
      "Epoch 29558: train_loss=115.04741, val_loss=126.39143\n",
      "Epoch 29559: train_loss=115.06238, val_loss=126.30141\n",
      "Epoch 29560: train_loss=115.08070, val_loss=126.44572\n",
      "Epoch 29561: train_loss=115.10320, val_loss=126.33692\n",
      "Epoch 29562: train_loss=115.12943, val_loss=126.51583\n",
      "Epoch 29563: train_loss=115.15821, val_loss=126.38374\n",
      "Epoch 29564: train_loss=115.18892, val_loss=126.58699\n",
      "Epoch 29565: train_loss=115.21592, val_loss=126.42313\n",
      "Epoch 29566: train_loss=115.23746, val_loss=126.62357\n",
      "Epoch 29567: train_loss=115.24614, val_loss=126.42508\n",
      "Epoch 29568: train_loss=115.24078, val_loss=126.59018\n",
      "Epoch 29569: train_loss=115.21738, val_loss=126.37461\n",
      "Epoch 29570: train_loss=115.17988, val_loss=126.48744\n",
      "Epoch 29571: train_loss=115.13149, val_loss=126.29653\n",
      "Epoch 29572: train_loss=115.08070, val_loss=126.36245\n",
      "Epoch 29573: train_loss=115.03352, val_loss=126.23775\n",
      "Epoch 29574: train_loss=114.99541, val_loss=126.26754\n",
      "Epoch 29575: train_loss=114.97002, val_loss=126.22591\n",
      "Epoch 29576: train_loss=114.95691, val_loss=126.22427\n",
      "Epoch 29577: train_loss=114.95468, val_loss=126.25278\n",
      "Epoch 29578: train_loss=114.96036, val_loss=126.21883\n",
      "Epoch 29579: train_loss=114.97070, val_loss=126.29237\n",
      "Epoch 29580: train_loss=114.98288, val_loss=126.22867\n",
      "Epoch 29581: train_loss=114.99397, val_loss=126.32549\n",
      "Epoch 29582: train_loss=115.00311, val_loss=126.23859\n",
      "Epoch 29583: train_loss=115.00787, val_loss=126.33669\n",
      "Epoch 29584: train_loss=115.00872, val_loss=126.23682\n",
      "Epoch 29585: train_loss=115.00497, val_loss=126.32337\n",
      "Epoch 29586: train_loss=114.99789, val_loss=126.22412\n",
      "Epoch 29587: train_loss=114.98763, val_loss=126.29372\n",
      "Epoch 29588: train_loss=114.97626, val_loss=126.20911\n",
      "Epoch 29589: train_loss=114.96411, val_loss=126.25951\n",
      "Epoch 29590: train_loss=114.95278, val_loss=126.19753\n",
      "Epoch 29591: train_loss=114.94249, val_loss=126.22852\n",
      "Epoch 29592: train_loss=114.93403, val_loss=126.19355\n",
      "Epoch 29593: train_loss=114.92750, val_loss=126.20690\n",
      "Epoch 29594: train_loss=114.92299, val_loss=126.19727\n",
      "Epoch 29595: train_loss=114.92008, val_loss=126.19469\n",
      "Epoch 29596: train_loss=114.91837, val_loss=126.20412\n",
      "Epoch 29597: train_loss=114.91761, val_loss=126.18810\n",
      "Epoch 29598: train_loss=114.91741, val_loss=126.21214\n",
      "Epoch 29599: train_loss=114.91770, val_loss=126.18327\n",
      "Epoch 29600: train_loss=114.91827, val_loss=126.21866\n",
      "Epoch 29601: train_loss=114.91920, val_loss=126.17784\n",
      "Epoch 29602: train_loss=114.92039, val_loss=126.22396\n",
      "Epoch 29603: train_loss=114.92175, val_loss=126.17443\n",
      "Epoch 29604: train_loss=114.92329, val_loss=126.23248\n",
      "Epoch 29605: train_loss=114.92521, val_loss=126.17569\n",
      "Epoch 29606: train_loss=114.92699, val_loss=126.24311\n",
      "Epoch 29607: train_loss=114.92953, val_loss=126.17695\n",
      "Epoch 29608: train_loss=114.93201, val_loss=126.25347\n",
      "Epoch 29609: train_loss=114.93520, val_loss=126.17802\n",
      "Epoch 29610: train_loss=114.93843, val_loss=126.26441\n",
      "Epoch 29611: train_loss=114.94263, val_loss=126.18059\n",
      "Epoch 29612: train_loss=114.94720, val_loss=126.27872\n",
      "Epoch 29613: train_loss=114.95254, val_loss=126.18705\n",
      "Epoch 29614: train_loss=114.95826, val_loss=126.29853\n",
      "Epoch 29615: train_loss=114.96461, val_loss=126.19653\n",
      "Epoch 29616: train_loss=114.97095, val_loss=126.31708\n",
      "Epoch 29617: train_loss=114.97713, val_loss=126.20322\n",
      "Epoch 29618: train_loss=114.98213, val_loss=126.32910\n",
      "Epoch 29619: train_loss=114.98622, val_loss=126.20521\n",
      "Epoch 29620: train_loss=114.98814, val_loss=126.33105\n",
      "Epoch 29621: train_loss=114.98820, val_loss=126.20051\n",
      "Epoch 29622: train_loss=114.98513, val_loss=126.31934\n",
      "Epoch 29623: train_loss=114.97931, val_loss=126.18887\n",
      "Epoch 29624: train_loss=114.97043, val_loss=126.29581\n",
      "Epoch 29625: train_loss=114.95940, val_loss=126.17175\n",
      "Epoch 29626: train_loss=114.94630, val_loss=126.26158\n",
      "Epoch 29627: train_loss=114.93243, val_loss=126.15161\n",
      "Epoch 29628: train_loss=114.91792, val_loss=126.22375\n",
      "Epoch 29629: train_loss=114.90443, val_loss=126.13412\n",
      "Epoch 29630: train_loss=114.89104, val_loss=126.18790\n",
      "Epoch 29631: train_loss=114.87951, val_loss=126.12196\n",
      "Epoch 29632: train_loss=114.86918, val_loss=126.15777\n",
      "Epoch 29633: train_loss=114.86066, val_loss=126.11602\n",
      "Epoch 29634: train_loss=114.85390, val_loss=126.13625\n",
      "Epoch 29635: train_loss=114.84879, val_loss=126.11686\n",
      "Epoch 29636: train_loss=114.84489, val_loss=126.12401\n",
      "Epoch 29637: train_loss=114.84217, val_loss=126.12047\n",
      "Epoch 29638: train_loss=114.84013, val_loss=126.11469\n",
      "Epoch 29639: train_loss=114.83870, val_loss=126.12424\n",
      "Epoch 29640: train_loss=114.83758, val_loss=126.10804\n",
      "Epoch 29641: train_loss=114.83686, val_loss=126.12881\n",
      "Epoch 29642: train_loss=114.83671, val_loss=126.10275\n",
      "Epoch 29643: train_loss=114.83685, val_loss=126.13565\n",
      "Epoch 29644: train_loss=114.83772, val_loss=126.09962\n",
      "Epoch 29645: train_loss=114.83905, val_loss=126.14581\n",
      "Epoch 29646: train_loss=114.84107, val_loss=126.09974\n",
      "Epoch 29647: train_loss=114.84399, val_loss=126.16166\n",
      "Epoch 29648: train_loss=114.84829, val_loss=126.10245\n",
      "Epoch 29649: train_loss=114.85366, val_loss=126.18276\n",
      "Epoch 29650: train_loss=114.86111, val_loss=126.11004\n",
      "Epoch 29651: train_loss=114.87042, val_loss=126.21402\n",
      "Epoch 29652: train_loss=114.88250, val_loss=126.12625\n",
      "Epoch 29653: train_loss=114.89733, val_loss=126.25890\n",
      "Epoch 29654: train_loss=114.91584, val_loss=126.15325\n",
      "Epoch 29655: train_loss=114.93710, val_loss=126.31553\n",
      "Epoch 29656: train_loss=114.96049, val_loss=126.18932\n",
      "Epoch 29657: train_loss=114.98474, val_loss=126.37415\n",
      "Epoch 29658: train_loss=115.00688, val_loss=126.22238\n",
      "Epoch 29659: train_loss=115.02578, val_loss=126.40975\n",
      "Epoch 29660: train_loss=115.03558, val_loss=126.22945\n",
      "Epoch 29661: train_loss=115.03599, val_loss=126.39363\n",
      "Epoch 29662: train_loss=115.02222, val_loss=126.19598\n",
      "Epoch 29663: train_loss=114.99722, val_loss=126.31873\n",
      "Epoch 29664: train_loss=114.96126, val_loss=126.13292\n",
      "Epoch 29665: train_loss=114.92000, val_loss=126.21284\n",
      "Epoch 29666: train_loss=114.87807, val_loss=126.07547\n",
      "Epoch 29667: train_loss=114.84076, val_loss=126.12055\n",
      "Epoch 29668: train_loss=114.81198, val_loss=126.05191\n",
      "Epoch 29669: train_loss=114.79234, val_loss=126.06570\n",
      "Epoch 29670: train_loss=114.78230, val_loss=126.06353\n",
      "Epoch 29671: train_loss=114.78014, val_loss=126.04805\n",
      "Epoch 29672: train_loss=114.78394, val_loss=126.09443\n",
      "Epoch 29673: train_loss=114.79142, val_loss=126.05022\n",
      "Epoch 29674: train_loss=114.80034, val_loss=126.12585\n",
      "Epoch 29675: train_loss=114.80904, val_loss=126.05714\n",
      "Epoch 29676: train_loss=114.81602, val_loss=126.14505\n",
      "Epoch 29677: train_loss=114.82100, val_loss=126.05946\n",
      "Epoch 29678: train_loss=114.82254, val_loss=126.14668\n",
      "Epoch 29679: train_loss=114.82136, val_loss=126.05443\n",
      "Epoch 29680: train_loss=114.81716, val_loss=126.13380\n",
      "Epoch 29681: train_loss=114.81110, val_loss=126.04472\n",
      "Epoch 29682: train_loss=114.80321, val_loss=126.11092\n",
      "Epoch 29683: train_loss=114.79472, val_loss=126.03267\n",
      "Epoch 29684: train_loss=114.78537, val_loss=126.08395\n",
      "Epoch 29685: train_loss=114.77668, val_loss=126.02442\n",
      "Epoch 29686: train_loss=114.76852, val_loss=126.06207\n",
      "Epoch 29687: train_loss=114.76147, val_loss=126.02129\n",
      "Epoch 29688: train_loss=114.75553, val_loss=126.04522\n",
      "Epoch 29689: train_loss=114.75069, val_loss=126.02102\n",
      "Epoch 29690: train_loss=114.74676, val_loss=126.03244\n",
      "Epoch 29691: train_loss=114.74367, val_loss=126.02129\n",
      "Epoch 29692: train_loss=114.74111, val_loss=126.02247\n",
      "Epoch 29693: train_loss=114.73904, val_loss=126.02188\n",
      "Epoch 29694: train_loss=114.73727, val_loss=126.01463\n",
      "Epoch 29695: train_loss=114.73571, val_loss=126.02225\n",
      "Epoch 29696: train_loss=114.73443, val_loss=126.00746\n",
      "Epoch 29697: train_loss=114.73333, val_loss=126.02412\n",
      "Epoch 29698: train_loss=114.73268, val_loss=126.00124\n",
      "Epoch 29699: train_loss=114.73243, val_loss=126.02998\n",
      "Epoch 29700: train_loss=114.73263, val_loss=125.99875\n",
      "Epoch 29701: train_loss=114.73347, val_loss=126.03967\n",
      "Epoch 29702: train_loss=114.73515, val_loss=125.99721\n",
      "Epoch 29703: train_loss=114.73775, val_loss=126.05376\n",
      "Epoch 29704: train_loss=114.74152, val_loss=125.99906\n",
      "Epoch 29705: train_loss=114.74660, val_loss=126.07484\n",
      "Epoch 29706: train_loss=114.75384, val_loss=126.00611\n",
      "Epoch 29707: train_loss=114.76311, val_loss=126.10655\n",
      "Epoch 29708: train_loss=114.77540, val_loss=126.02174\n",
      "Epoch 29709: train_loss=114.79086, val_loss=126.15243\n",
      "Epoch 29710: train_loss=114.80976, val_loss=126.04929\n",
      "Epoch 29711: train_loss=114.83147, val_loss=126.21116\n",
      "Epoch 29712: train_loss=114.85524, val_loss=126.08685\n",
      "Epoch 29713: train_loss=114.88000, val_loss=126.27288\n",
      "Epoch 29714: train_loss=114.90363, val_loss=126.12243\n",
      "Epoch 29715: train_loss=114.92387, val_loss=126.31240\n",
      "Epoch 29716: train_loss=114.93530, val_loss=126.13314\n",
      "Epoch 29717: train_loss=114.93766, val_loss=126.30063\n",
      "Epoch 29718: train_loss=114.92545, val_loss=126.10102\n",
      "Epoch 29719: train_loss=114.90137, val_loss=126.22588\n",
      "Epoch 29720: train_loss=114.86543, val_loss=126.03602\n",
      "Epoch 29721: train_loss=114.82353, val_loss=126.11709\n",
      "Epoch 29722: train_loss=114.78066, val_loss=125.97569\n",
      "Epoch 29723: train_loss=114.74214, val_loss=126.02167\n",
      "Epoch 29724: train_loss=114.71217, val_loss=125.95056\n",
      "Epoch 29725: train_loss=114.69147, val_loss=125.96655\n",
      "Epoch 29726: train_loss=114.68050, val_loss=125.96181\n",
      "Epoch 29727: train_loss=114.67775, val_loss=125.94776\n",
      "Epoch 29728: train_loss=114.68103, val_loss=125.99158\n",
      "Epoch 29729: train_loss=114.68822, val_loss=125.94891\n",
      "Epoch 29730: train_loss=114.69688, val_loss=126.02292\n",
      "Epoch 29731: train_loss=114.70595, val_loss=125.95617\n",
      "Epoch 29732: train_loss=114.71329, val_loss=126.04426\n",
      "Epoch 29733: train_loss=114.71887, val_loss=125.96021\n",
      "Epoch 29734: train_loss=114.72105, val_loss=126.04900\n",
      "Epoch 29735: train_loss=114.72092, val_loss=125.95625\n",
      "Epoch 29736: train_loss=114.71733, val_loss=126.03667\n",
      "Epoch 29737: train_loss=114.71185, val_loss=125.94644\n",
      "Epoch 29738: train_loss=114.70394, val_loss=126.01556\n",
      "Epoch 29739: train_loss=114.69559, val_loss=125.93627\n",
      "Epoch 29740: train_loss=114.68633, val_loss=125.99153\n",
      "Epoch 29741: train_loss=114.67744, val_loss=125.92853\n",
      "Epoch 29742: train_loss=114.66893, val_loss=125.96865\n",
      "Epoch 29743: train_loss=114.66158, val_loss=125.92375\n",
      "Epoch 29744: train_loss=114.65520, val_loss=125.94869\n",
      "Epoch 29745: train_loss=114.64980, val_loss=125.92136\n",
      "Epoch 29746: train_loss=114.64556, val_loss=125.93335\n",
      "Epoch 29747: train_loss=114.64220, val_loss=125.92147\n",
      "Epoch 29748: train_loss=114.63956, val_loss=125.92350\n",
      "Epoch 29749: train_loss=114.63740, val_loss=125.92373\n",
      "Epoch 29750: train_loss=114.63567, val_loss=125.91698\n",
      "Epoch 29751: train_loss=114.63424, val_loss=125.92643\n",
      "Epoch 29752: train_loss=114.63314, val_loss=125.91112\n",
      "Epoch 29753: train_loss=114.63223, val_loss=125.92970\n",
      "Epoch 29754: train_loss=114.63162, val_loss=125.90657\n",
      "Epoch 29755: train_loss=114.63151, val_loss=125.93571\n",
      "Epoch 29756: train_loss=114.63177, val_loss=125.90393\n",
      "Epoch 29757: train_loss=114.63266, val_loss=125.94588\n",
      "Epoch 29758: train_loss=114.63428, val_loss=125.90324\n",
      "Epoch 29759: train_loss=114.63696, val_loss=125.95979\n",
      "Epoch 29760: train_loss=114.64062, val_loss=125.90471\n",
      "Epoch 29761: train_loss=114.64567, val_loss=125.97996\n",
      "Epoch 29762: train_loss=114.65265, val_loss=125.91081\n",
      "Epoch 29763: train_loss=114.66145, val_loss=126.00947\n",
      "Epoch 29764: train_loss=114.67293, val_loss=125.92503\n",
      "Epoch 29765: train_loss=114.68693, val_loss=126.05115\n",
      "Epoch 29766: train_loss=114.70371, val_loss=125.94900\n",
      "Epoch 29767: train_loss=114.72292, val_loss=126.10231\n",
      "Epoch 29768: train_loss=114.74382, val_loss=125.98040\n",
      "Epoch 29769: train_loss=114.76556, val_loss=126.15546\n",
      "Epoch 29770: train_loss=114.78558, val_loss=126.01033\n",
      "Epoch 29771: train_loss=114.80240, val_loss=126.19002\n",
      "Epoch 29772: train_loss=114.81230, val_loss=126.01953\n",
      "Epoch 29773: train_loss=114.81400, val_loss=126.18091\n",
      "Epoch 29774: train_loss=114.80476, val_loss=125.99402\n",
      "Epoch 29775: train_loss=114.78533, val_loss=126.12006\n",
      "Epoch 29776: train_loss=114.75561, val_loss=125.94049\n",
      "Epoch 29777: train_loss=114.71991, val_loss=126.02676\n",
      "Epoch 29778: train_loss=114.68218, val_loss=125.88626\n",
      "Epoch 29779: train_loss=114.64695, val_loss=125.93835\n",
      "Epoch 29780: train_loss=114.61796, val_loss=125.85757\n",
      "Epoch 29781: train_loss=114.59634, val_loss=125.88036\n",
      "Epoch 29782: train_loss=114.58278, val_loss=125.86065\n",
      "Epoch 29783: train_loss=114.57652, val_loss=125.85611\n",
      "Epoch 29784: train_loss=114.57613, val_loss=125.88350\n",
      "Epoch 29785: train_loss=114.57999, val_loss=125.85206\n",
      "Epoch 29786: train_loss=114.58641, val_loss=125.91222\n",
      "Epoch 29787: train_loss=114.59389, val_loss=125.85690\n",
      "Epoch 29788: train_loss=114.60114, val_loss=125.93516\n",
      "Epoch 29789: train_loss=114.60757, val_loss=125.86084\n",
      "Epoch 29790: train_loss=114.61208, val_loss=125.94672\n",
      "Epoch 29791: train_loss=114.61503, val_loss=125.86116\n",
      "Epoch 29792: train_loss=114.61541, val_loss=125.94710\n",
      "Epoch 29793: train_loss=114.61430, val_loss=125.85692\n",
      "Epoch 29794: train_loss=114.61077, val_loss=125.93692\n",
      "Epoch 29795: train_loss=114.60619, val_loss=125.84985\n",
      "Epoch 29796: train_loss=114.59995, val_loss=125.92191\n",
      "Epoch 29797: train_loss=114.59321, val_loss=125.84250\n",
      "Epoch 29798: train_loss=114.58563, val_loss=125.90247\n",
      "Epoch 29799: train_loss=114.57798, val_loss=125.83393\n",
      "Epoch 29800: train_loss=114.57037, val_loss=125.88151\n",
      "Epoch 29801: train_loss=114.56363, val_loss=125.82664\n",
      "Epoch 29802: train_loss=114.55722, val_loss=125.86314\n",
      "Epoch 29803: train_loss=114.55165, val_loss=125.82240\n",
      "Epoch 29804: train_loss=114.54674, val_loss=125.84863\n",
      "Epoch 29805: train_loss=114.54249, val_loss=125.81998\n",
      "Epoch 29806: train_loss=114.53891, val_loss=125.83765\n",
      "Epoch 29807: train_loss=114.53571, val_loss=125.81835\n",
      "Epoch 29808: train_loss=114.53300, val_loss=125.82838\n",
      "Epoch 29809: train_loss=114.53046, val_loss=125.81659\n",
      "Epoch 29810: train_loss=114.52824, val_loss=125.82076\n",
      "Epoch 29811: train_loss=114.52622, val_loss=125.81474\n",
      "Epoch 29812: train_loss=114.52425, val_loss=125.81454\n",
      "Epoch 29813: train_loss=114.52243, val_loss=125.81342\n",
      "Epoch 29814: train_loss=114.52065, val_loss=125.80956\n",
      "Epoch 29815: train_loss=114.51891, val_loss=125.81353\n",
      "Epoch 29816: train_loss=114.51723, val_loss=125.80547\n",
      "Epoch 29817: train_loss=114.51568, val_loss=125.81400\n",
      "Epoch 29818: train_loss=114.51430, val_loss=125.79943\n",
      "Epoch 29819: train_loss=114.51324, val_loss=125.81496\n",
      "Epoch 29820: train_loss=114.51250, val_loss=125.79271\n",
      "Epoch 29821: train_loss=114.51239, val_loss=125.82063\n",
      "Epoch 29822: train_loss=114.51293, val_loss=125.78851\n",
      "Epoch 29823: train_loss=114.51468, val_loss=125.83424\n",
      "Epoch 29824: train_loss=114.51781, val_loss=125.78983\n",
      "Epoch 29825: train_loss=114.52274, val_loss=125.85804\n",
      "Epoch 29826: train_loss=114.53052, val_loss=125.79795\n",
      "Epoch 29827: train_loss=114.54168, val_loss=125.89957\n",
      "Epoch 29828: train_loss=114.55812, val_loss=125.82227\n",
      "Epoch 29829: train_loss=114.58101, val_loss=125.97006\n",
      "Epoch 29830: train_loss=114.61118, val_loss=125.87267\n",
      "Epoch 29831: train_loss=114.65059, val_loss=126.07774\n",
      "Epoch 29832: train_loss=114.69789, val_loss=125.95535\n",
      "Epoch 29833: train_loss=114.75313, val_loss=126.21017\n",
      "Epoch 29834: train_loss=114.80904, val_loss=126.04599\n",
      "Epoch 29835: train_loss=114.86103, val_loss=126.31003\n",
      "Epoch 29836: train_loss=114.89539, val_loss=126.08161\n",
      "Epoch 29837: train_loss=114.90302, val_loss=126.28506\n",
      "Epoch 29838: train_loss=114.87280, val_loss=125.99996\n",
      "Epoch 29839: train_loss=114.80860, val_loss=126.10347\n",
      "Epoch 29840: train_loss=114.71795, val_loss=125.84541\n",
      "Epoch 29841: train_loss=114.62298, val_loss=125.88267\n",
      "Epoch 29842: train_loss=114.54208, val_loss=125.75333\n",
      "Epoch 29843: train_loss=114.48904, val_loss=125.76122\n",
      "Epoch 29844: train_loss=114.46756, val_loss=125.77818\n",
      "Epoch 29845: train_loss=114.47293, val_loss=125.75269\n",
      "Epoch 29846: train_loss=114.49622, val_loss=125.86486\n",
      "Epoch 29847: train_loss=114.52740, val_loss=125.79038\n",
      "Epoch 29848: train_loss=114.55624, val_loss=125.92876\n",
      "Epoch 29849: train_loss=114.57441, val_loss=125.80598\n",
      "Epoch 29850: train_loss=114.57735, val_loss=125.91812\n",
      "Epoch 29851: train_loss=114.56477, val_loss=125.77947\n",
      "Epoch 29852: train_loss=114.54060, val_loss=125.85053\n",
      "Epoch 29853: train_loss=114.51188, val_loss=125.74353\n",
      "Epoch 29854: train_loss=114.48399, val_loss=125.77859\n",
      "Epoch 29855: train_loss=114.46242, val_loss=125.73273\n",
      "Epoch 29856: train_loss=114.44878, val_loss=125.73731\n",
      "Epoch 29857: train_loss=114.44386, val_loss=125.75176\n",
      "Epoch 29858: train_loss=114.44585, val_loss=125.72688\n",
      "Epoch 29859: train_loss=114.45218, val_loss=125.78234\n",
      "Epoch 29860: train_loss=114.46033, val_loss=125.73066\n",
      "Epoch 29861: train_loss=114.46725, val_loss=125.80270\n",
      "Epoch 29862: train_loss=114.47173, val_loss=125.73177\n",
      "Epoch 29863: train_loss=114.47226, val_loss=125.80106\n",
      "Epoch 29864: train_loss=114.46964, val_loss=125.72606\n",
      "Epoch 29865: train_loss=114.46360, val_loss=125.78408\n",
      "Epoch 29866: train_loss=114.45588, val_loss=125.71893\n",
      "Epoch 29867: train_loss=114.44704, val_loss=125.75933\n",
      "Epoch 29868: train_loss=114.43855, val_loss=125.71306\n",
      "Epoch 29869: train_loss=114.43081, val_loss=125.73425\n",
      "Epoch 29870: train_loss=114.42471, val_loss=125.71031\n",
      "Epoch 29871: train_loss=114.42019, val_loss=125.71543\n",
      "Epoch 29872: train_loss=114.41723, val_loss=125.71381\n",
      "Epoch 29873: train_loss=114.41540, val_loss=125.70676\n",
      "Epoch 29874: train_loss=114.41447, val_loss=125.72289\n",
      "Epoch 29875: train_loss=114.41416, val_loss=125.70255\n",
      "Epoch 29876: train_loss=114.41420, val_loss=125.72808\n",
      "Epoch 29877: train_loss=114.41438, val_loss=125.69626\n",
      "Epoch 29878: train_loss=114.41449, val_loss=125.73074\n",
      "Epoch 29879: train_loss=114.41468, val_loss=125.69312\n",
      "Epoch 29880: train_loss=114.41447, val_loss=125.73488\n",
      "Epoch 29881: train_loss=114.41404, val_loss=125.69318\n",
      "Epoch 29882: train_loss=114.41338, val_loss=125.73765\n",
      "Epoch 29883: train_loss=114.41254, val_loss=125.69103\n",
      "Epoch 29884: train_loss=114.41133, val_loss=125.73515\n",
      "Epoch 29885: train_loss=114.40998, val_loss=125.68678\n",
      "Epoch 29886: train_loss=114.40862, val_loss=125.73205\n",
      "Epoch 29887: train_loss=114.40720, val_loss=125.68268\n",
      "Epoch 29888: train_loss=114.40569, val_loss=125.72930\n",
      "Epoch 29889: train_loss=114.40447, val_loss=125.67879\n",
      "Epoch 29890: train_loss=114.40321, val_loss=125.72755\n",
      "Epoch 29891: train_loss=114.40259, val_loss=125.67551\n",
      "Epoch 29892: train_loss=114.40199, val_loss=125.72926\n",
      "Epoch 29893: train_loss=114.40211, val_loss=125.67435\n",
      "Epoch 29894: train_loss=114.40222, val_loss=125.73466\n",
      "Epoch 29895: train_loss=114.40347, val_loss=125.67445\n",
      "Epoch 29896: train_loss=114.40494, val_loss=125.74298\n",
      "Epoch 29897: train_loss=114.40747, val_loss=125.67555\n",
      "Epoch 29898: train_loss=114.41028, val_loss=125.75474\n",
      "Epoch 29899: train_loss=114.41449, val_loss=125.67896\n",
      "Epoch 29900: train_loss=114.41915, val_loss=125.77135\n",
      "Epoch 29901: train_loss=114.42538, val_loss=125.68616\n",
      "Epoch 29902: train_loss=114.43218, val_loss=125.79280\n",
      "Epoch 29903: train_loss=114.44006, val_loss=125.69600\n",
      "Epoch 29904: train_loss=114.44839, val_loss=125.81574\n",
      "Epoch 29905: train_loss=114.45702, val_loss=125.70673\n",
      "Epoch 29906: train_loss=114.46537, val_loss=125.83672\n",
      "Epoch 29907: train_loss=114.47275, val_loss=125.71510\n",
      "Epoch 29908: train_loss=114.47789, val_loss=125.84675\n",
      "Epoch 29909: train_loss=114.48023, val_loss=125.71439\n",
      "Epoch 29910: train_loss=114.47881, val_loss=125.83864\n",
      "Epoch 29911: train_loss=114.47344, val_loss=125.70190\n",
      "Epoch 29912: train_loss=114.46399, val_loss=125.81059\n",
      "Epoch 29913: train_loss=114.45101, val_loss=125.68001\n",
      "Epoch 29914: train_loss=114.43497, val_loss=125.76849\n",
      "Epoch 29915: train_loss=114.41765, val_loss=125.65553\n",
      "Epoch 29916: train_loss=114.39993, val_loss=125.72291\n",
      "Epoch 29917: train_loss=114.38305, val_loss=125.63622\n",
      "Epoch 29918: train_loss=114.36765, val_loss=125.68105\n",
      "Epoch 29919: train_loss=114.35467, val_loss=125.62272\n",
      "Epoch 29920: train_loss=114.34412, val_loss=125.64849\n",
      "Epoch 29921: train_loss=114.33611, val_loss=125.62215\n",
      "Epoch 29922: train_loss=114.33054, val_loss=125.63153\n",
      "Epoch 29923: train_loss=114.32698, val_loss=125.62889\n",
      "Epoch 29924: train_loss=114.32505, val_loss=125.62014\n",
      "Epoch 29925: train_loss=114.32419, val_loss=125.63514\n",
      "Epoch 29926: train_loss=114.32426, val_loss=125.61340\n",
      "Epoch 29927: train_loss=114.32478, val_loss=125.64557\n",
      "Epoch 29928: train_loss=114.32595, val_loss=125.61240\n",
      "Epoch 29929: train_loss=114.32753, val_loss=125.65743\n",
      "Epoch 29930: train_loss=114.32948, val_loss=125.61171\n",
      "Epoch 29931: train_loss=114.33171, val_loss=125.66703\n",
      "Epoch 29932: train_loss=114.33430, val_loss=125.61135\n",
      "Epoch 29933: train_loss=114.33766, val_loss=125.68080\n",
      "Epoch 29934: train_loss=114.34200, val_loss=125.61523\n",
      "Epoch 29935: train_loss=114.34738, val_loss=125.70074\n",
      "Epoch 29936: train_loss=114.35426, val_loss=125.62312\n",
      "Epoch 29937: train_loss=114.36206, val_loss=125.72590\n",
      "Epoch 29938: train_loss=114.37155, val_loss=125.63570\n",
      "Epoch 29939: train_loss=114.38224, val_loss=125.75794\n",
      "Epoch 29940: train_loss=114.39465, val_loss=125.65405\n",
      "Epoch 29941: train_loss=114.40780, val_loss=125.79335\n",
      "Epoch 29942: train_loss=114.42101, val_loss=125.67316\n",
      "Epoch 29943: train_loss=114.43364, val_loss=125.82322\n",
      "Epoch 29944: train_loss=114.44410, val_loss=125.68641\n",
      "Epoch 29945: train_loss=114.45153, val_loss=125.83510\n",
      "Epoch 29946: train_loss=114.45395, val_loss=125.68331\n",
      "Epoch 29947: train_loss=114.45070, val_loss=125.81889\n",
      "Epoch 29948: train_loss=114.44077, val_loss=125.66212\n",
      "Epoch 29949: train_loss=114.42509, val_loss=125.77394\n",
      "Epoch 29950: train_loss=114.40436, val_loss=125.62830\n",
      "Epoch 29951: train_loss=114.38035, val_loss=125.71323\n",
      "Epoch 29952: train_loss=114.35525, val_loss=125.59453\n",
      "Epoch 29953: train_loss=114.33116, val_loss=125.65141\n",
      "Epoch 29954: train_loss=114.30994, val_loss=125.57063\n",
      "Epoch 29955: train_loss=114.29243, val_loss=125.60302\n",
      "Epoch 29956: train_loss=114.27925, val_loss=125.56387\n",
      "Epoch 29957: train_loss=114.27036, val_loss=125.57431\n",
      "Epoch 29958: train_loss=114.26524, val_loss=125.57114\n",
      "Epoch 29959: train_loss=114.26319, val_loss=125.56100\n",
      "Epoch 29960: train_loss=114.26338, val_loss=125.58542\n",
      "Epoch 29961: train_loss=114.26512, val_loss=125.55679\n",
      "Epoch 29962: train_loss=114.26792, val_loss=125.60153\n",
      "Epoch 29963: train_loss=114.27142, val_loss=125.55630\n",
      "Epoch 29964: train_loss=114.27524, val_loss=125.61478\n",
      "Epoch 29965: train_loss=114.27889, val_loss=125.55553\n",
      "Epoch 29966: train_loss=114.28249, val_loss=125.62613\n",
      "Epoch 29967: train_loss=114.28594, val_loss=125.55798\n",
      "Epoch 29968: train_loss=114.28894, val_loss=125.63753\n",
      "Epoch 29969: train_loss=114.29153, val_loss=125.56078\n",
      "Epoch 29970: train_loss=114.29387, val_loss=125.64626\n",
      "Epoch 29971: train_loss=114.29594, val_loss=125.56315\n",
      "Epoch 29972: train_loss=114.29762, val_loss=125.65247\n",
      "Epoch 29973: train_loss=114.29899, val_loss=125.56305\n",
      "Epoch 29974: train_loss=114.29977, val_loss=125.65504\n",
      "Epoch 29975: train_loss=114.30006, val_loss=125.56095\n",
      "Epoch 29976: train_loss=114.29946, val_loss=125.65279\n",
      "Epoch 29977: train_loss=114.29850, val_loss=125.55672\n",
      "Epoch 29978: train_loss=114.29702, val_loss=125.64835\n",
      "Epoch 29979: train_loss=114.29506, val_loss=125.55197\n",
      "Epoch 29980: train_loss=114.29259, val_loss=125.64243\n",
      "Epoch 29981: train_loss=114.28970, val_loss=125.54704\n",
      "Epoch 29982: train_loss=114.28603, val_loss=125.63396\n",
      "Epoch 29983: train_loss=114.28191, val_loss=125.54104\n",
      "Epoch 29984: train_loss=114.27706, val_loss=125.62108\n",
      "Epoch 29985: train_loss=114.27184, val_loss=125.53081\n",
      "Epoch 29986: train_loss=114.26584, val_loss=125.60343\n",
      "Epoch 29987: train_loss=114.25961, val_loss=125.52051\n",
      "Epoch 29988: train_loss=114.25279, val_loss=125.58516\n",
      "Epoch 29989: train_loss=114.24621, val_loss=125.51251\n",
      "Epoch 29990: train_loss=114.23973, val_loss=125.56949\n",
      "Epoch 29991: train_loss=114.23375, val_loss=125.50687\n",
      "Epoch 29992: train_loss=114.22780, val_loss=125.55390\n",
      "Epoch 29993: train_loss=114.22218, val_loss=125.50050\n",
      "Epoch 29994: train_loss=114.21716, val_loss=125.53949\n",
      "Epoch 29995: train_loss=114.21257, val_loss=125.49586\n",
      "Epoch 29996: train_loss=114.20850, val_loss=125.52917\n",
      "Epoch 29997: train_loss=114.20503, val_loss=125.49339\n",
      "Epoch 29998: train_loss=114.20198, val_loss=125.52173\n",
      "Epoch 29999: train_loss=114.19935, val_loss=125.48916\n"
     ]
    }
   ],
   "source": [
    "# --- Training ---\n",
    "for epoch in range(n_epochs):\n",
    "    train_losses[epoch] = train_loop(train_inputs, train_outputs_T, model, loss_fn, optimizer)\n",
    "    val_losses[epoch] = eval_loop(valid_inputs, valid_outputs_T, model, loss_fn)\n",
    "\n",
    "    print(f\"Epoch {epoch:03d}: train_loss={train_losses[epoch]:.5f}, val_loss={val_losses[epoch]:.5f}\")\n",
    "\n",
    "#Save model \n",
    "torch.save(model.state_dict(), model_save_path + f'NN_{n_epochs}epochs.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d635598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final test loss: 126.51097\n"
     ]
    }
   ],
   "source": [
    "# --- Testing ---\n",
    "test_loss = eval_loop(test_inputs, test_outputs_T, model, loss_fn)\n",
    "print(f\"\\nFinal test loss: {test_loss:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9276f73",
   "metadata": {},
   "source": [
    "## Sixth step : Diagnostic plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "955237ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loss curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(np.arange(n_epochs), train_losses, label=\"Train\")\n",
    "plt.plot(np.arange(n_epochs), val_losses, label=\"Validation\")\n",
    "plt.yscale('log')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MSE Loss\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "febd876d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Comparing predicted T-P profiles vs true T-P profiles with residuals\n",
    "substep = 1000\n",
    "\n",
    "#Converting tensors to numpy arrays if this isn't already done\n",
    "if (type(test_outputs_T) != np.ndarray):\n",
    "    test_outputs_T = test_outputs_T.numpy()\n",
    "    test_outputs_P = test_outputs_P.numpy()\n",
    "\n",
    "for test_idx, (test_input, test_output_T, test_output_P) in enumerate(zip(test_inputs, test_outputs_T, test_outputs_P)):\n",
    "\n",
    "    #Retrieve prediction\n",
    "    pred_output_T = model(test_input).detach().numpy()\n",
    "\n",
    "    #Convert to numpy\n",
    "    test_input = test_input.numpy()\n",
    "\n",
    "    #Plotting\n",
    "    if (test_idx % substep == 0):\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=[8, 6], sharey=True, gridspec_kw = {'width_ratios':[3, 1]})\n",
    "        ax1.plot(test_output_T, np.log(test_output_P/1000), '.', linestyle='-', color='blue', linewidth=2)\n",
    "        ax1.plot(pred_output_T, np.log(test_output_P/1000), color='green', linewidth=2)\n",
    "        ax1.invert_yaxis()\n",
    "        ax1.set_ylabel(r'log$_{10}$ Pressure (bar)')\n",
    "        ax1.set_xlabel('Temperature (K)')\n",
    "        ax2.plot(pred_output_T - test_output_T, np.log(test_output_P/1000), '.', linestyle='-', color='green', linewidth=2)\n",
    "        ax2.set_xlabel('Residuals (K)')\n",
    "        plt.suptitle(rf'H$_2$O : {test_input[0]} bar, CO$_2$ : {test_input[1]} bar, LoD : {test_input[2]:.0f} days, Obliquity : {test_input[3]} deg')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4b3c02e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 51)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median: 0.022 K, Standard deviation: 11.248 K\n"
     ]
    }
   ],
   "source": [
    "#Plotting all residuals \n",
    "\n",
    "#Storage\n",
    "residuals = np.zeros(test_outputs_T.shape,  dtype=object)\n",
    "print(residuals.shape)\n",
    "\n",
    "#Converting tensors to numpy arrays if this isn't already done\n",
    "if (type(test_outputs_T) != np.ndarray):\n",
    "    test_outputs_T = test_outputs_T.numpy()\n",
    "\n",
    "for test_idx, (test_input, test_output_T) in enumerate(zip(test_inputs, test_outputs_T)):\n",
    "\n",
    "    #Retrieve prediction\n",
    "    residuals[test_idx] = model(test_input).detach().numpy() - test_output_T\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=[8, 6])\n",
    "ax.plot(residuals, color='green', alpha=0.2)\n",
    "ax.axhline(0, color='black', linestyle='dashed')\n",
    "plt.xlabel('Output dimension')\n",
    "plt.ylabel('Temperature (K)')\n",
    "plt.show()\n",
    "print(f'Median: {np.median(residuals):.3f} K, Standard deviation: {np.std(residuals):.3f} K')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b247e1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
