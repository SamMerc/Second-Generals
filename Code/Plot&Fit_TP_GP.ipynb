{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee5a7ebf",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c0b871",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import celerite2\n",
    "from celerite2 import terms\n",
    "import torch\n",
    "import os\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0073caf",
   "metadata": {},
   "source": [
    "# Import raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe717a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining function to check if directory exists, if not it generates it\n",
    "def check_and_make_dir(dir):\n",
    "    if not os.path.isdir(dir):os.mkdir(dir)\n",
    "#Base directory \n",
    "base_dir = '/Users/samsonmercier/Desktop/Work/PhD/Research/Second_Generals/'\n",
    "#File containing temperature values\n",
    "raw_T_data = np.loadtxt(base_dir+'Data/bt-4500k/training_data_T.csv', delimiter=',')\n",
    "#File containing pressure values\n",
    "raw_P_data = np.loadtxt(base_dir+'Data/bt-4500k/training_data_P.csv', delimiter=',')\n",
    "#Path to store model\n",
    "model_save_path = base_dir+'Model_Storage/GP/'\n",
    "check_and_make_dir(model_save_path)\n",
    "#Path to store plots\n",
    "plot_save_path = base_dir+'Plots/GP/'\n",
    "check_and_make_dir(plot_save_path)\n",
    "\n",
    "#Last 51 columns are the temperature/pressure values, \n",
    "#First 5 are the input values (H2 pressure in bar, CO2 pressure in bar, LoD in hours, Obliquity in deg, H2+Co2 pressure) but we remove the last one since it's not adding info.\n",
    "raw_inputs = raw_T_data[:, :4]\n",
    "raw_outputs_T = raw_T_data[:, 5:]\n",
    "raw_outputs_P = raw_P_data[:, 5:]\n",
    "\n",
    "#Storing useful quantitites\n",
    "N = raw_inputs.shape[0] #Number of data points\n",
    "D = raw_inputs.shape[1] #Number of features\n",
    "O = raw_outputs_T.shape[1] #Number of outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91916a9",
   "metadata": {},
   "source": [
    "# Plotting of the T-P profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74b0ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for raw_input, raw_output_T, raw_output_P in zip(raw_inputs,raw_outputs_T,raw_outputs_P):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=[8, 6])\n",
    "    ax.plot(raw_output_T, np.log(raw_output_P/1000), color='blue', linewidth=2)\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_xlabel('Temperature (K)')\n",
    "    ax.set_ylabel(r'log$_{10}$ Pressure (bar)')\n",
    "    ax.set_title(rf'H$_2$O : {raw_input[0]} bar, CO$_2$ : {raw_input[1]} bar, LoD : {raw_input[2]:.0f} days, Obliquity : {raw_input[3]} deg')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411d210a",
   "metadata": {},
   "source": [
    "# Fitting data with a Gaussian Process (celerite) - trying it out on one T-P profile (Can't be generalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c057da",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 4\n",
    "\n",
    "#Plot the T-P profile we want to look at\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=[8, 6], gridspec_kw={'height_ratios':[3,1]})\n",
    "ax1.plot(np.log(raw_outputs_P[4]/1000), raw_outputs_T[4], '.', color='blue', linewidth=2, label='Data')\n",
    "ax1.invert_yaxis()\n",
    "ax1.set_ylabel('Temperature (K)')\n",
    "ax2.set_ylabel('Residuals')\n",
    "ax2.set_xlabel(r'log$_{10}$ Pressure (bar)')\n",
    "ax1.set_title(rf'H$_2$O : {raw_inputs[key][0]} bar, CO$_2$ : {raw_inputs[key][1]} bar, LoD : {raw_inputs[key][2]:.0f} days, Obliquity : {raw_inputs[key][3]} deg')\n",
    "\n",
    "#GP\n",
    "#Defining a quasi-periodic term\n",
    "term1 = terms.SHOTerm(sigma=1.0, rho=1.0, tau=10.0)\n",
    "\n",
    "#Defining a non-periodic term\n",
    "term2 = terms.SHOTerm(sigma=1.0, rho=5.0, Q=0.25)\n",
    "kernel = term1 + term2\n",
    "\n",
    "# Setup the GP\n",
    "gp = celerite2.GaussianProcess(kernel, mean=0.0)\n",
    "gp.compute(np.log(raw_outputs_P[4]/1000))\n",
    "\n",
    "#Plot resulting GP fit\n",
    "pred_T, variance = gp.predict(raw_outputs_T[4], t=np.log(raw_outputs_P[4]/1000), return_var=True)\n",
    "sigma = np.sqrt(variance)\n",
    "ax1.plot(np.log(raw_outputs_P[4]/1000), pred_T, label='initial guess')\n",
    "ax1.fill_between(np.log(raw_outputs_P[4]/1000), pred_T - sigma, pred_T + sigma, color=\"C0\", alpha=0.2)\n",
    "ax2.plot(np.log(raw_outputs_P[4]/1000), raw_outputs_T[4]-pred_T)\n",
    "ax2.axhline(0, color='black', linestyle='--')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d894c0",
   "metadata": {},
   "source": [
    "# Fitting data with an Ensemble Conditional GP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad32a1a",
   "metadata": {},
   "source": [
    "## First step : partition data into a training set, and a testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b6afd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining partition of data used for 1. training and 2. testing\n",
    "data_partition = [0.8, 0.2]\n",
    "\n",
    "#Defining the noise seed for the random partitioning of the training data\n",
    "partition_seed = 4\n",
    "\n",
    "#Splitting the data \n",
    "## Setting noise seed\n",
    "generator = torch.Generator().manual_seed(partition_seed)\n",
    "## Retrieving indices of data partitions\n",
    "train_idx, test_idx = torch.utils.data.random_split(range(N), data_partition, generator=generator)\n",
    "## Generate the data partitions\n",
    "### Training\n",
    "train_inputs = raw_inputs[train_idx]\n",
    "train_outputs_T = raw_outputs_T[train_idx]\n",
    "train_outputs_P = raw_outputs_P[train_idx]\n",
    "\n",
    "### Testing\n",
    "test_inputs = raw_inputs[test_idx]\n",
    "test_outputs_T = raw_outputs_T[test_idx]\n",
    "test_outputs_P = raw_outputs_P[test_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31f11a3",
   "metadata": {},
   "source": [
    "## Second step : Building Sai's Conditional GP function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8ccf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sai_CGP(obs_features, obs_labels, query_features):\n",
    "    \"\"\"\n",
    "    Conditional Gaussian Process\n",
    "    Inputs: \n",
    "        obs_features : ndarray (D, N)\n",
    "            D-dimensional features of the N observation data points.\n",
    "        obs_labels : ndarray (K, N)\n",
    "            K-dimensional labels of the N observation data points.\n",
    "        query_features : ndarray (D, 1)\n",
    "            D-dimensional features of the query data point.\n",
    "    Outputs:\n",
    "        query_labels : ndarray (K, 1)\n",
    "            K-dimensional labels of the query data point.\n",
    "\n",
    "    \"\"\"\n",
    "    # Defining relevant means\n",
    "    mean_obs_labels = np.mean(obs_labels, axis=1, keepdims=True)\n",
    "    mean_obs_features = np.mean(obs_features, axis=1, keepdims=True)\n",
    "    \n",
    "    # Defining relevant covariance matrices\n",
    "    ## Between feature and label of observation data\n",
    "    Cyx = (obs_labels @ obs_features.T) / (obs_features.shape[0] - 1)\n",
    "    ## Between label and feature of observation data\n",
    "    Cxy = (obs_features @ obs_labels.T) / (obs_features.shape[0] - 1)\n",
    "    ## Between feature and feature of observation data\n",
    "    Cxx = (obs_features @ obs_features.T) / (obs_features.shape[0] - 1)\n",
    "    ## Between label and label of observation data\n",
    "    Cyy = (obs_labels @ obs_labels.T) / (obs_features.shape[0] - 1)\n",
    "    ## Adding regularizer to avoid singularities\n",
    "    Cxx += 1e-8 * np.eye(Cxx.shape[0]) \n",
    "\n",
    "    query_mean_labels = mean_obs_labels + (Cyx @ scipy.linalg.inv(Cxx) @ (query_features - mean_obs_features))\n",
    "\n",
    "    query_cov_labels = Cyy - Cyx @ scipy.linalg.inv(Cxx) @ Cxy\n",
    "\n",
    "    return query_mean_labels, query_cov_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e19df2",
   "metadata": {},
   "source": [
    "## Third step : Going through test set (query points), find observations in proximity, and use them to get guess labels for query point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65772b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable to show plots or not \n",
    "show_plot = True\n",
    "\n",
    "#Number of nearest neighbors to choose\n",
    "N_neigbors = 50\n",
    "\n",
    "#Initialize array to store residuals\n",
    "input_output_residuals_T = np.zeros(test_outputs_T.shape, dtype=float)\n",
    "input_output_residuals_P = np.zeros(test_outputs_P.shape, dtype=float)\n",
    "\n",
    "for query_idx, (test_input, test_output_T, test_output_P) in enumerate(zip(test_inputs, test_outputs_T, test_outputs_P)):\n",
    "\n",
    "    #Calculate proximity of query point to observations\n",
    "    distances = np.sqrt( (test_input[0] - train_inputs[:,0])**2 + (test_input[1] - train_inputs[:,1])**2 + (test_input[2] - train_inputs[:,2])**2 + (test_input[3] - train_inputs[:,3])**2 )\n",
    "\n",
    "    #Choose the N closest points\n",
    "    N_closest_idx = np.argsort(distances)[:N_neigbors]\n",
    "    prox_train_inputs = train_inputs[N_closest_idx, :]\n",
    "    prox_train_outputs_T = train_outputs_T[N_closest_idx, :]\n",
    "    prox_train_outputs_P = train_outputs_P[N_closest_idx, :]\n",
    "    \n",
    "    #Find the query labels from nearest neigbours\n",
    "    mean_test_output, cov_test_output = Sai_CGP(prox_train_inputs.T, np.concat((prox_train_outputs_T, np.log10(prox_train_outputs_P/1000)), axis=1).T, test_input.reshape((1, 4)).T)\n",
    "    model_test_output_T = mean_test_output[:O,0] \n",
    "    model_test_output_P = mean_test_output[O:,0] \n",
    "    model_test_output_Terr = np.sqrt(np.diag(cov_test_output))[:O]\n",
    "    model_test_output_Perr = np.sqrt(np.diag(cov_test_output))[O:]\n",
    "    input_output_residuals_T[query_idx, :] = model_test_output_T - test_output_T\n",
    "    input_output_residuals_P[query_idx, :] = model_test_output_P - np.log10(test_output_P/1000)\n",
    "\n",
    "    #Diagnostic plot\n",
    "    if show_plot:\n",
    "\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.imshow(cov_test_output, cmap='coolwarm', origin='lower')\n",
    "        plt.colorbar(label='Covariance')\n",
    "        plt.title('Joint Covariance Matrix of [T | P]')\n",
    "        plt.xlabel('Output index')\n",
    "        plt.ylabel('Output index')\n",
    "        plt.show()\n",
    "\n",
    "        fig, axs = plt.subplot_mosaic([['res_pressure', '.'],\n",
    "                                       ['results', 'res_temperature']],\n",
    "                              figsize=(8, 6),\n",
    "                              width_ratios=(3, 1), height_ratios=(1, 3),\n",
    "                              layout='constrained')\n",
    "        for prox_idx in range(N_neigbors):axs['results'].plot(prox_train_outputs_T[prox_idx], np.log10(prox_train_outputs_P[prox_idx]/1000), '.', linestyle='-', color='red', alpha=0.1, linewidth=2, zorder=1)\n",
    "        axs['results'].plot(model_test_output_T, model_test_output_P, '.', linestyle='-', color='green', linewidth=2, markersize=10, zorder=2)\n",
    "        axs['results'].errorbar(model_test_output_T, model_test_output_P, xerr=model_test_output_Terr, yerr=model_test_output_Perr, fmt='.', linestyle='-', color='green', linewidth=2, zorder=2, alpha=0.5, markersize=10)\n",
    "        axs['results'].plot(test_output_T, np.log10(test_output_P/1000), '.', linestyle='-', color='blue', linewidth=2, zorder=2, markersize=10)\n",
    "        axs['results'].invert_yaxis()\n",
    "        axs['results'].set_ylabel(r'log$_{10}$ Pressure (bar)')\n",
    "        axs['results'].set_xlabel('Temperature (K)')\n",
    "        \n",
    "        axs['res_temperature'].fill_betweenx(np.log10(test_output_P/1000), input_output_residuals_T[query_idx, :] - model_test_output_Terr, input_output_residuals_T[query_idx, :] + model_test_output_Terr, color='green', alpha=0.4)\n",
    "        axs['res_temperature'].plot(input_output_residuals_T[query_idx, :], np.log10(test_output_P/1000), '.', linestyle='-', color='green', linewidth=2)\n",
    "        axs['res_temperature'].axvline(0, color='black', linestyle='dashed', zorder=2)\n",
    "        axs['res_temperature'].invert_yaxis()\n",
    "        axs['res_temperature'].set_xlabel('Residuals (K)')\n",
    "        \n",
    "        axs['res_pressure'].fill_between(test_output_T, input_output_residuals_P[query_idx, :] - model_test_output_Perr, input_output_residuals_P[query_idx, :] + model_test_output_Perr, color='green', alpha=0.4)\n",
    "        axs['res_pressure'].axhline(0, color='black', linestyle='dashed', zorder=2)\n",
    "        axs['res_pressure'].invert_yaxis()\n",
    "        axs['res_pressure'].set_ylabel('Residuals (bar)')\n",
    "        \n",
    "        plt.suptitle(rf'H$_2$ : {test_input[0]} bar, CO$_2$ : {test_input[1]} bar, LoD : {test_input[2]:.0f} days, Obliquity : {test_input[3]} deg')\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad7ea03",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Temperature Residuals : Median = {np.median(input_output_residuals_T):.2f} K, Std = {np.std(input_output_residuals_T):.2f} K')\n",
    "print(rf'Pressure Residuals : Median = {np.median(input_output_residuals_P):.9} $log_{10}$ bar, Std = {np.std(input_output_residuals_P):.9} $log_{10}$ bar')\n",
    "\n",
    "#Plot residuals\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=[10, 6])\n",
    "ax1.plot(input_output_residuals_T.T, alpha=0.1, color='green')\n",
    "ax2.plot(input_output_residuals_P.T, alpha=0.1, color='green')\n",
    "for ax in [ax1, ax2]:ax.axhline(0, color='black', linestyle='dashed')\n",
    "ax2.set_xlabel('Index')\n",
    "ax1.set_ylabel('Temperature')\n",
    "ax2.set_ylabel('log$_{10}$ Pressure (bar)')\n",
    "for ax in [ax1, ax2]:ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987bc504",
   "metadata": {},
   "source": [
    "# Correlations between residuals and input variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0377013",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
