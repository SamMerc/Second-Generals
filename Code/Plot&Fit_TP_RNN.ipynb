{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee5a7ebf",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c0b871",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0073caf",
   "metadata": {},
   "source": [
    "# Import raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe717a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#File containing temperature values\n",
    "raw_T_data = np.loadtxt('/Users/samsonmercier/Desktop/Work/PhD/Research/Second_Generals/Data/bt-4500k/training_data_T.csv', delimiter=',')\n",
    "#File containing pressure values\n",
    "raw_P_data = np.loadtxt('/Users/samsonmercier/Desktop/Work/PhD/Research/Second_Generals/Data/bt-4500k/training_data_P.csv', delimiter=',')\n",
    "#Path to store model\n",
    "model_save_path = '/Users/samsonmercier/Desktop/Work/PhD/Research/Second_Generals/Data/Model_Storage/'\n",
    "\n",
    "#Last 51 columns are the temperature/pressure values, \n",
    "#First 5 are the input values (H2 pressure in bar, CO2 pressure in bar, LoD in hours, Obliquity in deg, H2+Co2 pressure) but we remove the last one since it's not adding info.\n",
    "raw_inputs = raw_T_data[:, :4]\n",
    "raw_outputs_T = raw_T_data[:, 5:]\n",
    "raw_outputs_P = raw_P_data[:, 5:]\n",
    "\n",
    "#Storing useful quantitites\n",
    "N = raw_inputs.shape[0] #Number of data points\n",
    "D = raw_inputs.shape[1] #Number of features\n",
    "O = raw_outputs_T.shape[1] #Number of outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b3f486",
   "metadata": {},
   "source": [
    "# Fitting the training data with a recurrent neural network (built myself)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293984f4",
   "metadata": {},
   "source": [
    "## 0th step : Shrink down data so we can work with it locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8329ae71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of samples to shrink our dataset to \n",
    "sample_size = 10000\n",
    "\n",
    "filter = np.random.choice(np.arange(N), size=sample_size, replace=False)\n",
    "\n",
    "raw_inputs = torch.tensor(raw_inputs[filter, :], dtype=torch.float32)\n",
    "raw_outputs_T = torch.tensor(raw_outputs_T[filter, :], dtype=torch.float32)\n",
    "raw_outputs_P = torch.tensor(raw_outputs_P[filter, :], dtype=torch.float32)\n",
    "\n",
    "N = sample_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79090012",
   "metadata": {},
   "source": [
    "## First step : Define a training, validation, and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78466da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining partition of data used for 1. training 2. validation and 3. testing\n",
    "data_partitions = [0.7, 0.1, 0.2]\n",
    "\n",
    "#Defining the noise seed for the random partitioning of the training data\n",
    "partition_seed = 4\n",
    "\n",
    "#Splitting the data \n",
    "## Setting noise seec\n",
    "generator = torch.Generator().manual_seed(partition_seed)\n",
    "## Retrieving indices of data partitions\n",
    "train_idx, valid_idx, test_idx = torch.utils.data.random_split(range(N), data_partitions, generator=generator)\n",
    "## Generate the data partitions\n",
    "### Training\n",
    "train_inputs = raw_inputs[train_idx]\n",
    "train_outputs_T = raw_outputs_T[train_idx]\n",
    "train_outputs_P = raw_outputs_P[train_idx]\n",
    "### Validation\n",
    "valid_inputs = raw_inputs[valid_idx]\n",
    "valid_outputs_T = raw_outputs_T[valid_idx]\n",
    "valid_outputs_P = raw_outputs_P[valid_idx]\n",
    "### Testing\n",
    "test_inputs = raw_inputs[test_idx]\n",
    "test_outputs_T = raw_outputs_T[test_idx]\n",
    "test_outputs_P = raw_outputs_P[test_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fa2735",
   "metadata": {},
   "source": [
    "## Second step : Define the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3491d4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentNeuralNetworkCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # Input + previous hidden layer\n",
    "        self.input_layer = nn.Linear(input_size + hidden_size, hidden_size, bias=True)\n",
    "        # Hidden layer n.1\n",
    "        self.hidden_layer1 = nn.Linear(hidden_size, hidden_size, bias=True)\n",
    "        # Hidden layer n.2\n",
    "        self.hidden_layer2 = nn.Linear(hidden_size, hidden_size, bias=True)\n",
    "        \n",
    "        # Hidden layer n.3\n",
    "        self.hidden_layer3 = nn.Linear(hidden_size, hidden_size, bias=True)\n",
    "        # Hidden layer n.4\n",
    "        self.hidden_layer4 = nn.Linear(hidden_size, hidden_size, bias=True)\n",
    "        # Hidden layer n.5\n",
    "        self.hidden_layer5 = nn.Linear(hidden_size, hidden_size, bias=True)\n",
    "        # Output layer\n",
    "        self.output_layer = nn.Linear(hidden_size, output_size, bias=True)\n",
    "\n",
    "    def forward(self, x, h_prev):\n",
    "        # Concatenate input and previous hidden state\n",
    "        combined = torch.cat((x, h_prev), dim=1)\n",
    "\n",
    "        # Pass through all hidden layers manually\n",
    "        h = torch.tanh(self.input_layer(combined))\n",
    "        h = torch.tanh(self.hidden_layer1(h))\n",
    "        h = torch.tanh(self.hidden_layer2(h))\n",
    "        h = torch.tanh(self.hidden_layer3(h))\n",
    "        h = torch.tanh(self.hidden_layer4(h))\n",
    "        h = torch.tanh(self.hidden_layer5(h))\n",
    "\n",
    "        # Output\n",
    "        y = self.output_layer(h)\n",
    "        return y, h\n",
    "    \n",
    "class DeepRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.cell = RecurrentNeuralNetworkCell(input_size, hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (batch_size, seq_len, input_size)\n",
    "        Returns:\n",
    "            y_seq: (batch_size, seq_len, output_size)\n",
    "        \"\"\"\n",
    "        batch_size, seq_len, _ = x.shape\n",
    "\n",
    "        # Initialize hidden state\n",
    "        h = torch.zeros(batch_size, self.hidden_size, device=x.device)\n",
    "\n",
    "        # Container for outputs\n",
    "        outputs = []\n",
    "\n",
    "        # Loop over sequence\n",
    "        for t in range(seq_len):\n",
    "            x_t = x[:, t, :]          # shape: (batch_size, input_size)\n",
    "            y_t, h = self.cell(x_t, h)\n",
    "            outputs.append(y_t.unsqueeze(1))  # keep sequence dimension\n",
    "\n",
    "        # Concatenate along sequence dimension\n",
    "        y_seq = torch.cat(outputs, dim=1)  # shape: (batch_size, seq_len, output_size)\n",
    "        return y_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce508dd",
   "metadata": {},
   "source": [
    "## Third step : Define device for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f1e0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "device = \"cpu\"\n",
    "num_threads = 2\n",
    "torch.set_num_threads(num_threads)\n",
    "print(f\"Using {device} device with {num_threads} threads\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa87254",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define sizes\n",
    "in_size=train_inputs.shape[1]\n",
    "out_size=train_outputs_T.shape[1]\n",
    "hidden_size=100\n",
    "model = DeepRNN(input_size=in_size, hidden_size=hidden_size, output_size=out_size).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c607115",
   "metadata": {},
   "source": [
    "## Fourth step : Define optimization functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d568dc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Loss and optimizer ---\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "\n",
    "# --- Training loop ---\n",
    "def train_loop(inputs, targets, model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    pred = model(inputs)\n",
    "    loss = loss_fn(pred, targets)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "def eval_loop(inputs, targets, model, loss_fn):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred = model(inputs)\n",
    "        loss = loss_fn(pred, targets)\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd2d7f7",
   "metadata": {},
   "source": [
    "## Fifth step : Run optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1514d6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define number of epochs \n",
    "n_epochs = 100\n",
    "train_losses = np.zeros(n_epochs, dtype=float)\n",
    "val_losses = np.zeros(n_epochs, dtype=float)\n",
    "\n",
    "#Define batch size\n",
    "batch_size = 1\n",
    "\n",
    "#Define storage for losses\n",
    "val_losses = np.zeros(n_epochs, dtype=float)\n",
    "\n",
    "#Change shapes of training/validation dataset to work with RNN\n",
    "RNN_train_inputs = train_inputs.reshape(batch_size, train_inputs.shape[0], in_size)  # shape: (batch size = 1, sequence length = N, input_size)\n",
    "RNN_valid_inputs = valid_inputs.reshape(batch_size, valid_inputs.shape[0], in_size)\n",
    "RNN_train_outputs_T = train_outputs_T.reshape(batch_size, train_inputs.shape[0], out_size)\n",
    "RNN_valid_outputs_T = valid_outputs_T.reshape(batch_size, valid_inputs.shape[0], out_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1beb5d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Training ---\n",
    "for epoch in range(n_epochs):\n",
    "    train_losses[epoch] = train_loop(RNN_train_inputs, RNN_train_outputs_T, model, loss_fn, optimizer)\n",
    "    val_losses[epoch] = eval_loop(RNN_valid_inputs, valid_outputs_T, model, loss_fn)\n",
    "\n",
    "    print(f\"Epoch {epoch:03d}: train_loss={train_losses[epoch]:.5f}, val_loss={val_losses[epoch]:.5f}\")\n",
    "\n",
    "#Save model \n",
    "torch.save(model.state_dict(), model_save_path + f'RNN_{n_epochs}epochs.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d635598",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change shapes of testing dataset to work with RNN\n",
    "eval_test_inputs = test_inputs.reshape(batch_size, test_inputs.shape[0], in_size) \n",
    "eval_test_outputs_T = test_outputs_T.reshape(batch_size, test_inputs.shape[0], out_size) \n",
    "\n",
    "# --- Testing ---\n",
    "test_loss = eval_loop(eval_test_inputs, eval_test_outputs_T, model, loss_fn)\n",
    "print(f\"\\nFinal test loss: {test_loss:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9276f73",
   "metadata": {},
   "source": [
    "## Sixth step : Diagnostic plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955237ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(np.arange(n_epochs), train_losses, label=\"Train\")\n",
    "plt.plot(np.arange(n_epochs), val_losses, label=\"Validation\")\n",
    "plt.yscale('log')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MSE Loss\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febd876d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparing predicted T-P profiles vs true T-P profiles with residuals\n",
    "substep = 1000\n",
    "\n",
    "#Converting tensors to numpy arrays if this isn't already done\n",
    "if (type(test_outputs_T) != np.ndarray):\n",
    "    test_outputs_T = test_outputs_T.detach().cpu().numpy()\n",
    "    test_outputs_P = test_outputs_P.detach().cpu().numpy()\n",
    "\n",
    "for test_idx, (test_input, test_output_T, test_output_P) in enumerate(zip(test_inputs, test_outputs_T, test_outputs_P)):\n",
    "\n",
    "    #Retrieve prediction\n",
    "    pred_output_T = model(test_input.reshape(1, 1, in_size)).detach().numpy()\n",
    "    pred_output_T = pred_output_T.reshape(out_size)\n",
    "\n",
    "    #Convert to numpy\n",
    "    test_input = test_input.numpy()\n",
    "\n",
    "    #Plotting\n",
    "    if (test_idx % substep == 0):\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=[8, 6], sharey=True, gridspec_kw = {'width_ratios':[3, 1]})\n",
    "        ax1.plot(test_output_T, np.log(test_output_P/1000), '.', linestyle='-', color='blue', linewidth=2)\n",
    "        ax1.plot(pred_output_T, np.log(test_output_P/1000), color='green', linewidth=2)\n",
    "        ax1.invert_yaxis()\n",
    "        ax1.set_ylabel(r'log$_{10}$ Pressure (bar)')\n",
    "        ax1.set_xlabel('Temperature (K)')\n",
    "        ax2.plot(pred_output_T - test_output_T, np.log(test_output_P/1000), '.', linestyle='-', color='green', linewidth=2)\n",
    "        ax2.set_xlabel('Residuals (K)')\n",
    "        plt.suptitle(rf'H$_2$O : {test_input[0]} bar, CO$_2$ : {test_input[1]} bar, LoD : {test_input[2]:.0f} days, Obliquity : {test_input[3]} deg')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3c02e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting all residuals \n",
    "\n",
    "#Storage\n",
    "residuals = np.zeros(test_outputs_T.shape,  dtype=object)\n",
    "print(residuals.shape)\n",
    "\n",
    "#Converting tensors to numpy arrays if this isn't already done\n",
    "if (type(test_outputs_T) != np.ndarray):\n",
    "    test_outputs_T = test_outputs_T.numpy()\n",
    "\n",
    "for test_idx, (test_input, test_output_T) in enumerate(zip(test_inputs, test_outputs_T)):\n",
    "\n",
    "    #Retrieve prediction\n",
    "    residuals[test_idx] = model(test_input.reshape(1, 1, in_size)).detach().numpy().reshape(out_size) - test_output_T\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=[8, 6])\n",
    "ax.plot(residuals, color='green', alpha=0.2)\n",
    "ax.axhline(0, color='black', linestyle='dashed')\n",
    "plt.xlabel('Output dimension')\n",
    "plt.ylabel('Temperature (K)')\n",
    "plt.show()\n",
    "print(f'Median: {np.median(residuals):.3f} K, Standard deviation: {np.std(residuals):.3f} K')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678c2ad3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
