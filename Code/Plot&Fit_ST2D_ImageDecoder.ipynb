{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee5a7ebf",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c0b871",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0073caf",
   "metadata": {},
   "source": [
    "# Import raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe717a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining function to check if directory exists, if not it generates it\n",
    "def check_and_make_dir(dir):\n",
    "    if not os.path.isdir(dir):os.mkdir(dir)\n",
    "#Base directory \n",
    "base_dir = '/Users/samsonmercier/Desktop/Work/PhD/Research/Second_Generals/'\n",
    "#File containing surface temperature map\n",
    "raw_ST_data = np.loadtxt(base_dir+'Data/bt-4500k/training_data_ST2D.csv', delimiter=',')\n",
    "#Path to store model\n",
    "model_save_path = base_dir+'Model_Storage/CNN/'\n",
    "check_and_make_dir(model_save_path)\n",
    "#Path to store plots\n",
    "plot_save_path = base_dir+'Plots/CNN/'\n",
    "check_and_make_dir(plot_save_path)\n",
    "\n",
    "#Last 51 columns are the temperature/pressure values, \n",
    "#First 5 are the input values (H2 pressure in bar, CO2 pressure in bar, LoD in hours, Obliquity in deg, H2+Co2 pressure) but we remove the last one since it's not adding info.\n",
    "raw_inputs = raw_ST_data[:, :4] #has shape 46 x 72 = 3,312\n",
    "raw_outputs_ST = raw_ST_data[:, 5:]\n",
    "\n",
    "#Storing useful quantitites\n",
    "N = raw_inputs.shape[0] #Number of data points\n",
    "D = raw_inputs.shape[1] #Number of features\n",
    "\n",
    "#Reshaping all surface temperature maps to have shape 1 (num channels) x 46 (num latitudes) x 72 (num longitudes)\n",
    "raw_outputs_ST = raw_outputs_ST.reshape((N, 1, 46, 72))\n",
    "\n",
    "#Mode for optimization\n",
    "run_mode = 'use'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d66e740",
   "metadata": {},
   "source": [
    "# Defining hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feba1f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining partition of data used for 1. training 2. validation and 3. testing\n",
    "data_partitions = [0.7, 0.1, 0.2]\n",
    "\n",
    "#Defining the device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_threads = 6\n",
    "torch.set_num_threads(num_threads)\n",
    "print(f\"Using {device} device with {num_threads} threads\")\n",
    "torch.set_default_device(device)\n",
    "\n",
    "#Defining the noise seed\n",
    "partition_seed = 4\n",
    "rng = torch.Generator(device=device)\n",
    "rng.manual_seed(partition_seed)\n",
    "\n",
    "#Optimizer learning rate\n",
    "learning_rate = 1e-3\n",
    "\n",
    "#Batch size \n",
    "batch_size = 32\n",
    "\n",
    "#Number of epochs \n",
    "n_epochs = 5\n",
    "\n",
    "#Define storage for losses\n",
    "train_losses = []\n",
    "eval_losses = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b3f486",
   "metadata": {},
   "source": [
    "# Fitting the training data with a basic deep neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79090012",
   "metadata": {},
   "source": [
    "## First step : Define a training, validation, and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78466da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data \n",
    "\n",
    "## Retrieving indices of data partitions\n",
    "train_idx, valid_idx, test_idx = torch.utils.data.random_split(range(N), data_partitions, generator=rng)\n",
    "\n",
    "## Generate the data partitions\n",
    "### Training\n",
    "train_inputs = torch.tensor(raw_inputs[train_idx], dtype=torch.float32)\n",
    "train_outputs_ST = torch.tensor(raw_outputs_ST[train_idx], dtype=torch.float32)\n",
    "### Validation\n",
    "valid_inputs = torch.tensor(raw_inputs[valid_idx], dtype=torch.float32)\n",
    "valid_outputs_ST = torch.tensor(raw_outputs_ST[valid_idx], dtype=torch.float32)\n",
    "### Testing\n",
    "test_inputs = torch.tensor(raw_inputs[test_idx], dtype=torch.float32)\n",
    "test_outputs_ST = torch.tensor(raw_outputs_ST[test_idx], dtype=torch.float32)\n",
    "\n",
    "##Generating data loaders\n",
    "train_dataloader = DataLoader(TensorDataset(train_inputs,train_outputs_ST), batch_size=batch_size, generator=rng, shuffle=True)\n",
    "eval_dataloader = DataLoader(TensorDataset(valid_inputs,valid_outputs_ST), batch_size=batch_size, generator=rng)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fa2735",
   "metadata": {},
   "source": [
    "## Second step : Define the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3491d4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDecoder(nn.Module):\n",
    "    def __init__(self, input_dim, output_channels):\n",
    "        super(ImageDecoder, self).__init__()\n",
    "        \n",
    "\n",
    "        # Project input parameters to a higher dimension\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 128 * 6 * 9)  # 6x9 feature maps with 128 channels\n",
    "        )\n",
    "\n",
    "        # Decoder layers - progressively upsample\n",
    "        self.decoder = nn.Sequential(\n",
    "            # Input: 128 x 6 x 9\n",
    "            nn.ConvTranspose2d(128, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # Output: 128 x 12 x 18\n",
    "            \n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # Output: 64 x 24 x 36\n",
    "            \n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # Output: 32 x 48 x 72\n",
    "            \n",
    "            # Fine-tune to exact dimensions (48x72 -> 46x72)\n",
    "            nn.Conv2d(32, 16, kernel_size=(3,3), stride=1, padding=(0,1)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # Output: 16 x 46 x 72\n",
    "            \n",
    "            nn.Conv2d(16, output_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Sigmoid()  # Output values between 0 and 1\n",
    "            # Output: output_channels x 46 x 72\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the decoder.\n",
    "        \n",
    "        Args:\n",
    "            x: Input tensor of shape (batch_size, input_dim)\n",
    "            \n",
    "        Returns:\n",
    "            Generated images of shape (batch_size, output_channels, 46, 72)\n",
    "        \"\"\"\n",
    "        # Project to higher dimension and reshape\n",
    "        x = self.fc(x)\n",
    "        x = x.view(-1, 128, 6, 9)  # Reshape to (batch, channels, height, width)\n",
    "        \n",
    "        # Decode to image\n",
    "        x = self.decoder(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa87254",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ImageDecoder(D, 1).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c607115",
   "metadata": {},
   "source": [
    "## Fourth step : Define optimization functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d568dc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Training loop ---\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.train()\n",
    "    total_loss=0\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss+=loss.item()\n",
    "        print(f\"Train loss: {loss.item():>7f}  [{batch * batch_size + len(X):>5d}/{size:>5d}]\")\n",
    "\n",
    "    #Store loss\n",
    "    train_losses.append(total_loss/len(dataloader))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- Evaluation loop ---\n",
    "def eval_loop(dataloader, model, loss_fn):\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "    num_batches = len(dataloader)\n",
    "    eval_loss = 0\n",
    "\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            eval_loss += loss_fn(pred, y).item()\n",
    "\n",
    "    #Store loss\n",
    "    eval_loss /= num_batches\n",
    "    eval_losses.append(eval_loss)\n",
    "    print(f\"Eval loss={eval_loss:.5f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd2d7f7",
   "metadata": {},
   "source": [
    "## Fifth step : Run optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1beb5d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Loss and optimizer ---\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "if run_mode == 'use':\n",
    "    # --- Optimization ---\n",
    "    for t in range(n_epochs):\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "        eval_loop(eval_dataloader, model, loss_fn)\n",
    "    print(\"Done!\")\n",
    "\n",
    "    #Save everything \n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'train_losses': train_losses,\n",
    "        'eval_losses': eval_losses\n",
    "    }, \n",
    "    model_save_path + f'{n_epochs}epochs_{learning_rate}LR_{batch_size}BS.pth')\n",
    "    \n",
    "\n",
    "else:\n",
    "    #Load model\n",
    "    dataload = torch.load(model_save_path + f'{n_epochs}epochs_{learning_rate}LR_{batch_size}BS.pth')\n",
    "\n",
    "    model.load_state_dict(dataload['model_state_dict'])\n",
    "    optimizer.load_state_dict(dataload['optimizer_state_dict'])\n",
    "    train_losses = dataload['train_losses']\n",
    "    eval_losses = dataload['eval_losses']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9276f73",
   "metadata": {},
   "source": [
    "## Sixth step : Diagnostic plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955237ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss curves\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, gridspec_kw={'height_ratios':[3, 1]}, figsize=(10, 6))\n",
    "ax1.plot(np.arange(n_epochs), train_losses, label=\"Train\")\n",
    "ax1.plot(np.arange(n_epochs), eval_losses, label=\"Validation\")\n",
    "ax2.plot(np.arange(n_epochs), np.array(train_losses) - np.array(eval_losses), label=\"Train\")\n",
    "ax1.set_yscale('log')\n",
    "# ax2.set_yscale('log')\n",
    "ax2.set_xlabel(\"Epoch\")\n",
    "ax1.set_ylabel(\"MSE Loss\")\n",
    "ax2.set_ylabel(\"Loss Diff.\")\n",
    "ax1.legend()\n",
    "ax1.grid()\n",
    "plt.subplots_adjust(hspace=0)\n",
    "plt.savefig(plot_save_path+'/loss.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febd876d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparing predicted T-P profiles vs true T-P profiles with residuals\n",
    "substep = 1000\n",
    "\n",
    "#Converting tensors to numpy arrays if this isn't already done\n",
    "if (type(test_outputs_ST) != np.ndarray):\n",
    "    test_outputs_ST = test_outputs_ST.numpy()\n",
    "\n",
    "res = np.zeros((N, 46, 72), dtype=float)\n",
    "for test_idx, (test_input, test_output_ST) in enumerate(zip(test_inputs, test_outputs_ST)):\n",
    "    \n",
    "    #Retrieve prediction\n",
    "    pred_output = model(test_input).detach().numpy()[0][0]\n",
    "    test_output = test_output_ST[0]\n",
    "\n",
    "    #Convert to numpy\n",
    "    test_input = test_input.numpy()\n",
    "\n",
    "    #Storing residuals \n",
    "    res[test_idx, :] = pred_output - test_output\n",
    "\n",
    "    #Plotting\n",
    "    if (test_idx % substep == 0):\n",
    "        fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(8, 6), layout='constrained')        \n",
    "        ax1.imshow(test_output, cmap='viridis')\n",
    "        ax2.imshow(pred_output, cmap='viridis')\n",
    "        ax3.imshow(res[test_idx, :], cmap='viridis')\n",
    "        plt.suptitle(rf'H$_2$ : {test_input[0]} bar, CO$_2$ : {test_input[1]} bar, LoD : {test_input[2]:.0f} days, Obliquity : {test_input[3]} deg')\n",
    "        plt.savefig(plot_save_path+f'/pred_vs_actual_n.{test_idx}.pdf')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3c02e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Temperature Residuals : Median = {np.median(res_T):.2f} K, Std = {np.std(res_T):.2f} K')\n",
    "print(rf'Pressure Residuals : Median = {np.median(res_P):.9} $log_{10}$ bar, Std = {np.std(res_P):.9} $log_{10}$ bar')\n",
    "\n",
    "#Plot residuals\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=[10, 6])\n",
    "ax1.plot(res_T, alpha=0.1, color='green')\n",
    "ax2.plot(res_P, alpha=0.1, color='green')\n",
    "for ax in [ax1, ax2]:ax.axhline(0, color='black', linestyle='dashed')\n",
    "ax1.set_xlabel('Index')\n",
    "ax1.set_ylabel('Temperature')\n",
    "ax2.set_ylabel('log$_{10}$ Pressure (bar)')\n",
    "ax2.set_yscale('log')\n",
    "for ax in [ax1, ax2]:ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29449ead",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
