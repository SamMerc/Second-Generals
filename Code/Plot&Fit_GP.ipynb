{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee5a7ebf",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c0b871",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import celerite2\n",
    "from celerite2 import terms\n",
    "import torch\n",
    "import os\n",
    "import scipy\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0073caf",
   "metadata": {},
   "source": [
    "# Import raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe717a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining function to check if directory exists, if not it generates it\n",
    "def check_and_make_dir(dir):\n",
    "    if not os.path.isdir(dir):os.mkdir(dir)\n",
    "#Base directory \n",
    "base_dir = '/Users/samsonmercier/Desktop/Work/PhD/Research/Second_Generals/'\n",
    "#File containing temperature values\n",
    "raw_T_data = np.loadtxt(base_dir+'Data/bt-4500k/training_data_T.csv', delimiter=',')\n",
    "#File containing pressure values\n",
    "raw_P_data = np.loadtxt(base_dir+'Data/bt-4500k/training_data_P.csv', delimiter=',')\n",
    "#File containing surface temperature map\n",
    "raw_ST_data = np.loadtxt(base_dir+'Data/bt-4500k/training_data_ST2D.csv', delimiter=',')\n",
    "#Path to store model\n",
    "model_save_path = base_dir+'Model_Storage/GP_full/'\n",
    "check_and_make_dir(model_save_path)\n",
    "#Path to store plots\n",
    "plot_save_path = base_dir+'Plots/GP_full/'\n",
    "check_and_make_dir(plot_save_path)\n",
    "\n",
    "#Last 51 columns are the temperature/pressure values, \n",
    "#First 5 are the input values (H2 pressure in bar, CO2 pressure in bar, LoD in hours, Obliquity in deg, H2+Co2 pressure) but we remove the last one since it's not adding info.\n",
    "raw_inputs = raw_T_data[:, :4]\n",
    "raw_outputs_T = raw_T_data[:, 5:]\n",
    "raw_outputs_P = raw_P_data[:, 5:]\n",
    "raw_outputs_ST = raw_ST_data[:, 5:]\n",
    "\n",
    "#Storing useful quantitites\n",
    "N = raw_inputs.shape[0] #Number of data points\n",
    "D = raw_inputs.shape[1] #Number of features\n",
    "O_TP = raw_outputs_T.shape[1] #Number of outputs for T-P profile\n",
    "O_ST = raw_outputs_ST.shape[1] #Number of outputs for surface temperature map\n",
    "\n",
    "## HYPER-PARAMETERS ##\n",
    "#Defining partition of data used for 1. training and 2. testing\n",
    "data_partition = [0.8, 0.2]\n",
    "\n",
    "#Defining the device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_threads = 6\n",
    "torch.set_num_threads(num_threads)\n",
    "print(f\"Using {device} device with {num_threads} threads\")\n",
    "torch.set_default_device(device)\n",
    "\n",
    "#Defining the noise seed for the random partitioning of the training data\n",
    "partition_seed = 4\n",
    "rng = torch.Generator(device=device)\n",
    "rng.manual_seed(partition_seed)\n",
    "\n",
    "# Variable to show plots or not \n",
    "show_plot = True\n",
    "\n",
    "#Number of nearest neighbors to choose\n",
    "N_neigbors = 500\n",
    "\n",
    "#Neural network width and depth\n",
    "nn_width = 3414\n",
    "nn_depth = 5\n",
    "\n",
    "#Optimizer learning rate\n",
    "learning_rate = 1e-5\n",
    "\n",
    "#Batch size \n",
    "batch_size = 64\n",
    "\n",
    "#Number of epochs \n",
    "n_epochs = 100\n",
    "\n",
    "#Define storage for losses\n",
    "train_losses = []\n",
    "eval_losses = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91916a9",
   "metadata": {},
   "source": [
    "# Plotting of the T-P profiles and corresponding surface temperature map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74b0ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for raw_input, raw_output_T, raw_output_P, raw_output_ST in zip(raw_inputs,raw_outputs_T,raw_outputs_P,raw_outputs_ST):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=[12, 6], gridspec_kw={'width_ratios':[1, 3]})\n",
    "    \n",
    "    ax1.plot(raw_output_T, np.log(raw_output_P/1000), color='blue', linewidth=2)\n",
    "    ax1.invert_yaxis()\n",
    "    ax1.set_xlabel('Temperature (K)')\n",
    "    ax1.set_ylabel(r'log$_{10}$ Pressure (bar)')\n",
    "\n",
    "    hm = sns.heatmap(raw_output_ST.reshape((46, 72)), ax=ax2)\n",
    "    cbar = hm.collections[0].colorbar\n",
    "    cbar.set_label('Temperature (K)')\n",
    "\n",
    "    # Fix longitude ticks\n",
    "    ax2.set_xticks(np.linspace(0, 72, 5))\n",
    "    ax2.set_xticklabels(np.linspace(-180, 180, 5).astype(int))\n",
    "\n",
    "    # Fix latitude ticks\n",
    "    ax2.set_yticks(np.linspace(0, 46, 5))\n",
    "    ax2.set_yticklabels(np.linspace(-90, 90, 5).astype(int))\n",
    "\n",
    "    ax2.set_xlabel('Longitude (degrees)')\n",
    "    ax2.set_ylabel('Latitude (degrees)')\n",
    "\n",
    "    plt.suptitle(rf'H$_2$ : {raw_input[0]} bar, CO$_2$ : {raw_input[1]} bar, LoD : {raw_input[2]:.0f} days, Obliquity : {raw_input[3]} deg')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411d210a",
   "metadata": {},
   "source": [
    "# Fitting data with a Gaussian Process (celerite) - trying it out on one T-P profile (Can't be generalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c057da",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 4\n",
    "\n",
    "#Plot the T-P profile we want to look at\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=[8, 6], gridspec_kw={'height_ratios':[3,1]})\n",
    "ax1.plot(np.log(raw_outputs_P[4]/1000), raw_outputs_T[4], '.', color='blue', linewidth=2, label='Data')\n",
    "ax1.invert_yaxis()\n",
    "ax1.set_ylabel('Temperature (K)')\n",
    "ax2.set_ylabel('Residuals')\n",
    "ax2.set_xlabel(r'log$_{10}$ Pressure (bar)')\n",
    "ax1.set_title(rf'H$_2$O : {raw_inputs[key][0]} bar, CO$_2$ : {raw_inputs[key][1]} bar, LoD : {raw_inputs[key][2]:.0f} days, Obliquity : {raw_inputs[key][3]} deg')\n",
    "\n",
    "#GP\n",
    "#Defining a quasi-periodic term\n",
    "term1 = terms.SHOTerm(sigma=1.0, rho=1.0, tau=10.0)\n",
    "\n",
    "#Defining a non-periodic term\n",
    "term2 = terms.SHOTerm(sigma=1.0, rho=5.0, Q=0.25)\n",
    "kernel = term1 + term2\n",
    "\n",
    "# Setup the GP\n",
    "gp = celerite2.GaussianProcess(kernel, mean=0.0)\n",
    "gp.compute(np.log(raw_outputs_P[4]/1000))\n",
    "\n",
    "#Plot resulting GP fit\n",
    "pred_T, variance = gp.predict(raw_outputs_T[4], t=np.log(raw_outputs_P[4]/1000), return_var=True)\n",
    "sigma = np.sqrt(variance)\n",
    "ax1.plot(np.log(raw_outputs_P[4]/1000), pred_T, label='initial guess')\n",
    "ax1.fill_between(np.log(raw_outputs_P[4]/1000), pred_T - sigma, pred_T + sigma, color=\"C0\", alpha=0.2)\n",
    "ax2.plot(np.log(raw_outputs_P[4]/1000), raw_outputs_T[4]-pred_T)\n",
    "ax2.axhline(0, color='black', linestyle='--')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d894c0",
   "metadata": {},
   "source": [
    "# Fitting data with an Ensemble Conditional GP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad32a1a",
   "metadata": {},
   "source": [
    "## First step : partition data into a training set, and a testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b6afd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieving indices of data partitions\n",
    "train_idx, test_idx = torch.utils.data.random_split(range(N), data_partition, generator=rng)\n",
    "## Generate the data partitions\n",
    "### Training\n",
    "train_inputs = raw_inputs[train_idx]\n",
    "train_outputs_T = raw_outputs_T[train_idx]\n",
    "train_outputs_P = raw_outputs_P[train_idx]\n",
    "train_outputs_ST = raw_outputs_ST[train_idx]\n",
    "\n",
    "### Testing\n",
    "test_inputs = raw_inputs[test_idx]\n",
    "test_outputs_T = raw_outputs_T[test_idx]\n",
    "test_outputs_P = raw_outputs_P[test_idx]\n",
    "test_outputs_ST = raw_outputs_ST[train_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31f11a3",
   "metadata": {},
   "source": [
    "## Second step : Building Sai's Conditional GP function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8ccf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sai_CGP(obs_features, obs_labels, query_features):\n",
    "    \"\"\"\n",
    "    Conditional Gaussian Process\n",
    "    Inputs: \n",
    "        obs_features : ndarray (D, N)\n",
    "            D-dimensional features of the N observation data points.\n",
    "        obs_labels : ndarray (K, N)\n",
    "            K-dimensional labels of the N observation data points.\n",
    "        query_features : ndarray (D, 1)\n",
    "            D-dimensional features of the query data point.\n",
    "    Outputs:\n",
    "        query_labels : ndarray (K, 1)\n",
    "            K-dimensional labels of the query data point.\n",
    "\n",
    "    \"\"\"\n",
    "    # Defining relevant means\n",
    "    mean_obs_labels = np.mean(obs_labels, axis=1, keepdims=True)\n",
    "    mean_obs_features = np.mean(obs_features, axis=1, keepdims=True)\n",
    "    \n",
    "    # Defining relevant covariance matrices\n",
    "    ## Between feature and label of observation data\n",
    "    Cyx = (obs_labels @ obs_features.T) / (obs_features.shape[0] - 1)\n",
    "    ## Between label and feature of observation data\n",
    "    Cxy = (obs_features @ obs_labels.T) / (obs_features.shape[0] - 1)\n",
    "    ## Between feature and feature of observation data\n",
    "    Cxx = (obs_features @ obs_features.T) / (obs_features.shape[0] - 1)\n",
    "    ## Between label and label of observation data\n",
    "    Cyy = (obs_labels @ obs_labels.T) / (obs_features.shape[0] - 1)\n",
    "    ## Adding regularizer to avoid singularities\n",
    "    Cxx += 1e-8 * np.eye(Cxx.shape[0]) \n",
    "\n",
    "    query_mean_labels = mean_obs_labels + (Cyx @ scipy.linalg.inv(Cxx) @ (query_features - mean_obs_features))\n",
    "\n",
    "    query_cov_labels = Cyy - Cyx @ scipy.linalg.inv(Cxx) @ Cxy\n",
    "\n",
    "    return query_mean_labels, query_cov_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e19df2",
   "metadata": {},
   "source": [
    "## Third step : Going through test set (query points), find observations in proximity, and use them to get guess labels for query point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65772b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize array to store residuals\n",
    "res_T = np.zeros(test_outputs_T.shape, dtype=float)\n",
    "res_P = np.zeros(test_outputs_P.shape, dtype=float)\n",
    "res_ST = np.zeros(test_outputs_ST.shape, dtype=float)\n",
    "\n",
    "for query_idx, (test_input, test_output_T, test_output_P, test_output_ST) in enumerate(zip(test_inputs, test_outputs_T, test_outputs_P, test_outputs_ST)):\n",
    "\n",
    "    #Calculate proximity of query point to observations\n",
    "    distances = np.sqrt( (test_input[0] - train_inputs[:,0])**2 + (test_input[1] - train_inputs[:,1])**2 + (test_input[2] - train_inputs[:,2])**2 + (test_input[3] - train_inputs[:,3])**2 )\n",
    "\n",
    "    #Choose the N closest points\n",
    "    N_closest_idx = np.argsort(distances)[:N_neigbors]\n",
    "    prox_train_inputs = train_inputs[N_closest_idx, :]\n",
    "    prox_train_outputs_T = train_outputs_T[N_closest_idx, :]\n",
    "    prox_train_outputs_P = train_outputs_P[N_closest_idx, :]\n",
    "    prox_train_outputs_ST = train_outputs_ST[N_closest_idx, :]\n",
    "    \n",
    "    #Find the query labels from nearest neigbours\n",
    "    mean_test_output, cov_test_output = Sai_CGP(prox_train_inputs.T, np.concat((prox_train_outputs_T, np.log10(prox_train_outputs_P/1000), prox_train_outputs_ST), axis=1).T, test_input.reshape((1, 4)).T)\n",
    "    \n",
    "    #Get model outputs\n",
    "    model_test_output_T = mean_test_output[:O_TP,0] \n",
    "    model_test_output_P = mean_test_output[O_TP:2*O_TP,0] \n",
    "    model_test_output_ST = mean_test_output[2*O_TP:,0] \n",
    "\n",
    "    #Get model output errors\n",
    "    model_test_output_Terr = np.sqrt(np.diag(cov_test_output))[:O_TP]\n",
    "    model_test_output_Perr = np.sqrt(np.diag(cov_test_output))[O_TP:2*O_TP]\n",
    "    model_test_output_STerr = np.sqrt(np.diag(cov_test_output))[2*O_TP:]\n",
    "\n",
    "    #Get residuals\n",
    "    res_T[query_idx, :] = model_test_output_T - test_output_T\n",
    "    res_P[query_idx, :] = model_test_output_P - np.log10(test_output_P/1000)\n",
    "    res_ST[query_idx, :] = model_test_output_ST - test_output_ST\n",
    "\n",
    "    #Diagnostic plot\n",
    "    if show_plot:\n",
    "\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.imshow(cov_test_output, cmap='coolwarm', origin='lower')\n",
    "        plt.colorbar(label='Covariance')\n",
    "        plt.title('Joint Covariance Matrix of [T | P | ST]')\n",
    "        plt.xlabel('Output index')\n",
    "        plt.ylabel('Output index')\n",
    "        plt.show()\n",
    "\n",
    "        #Plot TP profiles\n",
    "        fig, axs = plt.subplot_mosaic([['res_pressure', '.'],\n",
    "                                       ['results', 'res_temperature']],\n",
    "                              figsize=(8, 6),\n",
    "                              width_ratios=(3, 1), height_ratios=(1, 3),\n",
    "                              layout='constrained')\n",
    "        for prox_idx in range(N_neigbors):\n",
    "            axs['results'].plot(prox_train_outputs_T[prox_idx], np.log10(prox_train_outputs_P[prox_idx]/1000), '.', linestyle='-', color='red', alpha=0.1, linewidth=2, zorder=1, label='Ensemble' if prox_idx==0 else None)\n",
    "        axs['results'].plot(model_test_output_T, model_test_output_P, '.', linestyle='-', color='green', linewidth=2, markersize=10, zorder=2, label='Prediction')\n",
    "        axs['results'].errorbar(model_test_output_T, model_test_output_P, xerr=model_test_output_Terr, yerr=model_test_output_Perr, fmt='.', linestyle='-', color='green', linewidth=2, zorder=2, alpha=0.5, markersize=10)\n",
    "        axs['results'].plot(test_output_T, np.log10(test_output_P/1000), '.', linestyle='-', color='blue', linewidth=2, zorder=2, markersize=10, label='Truth')\n",
    "        axs['results'].invert_yaxis()\n",
    "        axs['results'].set_ylabel(r'log$_{10}$ Pressure (bar)')\n",
    "        axs['results'].set_xlabel('Temperature (K)')\n",
    "        axs['results'].grid()\n",
    "        axs['results'].legend()        \n",
    "        \n",
    "        axs['res_temperature'].fill_betweenx(np.log10(test_output_P/1000), res_T[query_idx, :] - model_test_output_Terr, res_T[query_idx, :] + model_test_output_Terr, color='green', alpha=0.4)\n",
    "        axs['res_temperature'].plot(res_T[query_idx, :], np.log10(test_output_P/1000), '.', linestyle='-', color='green', linewidth=2)\n",
    "        axs['res_temperature'].axvline(0, color='black', linestyle='dashed', zorder=2)\n",
    "        axs['res_temperature'].invert_yaxis()\n",
    "        axs['res_temperature'].set_xlabel('Residuals (K)')\n",
    "        axs['res_temperature'].yaxis.tick_right()\n",
    "        axs['res_temperature'].yaxis.set_label_position(\"right\")\n",
    "        axs['res_temperature'].grid()\n",
    "\n",
    "        axs['res_pressure'].fill_between(test_output_T, res_P[query_idx, :] - model_test_output_Perr, res_P[query_idx, :] + model_test_output_Perr, color='green', alpha=0.4)\n",
    "        axs['res_pressure'].axhline(0, color='black', linestyle='dashed', zorder=2)\n",
    "        axs['res_pressure'].invert_yaxis()\n",
    "        axs['res_pressure'].set_ylabel('Residuals (bar)')\n",
    "        axs['res_pressure'].xaxis.tick_top()\n",
    "        axs['res_pressure'].xaxis.set_label_position(\"top\")\n",
    "        axs['res_pressure'].grid()\n",
    "\n",
    "        plt.suptitle(rf'H$_2$ : {test_input[0]} bar, CO$_2$ : {test_input[1]} bar, LoD : {test_input[2]:.0f} days, Obliquity : {test_input[3]} deg')\n",
    "        plt.subplots_adjust(hspace=0, wspace=0)\n",
    "        plt.show()\n",
    "\n",
    "        #Convert shape\n",
    "        plot_test_output_ST = test_output_ST.reshape((46, 72))\n",
    "        plot_model_test_output_ST = model_test_output_ST.reshape((46, 72))\n",
    "        plot_res = res_ST[query_idx, :].reshape((46, 72))\n",
    "        \n",
    "        #Plot ST map\n",
    "        fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(8, 8), sharex=True, layout='constrained')        \n",
    "        # Compute global vmin/vmax across all datasets\n",
    "        vmin = np.min(test_output_ST)\n",
    "        vmax = np.max(test_output_ST)\n",
    "        # Plot heatmaps\n",
    "        ax1.set_title('Data')\n",
    "        hm1 = sns.heatmap(plot_test_output_ST, ax=ax1)#, cbar=False, vmin=vmin, vmax=vmax)\n",
    "        cbar = hm1.collections[0].colorbar\n",
    "        cbar.set_label('Temperature (K)')\n",
    "        ax2.set_title('Model')\n",
    "        hm2 = sns.heatmap(plot_model_test_output_ST, ax=ax2)#, cbar=False, vmin=vmin, vmax=vmax)\n",
    "        cbar = hm2.collections[0].colorbar\n",
    "        cbar.set_label('Temperature (K)')\n",
    "        ax3.set_title('Residuals')\n",
    "        hm3 = sns.heatmap(plot_res, ax=ax3)#, cbar=False, vmin=vmin, vmax=vmax)\n",
    "        cbar = hm3.collections[0].colorbar\n",
    "        cbar.set_label('Temperature (K)')\n",
    "        # Shared colorbar (use the last heatmap's mappable)\n",
    "        # cbar = fig.colorbar(hm3.get_children()[0], ax=[ax1, ax2, ax3], location='right')\n",
    "        # cbar.set_label(\"Temperature\")\n",
    "        # Fix longitude ticks\n",
    "        ax3.set_xticks(np.linspace(0, 72, 5))\n",
    "        ax3.set_xticklabels(np.linspace(-180, 180, 5).astype(int))\n",
    "        ax3.set_xlabel('Longitude (degrees)')\n",
    "        # Fix latitude ticks\n",
    "        for ax in [ax1, ax2, ax3]:\n",
    "            ax.set_yticks(np.linspace(0, 46, 5))\n",
    "            ax.set_yticklabels(np.linspace(-90, 90, 5).astype(int))\n",
    "            ax.set_ylabel('Latitude (degrees)')\n",
    "        plt.suptitle(rf'H$_2$O : {test_input[0]} bar, CO$_2$ : {test_input[1]} bar, LoD : {test_input[2]:.0f} days, Obliquity : {test_input[3]} deg')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad7ea03",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Temperature Residuals : Median = {np.median(res_T):.2f} K, Std = {np.std(res_T):.2f} K')\n",
    "print(rf'Pressure Residuals : Median = {np.median(res_P):.9} $log_{10}$ bar, Std = {np.std(res_P):.9} $log_{10}$ bar')\n",
    "\n",
    "#Plot residuals\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=[10, 6])\n",
    "ax1.plot(res_T.T, alpha=0.1, color='green')\n",
    "ax2.plot(res_P.T, alpha=0.1, color='green')\n",
    "for ax in [ax1, ax2]:ax.axhline(0, color='black', linestyle='dashed')\n",
    "ax2.set_xlabel('Index')\n",
    "ax1.set_ylabel('Temperature')\n",
    "ax2.set_ylabel('log$_{10}$ Pressure (bar)')\n",
    "for ax in [ax1, ax2]:ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987bc504",
   "metadata": {},
   "source": [
    "# Build an Encoder-Decoder Neural Network "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
